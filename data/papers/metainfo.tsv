group	title	authors	abstract	categories	author comment
1	Symmetries and anomalies of Kitaev spin-$S$ models	Ruizhi Liu,Ho Tat Lam,Han Ma,Liujun Zou	We analyze the internal symmetries and their anomalies in the Kitaev spin-$S$ models. Importantly, these models have a lattice version of a $\mathbb{Z}_2$ 1-form symmetry, denoted by $\mathbb{Z}_2^{[1]}$. There is also an ordinary 0-form $\mathbb{Z}_2^{(x)}\times\mathbb{Z}_2^{(y)}\times\mathbb{Z}_2^T$ symmetry, where $\mathbb{Z}_2^{(x)}\times\mathbb{Z}_2^{(y)}$ are $\pi$ spin rotations around two orthogonal axes, and $\mathbb{Z}_2^T$ is the time reversal symmetry. The anomalies associated with the full $\mathbb{Z}_2^{(x)}\times\mathbb{Z}_2^{(y)}\times\mathbb{Z}_2^T\times\mathbb{Z}_2^{[1]}$ symmetry are classified by $\mathbb{Z}_2^{17}$. We find that for $S\in\mathbb{Z}$ the model is anomaly-free, while for $S\in\mathbb{Z}+\frac{1}{2}$ there is an anomaly purely associated with the 1-form symmetry, but there is no anomaly purely associated with the ordinary symmetry or mixed anomaly between the 0-form and 1-form symmetries. The consequences of these anomalies apply to not only the Kitaev spin-$S$ models, but also any of their perturbed versions, assuming that the perturbations are local and respect the symmetries. If these local perturbations are weak, these consequences apply even if the perturbations break the 1-form symmetry. A notable consequence is that there must be a deconfined fermionic excitation carrying no fractional quantum number under the $\mathbb{Z}_2^{(x)}\times\mathbb{Z}_2^{(y)}\times\mathbb{Z}_2^T$ symmetry if $S\in\mathbb{Z}+\frac{1}{2}$.	cond-mat.str-el	4.5 pages + supplemental materials
2	SparseDFF: Sparse-View Feature Distillation for One-Shot Dexterous Manipulation	Qianxu Wang,Haotong Zhang,Congyue Deng,Yang You,Hao Dong,Yixin Zhu,Leonidas Guibas	Humans excel at transferring manipulation skills across diverse object shapes, poses, and appearances due to their understanding of semantic correspondences between different instances. To endow robots with a similar high-level understanding, we develop a Distilled Feature Field (DFF) for 3D scenes, leveraging large 2D vision models to distill semantic features from multiview images. While current research demonstrates advanced performance in reconstructing DFFs from dense views, the development of learning a DFF from sparse views is relatively nascent, despite its prevalence in numerous manipulation tasks with fixed cameras. In this work, we introduce SparseDFF, a novel method for acquiring view-consistent 3D DFFs from sparse RGBD observations, enabling one-shot learning of dexterous manipulations that are transferable to novel scenes. Specifically, we map the image features to the 3D point cloud, allowing for propagation across the 3D space to establish a dense feature field. At the core of SparseDFF is a lightweight feature refinement network, optimized with a contrastive loss between pairwise views after back-projecting the image features onto the 3D point cloud. Additionally, we implement a point-pruning mechanism to augment feature continuity within each local neighborhood. By establishing coherent feature fields on both source and target scenes, we devise an energy function that facilitates the minimization of feature discrepancies w.r.t. the end-effector parameters between the demonstration and the target manipulation. We evaluate our approach using a dexterous hand, mastering real-world manipulations on both rigid and deformable objects, and showcase robust generalization in the face of object and scene-context variations.	cs.RO	None
3	LLM-FP4: 4-Bit Floating-Point Quantized Transformers	Shih-yang Liu,Zechun Liu,Xijie Huang,Pingcheng Dong,Kwang-Ting Cheng	We propose LLM-FP4 for quantizing both weights and activations in large language models (LLMs) down to 4-bit floating-point values, in a post-training manner. Existing post-training quantization (PTQ) solutions are primarily integer-based and struggle with bit widths below 8 bits. Compared to integer quantization, floating-point (FP) quantization is more flexible and can better handle long-tail or bell-shaped distributions, and it has emerged as a default choice in many hardware platforms. One characteristic of FP quantization is that its performance largely depends on the choice of exponent bits and clipping range. In this regard, we construct a strong FP-PTQ baseline by searching for the optimal quantization parameters. Furthermore, we observe a high inter-channel variance and low intra-channel variance pattern in activation distributions, which adds activation quantization difficulty. We recognize this pattern to be consistent across a spectrum of transformer models designed for diverse tasks, such as LLMs, BERT, and Vision Transformer models. To tackle this, we propose per-channel activation quantization and show that these additional scaling factors can be reparameterized as exponential biases of weights, incurring a negligible cost. Our method, for the first time, can quantize both weights and activations in the LLaMA-13B to only 4-bit and achieves an average score of 63.1 on the common sense zero-shot reasoning tasks, which is only 5.8 lower than the full-precision model, significantly outperforming the previous state-of-the-art by 12.7 points. Code is available at: https://github.com/nbasyl/LLM-FP4.	cs.CL	EMNLP 2023 Main Conference
4	Proposal-Contrastive Pretraining for Object Detection from Fewer Data	Quentin Bouniot,Romaric Audigier,Ang√©lique Loesch,Amaury Habrard	The use of pretrained deep neural networks represents an attractive way to achieve strong results with few data available. When specialized in dense problems such as object detection, learning local rather than global information in images has proven to be more efficient. However, for unsupervised pretraining, the popular contrastive learning requires a large batch size and, therefore, a lot of resources. To address this problem, we are interested in transformer-based object detectors that have recently gained traction in the community with good performance and with the particularity of generating many diverse object proposals.   In this work, we present Proposal Selection Contrast (ProSeCo), a novel unsupervised overall pretraining approach that leverages this property. ProSeCo uses the large number of object proposals generated by the detector for contrastive learning, which allows the use of a smaller batch size, combined with object-level features to learn local information in the images. To improve the effectiveness of the contrastive loss, we introduce the object location information in the selection of positive examples to take into account multiple overlapping object proposals. When reusing pretrained backbone, we advocate for consistency in learning local information between the backbone and the detection head.   We show that our method outperforms state of the art in unsupervised pretraining for object detection on standard and novel benchmarks in learning with fewer data.	cs.CV	Published as a conference paper at ICLR 2023
5	Discrete Diffusion Language Modeling by Estimating the Ratios of the Data Distribution	Aaron Lou,Chenlin Meng,Stefano Ermon	Despite their groundbreaking performance for many generative modeling tasks, diffusion models have fallen short on discrete data domains such as natural language. Crucially, standard diffusion models rely on the well-established theory of score matching, but efforts to generalize this to discrete structures have not yielded the same empirical gains. In this work, we bridge this gap by proposing score entropy, a novel discrete score matching loss that is more stable than existing methods, forms an ELBO for maximum likelihood training, and can be efficiently optimized with a denoising variant. We scale our Score Entropy Discrete Diffusion models (SEDD) to the experimental setting of GPT-2, achieving highly competitive likelihoods while also introducing distinct algorithmic advantages. In particular, when comparing similarly sized SEDD and GPT-2 models, SEDD attains comparable perplexities (normally within $+10\%$ of and sometimes outperforming the baseline). Furthermore, SEDD models learn a more faithful sequence distribution (around $4\times$ better compared to GPT-2 models with ancestral sampling as measured by large models), can trade off compute for generation quality (needing only $16\times$ fewer network evaluations to match GPT-2), and enables arbitrary infilling beyond the standard left to right prompting.	stat.ML	30 pages
6	PERF: Panoramic Neural Radiance Field from a Single Panorama	Guangcong Wang,Peng Wang,Zhaoxi Chen,Wenping Wang,Chen Change Loy,Ziwei Liu	Neural Radiance Field (NeRF) has achieved substantial progress in novel view synthesis given multi-view images. Recently, some works have attempted to train a NeRF from a single image with 3D priors. They mainly focus on a limited field of view and there are few invisible occlusions, which greatly limits their scalability to real-world 360-degree panoramic scenarios with large-size occlusions. In this paper, we present PERF, a 360-degree novel view synthesis framework that trains a panoramic neural radiance field from a single panorama. Notably, PERF allows 3D roaming in a complex scene without expensive and tedious image collection. To achieve this goal, we propose a novel collaborative RGBD inpainting method and a progressive inpainting-and-erasing method to lift up a 360-degree 2D scene to a 3D scene. Specifically, we first predict a panoramic depth map as initialization given a single panorama, and reconstruct visible 3D regions with volume rendering. Then we introduce a collaborative RGBD inpainting approach into a NeRF for completing RGB images and depth maps from random views, which is derived from an RGB Stable Diffusion model and a monocular depth estimator. Finally, we introduce an inpainting-and-erasing strategy to avoid inconsistent geometry between a newly-sampled view and reference views. The two components are integrated into the learning of NeRFs in a unified optimization framework and achieve promising results. Extensive experiments on Replica and a new dataset PERF-in-the-wild demonstrate the superiority of our PERF over state-of-the-art methods. Our PERF can be widely used for real-world applications, such as panorama-to-3D, text-to-3D, and 3D scene stylization applications. Project page and code are available at https://perf-project.github.io/.	cs.CV	Project page and code: https://perf-project.github.io/
7	TD-MPC2: Scalable, Robust World Models for Continuous Control	Nicklas Hansen,Hao Su,Xiaolong Wang	TD-MPC is a model-based reinforcement learning (RL) algorithm that performs local trajectory optimization in the latent space of a learned implicit (decoder-free) world model. In this work, we present TD-MPC2: a series of improvements upon the TD-MPC algorithm. We demonstrate that TD-MPC2 improves significantly over baselines across 104 online RL tasks spanning 4 diverse task domains, achieving consistently strong results with a single set of hyperparameters. We further show that agent capabilities increase with model and data size, and successfully train a single 317M parameter agent to perform 80 tasks across multiple task domains, embodiments, and action spaces. We conclude with an account of lessons, opportunities, and risks associated with large TD-MPC2 agents. Explore videos, models, data, code, and more at https://nicklashansen.github.io/td-mpc2	cs.LG	Explore videos, models, data, code, and more at   https://nicklashansen.github.io/td-mpc2
8	Robust Sparsification for Matroid Intersection with Applications	Chien-Chung Huang,Fran√ßois Sellier	"Matroid intersection is a classical optimization problem where, given two matroids over the same ground set, the goal is to find the largest common independent set. In this paper, we show that there exists a certain ""sparsifer"": a subset of elements, of size $O(|S^{opt}| \cdot 1/\varepsilon)$, where $S^{opt}$ denotes the optimal solution, that is guaranteed to contain a $3/2 + \varepsilon$ approximation, while guaranteeing certain robustness properties. We call such a small subset a Density Constrained Subset (DCS), which is inspired by the Edge-Degree Constrained Subgraph (EDCS) [Bernstein and Stein, 2015], originally designed for the maximum cardinality matching problem in a graph. Our proof is constructive and hinges on a greedy decomposition of matroids, which we call the density-based decomposition. We show that this sparsifier has certain robustness properties that can be used in one-way communication and random-order streaming models."	cs.DS	None
9	Deep machine learning for meteor monitoring: advances with transfer learning and gradient-weighted class activation mapping	Eloy Pe√±a-Asensio,Josep M. Trigo-Rodr√≠guez,Pau Gr√®bol-Tom√†s,David Regordosa-Avellana,Albert Rimola	In recent decades, the use of optical detection systems for meteor studies has increased dramatically, resulting in huge amounts of data being analyzed. Automated meteor detection tools are essential for studying the continuous meteoroid incoming flux, recovering fresh meteorites, and achieving a better understanding of our Solar System. Concerning meteor detection, distinguishing false positives between meteor and non-meteor images has traditionally been performed by hand, which is significantly time-consuming. To address this issue, we developed a fully automated pipeline that uses Convolutional Neural Networks (CNNs) to classify candidate meteor detections. Our new method is able to detect meteors even in images that contain static elements such as clouds, the Moon, and buildings. To accurately locate the meteor within each frame, we employ the Gradient-weighted Class Activation Mapping (Grad-CAM) technique. This method facilitates the identification of the region of interest by multiplying the activations from the last convolutional layer with the average of the gradients across the feature map of that layer. By combining these findings with the activation map derived from the first convolutional layer, we effectively pinpoint the most probable pixel location of the meteor. We trained and evaluated our model on a large dataset collected by the Spanish Meteor Network (SPMN) and achieved a precision of 98\%. Our new methodology presented here has the potential to reduce the workload of meteor scientists and station operators and improve the accuracy of meteor tracking and classification.	astro-ph.EP	Accepted in Planetary and Space Science
0	CommonCanvas: An Open Diffusion Model Trained with Creative-Commons Images	Aaron Gokaslan,A. Feder Cooper,Jasmine Collins,Landan Seguin,Austin Jacobson,Mihir Patel,Jonathan Frankle,Cory Stephenson,Volodymyr Kuleshov	We assemble a dataset of Creative-Commons-licensed (CC) images, which we use to train a set of open diffusion models that are qualitatively competitive with Stable Diffusion 2 (SD2). This task presents two challenges: (1) high-resolution CC images lack the captions necessary to train text-to-image generative models; (2) CC images are relatively scarce. In turn, to address these challenges, we use an intuitive transfer learning technique to produce a set of high-quality synthetic captions paired with curated CC images. We then develop a data- and compute-efficient training recipe that requires as little as 3% of the LAION-2B data needed to train existing SD2 models, but obtains comparable quality. These results indicate that we have a sufficient number of CC images (~70 million) for training high-quality models. Our training recipe also implements a variety of optimizations that achieve ~3X training speed-ups, enabling rapid model iteration. We leverage this recipe to train several high-quality text-to-image models, which we dub the CommonCanvas family. Our largest model achieves comparable performance to SD2 on a human evaluation, despite being trained on our CC dataset that is significantly smaller than LAION and using synthetic captions for training. We release our models, data, and code at https://github.com/mosaicml/diffusion/blob/main/assets/common-canvas.md	cs.CV	None
1	Parametric model for post-processing visibility ensemble forecasts	√Ågnes Baran,S√°ndor Baran	Despite the continuous development of the different operational ensemble prediction systems over the past decades, ensemble forecasts still might suffer from lack of calibration and/or display systematic bias, thus require some post-processing to improve their forecast skill. Here we focus on visibility, which quantity plays a crucial role e.g. in aviation and road safety or in ship navigation, and propose a parametric model where the predictive distribution is a mixture of a gamma and a truncated normal distribution, both right censored at the maximal reported visibility value. The new model is evaluated in two case studies based on visibility ensemble forecasts of the European Centre for Medium-Range Weather Forecasts covering two distinct domains in Central and Western Europe and two different time periods. The results of the case studies indicate that climatology is substantially superior to the raw ensemble; nevertheless, the forecast skill can be further improved by post-processing, at least for short lead times. Moreover, the proposed mixture model consistently outperforms the Bayesian model averaging approach used as reference post-processing technique.	stat.AP	26 pages, 14 figures, 2 tables
2	Quasithermal GeV neutrinos from neutron-loaded magnetized outflows in core-collapse supernovae: spectra and light curves	Jose Alonso Carpio,Nick Ekanger,Mukul Bhattacharya,Kohta Murase,Shunsaku Horiuchi	Rapidly rotating and strongly magnetized protoneutron stars (PNSs) created in core-collapse supernovae can drive relativistic magnetized winds. Ions and neutrons can be co-accelerated while they remain coupled through elastic collisions. We investigate the nucleosynthesis and subsequent nuclear disintegration, and find that relativistic neutrons can be generated in such magnetized winds. Upon eventual decoupling, resulting inelastic collisions with ejecta lead to pion production, resulting in $0.1-10\,{\rm GeV}$ neutrinos. Following this scenario presented in Murase, Dasgupta & Thompson, Phys. Rev. D, 89, 043012 (2014), we numerically calculate the spectra and light curves of quasithermal neutrino emission and find that power-law tails are formed without cosmic-ray acceleration. In the event of a Galactic supernova, $\sim 10-1000$ neutrino events could be detected with Hyper-Kamiokande, KM3Net-ORCA and IceCube-Upgrade for PNSs with surface magnetic field $B_{\rm dip}\sim 10^{13-15}\,{\rm G}$ and initial spin period $P_i \sim 1-30\,{\rm ms}$. Successful detection will enable us to study supernovae as multienergy neutrino sources and may provide clues to the roles of PNSs in diverse classes of transients.	astro-ph.HE	11 pages
3	Generally applicable physics-based equation of state for liquids	G. E. Proctor,K. Trachenko	"Physics-based first-principles pressure-volume-temperature equations of state (EOS) exist for solids and gases but not for liquids due to the long-standing fundamental problems involved in liquid theory. Current EOS models that are applicable to liquids and supercritical fluids at liquid-like density under conditions relevant to planetary interiors and industrial processes are complex empirical models with many physically meaningless adjustable parameters. Here, we develop a generally applicable physics-based (GAP) EOS for liquids including supercritical fluids at liquid-like density. The GAP equation has only one dimensionless parameter: the Gr\""uneisen parameter for the fluid. The GAP equation is explicit in the internal energy, and hence links the most fundamental macroscopic static property of fluids, the pressure-volume-temperature EOS, to their key microscopic property: the molecular hopping frequency or liquid relaxation time, from which the internal energy can be obtained. We test our GAP equation against available experimental data in several different ways and find good agreement. We observe that the GAP equation is similar to the Mie-Gr\""{u}neisen solid EOS in a wide range of the liquid phase diagram. This similarity is ultimately related to the condensed state of these two phases. On the other hand, the differences between the GAP equation and EOS for gases are fundamental. Finally, we identify the key gaps in the experimental data that need to be filled in to proceed further with the liquid EOS."	cond-mat.soft	None
4	CATE Lasso: Conditional Average Treatment Effect Estimation with High-Dimensional Linear Regression	Masahiro Kato,Masaaki Imaizumi	In causal inference about two treatments, Conditional Average Treatment Effects (CATEs) play an important role as a quantity representing an individualized causal effect, defined as a difference between the expected outcomes of the two treatments conditioned on covariates. This study assumes two linear regression models between a potential outcome and covariates of the two treatments and defines CATEs as a difference between the linear regression models. Then, we propose a method for consistently estimating CATEs even under high-dimensional and non-sparse parameters. In our study, we demonstrate that desirable theoretical properties, such as consistency, remain attainable even without assuming sparsity explicitly if we assume a weaker assumption called implicit sparsity originating from the definition of CATEs. In this assumption, we suppose that parameters of linear models in potential outcomes can be divided into treatment-specific and common parameters, where the treatment-specific parameters take difference values between each linear regression model, while the common parameters remain identical. Thus, in a difference between two linear regression models, the common parameters disappear, leaving only differences in the treatment-specific parameters. Consequently, the non-zero parameters in CATEs correspond to the differences in the treatment-specific parameters. Leveraging this assumption, we develop a Lasso regression method specialized for CATE estimation and present that the estimator is consistent. Finally, we confirm the soundness of the proposed method by simulation studies.	econ.EM	None
5	DreamCraft3D: Hierarchical 3D Generation with Bootstrapped Diffusion Prior	Jingxiang Sun,Bo Zhang,Ruizhi Shao,Lizhen Wang,Wen Liu,Zhenda Xie,Yebin Liu	We present DreamCraft3D, a hierarchical 3D content generation method that produces high-fidelity and coherent 3D objects. We tackle the problem by leveraging a 2D reference image to guide the stages of geometry sculpting and texture boosting. A central focus of this work is to address the consistency issue that existing works encounter. To sculpt geometries that render coherently, we perform score distillation sampling via a view-dependent diffusion model. This 3D prior, alongside several training strategies, prioritizes the geometry consistency but compromises the texture fidelity. We further propose Bootstrapped Score Distillation to specifically boost the texture. We train a personalized diffusion model, Dreambooth, on the augmented renderings of the scene, imbuing it with 3D knowledge of the scene being optimized. The score distillation from this 3D-aware diffusion prior provides view-consistent guidance for the scene. Notably, through an alternating optimization of the diffusion prior and 3D scene representation, we achieve mutually reinforcing improvements: the optimized 3D scene aids in training the scene-specific diffusion model, which offers increasingly view-consistent guidance for 3D optimization. The optimization is thus bootstrapped and leads to substantial texture boosting. With tailored 3D priors throughout the hierarchical generation, DreamCraft3D generates coherent 3D objects with photorealistic renderings, advancing the state-of-the-art in 3D content generation. Code available at https://github.com/deepseek-ai/DreamCraft3D.	cs.CV	Project Page: https://mrtornado24.github.io/DreamCraft3D/
6	All-optical single-shot readout of a superconducting qubit	Georg Arnold,Thomas Werner,Rishabh Sahu,Lucky N. Kapoor,Liu Qiu,Johannes M. Fink	The rapid development of superconducting quantum hardware is expected to run into significant I/O restrictions due to the need for large-scale error correction in a cryogenic environment. Classical data centers rely on fiber-optic interconnects to remove similar networking bottlenecks and to allow for reconfigurable, software-defined infrastructures. In the same spirit, ultra-cold electro-optic links have been proposed and used to generate qubit control signals, or to replace cryogenic readout electronics. So far, the latter suffered from either low efficiency, low bandwidth and the need for additional microwave drives, or breaking of Cooper pairs and qubit states. In this work we realize electro-optic microwave photonics at millikelvin temperatures to implement a radio-over-fiber qubit readout that does not require any active or passive cryogenic microwave equipment. We demonstrate all-optical single-shot-readout by means of the Jaynes-Cummings nonlinearity in a circulator-free readout scheme. Importantly, we do not observe any direct radiation impact on the qubit state as verified with high-fidelity quantum-non-demolition measurements despite the absence of shielding elements. This compatibility between superconducting circuits and telecom wavelength light is not only a prerequisite to establish modular quantum networks, it is also relevant for multiplexed readout of superconducting photon detectors and classical superconducting logic. Moreover, this experiment showcases the potential of electro-optic radiometry in harsh environments - an electronics-free sensing principle that extends into the THz regime with applications in radio astronomy, planetary missions and earth observation.	quant-ph	None
7	The intelligent agent model -- a fully two-dimensional microscopic traffic flow model	Martin Treiber,Ankit Anil Chaudhari	Recently, a fully two-dimensional microscopic traffic flow model for lane-free vehicular traffic flow has been proposed [Physica A, 509, pp. 1-11 (2018)]. In this contribution, we generalize this model to describe any kind of human-driven directed flow including lane-based vehicular flow, lane-free mixed traffic, bicycle traffic, and pedestrian flow. The proposed intelligent-agent model (IAM) has the same philosophy as the well-known social-force model (SFM) for pedestrians but the interaction and boundary forces are based on car-following models making this model suitable for higher speeds. Depending on the underlying car-following model, the IAM includes anticipation, response to relative velocities, and accident-free driving. When adding a suitable floor field, the IAM reverts to an integrated car-following and lane-changing model with continuous lane changes. We simulate this model in several lane-based and lane-free environments in various geometries with and without obstacles. We observe that the model produces accident-free traffic flow reproducing the observed self-organisation phenomena.	physics.soc-ph	Accepted by Transportation Letters: the International Journal of   Transportation Research
8	Manipulating Plasma Excitations with Terahertz Light Pulses in Superconducting Cuprates	Jacopo Fiore,Niccol√≤ Sellati,Francesco Gabriele,Claudio Castellani,Goetz Seibold,Mattia Udina,Lara Benfatto	Layered cuprates offer a preferential playground for optical non-linearity thanks to the emergence, below Tc, of soft out-of-plane Josephson plasmons. The hallmark of such a non-linearity is the observation of Third Harmonic Generation, that has been theoretically understood as a sum-frequency process involving a two-plasmon excitation. However, recent experiments in cuprates with two planes per unit cell challenge this interpretation, due to the lack of resonant response at the temperature where the driving frequency matches the plasma energy scale, as observed instead in single-layer cuprates. Here we show that such an apparent discrepancy in bilayer systems can be resolved by taking into account the combined effect of light polarization and Josephson-coupling anisotropy on setting the energy range where three-dimensional layered plasma modes can be resonantly excited. Our results offer a novel perspective on the possibility to tune on demand high-harmonic generation by artificially designing Josephson heterostructures.	cond-mat.supr-con	None
9	Can GPT models Follow Human Summarization Guidelines? Evaluating ChatGPT and GPT-4 for Dialogue Summarization	Yongxin Zhou,Fabien Ringeval,Fran√ßois Portet	This study explores the capabilities of prompt-driven Large Language Models (LLMs) like ChatGPT and GPT-4 in adhering to human guidelines for dialogue summarization. Experiments employed DialogSum (English social conversations) and DECODA (French call center interactions), testing various prompts: including prompts from existing literature and those from human summarization guidelines, as well as a two-step prompt approach. Our findings indicate that GPT models often produce lengthy summaries and deviate from human summarization guidelines. However, using human guidelines as an intermediate step shows promise, outperforming direct word-length constraint prompts in some cases. The results reveal that GPT models exhibit unique stylistic tendencies in their summaries. While BERTScores did not dramatically decrease for GPT outputs suggesting semantic similarity to human references and specialised pre-trained models, ROUGE scores reveal grammatical and lexical disparities between GPT-generated and human-written summaries. These findings shed light on the capabilities and limitations of GPT models in following human instructions for dialogue summarization.	cs.CL	None
0	Exploring OCR Capabilities of GPT-4V(ision) : A Quantitative and In-depth Evaluation	Yongxin Shi,Dezhi Peng,Wenhui Liao,Zening Lin,Xinhong Chen,Chongyu Liu,Yuyi Zhang,Lianwen Jin	This paper presents a comprehensive evaluation of the Optical Character Recognition (OCR) capabilities of the recently released GPT-4V(ision), a Large Multimodal Model (LMM). We assess the model's performance across a range of OCR tasks, including scene text recognition, handwritten text recognition, handwritten mathematical expression recognition, table structure recognition, and information extraction from visually-rich document. The evaluation reveals that GPT-4V performs well in recognizing and understanding Latin contents, but struggles with multilingual scenarios and complex tasks. Based on these observations, we delve deeper into the necessity of specialized OCR models and deliberate on the strategies to fully harness the pretrained general LMMs like GPT-4V for OCR downstream tasks. The study offers a critical reference for future research in OCR with LMMs. Evaluation pipeline and results are available at https://github.com/SCUT-DLVCLab/GPT-4V_OCR.	cs.CV	None
1	Two-Sided Matching Markets: Impossibility Results on Existence of Efficient and Envy Free Solutions	Thorben Tr√∂bst,Vijay V Vazirani	The Hylland-Zeckhauser gave a classic pricing-based mechanism (HZ) for a one-sided matching market; it yields allocations satisfying Pareto optimality and envy-freeness (Hylland and Zeckhauser, 1979), and the mechanism is incentive compatible in the large (He et al., 2018). They also studied the exchange extension of HZ and gave an example showing that it may not even admit an equilibrium. In this paper, we consider two models of two sided matching markets: when utility functions are symmetric and when they are non-symmetric. We ask if these models always admit allocations satisfying the two basic properties of Pareto efficiency and envy freeness. Our results are negative. A corollary of the former result is a negative result for non-bipartite matching markets as well.	cs.GT	None
2	Learning COVID-19 Regional Transmission Using Universal Differential Equations in a SIR model	Adrian Rojas-Campos,Lukas Stelz,Pascal Nieters	Highly-interconnected societies difficult to model the spread of infectious diseases such as COVID-19. Single-region SIR models fail to account for incoming forces of infection and expanding them to a large number of interacting regions involves many assumptions that do not hold in the real world. We propose using Universal Differential Equations (UDEs) to capture the influence of neighboring regions and improve the model's predictions in a combined SIR+UDE model. UDEs are differential equations totally or partially defined by a deep neural network (DNN). We include an additive term to the SIR equations composed by a DNN that learns the incoming force of infection from the other regions. The learning is performed using automatic differentiation and gradient descent to approach the change in the target system caused by the state of the neighboring regions. We compared the proposed model using a simulated COVID-19 outbreak against a single-region SIR and a fully data-driven model composed only of a DNN. The proposed UDE+SIR model generates predictions that capture the outbreak dynamic more accurately, but a decay in performance is observed at the last stages of the outbreak. The single-area SIR and the fully data-driven approach do not capture the proper dynamics accurately. Once the predictions were obtained, we employed the SINDy algorithm to substitute the DNN with a regression, removing the black box element of the model with no considerable increase in the error levels.	cs.LG	18 pages
3	Language Agnostic Code Embeddings	Saiteja Utpala,Alex Gu,Pin Yu Chen	Recently, code language models have achieved notable advancements in addressing a diverse array of essential code comprehension and generation tasks. Yet, the field lacks a comprehensive deep dive and understanding of the code embeddings of multilingual code models. In this paper, we present a comprehensive study on multilingual code embeddings, focusing on the cross-lingual capabilities of these embeddings across different programming languages. Through probing experiments, we demonstrate that code embeddings comprise two distinct components: one deeply tied to the nuances and syntax of a specific language, and the other remaining agnostic to these details, primarily focusing on semantics. Further, we show that when we isolate and eliminate this language-specific component, we witness significant improvements in downstream code retrieval tasks, leading to an absolute increase of up to +17 in the Mean Reciprocal Rank (MRR).	cs.CL	None
4	From Molecules to Materials: Pre-training Large Generalizable Models for Atomic Property Prediction	Nima Shoghi,Adeesh Kolluru,John R. Kitchin,Zachary W. Ulissi,C. Lawrence Zitnick,Brandon M. Wood	Foundation models have been transformational in machine learning fields such as natural language processing and computer vision. Similar success in atomic property prediction has been limited due to the challenges of training effective models across multiple chemical domains. To address this, we introduce Joint Multi-domain Pre-training (JMP), a supervised pre-training strategy that simultaneously trains on multiple datasets from different chemical domains, treating each dataset as a unique pre-training task within a multi-task framework. Our combined training dataset consists of $\sim$120M systems from OC20, OC22, ANI-1x, and Transition-1x. We evaluate performance and generalization by fine-tuning over a diverse set of downstream tasks and datasets including: QM9, rMD17, MatBench, QMOF, SPICE, and MD22. JMP demonstrates an average improvement of 59% over training from scratch, and matches or sets state-of-the-art on 34 out of 40 tasks. Our work highlights the potential of pre-training strategies that utilize diverse data to advance property prediction across chemical domains, especially for low-data tasks.	cs.LG	None
5	Can acoustic early dark energy still resolve the Hubble tension?	Th√©o Simon	In this paper, we re-assess the ability of the acoustic early dark energy (ADE) model to resolve the Hubble tension in light of the new Pantheon+ and S$H_0$ES data on the one hand, and the BOSS LRG and eBOSS QSO data, analysed under the effective field theory of large-scale structures (ETFofLSS) on the other hand. We find that the Pantheon+ data, which favor a larger $\Omega_m$ value than the Pantheon data, have a strong constraining power on the ADE model, while the EFTofLSS analysis of the BOSS and eBOSS data only slightly increases the constraints. We establish that the ADE model is now ruled out as a solution to the Hubble tension, with a remaining tension of $3.6\sigma$. In addition, we find that the axion-like early dark energy model performs better when confronted to the same datasets, with a residual tension of $2.5\sigma$. This work shows that the Pantheon+ data can have a decisive impact on models which aim to resolve the Hubble tension.	astro-ph.CO	12 + 4 pages, 6 figures. Comments welcome! arXiv admin note: text   overlap with arXiv:2302.09032
6	Measuring Supermassive Black Hole Properties via Gravitational Radiation from Eccentrically Orbiting Stellar Mass Black Hole Binaries	Andrew Laeuger,Brian Seymour,Yanbei Chen,Hang Yu	There may exist stellar-mass binary black holes (BBH) which merge while orbiting nearby a supermassive black hole (SMBH). In such a triple system, the SMBH will modulate the gravitational waveform of the BBH through orbital Doppler shift and de Sitter precession of the angular momentum. Future space-based GW observatories focused on the milli- and decihertz band will be uniquely poised to observe these waveform modulations, as the GW frequency from stellar-mass BBHs varies slowly in this band while modulation effects accumulate. In this work, we apply the Fisher information matrix formalism to estimate how well space-borne GW detectors can measure properties of BBH+SMBH hierarchical triples using the GW from orbiting BBH. We extend previous work by considering the more realistic case of an eccentric orbit around the SMBH, and notably include the effects of orbital pericenter precession. We find that for detector concepts such as LISA, B-DECIGO, and TianGO, we can extract the SMBH mass and semimajor axis of the orbit with a fractional uncertainty below the 0.1% level over a wide range of triple system parameters. Furthermore, we find that the effects of pericenter precession and orbital eccentricity significantly improve our ability to measure this system. We also find that while LISA could measure these systems, the decihertz detector concepts B-DECIGO and TianGO would enable better sensitivity to the triple's parameters.	gr-qc	12 pages (main text excluding references and appendices), 11 figures,   submitted to PRD
7	Sky location of Galactic white dwarf binaries in space-based gravitational wave detection	Pan Guo,Hong-Bo Jin,Cong-Feng Qiao,Yue-Liang Wu	Quickly localizing the identified white dwarf (WD) binaries is the basic requirement for the space-based gravitational wave (GW) detection. In fact, the amplitude of GW signals are modulated by the periodic motion of GW detectors on the solar orbit. The intensity of the observed signals is enhanced according to the observation time beyond a year to enhance a high signal to noise ratio (SNR). As data gap exists, the completeness of the data observed for a long time depends on filling gaps in the data. Actually, in a year period, the GW sources have a best observation orbit position of GW detectors, where the detector response intensity of GW is maximum. Thus, the best positions, where the direction of GW source is perpendicular to the detection arms, can be searched for the verified GW sources of the sky map to enhance SNR too. For the three arms response intensity of the GW signals changing more clearly with the location of the GW sources relative to the detector, the noises and the suppression of noise by time delay interferometer are ignored. In the four chosen sources, the two verification WD binaries: J0806 and V407 Vul are observed at the best orbit positions by TAIJI for the short time of 2 and 3 days respectively. The intensities of those GWs are above the values of the TAIJI sensitivity curve, significantly. Compared with a single detector, the network of two detectors does not significantly improve the accuracy of location of the verification binaries. The reason of that result is that one GW source can not be perpendicular to both detectors of TAIJI and LISA. These results imply that the searching of GW signals and parameter estimation of GW sources from the experimental data of the space-based mission do not ignore the orbit positions relevant to GW sources.	gr-qc	22 pages, 15 figures
8	QMoE: Practical Sub-1-Bit Compression of Trillion-Parameter Models	Elias Frantar,Dan Alistarh	Mixture-of-Experts (MoE) architectures offer a general solution to the high inference costs of large language models (LLMs) via sparse routing, bringing faster and more accurate models, at the cost of massive parameter counts. For example, the SwitchTransformer-c2048 model has 1.6 trillion parameters, requiring 3.2TB of accelerator memory to run efficiently, which makes practical deployment challenging and expensive. In this paper, we present a solution to this memory problem, in form of a new compression and execution framework called QMoE. Specifically, QMoE consists of a scalable algorithm which accurately compresses trillion-parameter MoEs to less than 1 bit per parameter, in a custom format co-designed with bespoke GPU decoding kernels to facilitate efficient end-to-end compressed inference, with minor runtime overheads relative to uncompressed execution. Concretely, QMoE can compress the 1.6 trillion parameter SwitchTransformer-c2048 model to less than 160GB (20x compression, 0.8 bits per parameter) at only minor accuracy loss, in less than a day on a single GPU. This enables, for the first time, the execution of a trillion-parameter model on affordable commodity hardware, like a single server with 4x NVIDIA A6000 or 8x NVIDIA 3090 GPUs, at less than 5% runtime overhead relative to ideal uncompressed inference. The source code and compressed models are available at github.com/IST-DASLab/qmoe.	cs.LG	None
9	Using Diffusion Models to Generate Synthetic Labelled Data for Medical Image Segmentation	Daniel Saragih,Pascal Tyrrell	In this paper, we proposed and evaluated a pipeline for generating synthetic labeled polyp images with the aim of augmenting automatic medical image segmentation models. In doing so, we explored the use of diffusion models to generate and style synthetic labeled data. The HyperKvasir dataset consisting of 1000 images of polyps in the human GI tract obtained from 2008 to 2016 during clinical endoscopies was used for training and testing. Furthermore, we did a qualitative expert review, and computed the Fr\'echet Inception Distance (FID) and Multi-Scale Structural Similarity (MS-SSIM) between the output images and the source images to evaluate our samples. To evaluate its augmentation potential, a segmentation model was trained with the synthetic data to compare their performance with the real data and previous Generative Adversarial Networks (GAN) methods. These models were evaluated using the Dice loss (DL) and Intersection over Union (IoU) score. Our pipeline generated images that more closely resembled real images according to the FID scores (GAN: $118.37 \pm 1.06 \text{ vs SD: } 65.99 \pm 0.37$). Improvements over GAN methods were seen on average when the segmenter was entirely trained (DL difference: $-0.0880 \pm 0.0170$, IoU difference: $0.0993 \pm 0.01493$) or augmented (DL difference: GAN $-0.1140 \pm 0.0900 \text{ vs SD }-0.1053 \pm 0.0981$, IoU difference: GAN $0.01533 \pm 0.03831 \text{ vs SD }0.0255 \pm 0.0454$) with synthetic data. Overall, we obtained more realistic synthetic images and improved segmentation model performance when fully or partially trained on synthetic data.	eess.IV	21 pages, 6 figures, 3 tables
0	Learning Independent Program and Architecture Representations for Generalizable Performance Modeling	Lingda Li,Thomas Flynn,Adolfy Hoisie	This paper proposes PerfVec, a novel deep learning-based performance modeling framework that learns high-dimensional, independent/orthogonal program and microarchitecture representations. Once learned, a program representation can be used to predict its performance on any microarchitecture, and likewise, a microarchitecture representation can be applied in the performance prediction of any program. Additionally, PerfVec yields a foundation model that captures the performance essence of instructions, which can be directly used by developers in numerous performance modeling related tasks without incurring its training cost. The evaluation demonstrates that PerfVec is more general, efficient, and accurate than previous approaches.	cs.LG	None
1	Covert Planning against Imperfect Observers	Haoxiang Ma,Chongyang Shi,Shuo Han,Michael R. Dorothy,Jie Fu	Covert planning refers to a class of constrained planning problems where an agent aims to accomplish a task with minimal information leaked to a passive observer to avoid detection. However, existing methods of covert planning often consider deterministic environments or do not exploit the observer's imperfect information. This paper studies how covert planning can leverage the coupling of stochastic dynamics and the observer's imperfect observation to achieve optimal task performance without being detected. Specifically, we employ a Markov decision process to model the interaction between the agent and its stochastic environment, and a partial observation function to capture the leaked information to a passive observer. Assuming the observer employs hypothesis testing to detect if the observation deviates from a nominal policy, the covert planning agent aims to maximize the total discounted reward while keeping the probability of being detected as an adversary below a given threshold. We prove that finite-memory policies are more powerful than Markovian policies in covert planning. Then, we develop a primal-dual proximal policy gradient method with a two-time-scale update to compute a (locally) optimal covert policy. We demonstrate the effectiveness of our methods using a stochastic gridworld example. Our experimental results illustrate that the proposed method computes a policy that maximizes the adversary's expected reward without violating the detection constraint, and empirically demonstrates how the environmental noises can influence the performance of the covert policies.	cs.MA	None
2	Improving a Named Entity Recognizer Trained on Noisy Data with a Few Clean Instances	Zhendong Chu,Ruiyi Zhang,Tong Yu,Rajiv Jain,Vlad I Morariu,Jiuxiang Gu,Ani Nenkova	To achieve state-of-the-art performance, one still needs to train NER models on large-scale, high-quality annotated data, an asset that is both costly and time-intensive to accumulate. In contrast, real-world applications often resort to massive low-quality labeled data through non-expert annotators via crowdsourcing and external knowledge bases via distant supervision as a cost-effective alternative. However, these annotation methods result in noisy labels, which in turn lead to a notable decline in performance. Hence, we propose to denoise the noisy NER data with guidance from a small set of clean instances. Along with the main NER model we train a discriminator model and use its outputs to recalibrate the sample weights. The discriminator is capable of detecting both span and category errors with different discriminative prompts. Results on public crowdsourcing and distant supervision datasets show that the proposed method can consistently improve performance with a small guidance set.	cs.CL	14 pages
3	Detecting Pretraining Data from Large Language Models	Weijia Shi,Anirudh Ajith,Mengzhou Xia,Yangsibo Huang,Daogao Liu,Terra Blevins,Danqi Chen,Luke Zettlemoyer	Although large language models (LLMs) are widely deployed, the data used to train them is rarely disclosed. Given the incredible scale of this data, up to trillions of tokens, it is all but certain that it includes potentially problematic text such as copyrighted materials, personally identifiable information, and test data for widely reported reference benchmarks. However, we currently have no way to know which data of these types is included or in what proportions. In this paper, we study the pretraining data detection problem: given a piece of text and black-box access to an LLM without knowing the pretraining data, can we determine if the model was trained on the provided text? To facilitate this study, we introduce a dynamic benchmark WIKIMIA that uses data created before and after model training to support gold truth detection. We also introduce a new detection method Min-K% Prob based on a simple hypothesis: an unseen example is likely to contain a few outlier words with low probabilities under the LLM, while a seen example is less likely to have words with such low probabilities. Min-K% Prob can be applied without any knowledge about the pretraining corpus or any additional training, departing from previous detection methods that require training a reference model on data that is similar to the pretraining data. Moreover, our experiments demonstrate that Min-K% Prob achieves a 7.4% improvement on WIKIMIA over these previous methods. We apply Min-K% Prob to two real-world scenarios, copyrighted book detection, and contaminated downstream example detection, and find it a consistently effective solution.	cs.CL	None
4	The GOOSE Dataset for Perception in Unstructured Environments	Peter Mortimer,Raphael Hagmanns,Miguel Granero,Thorsten Luettel,Janko Petereit,Hans-Joachim Wuensche	The potential for deploying autonomous systems can be significantly increased by improving the perception and interpretation of the environment. However, the development of deep learning-based techniques for autonomous systems in unstructured outdoor environments poses challenges due to limited data availability for training and testing. To address this gap, we present the German Outdoor and Offroad Dataset (GOOSE), a comprehensive dataset specifically designed for unstructured outdoor environments. The GOOSE dataset incorporates 10 000 labeled pairs of images and point clouds, which are utilized to train a range of state-of-the-art segmentation models on both image and point cloud data. We open source the dataset, along with an ontology for unstructured terrain, as well as dataset standards and guidelines. This initiative aims to establish a common framework, enabling the seamless inclusion of existing datasets and a fast way to enhance the perception capabilities of various robots operating in unstructured environments. The dataset, pre-trained models for offroad perception, and additional documentation can be found at https://goose-dataset.de/.	cs.CV	Preprint; Submitted to IEEE for review
5	The Data Provenance Initiative: A Large Scale Audit of Dataset Licensing & Attribution in AI	Shayne Longpre,Robert Mahari,Anthony Chen,Naana Obeng-Marnu,Damien Sileo,William Brannon,Niklas Muennighoff,Nathan Khazam,Jad Kabbara,Kartik Perisetla,Xinyi,Wu,Enrico Shippole,Kurt Bollacker,Tongshuang Wu,Luis Villa,Sandy Pentland,Deb Roy,Sara Hooker	The race to train language models on vast, diverse, and inconsistently documented datasets has raised pressing concerns about the legal and ethical risks for practitioners. To remedy these practices threatening data transparency and understanding, we convene a multi-disciplinary effort between legal and machine learning experts to systematically audit and trace 1800+ text datasets. We develop tools and standards to trace the lineage of these datasets, from their source, creators, series of license conditions, properties, and subsequent use. Our landscape analysis highlights the sharp divides in composition and focus of commercially open vs closed datasets, with closed datasets monopolizing important categories: lower resource languages, more creative tasks, richer topic variety, newer and more synthetic training data. This points to a deepening divide in the types of data that are made available under different license conditions, and heightened implications for jurisdictional legal interpretations of copyright and fair use. We also observe frequent miscategorization of licenses on widely used dataset hosting sites, with license omission of 72%+ and error rates of 50%+. This points to a crisis in misattribution and informed use of the most popular datasets driving many recent breakthroughs. As a contribution to ongoing improvements in dataset transparency and responsible use, we release our entire audit, with an interactive UI, the Data Provenance Explorer, which allows practitioners to trace and filter on data provenance for the most popular open source finetuning data collections: www.dataprovenance.org.	cs.CL	30 pages (18 main), 6 figures, 5 tables
6	The Simplest Inflationary Potentials	Tom√°s Sousa,Deaglan J. Bartlett,Harry Desmond,Pedro G. Ferreira	"Inflation is a highly favoured theory for the early Universe. It is compatible with current observations of the cosmic microwave background and large scale structure and is a driver in the quest to detect primordial gravitational waves. It is also, given the current quality of the data, highly under-determined with a large number of candidate implementations. We use a new method in symbolic regression to generate all possible simple scalar field potentials for one of two possible basis sets of operators. Treating these as single-field, slow-roll inflationary models we then score them with an information-theoretic metric (""minimum description length"") that quantifies their efficiency in compressing the information in the Planck data. We explore two possible priors on the parameter space of potentials, one related to the functions' structural complexity and one that uses a Katz back-off language model to prefer functions that may be theoretically motivated. This enables us to identify the inflaton potentials that optimally balance simplicity with accuracy at explaining the Planck data, which may subsequently find theoretical motivation. Our exploratory study opens the door to extraction of fundamental physics directly from data, and may be augmented with more refined theoretical priors in the quest for a complete understanding of the early Universe."	astro-ph.CO	13+4 pages, 4 figures; submitted to Physical Review D
7	S$^3$-TTA: Scale-Style Selection for Test-Time Augmentation in Biomedical Image Segmentation	Kangxian Xie,Siyu Huang,Sebastian Cajas Ordone,Hanspeter Pfister,Donglai Wei	Deep-learning models have been successful in biomedical image segmentation. To generalize for real-world deployment, test-time augmentation (TTA) methods are often used to transform the test image into different versions that are hopefully closer to the training domain. Unfortunately, due to the vast diversity of instance scale and image styles, many augmented test images produce undesirable results, thus lowering the overall performance. This work proposes a new TTA framework, S$^3$-TTA, which selects the suitable image scale and style for each test image based on a transformation consistency metric. In addition, S$^3$-TTA constructs an end-to-end augmentation-segmentation joint-training pipeline to ensure a task-oriented augmentation. On public benchmarks for cell and lung segmentation, S$^3$-TTA demonstrates improvements over the prior art by 3.4% and 1.3%, respectively, by simply augmenting the input data in testing phase.	cs.CV	None
8	Kiki or Bouba? Sound Symbolism in Vision-and-Language Models	Morris Alper,Hadar Averbuch-Elor	Although the mapping between sound and meaning in human language is assumed to be largely arbitrary, research in cognitive science has shown that there are non-trivial correlations between particular sounds and meanings across languages and demographic groups, a phenomenon known as sound symbolism. Among the many dimensions of meaning, sound symbolism is particularly salient and well-demonstrated with regards to cross-modal associations between language and the visual domain. In this work, we address the question of whether sound symbolism is reflected in vision-and-language models such as CLIP and Stable Diffusion. Using zero-shot knowledge probing to investigate the inherent knowledge of these models, we find strong evidence that they do show this pattern, paralleling the well-known kiki-bouba effect in psycholinguistics. Our work provides a novel method for demonstrating sound symbolism and understanding its nature using computational tools. Our code will be made publicly available.	cs.CV	Accepted to NeurIPS 2023 (spotlight). Project webpage:   https://kiki-bouba.github.io/
9	Pointwise convergence of some continuous-time polynomial ergodic averages	Wen Huang,Song Shao,Rongzhong Xiao	In this paper, we study the pointwise convergence of some continuous-time polynomial ergodic averages. Our method is based on the topological models of measurable flows. One of main results of the paper is as follow. Let $(X,\mathcal{X},\mu, (T^{t})_{t\in \mathbb{R}})$ and $(X,\mathcal{X},\mu, (S^{t})_{t\in \mathbb{R}})$ be two measurable flows, $a\in \mathbb{Q}$, and $Q\in \mathbb{R}[t]$ with $\text{deg}\ Q\ge 2$. Then for any $f_1, f_2, g\in L^{\infty}(\mu)$, the limit \begin{equation*}   \lim\limits_{M\to\infty}\frac{1}{M}\int_{0}^{M}f_1(T^{t}x)f_2(T^{at}x)g(S^{Q(t)}x)dt \end{equation*} exists for $\mu$-a.e. $x\in X$.	math.DS	46 pages
0	Multi-scale Diffusion Denoised Smoothing	Jongheon Jeong,Jinwoo Shin	"Along with recent diffusion models, randomized smoothing has become one of a few tangible approaches that offers adversarial robustness to models at scale, e.g., those of large pre-trained models. Specifically, one can perform randomized smoothing on any classifier via a simple ""denoise-and-classify"" pipeline, so-called denoised smoothing, given that an accurate denoiser is available - such as diffusion model. In this paper, we investigate the trade-off between accuracy and certified robustness of denoised smoothing: for example, we question on which representation of diffusion model would maximize the certified robustness of denoised smoothing. We consider a new objective that aims collective robustness of smoothed classifiers across multiple noise levels at a shared diffusion model, which also suggests a new way to compensate the cost of accuracy in randomized smoothing for its certified robustness. This objective motivates us to fine-tune diffusion model (a) to perform consistent denoising whenever the original image is recoverable, but (b) to generate rather diverse outputs otherwise. Our experiments show that this fine-tuning scheme of diffusion models combined with the multi-scale smoothing enables a strong certified robustness possible at highest noise level while maintaining the accuracy closer to non-smoothed classifiers."	cs.LG	24 pages; NeurIPS 2023; Code is available at   https://github.com/jh-jeong/smoothing-multiscale
1	Navigating Socio-Emotional Risk through Comfort-Building in a Physics Teaching Community of Practice: A Case Study	Maggie Mahmood,Hamideh Talafian,Devyn Shafer,Morten Lundsgaard,Eric Kuo,Tim Stelzer	In teacher professional development (PD), grouping teachers with varying levels of experience can be a productive and empowering way to stimulate the exchange and co-generation of content and pedagogical knowledge. However, less experienced teachers can face socio-emotional risks when engaging in collaborative science content reasoning tasks with more experienced colleagues (Finkelstein, Jaber, & Dini, 2018), and these risks may impact the collaborative experience of both parties and the learning environment in teacher PD. This descriptive case study examines the process of productively navigating socio-emotional risks and interpersonal tensions encountered by a veteran and pre-service physics teacher during one episode of discussing physics content. We use a single term, comfort-building, to encapsulate discursive moves that result in increased feelings of comfort and safety by the participants. Comfort-building includes moves that serve to mitigate social risk, ease tension, and avoid discomfort, as well as those geared toward finding common ground and co-navigating challenges. These moves can carve out conversational space for teachers to more confidently face risks associated with being accountable to the physics content knowledge and engage in discipline-based conversations more deeply. The presented episode in this study was followed by video-stimulated individual interviews to determine how consciously the teachers connected their participation to explicit risk and comfort. This case study highlights an affective dimension for consideration in the continued study and facilitation of science teaching communities of practice, especially ones that bring together teachers with a variety of backgrounds and skill sets.	physics.ed-ph	56 double space pages including references, 3 figure and 3 tables
2	MixerFlow for Image Modelling	Eshant English,Matthias Kirchler,Christoph Lippert	Normalising flows are statistical models that transform a complex density into a simpler density through the use of bijective transformations enabling both density estimation and data generation from a single model. In the context of image modelling, the predominant choice has been the Glow-based architecture, whereas alternative architectures remain largely unexplored in the research community. In this work, we propose a novel architecture called MixerFlow, based on the MLP-Mixer architecture, further unifying the generative and discriminative modelling architectures. MixerFlow offers an effective mechanism for weight sharing for flow-based models. Our results demonstrate better density estimation on image datasets under a fixed computational budget and scales well as the image resolution increases, making MixeFlow a powerful yet simple alternative to the Glow-based architectures. We also show that MixerFlow provides more informative embeddings than Glow-based architectures.	stat.ML	None
3	DEFT: Data Efficient Fine-Tuning for Large Language Models via Unsupervised Core-Set Selection	Devleena Das,Vivek Khetan	Recent advances have led to the availability of many pre-trained language models (PLMs); however, a question that remains is how much data is truly needed to fine-tune PLMs for downstream tasks? In this work, we introduce DEFT, a data-efficient fine-tuning framework that leverages unsupervised core-set selection to minimize the amount of data needed to fine-tune PLMs for downstream tasks. We demonstrate the efficacy of our DEFT framework in the context of text-editing LMs, and compare to the state-of-the art text-editing model, CoEDIT (Raheja et al., 2023). Our quantitative and qualitative results demonstrate that DEFT models are just as accurate as CoEDIT while being finetuned on ~70% less data.	cs.CL	None
4	From Heisenberg to Hubbard: An initial state for the shallow quantum simulation of correlated electrons	Bruno Murta,Joaqu√≠n Fern√°ndez-Rossier	The widespread use of the noninteracting ground state as the initial state for the digital quantum simulation of the Fermi-Hubbard model is largely due to the scarcity of alternative easy-to-prepare approximations to the exact ground state in the literature. Exploiting the fact that the spin-$\frac{1}{2}$ Heisenberg model is the effective low-energy theory of the Fermi-Hubbard model at half-filling in the strongly interacting limit, here we propose a three-step deterministic quantum routine to prepare an educated guess of the ground state of the Fermi-Hubbard model through a shallow circuit suitable for near-term quantum hardware. First, the ground state of the Heisenberg model is initialized via a hybrid variational method using an ansatz that explores only the correct symmetry subspace. Second, a general method is devised to convert a multi-spin-$\frac{1}{2}$ wave function into its fermionic version. Third, taking inspiration from the Baeriswyl ansatz, a constant-depth single-parameter layer that adds doublon-holon pairs is applied to this fermionic state. Numerical simulations on chains and ladders with up to 12 sites confirm the improvement over the noninteracting ground state of the overlap with the exact ground state for the intermediate values of the interaction strength at which quantum simulation is bound to be most relevant.	cond-mat.str-el	Main text: 4 pages, 3 figures. Supp. Mat.: 10 pages, 9 figures
5	Role of cilia activity and surrounding viscous fluid on properties of metachronal waves	Supravat Dey,Gladys Massiera,Estelle Pitard	Large groups of active cilia collectively beat in a fluid medium as metachronal waves, essential for some microorganisms motility and for flow generation in mucociliary clearance. Several models can predict the emergence of metachronal waves, but what controls the properties of metachronal waves is still unclear. Here, we investigate numerically a simple model for cilia in the presence of noise on regular lattices in one- and two-dimensions. We characterize the wave using spatial correlation and the frequency of collective beating. Our results clearly show that the viscosity of the fluid medium does not affect the wavelength; the activity of the cilia does. These numerical results are supported by a dimensional analysis, which is expected to be robust against the model for active force generation, unless surrounding fluid influences the cilia activity. Interestingly, enhancement of cilia activity increases the wavelength and decreases the beating frequency, keeping the wave velocity almost unchanged. These results might have significance in understanding paramecium locomotion and mucociliary clearance diseases.	cond-mat.soft	6 pages, 5 figures
6	AFLOW for alloys	Cormac Toher,Stefano Curtarolo	Many different types of phases can form within alloys, from highly-ordered intermetallic compounds, to structurally-ordered but chemically-disordered solid solutions, and structurally-disordered (i.e. amorphous) metallic glasses. The different types of phases display very different properties, so predicting phase formation is important for understanding how materials will behave. Here, we review how first-principles data from the AFLOW repository and the aflow++ software can be used to predict phase formation in alloys, and describe some general trends that can be deduced from the data, particularly with respect to the importance of disorder and entropy in multicomponent systems.	cond-mat.mtrl-sci	Small AFLOW review submitted to special issue. 6 pages, 4 pictures
7	Discrete variance decay analysis of spurious mixing	Tridib Banerjee,Sergey Danilov,Knut Klingbeil	Expressions for local discrete variance decay (DVD) rates are directly derived from discrete tracer equations without any assumptions on discrete fluxes of the second moment. Spurious mixing (SM) associated with numerical implementations of scalar advection and diffusion is thus estimated. The new framework is shown to avoid the need for second-moment flux definition when solved on finite-volume cell edges but still invoke certain second-moment fluxes when the DVD rates are partitioned to participating cell nodes. These implied discrete fluxes are shown to differ from those proposed in earlier literature (but share the same dissipative part) and thus reveal the non-uniqueness of their nature. They are shown to be ambiguous for high-order advection schemes introducing uncertainty to the locality of any estimates produced by a DVD approach. Additional damping of flux divergence through temporal averaging or some coarse-graining is thus shown to be necessary. Through the application of this technique, SM is found to be correlated with the distribution of eddy kinetic energy. The contribution from vertical advection to SM is found to be relatively small and correlated with the distribution of buoyancy fluxes. The explored high-order schemes are found to demonstrate levels of spurious mixing which may locally exceed background physical mixing.	physics.ao-ph	Submitted to Ocean Modelling Manuscript number: OCEMOD-D-23-00145.   Name of funder: Deutsche Forschungsgemeinschaft. Grant agreement or award   number: 274762653
8	Inversion Sets and Quotient Root Systems	Ivan Dimitrov,Cole Gigliotti,Etan Ossip,Charles Paquette,David Wehlau	We provide a recursive description of all decompositions of the positive roots $R^+$ of a quotient root system $R$ into disjoint unions of inversion sets. Our description is type-independent and generalizes the analogous result for type $\mathbb A$ root systems in [USRA]. The main tool is the notion of an inflation of a subset of a quotient root system. This new notion allows us to treat all root systems (and their quotients) uniformly. We also obtain some numerical results about the number of special decompositions. The new sequences we obtain may be considered as extensions of Catalan numbers.	math.CO	Preliminary Version
9	Conditional Euclidean distance optimization via relative tangency	Sandra Di Rocco,Lukas Gustafsson,Luca Sodomaco	We introduce a theory of relative tangency for projective algebraic varieties. The dual variety $X_Z^\vee$ of a variety $X$ relative to a subvariety $Z$ is the set of hyperplanes tangent to $X$ at a point of $Z$. We also introduce the concept of polar classes of $X$ relative to $Z$. We explore the duality of varieties of low rank matrices relative to special linear sections. In this framework, we study the critical points of the Euclidean Distance function from a data point to $X$, lying on $Z$. The locus where the number of such conditional critical points is positive is called the ED data locus of $X$ given $Z$. The generic number of such critical points defines the conditional ED degree of $X$ given $Z$. We show the irreducibility of ED data loci, and we compute their dimensions and degrees in terms of relative characteristic classes.	math.AG	40 pages, 4 figures
0	How to Extend 3D GBSM to Integrated Sensing and Communication Channel with Sharing Feature?	Yameng Liu,Jianhua Zhang,Yuxiang Zhang,Huiwen Gong,Tao Jiang,Guangyi Liu	Integrated Sensing and Communication (ISAC) is a promising technology in 6G systems. The existing 3D Geometry-Based Stochastic Model (GBSM), as standardized for 5G systems, addresses solely communication channels and lacks consideration of the integration with sensing channel. Therefore, this letter extends 3D GBSM to support ISAC research, with a particular focus on capturing the sharing feature of both channels, including shared scatterers, clusters, paths, and similar propagation param-eters, which have been experimentally verified in the literature. The proposed approach can be summarized as follows: Firstly, an ISAC channel model is proposed, where shared and non-shared components are superimposed for both communication and sensing. Secondly, sensing channel is characterized as a cascade of TX-target, radar cross section, and target-RX, with the introduction of a novel parameter S for shared target extraction. Finally, an ISAC channel implementation framework is proposed, allowing flexible configuration of sharing feature and the joint generation of communication and sensing channels. The proposed ISAC channel model can be compatible with the 3GPP standards and offers promising support for ISAC technology evaluation.	eess.SP	None
1	ConvNets Match Vision Transformers at Scale	Samuel L. Smith,Andrew Brock,Leonard Berrada,Soham De	Many researchers believe that ConvNets perform well on small or moderately sized datasets, but are not competitive with Vision Transformers when given access to datasets on the web-scale. We challenge this belief by evaluating a performant ConvNet architecture pre-trained on JFT-4B, a large labelled dataset of images often used for training foundation models. We consider pre-training compute budgets between 0.4k and 110k TPU-v4 core compute hours, and train a series of networks of increasing depth and width from the NFNet model family. We observe a log-log scaling law between held out loss and compute budget. After fine-tuning on ImageNet, NFNets match the reported performance of Vision Transformers with comparable compute budgets. Our strongest fine-tuned model achieves a Top-1 accuracy of 90.4%.	cs.CV	None
2	SuperHF: Supervised Iterative Learning from Human Feedback	Gabriel Mukobi,Peter Chatain,Su Fong,Robert Windesheim,Gitta Kutyniok,Kush Bhatia,Silas Alberti	While large language models demonstrate remarkable capabilities, they often present challenges in terms of safety, alignment with human values, and stability during training. Here, we focus on two prevalent methods used to align these models, Supervised Fine-Tuning (SFT) and Reinforcement Learning from Human Feedback (RLHF). SFT is simple and robust, powering a host of open-source models, while RLHF is a more sophisticated method used in top-tier models like ChatGPT but also suffers from instability and susceptibility to reward hacking. We propose a novel approach, Supervised Iterative Learning from Human Feedback (SuperHF), which seeks to leverage the strengths of both methods. Our hypothesis is two-fold: that the reward model used in RLHF is critical for efficient data use and model generalization and that the use of Proximal Policy Optimization (PPO) in RLHF may not be necessary and could contribute to instability issues. SuperHF replaces PPO with a simple supervised loss and a Kullback-Leibler (KL) divergence prior. It creates its own training data by repeatedly sampling a batch of model outputs and filtering them through the reward model in an online learning regime. We then break down the reward optimization problem into three components: robustly optimizing the training rewards themselves, preventing reward hacking-exploitation of the reward model that degrades model performance-as measured by a novel METEOR similarity metric, and maintaining good performance on downstream evaluations. Our experimental results show SuperHF exceeds PPO-based RLHF on the training objective, easily and favorably trades off high reward with low reward hacking, improves downstream calibration, and performs the same on our GPT-4 based qualitative evaluation scheme all the while being significantly simpler to implement, highlighting SuperHF's potential as a competitive language model alignment technique.	cs.CL	Accepted to the Socially Responsible Language Modelling Research   (SoLaR) workshop at NeurIPS 2023
3	An Infinite Needle in a Finite Haystack: Finding Infinite Counter-Models in Deductive Verification	Neta Elad,Oded Padon,Sharon Shoham	First-order logic, and quantifiers in particular, are widely used in deductive verification. Quantifiers are essential for describing systems with unbounded domains, but prove difficult for automated solvers. Significant effort has been dedicated to finding quantifier instantiations that establish unsatisfiability, thus ensuring validity of a system's verification conditions. However, in many cases the formulas are satisfiable: this is often the case in intermediate steps of the verification process. For such cases, existing tools are limited to finding finite models as counterexamples. Yet, some quantified formulas are satisfiable but only have infinite models. Such infinite counter-models are especially typical when first-order logic is used to approximate inductive definitions such as linked lists or the natural numbers. The inability of solvers to find infinite models makes them diverge in these cases. In this paper, we tackle the problem of finding such infinite models. These models allow the user to identify and fix bugs in the modeling of the system and its properties. Our approach consists of three parts. First, we introduce symbolic structures as a way to represent certain infinite models. Second, we describe an effective model finding procedure that symbolically explores a given family of symbolic structures. Finally, we identify a new decidable fragment of first-order logic that extends and subsumes the many-sorted variant of EPR, where satisfiable formulas always have a model representable by a symbolic structure within a known family. We evaluate our approach on examples from the domains of distributed consensus protocols and of heap-manipulating programs. Our implementation quickly finds infinite counter-models that demonstrate the source of verification failures in a simple way, while SMT solvers and theorem provers such as Z3, cvc5, and Vampire diverge.	cs.PL	None
4	IntenDD: A Unified Contrastive Learning Approach for Intent Detection and Discovery	Bhavuk Singhal,Ashim Gupta,Shivasankaran V P,Amrith Krishna	Identifying intents from dialogue utterances forms an integral component of task-oriented dialogue systems. Intent-related tasks are typically formulated either as a classification task, where the utterances are classified into predefined categories or as a clustering task when new and previously unknown intent categories need to be discovered from these utterances. Further, the intent classification may be modeled in a multiclass (MC) or multilabel (ML) setup. While typically these tasks are modeled as separate tasks, we propose IntenDD, a unified approach leveraging a shared utterance encoding backbone. IntenDD uses an entirely unsupervised contrastive learning strategy for representation learning, where pseudo-labels for the unlabeled utterances are generated based on their lexical features. Additionally, we introduce a two-step post-processing setup for the classification tasks using modified adsorption. Here, first, the residuals in the training data are propagated followed by smoothing the labels both modeled in a transductive setting. Through extensive evaluations on various benchmark datasets, we find that our approach consistently outperforms competitive baselines across all three tasks. On average, IntenDD reports percentage improvements of 2.32%, 1.26%, and 1.52% in their respective metrics for few-shot MC, few-shot ML, and the intent discovery tasks respectively.	cs.CL	EMNLP 2023 Findings
5	Using Knowledge Awareness to improve Safety of Autonomous Driving	Andrea Calvagna,Arabinda Ghosh,Sadegh Soudjani	We present a method, which incorporates knowledge awareness into the symbolic computation of discrete controllers for reactive cyber physical systems, to improve decision making about the unknown operating environment under uncertain/incomplete inputs. Assuming an abstract model of the system and the environment, we translate the knowledge awareness of the operating context into linear temporal logic formulas and incorporate them into the system specifications to synthesize a controller. The knowledge base is built upon an ontology model of the environment objects and behavioural rules, which includes also symbolic models of partial input features. The resulting symbolic controller support smoother, early reactions, which improves the security of the system over existing approaches based on incremental symbolic perception. A motion planning case study for an autonomous vehicle has been implemented to validate the approach, and presented results show significant improvements with respect to safety of state-of-the-art symbolic controllers for reactive systems.	eess.SY	None
6	Zero-sound modes for the nuclear equation of state at supra-normal densities	Jing Ye,J. Margueron,Niu Li,W. Z. Jiang	The meaningful correlations between the zero-sound modes and the stiffness of the nuclear equation of state (EOS) are uncovered in nuclear matter with the relativistic mean-field theory. It is demonstrated that the high-density zero-sound modes merely exist in models with the stiff EOS. While the stiff EOS can be softened by including {\omega}-meson self-interactions (the {\omega}4 term), the weakened coupling of the {\omega}-meson self-interactions reignites the zero sound at high density. These results suggest that the high-density zero-sound modes can be used to probe the stiffness of the EOS at supra-normal densities. The implications and effects of zero sounds are also discussed in heavy ion collisions and neutron stars.	nucl-th	None
7	All-rounder: A flexible DNN accelerator with diverse data format support	Seock-Hwan Noh,Seungpyo Lee,Banseok Shin,Sehun Park,Yongjoo Jang,Jaeha Kung	Recognizing the explosive increase in the use of DNN-based applications, several industrial companies developed a custom ASIC (e.g., Google TPU, IBM RaPiD, Intel NNP-I/NNP-T) and constructed a hyperscale cloud infrastructure with it. The ASIC performs operations of the inference or training process of DNN models which are requested by users. Since the DNN models have different data formats and types of operations, the ASIC needs to support diverse data formats and generality for the operations. However, the conventional ASICs do not fulfill these requirements. To overcome the limitations of it, we propose a flexible DNN accelerator called All-rounder. The accelerator is designed with an area-efficient multiplier supporting multiple precisions of integer and floating point datatypes. In addition, it constitutes a flexibly fusible and fissionable MAC array to support various types of DNN operations efficiently. We implemented the register transfer level (RTL) design using Verilog and synthesized it in 28nm CMOS technology. To examine practical effectiveness of our proposed designs, we designed two multiply units and three state-of-the-art DNN accelerators. We compare our multiplier with the multiply units and perform architectural evaluation on performance and energy efficiency with eight real-world DNN models. Furthermore, we compare benefits of the All-rounder accelerator to a high-end GPU card, i.e., NVIDIA GeForce RTX30390. The proposed All-rounder accelerator universally has speedup and high energy efficiency in various DNN benchmarks than the baselines.	cs.AR	None
8	Vacuum energy of scalar fields on spherical shells with general matching conditions	Guglielmo Fucci,C√©sar Romaniega Sancho	In this work we analyze the spectral zeta function for massless scalar fields propagating in a $D$-dimensional flat space under the influence of a shell potential. The shell potential is defined in terms of the two-interval self-adjoint extensions of the Hamiltonian describing the dynamics of the scalar field. After performing the necessary analytic continuation, we utilize the spectral zeta function of the system to compute the vacuum energy of the field.	hep-th	25 pages, 2 figures
9	HI-TOM: A Benchmark for Evaluating Higher-Order Theory of Mind Reasoning in Large Language Models	Yinghui He,Yufan Wu,Yilin Jia,Rada Mihalcea,Yulong Chen,Naihao Deng	Theory of Mind (ToM) is the ability to reason about one's own and others' mental states. ToM plays a critical role in the development of intelligence, language understanding, and cognitive processes. While previous work has primarily focused on first and second-order ToM, we explore higher-order ToM, which involves recursive reasoning on others' beliefs. We introduce HI-TOM, a Higher Order Theory of Mind benchmark. Our experimental evaluation using various Large Language Models (LLMs) indicates a decline in performance on higher-order ToM tasks, demonstrating the limitations of current LLMs. We conduct a thorough analysis of different failure cases of LLMs, and share our thoughts on the implications of our findings on the future of NLP.	cs.CL	Accepted at Findings of EMNLP 2023
0	PROMINET: Prototype-based Multi-View Network for Interpretable Email Response Prediction	Yuqing Wang,Prashanth Vijayaraghavan,Ehsan Degan	Email is a widely used tool for business communication, and email marketing has emerged as a cost-effective strategy for enterprises. While previous studies have examined factors affecting email marketing performance, limited research has focused on understanding email response behavior by considering email content and metadata. This study proposes a Prototype-based Multi-view Network (PROMINET) that incorporates semantic and structural information from email data. By utilizing prototype learning, the PROMINET model generates latent exemplars, enabling interpretable email response prediction. The model maps learned semantic and structural exemplars to observed samples in the training data at different levels of granularity, such as document, sentence, or phrase. The approach is evaluated on two real-world email datasets: the Enron corpus and an in-house Email Marketing corpus. Experimental results demonstrate that the PROMINET model outperforms baseline models, achieving a ~3% improvement in F1 score on both datasets. Additionally, the model provides interpretability through prototypes at different granularity levels while maintaining comparable performance to non-interpretable models. The learned prototypes also show potential for generating suggestions to enhance email text editing and improve the likelihood of effective email responses. This research contributes to enhancing sender-receiver communication and customer engagement in email interactions.	cs.CL	Accepted at EMNLP 2023 (industry)
1	Metrically Scaled Monocular Depth Estimation through Sparse Priors for Underwater Robots	Luca Ebner,Gideon Billings,Stefan Williams	In this work, we address the problem of real-time dense depth estimation from monocular images for mobile underwater vehicles. We formulate a deep learning model that fuses sparse depth measurements from triangulated features to improve the depth predictions and solve the problem of scale ambiguity. To allow prior inputs of arbitrary sparsity, we apply a dense parameterization method. Our model extends recent state-of-the-art approaches to monocular image based depth estimation, using an efficient encoder-decoder backbone and modern lightweight transformer optimization stage to encode global context. The network is trained in a supervised fashion on the forward-looking underwater dataset, FLSea. Evaluation results on this dataset demonstrate significant improvement in depth prediction accuracy by the fusion of the sparse feature priors. In addition, without any retraining, our method achieves similar depth prediction accuracy on a downward looking dataset we collected with a diver operated camera rig, conducting a survey of a coral reef. The method achieves real-time performance, running at 160 FPS on a laptop GPU and 7 FPS on a single CPU core and is suitable for direct deployment on embedded systems. The implementation of this work is made publicly available at https://github.com/ebnerluca/uw_depth.	cs.CV	Submitted to ICRA 2024
2	DISCO: A Large Scale Human Annotated Corpus for Disfluency Correction in Indo-European Languages	Vineet Bhat,Preethi Jyothi,Pushpak Bhattacharyya	Disfluency correction (DC) is the process of removing disfluent elements like fillers, repetitions and corrections from spoken utterances to create readable and interpretable text. DC is a vital post-processing step applied to Automatic Speech Recognition (ASR) outputs, before subsequent processing by downstream language understanding tasks. Existing DC research has primarily focused on English due to the unavailability of large-scale open-source datasets. Towards the goal of multilingual disfluency correction, we present a high-quality human-annotated DC corpus covering four important Indo-European languages: English, Hindi, German and French. We provide extensive analysis of results of state-of-the-art DC models across all four languages obtaining F1 scores of 97.55 (English), 94.29 (Hindi), 95.89 (German) and 92.97 (French). To demonstrate the benefits of DC on downstream tasks, we show that DC leads to 5.65 points increase in BLEU scores on average when used in conjunction with a state-of-the-art Machine Translation (MT) system. We release code to run our experiments along with our annotated dataset here.	cs.CL	Accepted at EMNLP 2023 Findings
3	HANSEN: Human and AI Spoken Text Benchmark for Authorship Analysis	Nafis Irtiza Tripto,Adaku Uchendu,Thai Le,Mattia Setzu,Fosca Giannotti,Dongwon Lee	Authorship Analysis, also known as stylometry, has been an essential aspect of Natural Language Processing (NLP) for a long time. Likewise, the recent advancement of Large Language Models (LLMs) has made authorship analysis increasingly crucial for distinguishing between human-written and AI-generated texts. However, these authorship analysis tasks have primarily been focused on written texts, not considering spoken texts. Thus, we introduce the largest benchmark for spoken texts - HANSEN (Human ANd ai Spoken tExt beNchmark). HANSEN encompasses meticulous curation of existing speech datasets accompanied by transcripts, alongside the creation of novel AI-generated spoken text datasets. Together, it comprises 17 human datasets, and AI-generated spoken texts created using 3 prominent LLMs: ChatGPT, PaLM2, and Vicuna13B. To evaluate and demonstrate the utility of HANSEN, we perform Authorship Attribution (AA) & Author Verification (AV) on human-spoken datasets and conducted Human vs. AI spoken text detection using state-of-the-art (SOTA) models. While SOTA methods, such as, character ngram or Transformer-based model, exhibit similar AA & AV performance in human-spoken datasets compared to written ones, there is much room for improvement in AI-generated spoken text detection. The HANSEN benchmark is available at: https://huggingface.co/datasets/HANSEN-REPO/HANSEN.	cs.CL	9 pages, EMNLP-23 findings, 5 pages appendix, 6 figures, 17 tables
4	Design Space Exploration of Sparsity-Aware Application-Specific Spiking Neural Network Accelerators	Ilkin Aliyev. Kama Svoboda,Tosiron Adegbija	Spiking Neural Networks (SNNs) offer a promising alternative to Artificial Neural Networks (ANNs) for deep learning applications, particularly in resource-constrained systems. This is largely due to their inherent sparsity, influenced by factors such as the input dataset, the length of the spike train, and the network topology. While a few prior works have demonstrated the advantages of incorporating sparsity into the hardware design, especially in terms of reducing energy consumption, the impact on hardware resources has not yet been explored. This is where design space exploration (DSE) becomes crucial, as it allows for the optimization of hardware performance by tailoring both the hardware and model parameters to suit specific application needs. However, DSE can be extremely challenging given the potentially large design space and the interplay of hardware architecture design choices and application-specific model parameters.   In this paper, we propose a flexible hardware design that leverages the sparsity of SNNs to identify highly efficient, application-specific accelerator designs. We develop a high-level, cycle-accurate simulation framework for this hardware and demonstrate the framework's benefits in enabling detailed and fine-grained exploration of SNN design choices, such as the layer-wise logical-to-hardware ratio (LHR). Our experimental results show that our design can (i) achieve up to $76\%$ reduction in hardware resources and (ii) deliver a speed increase of up to $31.25\times$, while requiring $27\%$ fewer hardware resources compared to sparsity-oblivious designs. We further showcase the robustness of our framework by varying spike train lengths with different neuron population sizes to find the optimal trade-off points between accuracy and hardware latency.	cs.AR	None
5	Simulating CDT quantum gravity	Joren Brunekreef,Andrzej G√∂rlich,Renate Loll	We provide a hands-on introduction to Monte Carlo simulations in nonperturbative lattice quantum gravity, formulated in terms of Causal Dynamical Triangulations (CDT). We describe explicitly the implementation of Monte Carlo moves and the associated detailed-balance equations in two and three spacetime dimensions. We discuss how to optimize data storage and retrieval, which are nontrivial due to the dynamical nature of the lattices, and how to reconstruct the full geometry from selected stored data. Various aspects of the simulation, including tuning, thermalization and the measurement of observables are also treated. An associated open-source C++ implementation code is freely available online.	hep-th	None
6	Scalar mass conservation in turbulent mixture fraction based combustion models through consistent local flow parameters	Marco Davidovic,Heinz Pitsch	Mixture fraction-based models are widely employed for predicting turbulent non-premixed combustion processes due to their cost-effectiveness and well-established subfilter closure. In these models, the transport of reactive scalars in physical space is decomposed into two components: scalar transport relative to mixture fraction and transport of mixture fraction in physical space. Conventional flamelet models do not consider that these two processes have to be formulated consistently, which can lead to scalar mass conservation errors. In the context of multiphase flows, scalar transport in mixture fraction space is governed by three conditional flow-dependent parameters: the conditional scalar dissipation rate, the conditional scalar diffusion rate, and the conditional spray source term. The evolution of mixture fraction in physical space is typically modeled using the presumed Filtered Density Function (FDF) approach. This paper introduces a novel formulation for the conditional flow parameters that aligns with the presumed FDF approach, thereby ensuring scalar mass conservation. The proposed model is applied to a Large-Eddy Simulation (LES) of the inert ECN Spray A case, with a comparison against a conventional flow parameter model that employs an inverse error function shape for the scalar dissipation rate. The results indicate that the conventional model produces similar conditional dissipation rates to the new model in regions where combustion takes place. However, significant discrepancies are observed in the conditional diffusion rate, highlighting the susceptibility of the conventional model to scalar mass conservation errors for non-unity Lewis number scalars.	physics.flu-dyn	None
7	Interferometric Neural Networks	Arun Sehrawat	On the one hand, artificial neural networks have many successful applications in the field of machine learning and optimization. On the other hand, interferometers are integral parts of any field that deals with waves such as optics, astronomy, and quantum physics. Here, we introduce neural networks composed of interferometers and then build generative adversarial networks from them. Our networks do not have any classical layer and can be realized on quantum computers or photonic chips. We demonstrate their applicability for combinatorial optimization, image classification, and image generation. For combinatorial optimization, our network consistently converges to the global optimum or remains within a narrow range of it. In multi-class image classification tasks, our networks achieve accuracies of 93% and 83%. Lastly, we show their capability to generate images of digits from 0 to 9 as well as human faces.	quant-ph	11 pages
8	Stochastic Latent Transformer: Efficient Modelling of Stochastically Forced Zonal Jets	Ira J. S. Shokar,Rich R. Kerswell,Peter H. Haynes	We introduce the 'Stochastic Latent Transformer', a probabilistic deep learning approach for efficient reduced-order modelling of stochastic partial differential equations (SPDEs). Despite recent advances in deep learning for fluid mechanics, limited research has explored modelling stochastically driven flows - which play a crucial role in understanding a broad spectrum of phenomena, from jets on giant planets to ocean circulation and the variability of midlatitude weather. The model architecture consists of a stochastically-forced transformer, paired with a translation-equivariant autoencoder, that we demonstrate is capable of reproducing system dynamics across various integration periods. We demonstrate its effectiveness applied to a well-researched zonal jet system, with the neural network achieving a five-order-of-magnitude speedup compared to numerical integration. This facilitates the cost-effective generation of large ensembles, enabling the exploration of statistical questions concerning probabilities of spontaneous transition events.	cs.LG	23 pages, 9 figures
9	Gap-free 16-year (2005-2020) sub-diurnal surface meteorological observations across Florida	Julie Peeling,Jasmeet Judge,Vasubandhu Misra,C. B. Jayasankar,Rick Lusher	The rather unique sub-tropical, flat, peninsular region of Florida is subject to a unique climate with extreme weather events across the year that impacts agriculture, public health, and management of natural resources. Meteorological data at high temporal resolutions especially in the tropical latitudes are essential to understand diurnal and semi-diurnal variations of climate, which are considered to be the fundamental modes of climate variations of our Earth system. However, many meteorological datasets contain gaps that limit their use for validation of models and further detailed observational analysis. The objective of this paper is to apply a set of data gap filling strategies to develop a gap-free dataset with 15-minute observations for the sub-tropical region of Florida. Using data from the Florida Automated Weather Network (FAWN), methods of linear interpolation, trend continuation, reference to external sources, and nearest station substitution were applied to fill in the data gaps depending on the extent of the gap. The outcome of this study provides continuous, publicly accessible surface meteorological observations for 30 FAWN stations at 15-minute intervals for the years 2005-2020.	physics.ao-ph	16 pages, 8 figures, 3 tables
0	Improving Conversational Recommendation Systems via Bias Analysis and Language-Model-Enhanced Data Augmentation	Xi Wang,Hossein A. Rahmani,Jiqun Liu,Emine Yilmaz	Conversational Recommendation System (CRS) is a rapidly growing research area that has gained significant attention alongside advancements in language modelling techniques. However, the current state of conversational recommendation faces numerous challenges due to its relative novelty and limited existing contributions. In this study, we delve into benchmark datasets for developing CRS models and address potential biases arising from the feedback loop inherent in multi-turn interactions, including selection bias and multiple popularity bias variants. Drawing inspiration from the success of generative data via using language models and data augmentation techniques, we present two novel strategies, 'Once-Aug' and 'PopNudge', to enhance model performance while mitigating biases. Through extensive experiments on ReDial and TG-ReDial benchmark datasets, we show a consistent improvement of CRS techniques with our data augmentation approaches and offer additional insights on addressing multiple newly formulated biases.	cs.CL	Accepted by EMNLP 2023 (Findings)
1	Translating Universal Scene Descriptions into Knowledge Graphs for Robotic Environment	Giang Hoang Nguyen,Daniel Bessler,Simon Stelter,Mihai Pomarlan,Michael Beetz	Robots performing human-scale manipulation tasks require an extensive amount of knowledge about their surroundings in order to perform their actions competently and human-like. In this work, we investigate the use of virtual reality technology as an implementation for robot environment modeling, and present a technique for translating scene graphs into knowledge bases. To this end, we take advantage of the Universal Scene Description (USD) format which is an emerging standard for the authoring, visualization and simulation of complex environments. We investigate the conversion of USD-based environment models into Knowledge Graph (KG) representations that facilitate semantic querying and integration with additional knowledge sources.	cs.RO	6 pages, 3 figures, ICRA 2024
2	Thermodynamic geometry of a system with unified quantum statistics	Habib Esmaili,Hosein Mohammadzadeh,Mehdi Biderang,Morteza Nattagh Najafi	We examine the thermodynamic characteristics of unified quantum statistics as a novel framework that undergoes a crossover between Bose-Einstein and Fermi-Dirac statistics by varying a generalization parameter $\delta$. We find an attractive intrinsic statistical interaction when $\delta\le0.5$ where the thermodynamic curvature remains positive throughout the entire physical range. For $0.5 < \delta < 1$ the system exhibits predominantly Fermi-like behavior at high temperatures, while at low temperatures, the thermodynamic curvature is positive and the system behaves like bosons. As the temperature decreases further, the system undergoes a transition into the condensate phase. We also report on a critical fugacity ($z = Z^*$) defined as the point at which the thermodynamic curvature changes sign, i.e. for $z< Z^*$ ($z > Z^*$), the statistical behavior resembles that of fermions (bosons). Also, we extract the variation of statistical behaviour of the system for different values of generalization parameter with respect to the temperature. We evaluate the critical fugacity and critical $\delta$ dependent condensation temperature of the system. Finally, we investigate the specific heat as a function of temperature and condensation phase transition temperature of the system for different values of generalization parameter in different dimensions.	cond-mat.stat-mech	10 pages, 17 figures
3	Mapping the Empirical Evidence of the GDPR (In-)Effectiveness: A Systematic Review	Wenlong Li,Zihao Li,Wenkai Li,Yueming Zhang,Aolan Li	In the realm of data protection, a striking disconnect prevails between traditional domains of doctrinal, legal, theoretical, and policy-based inquiries and a burgeoning body of empirical evidence. Much of the scholarly and regulatory discourse remains entrenched in abstract legal principles or normative frameworks, leaving the empirical landscape uncharted or minimally engaged. Since the birth of EU data protection law, a modest body of empirical evidence has been generated but remains widely scattered and unexamined. Such evidence offers vital insights into the perception, impact, clarity, and effects of data protection measures but languishes on the periphery, inadequately integrated into the broader conversation. To make a meaningful connection, we conduct a comprehensive review and synthesis of empirical research spanning nearly three decades (1995- March 2022), advocating for a more robust integration of empirical evidence into the evaluation and review of the GDPR, while laying a methodological foundation for future empirical research.	cs.CY	None
4	Breaking up with the continuous exoplanet mass-radius relation	Kathryn Edmondson,Jordan Norris,Eamonn Kerins	We use a carefully selected subsample of 1053 confirmed exoplanets from the NASA Exoplanet Archive to construct empirical power-law exoplanet mass-radius-temperature ($M$-$R$-$T$) relations. Using orthogonal distance regression to account for errors in both mass and radius, we allow the data to decide: 1) the number of distinct planetary regimes; 2) whether the boundaries of these regimes are best described by broken power laws joined at mass break points, or by discontinuous power laws motivated by changes in equations of state and temperature. We find strong support from the data for three distinct planetary $M$-$R$ regimes and for those regimes to be discontinuous. Our most successful model involves an $M$-$R$-$T$ relation in which ice/rock (rocky) and ice-giant (neptunian) planets are segregated by a pure-ice equation of state, whilst neptunes and gas giant (jovian) planets are segregated by a mass break at $M_{\rm br} = 115\pm19~M_{\oplus}$. The rocky planet regime is shown to follow $M \propto R^{0.34\pm0.01}$, whilst neptunes have $M\propto R^{0.55\pm0.02}$. Planets in both regimes are seen to extend to similar maximum masses. In the jovian regime, we find that $M \propto R^{0.00\pm0.01}T^{0.35\pm 0.02}$, where $T$ is the planet equilibrium temperature. This implies that, for jovian planets detected so far, equilibrium temperature alone provides a robust estimator of mass.	astro-ph.EP	11 pages, 11 figures. For submission to The Open Journal of   Astrophysics
5	A No-Reference Quality Assessment Method for Digital Human Head	Yingjie Zhou,Zicheng Zhang,Wei Sun,Xiongkuo Min,Xianghe Ma,Guangtao Zhai	In recent years, digital humans have been widely applied in augmented/virtual reality (A/VR), where viewers are allowed to freely observe and interact with the volumetric content. However, the digital humans may be degraded with various distortions during the procedure of generation and transmission. Moreover, little effort has been put into the perceptual quality assessment of digital humans. Therefore, it is urgent to carry out objective quality assessment methods to tackle the challenge of digital human quality assessment (DHQA). In this paper, we develop a novel no-reference (NR) method based on Transformer to deal with DHQA in a multi-task manner. Specifically, the front 2D projections of the digital humans are rendered as inputs and the vision transformer (ViT) is employed for the feature extraction. Then we design a multi-task module to jointly classify the distortion types and predict the perceptual quality levels of digital humans. The experimental results show that the proposed method well correlates with the subjective ratings and outperforms the state-of-the-art quality assessment methods.	cs.CV	None
6	Disentangling Extraction and Reasoning in Multi-hop Spatial Reasoning	Roshanak Mirzaee,Parisa Kordjamshidi	Spatial reasoning over text is challenging as the models not only need to extract the direct spatial information from the text but also reason over those and infer implicit spatial relations. Recent studies highlight the struggles even large language models encounter when it comes to performing spatial reasoning over text. In this paper, we explore the potential benefits of disentangling the processes of information extraction and reasoning in models to address this challenge. To explore this, we design various models that disentangle extraction and reasoning(either symbolic or neural) and compare them with state-of-the-art(SOTA) baselines with no explicit design for these parts. Our experimental results consistently demonstrate the efficacy of disentangling, showcasing its ability to enhance models' generalizability within realistic data domains.	cs.CL	Accepted in EMNLP-Finding 2023
7	MultiPrompter: Cooperative Prompt Optimization with Multi-Agent Reinforcement Learning	Dong-Ki Kim,Sungryull Sohn,Lajanugen Logeswaran,Dongsub Shim,Honglak Lee	Recently, there has been an increasing interest in automated prompt optimization based on reinforcement learning (RL). This approach offers important advantages, such as generating interpretable prompts and being compatible with black-box foundation models. However, the substantial prompt space size poses challenges for RL-based methods, often leading to suboptimal policy convergence. This paper introduces MultiPrompter, a new framework that views prompt optimization as a cooperative game between prompters which take turns composing a prompt together. Our cooperative prompt optimization effectively reduces the problem size and helps prompters learn optimal prompts. We test our method on the text-to-image task and show its ability to generate higher-quality images than baselines.	cs.LG	None
8	On the Kashaev signature conjecture	David Cimasoni,Livio Ferretti	"In 2018, Kashaev introduced a square matrix indexed by the regions of a link diagram, and conjectured that it provides a novel way of computing the Levine-Tristram signature and Alexander polynomial of the corresponding oriented link. In this article, we show that for the classical signature (i.e. the Levine-Tristram signature at -1), this conjecture follows from the seminal work of Gordon-Litherland. We also relate Kashaev's matrix to Kauffman's ""Formal Knot Theory"" model of the Alexander polynomial. As a consequence, we establish the Alexander polynomial and classical signature parts of the conjecture for arbitrary links, as well as the full conjecture for definite knots."	math.GT	8 pages, 3 figures
9	A Finely Segmented Semi-Monolithic Detector tailored for High Resolution PET	Yannick Kuhl,Florian Mueller,Stephan Naunheim,Matthias Bovelett,Janko Lambertus,David Schug,Bjoern Weissler,Eike Gegenmantel,Pierre Gebhardt,Volkmar Schulz	Preclinical research and organ-dedicated applications require high-resolution positron emission tomography (PET) detectors to visualize small structures and understand biological processes at a finer level of detail. Current commercial systems often employ finely pixelated or monolithic scintillators, each with its limitations. We present a semi-monolithic detector, tailored for high-resolution PET applications, and merging concepts of monolithic and pixelated crystals. The detector features slabs measuring (24 x 10 x 1) sq. mm, coupled to a 12 x 12 readout channel photosensor with 4 mm pitch. The slabs are grouped in two arrays of 44 slabs each to achieve a higher optical photon density. We employ a fan beam collimator for fast calibration to train machine-learning-based positioning models for all three dimensions, including slab identification and depth-of-interaction (DOI), utilizing gradient tree boosting (GTB). Energy calculation was based on a position-dependent energy calibration. Using an analytical timing calibration, time skews were corrected for coincidence timing resolution (CTR) estimation. Leveraging machine-learning-based calibration in all three dimensions, we achieved high detector spatial resolution: down to 1.18 mm full width at half maximum (FWHM) detector spatial resolution and 0.75 mm mean absolute error (MAE) in the planar-monolithic direction along the slabs, and 2.14 mm FWHM and 1.03 mm MAE for depth-of-interaction (DOI) at an energy window of (435-585) keV. Correct slab interaction identification exceeded 80%, alongside an energy resolution of 13.8% and a CTR of 450 ps FWHM. Therewith, the introduced finely segmented, high-resolution slab detector demonstrates an appealing performance suitable for high-resolution PET applications. The current benchtop-based detector calibration routine allows these detectors to be used in PET systems.	physics.med-ph	14 pages, 11 figures, IEEE NSS MIC RTSD 2023
0	Radical Pair Model for Magnetic Field Effects on NMDA Receptor Activity	Parvathy S Nair1,Hadi Zadeh-Haghighi,Christoph Simon	The N-methyl-D-aspartate receptor is a prominent player in brain development and functioning. Perturbations to its functioning through external stimuli like magnetic fields can potentially affect the brain in numerous ways. Various studies have shown that magnetic fields of varying strengths affect these receptors. We propose that the radical pair mechanism, a quantum mechanical process, could explain some of these field effects. Radicals of the form $[\mbox{RO}^\bullet \mbox{ Mg($\mbox{H}_2$O$)_n$}^{+\bullet}]$, where R is a protein residue that can be Serine or Tyrosine, are considered for this study. The variation in the singlet fractional yield of the radical pairs, as a function of magnetic field strength, is calculated to understand how the magnetic field affects the products of the radical pair reactions. Based on the results, the radical pair mechanism is a likely candidate for explaining the magnetic field effects observed on the receptor activity. The model predicts changes in the behaviour of the system as magnetic field strength is varied and also predicts certain isotope effects. The results further suggest that similar effects on radical pairs could be a plausible explanation for various magnetic field effects within the brain.	physics.bio-ph	None
1	Harmonic model predictive control for tracking periodic references	Pablo Krupa,Daniel Limon,Alberto Bemporad,Teodoro Alamo	Harmonic model predictive control (HMPC) is a recent model predictive control (MPC) formulation for tracking piece-wise constant references that includes a parameterized artificial harmonic reference as a decision variable, resulting in an increased performance and domain of attraction with respect to other MPC formulations. This article presents an extension of the HMPC formulation to track periodic harmonic references and discusses its use to track arbitrary references. The proposed formulation inherits the benefits of its predecessor, namely its good performance and large domain of attraction when using small prediction horizons, and that the complexity of its optimization problem does not depend on the period of the periodic reference. We show closed-loop results discussing its performance and comparing it to other MPC formulations.	eess.SY	(11 pages, 14 figures)
2	Assessing the Suitability of the Langevin Equation for Analyzing Measured Data Through Downsampling	Pyei Phyo Lin,Matthias W√§chter,Joachim Peinke,M. Reza Rahimi Tabar	The measured time series from complex systems are renowned for their intricate stochastic behavior, characterized by random fluctuations stemming from external influences and nonlinear interactions. These fluctuations take diverse forms, ranging from continuous trajectories reminiscent of Brownian motion to noncontinuous trajectories featuring jump events. The Langevin equation serves as a powerful tool for generating stochasticity and capturing the complex behavior of measured data with continuous stochastic characteristics. However, the traditional modeling framework of the Langevin equation falls short when it comes to capturing the presence of abrupt changes, particularly jumps, in trajectories that exhibit non-continuity. Such non-continuous changes pose a significant challenge for general processes and have profound implications for risk management. Moreover, the discrete nature of observed physical phenomena, measured with a finite sample rate, adds another layer of complexity. In such cases, data points often appear as a series of discontinuous jumps, even when the underlying trajectory is continuous. In this study, we present an analytical framework that goes beyond the limitations of the Langevin equation. Our approach effectively distinguishes between diffusive or Brownian-type trajectories and trajectories with jumps. By employing downsampling techniques, where we artificially lower the sample rate, we derive a set of measures and criteria to analyze the data and differentiate between diffusive and non-diffusive behaviors. To further demonstrate its versatility and practical applicability, we have applied our proposed method to real-world data in various scientific fields, turbulence, optical tweezers for trapped particles, neuroscience, renewable energy, and market price analysis.	cond-mat.stat-mech	None
3	Giant Gravitons and non-conformal vacua in twisted holography	Kasia Budzik	"Twisted holography relates the two-dimensional chiral algebra subsector of $\mathcal{N}=4$ SYM to the B-model topological string theory on the deformed conifold $SL(2,\mathbb{C})$. We review the relevant aspects of the duality and its two generalizations: the correspondence between determinant operators and ""Giant Graviton"" branes and the extension to non-conformal vacua of the chiral algebra."	hep-th	12 pages, contribution to proceedings of String Math 2022
4	Non-reciprocity permits edge states and strong localization in stochastic topological systems	Aleksandra Nelson,Evelyn Tang	According to the celebrated bulk-boundary correspondence, topological invariants in the bulk yield a system response on the boundary. While this has been established in quantum and other classical systems, we demonstrate that this correspondence operates under different conditions in stochastic systems. Namely, despite sharing the same bulk topological invariant, stochastic systems only exhibit boundary responses in the presence of non-reciprocal (or non-Hermitian) transitions. Indeed, this response in stochastic systems grows dramatically with increasing non-reciprocity but plateaus in quantum systems -- which we demonstrate for two models exhibiting localized probability and steady state currents respectively. For the latter, we propose a novel mechanism by which non-reciprocity engenders the steady-state edge current: it allows the spectrum to spread in complex space thereby decreasing edge-bulk hybridization. Our work highlights the necessity of non-reciprocal interactions in permitting localized dynamics in soft and living matter.	cond-mat.stat-mech	5 pages, 3 figures
5	Rebuild City Buildings from Off-Nadir Aerial Images with Offset-Building Model (OBM)	Kai Li,Yupeng Deng,Yunlong Kong,Diyou Liu,Jingbo Chen,Yu Meng,Junxian Ma	Accurate measurement of the offset from roof-to-footprint in very-high-resolution remote sensing imagery is crucial for urban information extraction tasks. With the help of deep learning, existing methods typically rely on two-stage CNN models to extract regions of interest on building feature maps. At the first stage, a Region Proposal Network (RPN) is applied to extract thousands of ROIs (Region of Interests) which will post-imported into a Region-based Convolutional Neural Networks (RCNN) to extract wanted information. However, because of inflexible RPN, these methods often lack effective user interaction, encounter difficulties in instance correspondence, and struggle to keep up with the advancements in general artificial intelligence. This paper introduces an interactive Transformer model combined with a prompt encoder to precisely extract building segmentation as well as the offset vectors from roofs to footprints. In our model, a powerful module, namely ROAM, was tailored for common problems in predicting roof-to-footprint offsets. We tested our model's feasibility on the publicly available BONAI dataset, achieving a significant reduction in Prompt-Instance-Level offset errors ranging from 14.6% to 16.3%. Additionally, we developed a Distance-NMS algorithm tailored for large-scale building offsets, significantly enhancing the accuracy of predicted building offset angles and lengths in a straightforward and efficient manner. To further validate the model's robustness, we created a new test set using 0.5m remote sensing imagery from Huizhou, China, for inference testing. Our code, training methods, and the updated dataset will be accessable at https://github.com/likaiucas.	cs.CV	24 pages, 9 figures
6	STRAW-b (STRings for Absorption length in Water-b): the second pathfinder mission for the Pacific Ocean Neutrino Experiment	Kilian Holzapfel,Christian Spannfellner,Omid Aghaei,Andrew Baron,Jeanette Bedard,Michael B√∂hmer,Jeff Bosma,Nathan Deis,Christopher Fink,Christian Fruck,Andreas G√§rtner,Roman Gernh√§user,Felix Henningsen,Ryan Hotte,Reyna Jenkyns,Martina Karl,Natascha Khera,Nikhita Khera,Ian Kulin,Alex Lam,Tim Lavallee,Klaus Leism√ºller,Laszlo Papp,Benoit Pirenne,Emily Price,Tom Qiu,Immacolata Carmen Rea,Elisa Resconi,Adrian Round,Carsten Rott,Albert Ruskey,Li Ruohan,Keita Sasaki,Matt Tradewell,Michael Traxler,Daniele Vivolo,Seann Wagner,Eva Laura Winter,Martin Wolf	Since 2018, the potential for a high-energy neutrino telescope, named the Pacific Ocean Neutrino Experiment (P-ONE), has been thoroughly examined by two pathfinder missions, STRAW and STRAW-b, short for short for Strings for Absorption Length in Water. The P-ONE project seeks to install a neutrino detector with a one cubic kilometer volume in the Cascadia Basin's deep marine surroundings, situated near the western shores of Vancouver Island, Canada. To assess the environmental conditions and feasibility of constructing a neutrino detector of that scale, the pathfinder missions, STRAW and STRAW-b, have been deployed at a depth of 2.7 km within the designated site for P-ONE and were connected to the NEPTUNE observatory, operated by Ocean Networks Canada (ONC). While STRAW focused on analyzing the optical properties of water in the Cascadia Basin, \ac{strawb} employed cameras and spectrometers to investigate the characteristics of bioluminescence in the deep-sea environment. This report introduces the STRAW-b concept, covering its scientific objectives and the instrumentation used. Furthermore, it discusses the design considerations implemented to guarantee a secure and dependable deployment process of STRAW-b. Additionally, it showcases the data collected by battery-powered loggers, which monitored the mechanical stress on the equipment throughout the deployment. The report also offers an overview of STRAW-b's operation, with a specific emphasis on the notable advancements achieved in the data acquisition (DAQ) system and its successful integration with the server infrastructure of ONC.	astro-ph.IM	20 pages, 11 figures, 2 tables
7	SkyMath: Technical Report	Liu Yang,Haihua Yang,Wenjun Cheng,Lei Lin,Chenxia Li,Yifu Chen,Lunan Liu,Jianfei Pan,Tianwen Wei,Biye Li,Liang Zhao,Lijie Wang,Bo Zhu,Jujie He,Guoliang Li,Xuejie Wu,Xilin Luo,Rui Hu	Large language models (LLMs) have shown great potential to solve varieties of natural language processing (NLP) tasks, including mathematical reasoning. In this work, we present SkyMath, a large language model for mathematics with 13 billion parameters. By applying self-compare fine-tuning, we have enhanced mathematical reasoning abilities of Skywork-13B-Base remarkably. On GSM8K, SkyMath outperforms all known open-source models of similar size and has established a new SOTA performance.	cs.CL	None
8	LLM Performance Predictors are good initializers for Architecture Search	Ganesh Jawahar,Muhammad Abdul-Mageed,Laks V. S. Lakshmanan,Dujian Ding	Large language models (LLMs) have become an integral component in solving a wide range of NLP tasks. In this work, we explore a novel use case of using LLMs to build performance predictors (PP): models that, given a specific deep neural network architecture, predict its performance on a downstream task. We design PP prompts for LLMs consisting of: (i) role: description of the role assigned to the LLM, (ii) instructions: set of instructions to be followed by the LLM to carry out performance prediction, (iii) hyperparameters: a definition of each architecture-specific hyperparameter and (iv) demonstrations: sample architectures along with their efficiency metrics and 'training from scratch' performance. For machine translation (MT) tasks, we discover that GPT-4 with our PP prompts (LLM-PP) can predict the performance of architecture with a mean absolute error matching the SOTA and a marginal degradation in rank correlation coefficient compared to SOTA performance predictors. Further, we show that the predictions from LLM-PP can be distilled to a small regression model (LLM-Distill-PP). LLM-Distill-PP models surprisingly retain the performance of LLM-PP largely and can be a cost-effective alternative for heavy use cases of performance estimation. Specifically, for neural architecture search (NAS), we propose a Hybrid-Search algorithm for NAS (HS-NAS), which uses LLM-Distill-PP for the initial part of search, resorting to the baseline predictor for rest of the search. We show that HS-NAS performs very similar to SOTA NAS across benchmarks, reduces search hours by 50% roughly, and in some cases, improves latency, GFLOPs, and model size.	cs.CL	None
9	CP-like Symmetry with Discrete and Continuous Groups and CP Violation-Restoration	Hiroshi Ohki,Shohei Uemura	We study physical implications of general CP symmetry including CP-like symmetry. Various scattering amplitudes of CP asymmetry are calculated in CP-like symmetric models. We explicitly show that the CP-like transformation leads to a specific relation between different CP asymmetries. The resultant relation is similar to the one obtained in GUT baryogenesis and sphaleron processes, where we also obtain a required condition for generating particle number asymmetry in CP-like symmetric models. In addition, we propose a generalization of a CP-like transformation for continuous symmetry groups. Since the CP transformation is an outer automorphism, which depends on the internal symmetry group, it turns out that the physical CP and CP-like symmetries can be mutually converted through the spontaneous symmetry breaking (SSB) of the internal symmetry. We investigate properties of physical CP asymmetry in both CP and CP-like symmetric phases, and find that the spontaneous CP violation and restoration can be observed even in models with continuous groups. We demonstrate that CP-like symmetric models with continuous Lie groups can be naturally realized in physical CP symmetric models through the SSB.	hep-ph	50 pages, 1 figure
0	Existence and uniqueness of slightly compressible Boussinesq's flow in Darcy-B√©nard problem	Giuseppe Arnone,Florinda Capone	In the present paper, we study the existence, uniqueness and behaviour in time of the solutions to the Darcy-B\'enard problem for an extended-quasi-thermal-incompressible fluid-saturated porous medium uniformly heated from below. Unlike the classical problem, where the compressibility factor of the fluid vanishes, in this paper we allow the fluid to be slightly compressible and we address the well-posedness analysis for the full nonlinear initial boundary value problem for the perturbed system of governing equations modelling the convection in porous media phenomenon.	math.AP	None
1	Nighttime Driver Behavior Prediction Using Taillight Signal Recognition via CNN-SVM Classifier	Amir Hossein Barshooi,Elmira Bagheri	This paper aims to enhance the ability to predict nighttime driving behavior by identifying taillights of both human-driven and autonomous vehicles. The proposed model incorporates a customized detector designed to accurately detect front-vehicle taillights on the road. At the beginning of the detector, a learnable pre-processing block is implemented, which extracts deep features from input images and calculates the data rarity for each feature. In the next step, drawing inspiration from soft attention, a weighted binary mask is designed that guides the model to focus more on predetermined regions. This research utilizes Convolutional Neural Networks (CNNs) to extract distinguishing characteristics from these areas, then reduces dimensions using Principal Component Analysis (PCA). Finally, the Support Vector Machine (SVM) is used to predict the behavior of the vehicles. To train and evaluate the model, a large-scale dataset is collected from two types of dash-cams and Insta360 cameras from the rear view of Ford Motor Company vehicles. This dataset includes over 12k frames captured during both daytime and nighttime hours. To address the limited nighttime data, a unique pixel-wise image processing technique is implemented to convert daytime images into realistic night images. The findings from the experiments demonstrate that the proposed methodology can accurately categorize vehicle behavior with 92.14% accuracy, 97.38% specificity, 92.09% sensitivity, 92.10% F1-measure, and 0.895 Cohen's Kappa Statistic. Further details are available at https://github.com/DeepCar/Taillight_Recognition.	cs.CV	12 pages, 10 figures
2	No-Arbitrage Deep Calibration for Volatility Smile and Skewness	Kentaro Hoshisashi,Carolyn E. Phelan,Paolo Barucca	Volatility smile and skewness are two key properties of option prices that are represented by the implied volatility (IV) surface. However, IV surface calibration through nonlinear interpolation is a complex problem due to several factors, including limited input data, low liquidity, and noise. Additionally, the calibrated surface must obey the fundamental financial principle of the absence of arbitrage, which can be modeled by various differential inequalities over the partial derivatives of the option price with respect to the expiration time and the strike price. To address these challenges, we have introduced a Derivative-Constrained Neural Network (DCNN), which is an enhancement of a multilayer perceptron (MLP) that incorporates derivatives in the output function. DCNN allows us to generate a smooth surface and incorporate the no-arbitrage condition thanks to the derivative terms in the loss function. In numerical experiments, we apply the stochastic volatility model with smile and skewness parameters and simulate it with different settings to examine the stability of the calibrated model under different conditions. The results show that DCNNs improve the interpolation of the implied volatility surface with smile and skewness by integrating the computation of the derivatives, which are necessary and sufficient no-arbitrage conditions. The developed algorithm also offers practitioners an effective tool for understanding expected market dynamics and managing risk associated with volatility smile and skewness.	q-fin.CP	9 pages, 7 figures
3	Causal Discovery with Generalized Linear Models through Peeling Algorithms	Minjie Wang,Xiaotong Shen,Wei Pan	This article presents a novel method for causal discovery with generalized structural equation models suited for analyzing diverse types of outcomes, including discrete, continuous, and mixed data. Causal discovery often faces challenges due to unmeasured confounders that hinder the identification of causal relationships. The proposed approach addresses this issue by developing two peeling algorithms (bottom-up and top-down) to ascertain causal relationships and valid instruments. This approach first reconstructs a super-graph to represent ancestral relationships between variables, using a peeling algorithm based on nodewise GLM regressions that exploit relationships between primary and instrumental variables. Then, it estimates parent-child effects from the ancestral relationships using another peeling algorithm while deconfounding a child's model with information borrowed from its parents' models. The article offers a theoretical analysis of the proposed approach, which establishes conditions for model identifiability and provides statistical guarantees for accurately discovering parent-child relationships via the peeling algorithms. Furthermore, the article presents numerical experiments showcasing the effectiveness of our approach in comparison to state-of-the-art structure learning methods without confounders. Lastly, it demonstrates an application to Alzheimer's disease (AD), highlighting the utility of the method in constructing gene-to-gene and gene-to-disease regulatory networks involving Single Nucleotide Polymorphisms (SNPs) for healthy and AD subjects.	stat.ME	None
4	Interpretable time series neural representation for classification purposes	Etienne Le Naour,Ghislain Agoua,Nicolas Baskiotis,Vincent Guigue	Deep learning has made significant advances in creating efficient representations of time series data by automatically identifying complex patterns. However, these approaches lack interpretability, as the time series is transformed into a latent vector that is not easily interpretable. On the other hand, Symbolic Aggregate approximation (SAX) methods allow the creation of symbolic representations that can be interpreted but do not capture complex patterns effectively. In this work, we propose a set of requirements for a neural representation of univariate time series to be interpretable. We propose a new unsupervised neural architecture that meets these requirements. The proposed model produces consistent, discrete, interpretable, and visualizable representations. The model is learned independently of any downstream tasks in an unsupervised setting to ensure robustness. As a demonstration of the effectiveness of the proposed model, we propose experiments on classification tasks using UCR archive datasets. The obtained results are extensively compared to other interpretable models and state-of-the-art neural representation learning models. The experiments show that the proposed model yields, on average better results than other interpretable approaches on multiple datasets. We also present qualitative experiments to asses the interpretability of the approach.	cs.LG	International Conference on Data Science and Advanced Analytics   (DSAA) 2023
5	From Pointwise to Powerhouse: Initialising Neural Networks with Generative Models	Christian Harder,Moritz Fuchs,Yuri Tolkach,Anirban Mukhopadhyay	Traditional initialisation methods, e.g. He and Xavier, have been effective in avoiding the problem of vanishing or exploding gradients in neural networks. However, they only use simple pointwise distributions, which model one-dimensional variables. Moreover, they ignore most information about the architecture and disregard past training experiences. These limitations can be overcome by employing generative models for initialisation. In this paper, we introduce two groups of new initialisation methods. First, we locally initialise weight groups by employing variational autoencoders. Secondly, we globally initialise full weight sets by employing graph hypernetworks. We thoroughly evaluate the impact of the employed generative models on state-of-the-art neural networks in terms of accuracy, convergence speed and ensembling. Our results show that global initialisations result in higher accuracy and faster initial convergence speed. However, the implementation through graph hypernetworks leads to diminished ensemble performance on out of distribution data. To counteract, we propose a modification called noise graph hypernetwork, which encourages diversity in the produced ensemble members. Furthermore, our approach might be able to transfer learned knowledge to different image distributions. Our work provides insights into the potential, the trade-offs and possible modifications of these new initialisation methods.	cs.CV	None
6	DSAM-GN:Graph Network based on Dynamic Similarity Adjacency Matrices for Vehicle Re-identification	Yuejun Jiao,Song Qiu,Mingsong Chen,Dingding Han,Qingli Li,Yue Lu	In recent years, vehicle re-identification (Re-ID) has gained increasing importance in various applications such as assisted driving systems, traffic flow management, and vehicle tracking, due to the growth of intelligent transportation systems. However, the presence of extraneous background information and occlusions can interfere with the learning of discriminative features, leading to significant variations in the same vehicle image across different scenarios. This paper proposes a method, named graph network based on dynamic similarity adjacency matrices (DSAM-GN), which incorporates a novel approach for constructing adjacency matrices to capture spatial relationships of local features and reduce background noise. Specifically, the proposed method divides the extracted vehicle features into different patches as nodes within the graph network. A spatial attention-based similarity adjacency matrix generation (SASAMG) module is employed to compute similarity matrices of nodes, and a dynamic erasure operation is applied to disconnect nodes with low similarity, resulting in similarity adjacency matrices. Finally, the nodes and similarity adjacency matrices are fed into graph networks to extract more discriminative features for vehicle Re-ID. Experimental results on public datasets VeRi-776 and VehicleID demonstrate the effectiveness of the proposed method compared with recent works.	cs.CV	This paper has been accepted by the 20th Pacific Rim International   Conference on Artificial Intelligence in 2023
7	Long term behavior of the stirred vacuum on a Dirac chain: geometry blur and the random Slater ensemble	Jos√© Vinaixa,Bego√±a Mula,Alfredo Dea√±o,Silvia N. Santalla,Javier Rodr√≠guez-Laguna	We characterize the long-term state of the 1D Dirac vacuum stirred by an impenetrable object, modeled as the ground state of a finite free-fermionic chain dynamically perturbed by a moving classical obstacle which suppresses the local hopping amplitudes. We find two different regimes, depending on the velocity of the obstacle. For a slow motion, the effective Floquet Hamiltonian presents features which are typical of the Gaussian orthogonal ensemble, and the occupation of the Floquet modes becomes roughly homogeneous. Moreover, the long term entanglement entropy of a contiguous block follows a Gaussian analogue of Page's law, i.e. a volumetric behavior. Indeed, the statistical properties of the reduced density matrices correspond to those of a random Slater determinant, which can be described using the Jacobi ensemble from random matrix theory. On the other hand, if the obstacle moves fast enough, the effective Floquet Hamiltonian presents a Poissonian behavior. The nature of the transition is clarified by the entanglement links, which determine the effective geometry underlying the entanglement structure, showing that the one-dimensionality of the physical Hamiltonian dissolves into a random adjacency matrix as we slow down the obstacle motion.	quant-ph	None
8	Field-Theory of Active Chiral Hard Disks: A First-Principles Approach to Steric Interactions	Erik Kalz,Abhinav Sharma,Ralf Metzler	A first-principles approach for active chiral hard disks is presented, that explicitly accounts for steric interactions on the two-body level. We derive an effective one-body equation for the joint probability distribution of positions and angles of the particles. By projecting on the angular modes, we write a hierarchy for the lowest hydrodynamic modes, i.e. particle density, polarization, and nematic tensor. By undimensionalising the equations, we highlight the assumptions, which - though inherent - are often included implicit in closing the hierarchy for finally arriving at an effective field-theoretical equation for the particle density. By considering different regimes of the P{\'e}clet number, the well-known models in active matter can be obtained through our conisderation. Explicitly, we derive the phenomenological Model B and by going to higher orders in the closure scheme, we show that this first-principles approach results in the recently introduced Active Model B +, a natural extension of the Model B for active processes. Remarkably, here we find that chirality can change the sign of the phenomonological activity parameters.	cond-mat.stat-mech	None
9	Dynamic treatment effect phenotyping through functional survival analysis	Caterina Gregorio,Giovanni Baj,Giulia Barbati,Francesca Ieva	In recent years, research interest in personalised treatments has been growing. However, treatment effect heterogeneity and possibly time-varying treatment effects are still often overlooked in clinical studies. Statistical tools are needed for the identification of treatment response patterns, taking into account that treatment response is not constant over time. We aim to provide an innovative method to obtain dynamic treatment effect phenotypes on a time-to-event outcome, conditioned on a set of relevant effect modifiers. The proposed method does not require the assumption of proportional hazards for the treatment effect, which is rarely realistic. We propose a spline-based survival neural network, inspired by the Royston-Parmar survival model, to estimate time-varying conditional treatment effects. We then exploit the functional nature of the resulting estimates to apply a functional clustering of the treatment effect curves in order to identify different patterns of treatment effects. The application that motivated this work is the discontinuation of treatment with Mineralocorticoid receptor Antagonists (MRAs) in patients with heart failure, where there is no clear evidence as to which patients it is the safest choice to discontinue treatment and, conversely, when it leads to a higher risk of adverse events. The data come from an electronic health record database. A simulation study was performed to assess the performance of the spline-based neural network and the stability of the treatment response phenotyping procedure. We provide a novel method to inform individualized medical decisions by characterising subject-specific treatment responses over time.	stat.ME	None
0	Learning-based adaption of robotic friction models	Philipp Scholl,Maged Iskandar,Sebastian Wolf,Jinoh Lee,Aras Bacho,Alexander Dietrich,Alin Albu-Sch√§ffer,Gitta Kutyniok	In the Fourth Industrial Revolution, wherein artificial intelligence and the automation of machines occupy a central role, the deployment of robots is indispensable. However, the manufacturing process using robots, especially in collaboration with humans, is highly intricate. In particular, modeling the friction torque in robotic joints is a longstanding problem due to the lack of a good mathematical description. This motivates the usage of data-driven methods in recent works. However, model-based and data-driven models often exhibit limitations in their ability to generalize beyond the specific dynamics they were trained on, as we demonstrate in this paper. To address this challenge, we introduce a novel approach based on residual learning, which aims to adapt an existing friction model to new dynamics using as little data as possible. We validate our approach by training a base neural network on a symmetric friction data set to learn an accurate relation between the velocity and the friction torque. Subsequently, to adapt to more complex asymmetric settings, we train a second network on a small dataset, focusing on predicting the residual of the initial network's output. By combining the output of both networks in a suitable manner, our proposed estimator outperforms the conventional model-based approach and the base neural network significantly. Furthermore, we evaluate our method on trajectories involving external loads and still observe a substantial improvement, approximately 60-70\%, over the conventional approach. Our method does not rely on data with external load during training, eliminating the need for external torque sensors. This demonstrates the generalization capability of our approach, even with a small amount of data-only 43 seconds of a robot movement-enabling adaptation to diverse scenarios based on prior knowledge about friction in different settings.	cs.RO	None
1	Dynamics Generalisation in Reinforcement Learning via Adaptive Context-Aware Policies	Michael Beukman,Devon Jarvis,Richard Klein,Steven James,Benjamin Rosman	While reinforcement learning has achieved remarkable successes in several domains, its real-world application is limited due to many methods failing to generalise to unfamiliar conditions. In this work, we consider the problem of generalising to new transition dynamics, corresponding to cases in which the environment's response to the agent's actions differs. For example, the gravitational force exerted on a robot depends on its mass and changes the robot's mobility. Consequently, in such cases, it is necessary to condition an agent's actions on extrinsic state information and pertinent contextual information reflecting how the environment responds. While the need for context-sensitive policies has been established, the manner in which context is incorporated architecturally has received less attention. Thus, in this work, we present an investigation into how context information should be incorporated into behaviour learning to improve generalisation. To this end, we introduce a neural network architecture, the Decision Adapter, which generates the weights of an adapter module and conditions the behaviour of an agent on the context information. We show that the Decision Adapter is a useful generalisation of a previously proposed architecture and empirically demonstrate that it results in superior generalisation performance compared to previous approaches in several environments. Beyond this, the Decision Adapter is more robust to irrelevant distractor variables than several alternative methods.	cs.AI	Accepted to NeurIPS 2023
2	Detection of news written by the ChatGPT through authorship attribution performed by a Bidirectional LSTM model	Amanda Ferrari Iaquinta,Gustavo Voltani von Atzingen	The large language based-model chatbot ChatGPT gained a lot of popularity since its launch and has been used in a wide range of situations. This research centers around a particular situation, when the ChatGPT is used to produce news that will be consumed by the population, causing the facilitation in the production of fake news, spread of misinformation and lack of trust in news sources. Aware of these problems, this research aims to build an artificial intelligence model capable of performing authorship attribution on news articles, identifying the ones written by the ChatGPT. To achieve this goal, a dataset containing equal amounts of human and ChatGPT written news was assembled and different natural processing language techniques were used to extract features from it that were used to train, validate and test three models built with different techniques. The best performance was produced by the Bidirectional Long Short Term Memory (LSTM) Neural Network model, achiving 91.57\% accuracy when tested against the data from the testing set.	cs.CL	None
3	Local Statistics for Generative Image Detection	Yung Jer Wong,Teck Khim Ng	Diffusion models (DMs) are generative models that learn to synthesize images from Gaussian noise. DMs can be trained to do a variety of tasks such as image generation and image super-resolution. Researchers have made significant improvement in the capability of synthesizing photorealistic images in the past few years. These successes also hasten the need to address the potential misuse of synthesized images. In this paper, we highlight the effectiveness of computing local statistics, as opposed to global statistics, in distinguishing digital camera images from DM-generated images. We hypothesized that local statistics should be used to address the spatial non-stationarity problem in images. We show that our approach produced promising results and it is also robust to various perturbations such as image resizing and JPEG compression.	cs.CV	None
4	Fracton infrared triangle	Alfredo P√©rez,Stefan Prohazka,Ali Seraj	In theories with conserved dipole moment, isolated charged particles (fractons) are immobile, but dipoles can move. We couple these dipoles to the fracton gauge theory and analyze the universal infrared structure. This uncovers an observable double kick memory effect which we relate to a novel dipole soft theorem. Together with their asymptotic symmetries this constitutes the first realization of an infrared triangle beyond Lorentz symmetry. This demonstrates the robustness of these IR structures and paves the way for their investigation in condensed matter systems and beyond.	hep-th	8+2 pages, 2 figures
5	Competing Gauge Fields and Entropically-Driven Spin Liquid to Spin Liquid Transition in non-Kramers Pyrochlores	Daniel Lozano-G√≥mez,Vincent Noculak,Jaan Oitmaa,Rajiv R. P. Singh,Yasir Iqbal,Johannes Reuther,Michel J. P. Gingras	Gauge theories are powerful tools in theoretical physics, allowing complex phenomena to be reduced to simple principles, and are used in both high-energy and condensed matter physics. In the latter context, gauge theories are becoming increasingly popular for capturing the intricate spin correlations in spin liquids, exotic states of matter in which the dynamics of quantum spins never ceases, even at absolute zero temperature. We consider a spin system on a three-dimensional pyrochlore lattice where emergent gauge fields not only describe the spin liquid behaviour at zero temperature but crucially determine the system's temperature evolution, with distinct gauge fields giving rise to different spin liquid phases in separate temperature regimes. Focusing first on classical spins, in an intermediate temperature regime, the system shows an unusual coexistence of emergent vector and matrix gauge fields where the former is known from classical spin ice systems while the latter has been associated with fractonic quasiparticles, a peculiar type of excitation with restricted mobility. Upon cooling, the system transitions into a low-temperature phase where an entropic selection mechanism depopulates the degrees of freedom associated with the matrix gauge field, rendering the system spin ice like. We further provide numerical evidence that in the corresponding quantum model, a spin liquid with coexisting vector and matrix gauge fields has a finite window of stability in the parameter space of spin interactions down to zero temperature. Finally, we discuss the relevance of our findings for non-Kramers pyrochlore materials.	cond-mat.str-el	13 pages, 5 figures
6	BabyStories: Can Reinforcement Learning Teach Baby Language Models to Write Better Stories?	Xingmeng Zhao,Tongnian Wang,Sheri Osborn,Anthony Rios	Language models have seen significant growth in the size of their corpus, leading to notable performance improvements. Yet, there has been limited progress in developing models that handle smaller, more human-like datasets. As part of the BabyLM shared task, this study explores the impact of reinforcement learning from human feedback (RLHF) on language models pretrained from scratch with a limited training corpus. Comparing two GPT-2 variants, the larger model performs better in storytelling tasks after RLHF fine-tuning. These findings suggest that RLHF techniques may be more advantageous for larger models due to their higher learning and adaptation capacity, though more experiments are needed to confirm this finding. These insights highlight the potential benefits of RLHF fine-tuning for language models within limited data, enhancing their ability to maintain narrative focus and coherence while adhering better to initial instructions in storytelling tasks. The code for this work is publicly at https://github.com/Zephyr1022/BabyStories-UTSA.	cs.CL	Accepted to BabyLM workshop at CoNLL
7	Robust and Actively Secure Serverless Collaborative Learning	Olive Franzese,Adam Dziedzic,Christopher A. Choquette-Choo,Mark R. Thomas,Muhammad Ahmad Kaleem,Stephan Rabanser,Congyu Fang,Somesh Jha,Nicolas Papernot,Xiao Wang	Collaborative machine learning (ML) is widely used to enable institutions to learn better models from distributed data. While collaborative approaches to learning intuitively protect user data, they remain vulnerable to either the server, the clients, or both, deviating from the protocol. Indeed, because the protocol is asymmetric, a malicious server can abuse its power to reconstruct client data points. Conversely, malicious clients can corrupt learning with malicious updates. Thus, both clients and servers require a guarantee when the other cannot be trusted to fully cooperate. In this work, we propose a peer-to-peer (P2P) learning scheme that is secure against malicious servers and robust to malicious clients. Our core contribution is a generic framework that transforms any (compatible) algorithm for robust aggregation of model updates to the setting where servers and clients can act maliciously. Finally, we demonstrate the computational efficiency of our approach even with 1-million parameter models trained by 100s of peers on standard datasets.	cs.LG	Accepted at NeurIPS 2023
8	SSLCL: An Efficient Model-Agnostic Supervised Contrastive Learning Framework for Emotion Recognition in Conversations	Tao Shi,Xiao Liang,Yaoyuan Liang,Xinyi Tong,Shao-Lun Huang	Emotion recognition in conversations (ERC) is a rapidly evolving task within the natural language processing community, which aims to detect the emotions expressed by speakers during a conversation. Recently, a growing number of ERC methods have focused on leveraging supervised contrastive learning (SCL) to enhance the robustness and generalizability of learned features. However, current SCL-based approaches in ERC are impeded by the constraint of large batch sizes and the lack of compatibility with most existing ERC models. To address these challenges, we propose an efficient and model-agnostic SCL framework named Supervised Sample-Label Contrastive Learning with Soft-HGR Maximal Correlation (SSLCL), which eliminates the need for a large batch size and can be seamlessly integrated with existing ERC models without introducing any model-specific assumptions. Specifically, we introduce a novel perspective on utilizing label representations by projecting discrete labels into dense embeddings through a shallow multilayer perceptron, and formulate the training objective to maximize the similarity between sample features and their corresponding ground-truth label embeddings, while minimizing the similarity between sample features and label embeddings of disparate classes. Moreover, we innovatively adopt the Soft-HGR maximal correlation as a measure of similarity between sample features and label embeddings, leading to significant performance improvements over conventional similarity measures. Additionally, multimodal cues of utterances are effectively leveraged by SSLCL as data augmentations to boost model performances. Extensive experiments on two ERC benchmark datasets, IEMOCAP and MELD, demonstrate the compatibility and superiority of our proposed SSLCL framework compared to existing state-of-the-art SCL methods. Our code is available at \url{https://github.com/TaoShi1998/SSLCL}.	cs.CL	None
9	Agreeing to Stop: Reliable Latency-Adaptive Decision Making via Ensembles of Spiking Neural Networks	Jiechen Chen,Sangwoo Park,Osvaldo Simeone	Spiking neural networks (SNNs) are recurrent models that can leverage sparsity in input time series to efficiently carry out tasks such as classification. Additional efficiency gains can be obtained if decisions are taken as early as possible as a function of the complexity of the input time series. The decision on when to stop inference and produce a decision must rely on an estimate of the current accuracy of the decision. Prior work demonstrated the use of conformal prediction (CP) as a principled way to quantify uncertainty and support adaptive-latency decisions in SNNs. In this paper, we propose to enhance the uncertainty quantification capabilities of SNNs by implementing ensemble models for the purpose of improving the reliability of stopping decisions. Intuitively, an ensemble of multiple models can decide when to stop more reliably by selecting times at which most models agree that the current accuracy level is sufficient. The proposed method relies on different forms of information pooling from ensemble models, and offers theoretical reliability guarantees. We specifically show that variational inference-based ensembles with p-variable pooling significantly reduce the average latency of state-of-the-art methods, while maintaining reliability guarantees.	cs.NE	Under review
0	Connecting Exceptional Orthogonal Polynomials of Different Kind	Christiane Quesne	The known asymptotic relations interconnecting Jacobi, Laguerre, and Hermite classical orthogonal polynomials are generalized to the corresponding exceptional orthogonal polynomials of codimension $m$. It is proved that $X_m$-Laguerre exceptional orthogonal polynomials of type I, II, or III can be obtained as limits of $X_m$-Jacobi exceptional orthogonal polynomials of the same type. Similarly, $X_m$-Hermite exceptional orthogonal polynomials of type III can be derived from $X_m$-Jacobi or $X_m$-Laguerre ones. The quadratic transformations expressing Hermite classical orthogonal polynomials in terms of Laguerre ones is also extended to even $X_{2m}$-Hermite exceptional orthogonal polynomials.	math.CA	14 pages, no figure
1	Exploring Large Language Models for Code Explanation	Paheli Bhattacharya,Manojit Chakraborty,Kartheek N S N Palepu,Vikas Pandey,Ishan Dindorkar,Rakesh Rajpurohit,Rishabh Gupta	Automating code documentation through explanatory text can prove highly beneficial in code understanding. Large Language Models (LLMs) have made remarkable strides in Natural Language Processing, especially within software engineering tasks such as code generation and code summarization. This study specifically delves into the task of generating natural-language summaries for code snippets, using various LLMs. The findings indicate that Code LLMs outperform their generic counterparts, and zero-shot methods yield superior results when dealing with datasets with dissimilar distributions between training and testing sets.	cs.SE	Accepted at the Forum for Information Retrieval Evaluation 2023 (IRSE   Track)
2	Relativistic disks by Appell-ring convolutions	David Kofro≈à,Petr Kotla≈ô√≠k,Old≈ôich Semer√°k	We present a new method for generating the gravitational field of thin disks within the Weyl class of static and axially symmetric spacetimes. Such a gravitational field is described by two metric functions: one satisfies the Laplace equation and represents the gravitational potential, while the other is determined by line integration. We show how to obtain analytic thin-disk solutions by convolving a certain weight function -- an Abel transformation of the physical surface-density profile -- with the Appell-ring potential. We thus re-derive several known thin-disk solutions while, in some cases, completing the metric by explicitly computing the second metric function. Additionally, we obtain the total gravitational field of several superpositions of a disk with the Schwarzschild black hole. While the superposition problem is simple (linear) for the potential, it is mostly not such for the second metric function. However, in particular cases, both metric functions of the superposition can be found explicitly. Finally, we discuss a simpler procedure which yields the potentials of power-law-density disks we studied recently.	gr-qc	"20 pages, 4 figures, supplemental material is provided in the   ancillary Mathematica notebook ""holeyMorganMorganDisks.nb"" and the MX file   ""holeyMorganMorganDisks.mx"""
3	CoDet: Co-Occurrence Guided Region-Word Alignment for Open-Vocabulary Object Detection	Chuofan Ma,Yi Jiang,Xin Wen,Zehuan Yuan,Xiaojuan Qi	Deriving reliable region-word alignment from image-text pairs is critical to learn object-level vision-language representations for open-vocabulary object detection. Existing methods typically rely on pre-trained or self-trained vision-language models for alignment, which are prone to limitations in localization accuracy or generalization capabilities. In this paper, we propose CoDet, a novel approach that overcomes the reliance on pre-aligned vision-language space by reformulating region-word alignment as a co-occurring object discovery problem. Intuitively, by grouping images that mention a shared concept in their captions, objects corresponding to the shared concept shall exhibit high co-occurrence among the group. CoDet then leverages visual similarities to discover the co-occurring objects and align them with the shared concept. Extensive experiments demonstrate that CoDet has superior performances and compelling scalability in open-vocabulary detection, e.g., by scaling up the visual backbone, CoDet achieves 37.0 $\text{AP}^m_{novel}$ and 44.7 $\text{AP}^m_{all}$ on OV-LVIS, surpassing the previous SoTA by 4.2 $\text{AP}^m_{novel}$ and 9.8 $\text{AP}^m_{all}$. Code is available at https://github.com/CVMI-Lab/CoDet.	cs.CV	Accepted by NeurIPS 2023
4	Robust Source-Free Domain Adaptation for Fundus Image Segmentation	Lingrui Li,Yanfeng Zhou,Ge Yang	Unsupervised Domain Adaptation (UDA) is a learning technique that transfers knowledge learned in the source domain from labelled training data to the target domain with only unlabelled data. It is of significant importance to medical image segmentation because of the usual lack of labelled training data. Although extensive efforts have been made to optimize UDA techniques to improve the ac?curacy of segmentation models in the target domain, few studies have addressed the robustness of these models under UDA. In this study, we propose a two-stage training strat?egy for robust domain adaptation. In the source training stage, we utilize adversarial sample augmentation to en?hance the robustness and generalization capability of the source model. And in the target training stage, we propose a novel robust pseudo-label and pseudo-boundary (PLPB) method, which effectively utilizes unlabeled target data to generate pseudo labels and pseudo boundaries that enable model self-adaptation without requiring source data. Ex?tensive experimental results on cross-domain fundus image segmentation confirm the effectiveness and versatility of our method. Source code of this study is openly accessible at https://github.com/LinGrayy/PLPB.	cs.CV	10 pages, WACV2024
5	Mapping Observations of Peptide-like molecules around Sagittarius B2	Siqi Zheng,Juan Li,Junzhi Wang,Yao Wang,Feng Gao,Donghui Quan,Fujun Du,Yajun Wu,Edwin Bergin,Yuqiang Li	Peptide-like molecule, which has a close connection with the origin of life, has been detected in universe. Mapping observations of HCONH$_2$ and CH$_3$CONH$_2$, two simplest peptide-like molecules, are performed towards Sagittarius B2 (Sgr B2) complex with the IRAM 30m telescope. Seven transitions of HCONH$_2$ and five transitions of CH$_3$CONH$_2$ are used in analysis. The spatial distribution of excitation temperature and column density of HCONH$_2$ in the molecular envelope of Sgr B2 are obtained by the rotation diagrams. Assuming the same excitation temperature as HCONH$_2$, the column densities of CH$_3$CONH$_2$ are also calculated. The results show that excitation temperature ranges from 6 K to 46 K in the molecular envelope of Sgr B2. The abundance ratio between HCONH$_2$ and CH$_3$CONH$_2$ are calculated to explore the relationship among them, as well as HNCO mentioned in our pervious research. The abundance ratio of CH$_3$CONH$_2$/HCONH$_2$ varies from 10% to 20%, while that of HCONH$_2$/HNCO ranges from 1.5% to 10%. CH$_3$CONH$_2$ is enhanced with respect to HCONH$_2$ in the northwest region of Sgr B2. One transition of H$^{13}$CONH$_2$ is detected toward 12 positions of Sgr B2, from which a $^{12}$C/$^{13}$C ratio of 28.7 is obtained. A time-dependent chemical model with a short duration of X-ray burst is used to explain the observed abundances of HCONH$_2$ and CH$_3$CONH$_2$, with the best fitting result at T$\rm_{dust}$ = 53-56 K. More chemical reactions are required to be included into the model since the modeled abundance is lower than the observed one at the observed T$\rm_{dust}$.	astro-ph.GA	None
6	Emergence of multifractality through cascade-like transitions in a mosaic interpolating Aubry-Andr√©-Fibonacci chain	Qi Dai,Zhanpeng Lu,Zhihao Xu	In this paper, we explore the localization features of wave functions in a family of mosaic quasiperiodic chains obtained by continuously interpolating between two limits: the mosaic Aubry-Andr\'{e} (AA) model, known for its exact mobility edges with extended states in the band-center region, and localized ones in the band-edge regions for a large enough modulation amplitude, and the mosaic Fibonacci chain, which exhibits its multifractal nature for all the states except for the extended one with $E=0$ for an arbitrary finite modulation amplitude. We discover that the mosaic AA limit for the states in the band-edge regions evolves into multifractal ones through a cascade of delocalization transitions. This cascade shows lobes of lower fractal dimension values separated by maxima of fractal dimension. In contrast, the states in the band-center region (except for the $E=0$ state) display an anomalous cascading process, where it emerges lobes of higher fractal dimension values are separated by the regions with lower fractal dimensions. Our findings offer insight into understanding the multifractality of quasiperiodic chains.	cond-mat.dis-nn	12 pages, 11 figures
7	Deep Learning Techniques for Cervical Cancer Diagnosis based on Pathology and Colposcopy Images	Hana Ahmadzadeh Sarhangi,Dorsa Beigifard,Elahe Farmani,Hamidreza Bolhasani	Cervical cancer is a prevalent disease affecting millions of women worldwide every year. It requires significant attention, as early detection during the precancerous stage provides an opportunity for a cure. The screening and diagnosis of cervical cancer rely on cytology and colposcopy methods. Deep learning, a promising technology in computer vision, has emerged as a potential solution to improve the accuracy and efficiency of cervical cancer screening compared to traditional clinical inspection methods that are prone to human error. This review article discusses cervical cancer and its screening processes, followed by the Deep Learning training process and the classification, segmentation, and detection tasks for cervical cancer diagnosis. Additionally, we explored the most common public datasets used in both cytology and colposcopy and highlighted the popular and most utilized architectures that researchers have applied to both cytology and colposcopy. We reviewed 24 selected practical papers in this study and summarized them. This article highlights the remarkable efficiency in enhancing the precision and speed of cervical cancer analysis by Deep Learning, bringing us closer to early diagnosis and saving lives.	eess.IV	None
8	The role of atomic interactions in cavity-induced continuous time crystals	Christian H. Johansen,Johannes Lang,Francesco Piazza	We consider continuous time-crystalline phases in dissipative many-body systems of atoms in cavities, focusing on the role of short-range interatomic interactions. First, we show that the latter can alter the nature of the time crystal by changing the type of the underlying critical bifurcation. Second, we characterize the heating mechanism and dynamics resulting from the short-range interactions and demonstrate that they make the time crystal inherently metastable. We argue that this is generic for the broader class of dissipative time crystals in atom-cavity systems whenever the cavity loss rate is comparable to the atomic recoil energy. We observe that such a scenario for heating resembles the one proposed for preheating of the early universe, where the oscillating coherent inflation field decays into a cascade of exponentially growing fluctuations. By extending approaches for dissipative dynamical systems to our many-body problem, we obtain analytical predictions for the parameters describing the phase transition and the heating rate inside the time-crystalline phase. We underpin and extend the analytical predictions of the heating rates with numerical simulations.	cond-mat.quant-gas	None
9	UAV Pathfinding in Dynamic Obstacle Avoidance with Multi-agent Reinforcement Learning	Qizhen Wu,Lei Chen,Kexin Liu,Jinhu Lv	Multi-agent reinforcement learning based methods are significant for online planning of feasible and safe paths for agents in dynamic and uncertain scenarios. Although some methods like fully centralized and fully decentralized methods achieve a certain measure of success, they also encounter problems such as dimension explosion and poor convergence, respectively. In this paper, we propose a novel centralized training with decentralized execution method based on multi-agent reinforcement learning to solve the dynamic obstacle avoidance problem online. In this approach, each agent communicates only with the central planner or only with its neighbors, respectively, to plan feasible and safe paths online. We improve our methods based on the idea of model predictive control to increase the training efficiency and sample utilization of agents. The experimental results in both simulation, indoor, and outdoor environments validate the effectiveness of our method. The video is available at https://www.bilibili.com/video/BV1gw41197hV/?vd_source=9de61aecdd9fb684e546d032ef7fe7bf	cs.RO	None
0	An Online Self-calibrating Refractive Camera Model with Application to Underwater Odometry	Mohit Singh,Mihir Dharmadhikari,Kostas Alexis	This work presents a camera model for refractive media such as water and its application in underwater visual-inertial odometry. The model is self-calibrating in real-time and is free of known correspondences or calibration targets. It is separable as a distortion model (dependent on refractive index $n$ and radial pixel coordinate) and a virtual pinhole model (as a function of $n$). We derive the self-calibration formulation leveraging epipolar constraints to estimate the refractive index and subsequently correct for distortion. Through experimental studies using an underwater robot integrating cameras and inertial sensing, the model is validated regarding the accurate estimation of the refractive index and its benefits for robust odometry estimation in an extended envelope of conditions. Lastly, we show the transition between media and the estimation of the varying refractive index online, thus allowing computer vision tasks across refractive media.	cs.RO	7 pages, 6 figures, Submitted to the IEEE International Conference on   Robotics and Automation, 2024
1	A Picture is Worth a Thousand Words: Principled Recaptioning Improves Image Generation	Eyal Segalis,Dani Valevski,Danny Lumen,Yossi Matias,Yaniv Leviathan	Text-to-image diffusion models achieved a remarkable leap in capabilities over the last few years, enabling high-quality and diverse synthesis of images from a textual prompt. However, even the most advanced models often struggle to precisely follow all of the directions in their prompts. The vast majority of these models are trained on datasets consisting of (image, caption) pairs where the images often come from the web, and the captions are their HTML alternate text. A notable example is the LAION dataset, used by Stable Diffusion and other models. In this work we observe that these captions are often of low quality, and argue that this significantly affects the model's capability to understand nuanced semantics in the textual prompts. We show that by relabeling the corpus with a specialized automatic captioning model and training a text-to-image model on the recaptioned dataset, the model benefits substantially across the board. First, in overall image quality: e.g. FID 14.84 vs. the baseline of 17.87, and 64.3% improvement in faithful image generation according to human evaluation. Second, in semantic alignment, e.g. semantic object accuracy 84.34 vs. 78.90, counting alignment errors 1.32 vs. 1.44 and positional alignment 62.42 vs. 57.60. We analyze various ways to relabel the corpus and provide evidence that this technique, which we call RECAP, both reduces the train-inference discrepancy and provides the model with more information per example, increasing sample efficiency and allowing the model to better understand the relations between captions and images.	cs.CV	None
2	Towards Control-Centric Representations in Reinforcement Learning from Images	Chen Liu,Hongyu Zang,Xin Li,Yong Heng,Yifei Wang,Zhen Fang,Yisen Wang,Mingzhong Wang	Image-based Reinforcement Learning is a practical yet challenging task. A major hurdle lies in extracting control-centric representations while disregarding irrelevant information. While approaches that follow the bisimulation principle exhibit the potential in learning state representations to address this issue, they still grapple with the limited expressive capacity of latent dynamics and the inadaptability to sparse reward environments. To address these limitations, we introduce ReBis, which aims to capture control-centric information by integrating reward-free control information alongside reward-specific knowledge. ReBis utilizes a transformer architecture to implicitly model the dynamics and incorporates block-wise masking to eliminate spatiotemporal redundancy. Moreover, ReBis combines bisimulation-based loss with asymmetric reconstruction loss to prevent feature collapse in environments with sparse rewards. Empirical studies on two large benchmarks, including Atari games and DeepMind Control Suit, demonstrate that ReBis has superior performance compared to existing methods, proving its effectiveness.	cs.LG	None
3	ChatGPT is a Potential Zero-Shot Dependency Parser	Boda Lin,Xinyi Zhou,Binghao Tang,Xiaocheng Gong,Si Li	Pre-trained language models have been widely used in dependency parsing task and have achieved significant improvements in parser performance. However, it remains an understudied question whether pre-trained language models can spontaneously exhibit the ability of dependency parsing without introducing additional parser structure in the zero-shot scenario. In this paper, we propose to explore the dependency parsing ability of large language models such as ChatGPT and conduct linguistic analysis. The experimental results demonstrate that ChatGPT is a potential zero-shot dependency parser, and the linguistic analysis also shows some unique preferences in parsing outputs.	cs.CL	10 pages
4	Adaptive importance sampling for heavy-tailed distributions via $Œ±$-divergence minimization	Thomas Guilmeau,Nicola Branchini,Emilie Chouzenoux,V√≠ctor Elvira	Adaptive importance sampling (AIS) algorithms are widely used to approximate expectations with respect to complicated target probability distributions. When the target has heavy tails, existing AIS algorithms can provide inconsistent estimators or exhibit slow convergence, as they often neglect the target's tail behaviour. To avoid this pitfall, we propose an AIS algorithm that approximates the target by Student-t proposal distributions. We adapt location and scale parameters by matching the escort moments - which are defined even for heavy-tailed distributions - of the target and the proposal. These updates minimize the $\alpha$-divergence between the target and the proposal, thereby connecting with variational inference. We then show that the $\alpha$-divergence can be approximated by a generalized notion of effective sample size and leverage this new perspective to adapt the tail parameter with Bayesian optimization. We demonstrate the efficacy of our approach through applications to synthetic targets and a Bayesian Student-t regression task on a real example with clinical trial data.	stat.CO	None
5	How Robust is Federated Learning to Communication Error? A Comparison Study Between Uplink and Downlink Channels	Linping Qu,Shenghui Song,Chi-Ying Tsui,Yuyi Mao	Because of its privacy-preserving capability, federated learning (FL) has attracted significant attention from both academia and industry. However, when being implemented over wireless networks, it is not clear how much communication error can be tolerated by FL. This paper investigates the robustness of FL to the uplink and downlink communication error. Our theoretical analysis reveals that the robustness depends on two critical parameters, namely the number of clients and the numerical range of model parameters. It is also shown that the uplink communication in FL can tolerate a higher bit error rate (BER) than downlink communication, and this difference is quantified by a proposed formula. The findings and theoretical analyses are further validated by extensive experiments.	cs.LG	Submitted to IEEE for possible publication
6	Dwarf galaxies show little ISM evolution from $z\sim1$ to $z\sim0$: a spectroscopic study of metallicity, star formation, and electron density	John Pharo,Yicheng Guo,Guillermo Barro Calvo,Teja Teppala,Fuyan Bian,Timothy Carleton,Sandra Faber,Puragra Guhathakurta,David C. Koo	We present gas-phase metallicity measurements for 583 emission line galaxies at $0.3<z<0.85$, including 388 dwarf galaxies with $log(M_{\star}/M_{\odot}) < 9.5$, and explore the dependence of the metallicity on the stellar mass and star formation properties of the galaxies. Metallicities are determined through the measurement of emission lines in very deep ($\sim$7 hr exposure) Keck/DEIMOS spectra taken primarily from the HALO7D survey. We measure metallicity with three strong-line calibrations (O3H$\beta$, R23, and O3O2) for the overall sample, as well as with the faint [Ne III]$\lambda$3869 and [O III]$\lambda$4363 emission lines for 112 and 17 galaxies where robust detections were possible. We construct mass-metallicity relations (MZR) for each calibration method, finding MZRs consistent with other strong-line results at comparable redshift, as well as with $z\sim0$ galaxies. We quantify the intrinsic scatter in the MZR as a function of mass, finding it increases with lower stellar mass. We also measure a weak but significant correlation between increased MZR scatter and higher specific star formation rate. We find a weak influence of SFR in the fundamental metallicity relation as well, with an SFR coefficient of $\alpha=0.21$. Finally, we use the flux ratios of the [O II]$\lambda\lambda$3727,3729 doublet to calculate gas electron density in $\sim$1000 galaxies with $log(M_{\star}/M_{\odot}) < 10.5$ as a function of redshift. We measure low electron densities ($n_e\sim25$ cm$^{-3}$) for $z<1$ galaxies, again consistent with $z\approx0$ conditions, but measure higher densities ($n_e\sim100$ cm$^{-3}$) at $z>1$. These results all suggest that there is little evolution in star-forming interstellar medium conditions from $z\sim1$ to $z=0$, confirmed with a more complete sample of low-mass galaxies than has previously been available in this redshift range.	astro-ph.GA	22 pages, 10 figures, accepted to ApJ
7	Data-integration with pseudoweights and survey-calibration: application to developing US-representative lung cancer risk models for use in screening	Lingxiao Wang,Yan Li,Barry Graubard,Hormuzd Katki	Accurate cancer risk estimation is crucial to clinical decision-making, such as identifying high-risk people for screening. However, most existing cancer risk models incorporate data from epidemiologic studies, which usually cannot represent the target population. While population-based health surveys are ideal for making inference to the target population, they typically do not collect time-to-cancer incidence data. Instead, time-to-cancer specific mortality is often readily available on surveys via linkage to vital statistics. We develop calibrated pseudoweighting methods that integrate individual-level data from a cohort and a survey, and summary statistics of cancer incidence from national cancer registries. By leveraging individual-level cancer mortality data in the survey, the proposed methods impute time-to-cancer incidence for survey sample individuals and use survey calibration with auxiliary variables of influence functions generated from Cox regression to improve robustness and efficiency of the inverse-propensity pseudoweighting method in estimating pure risks. We develop a lung cancer incidence pure risk model from the Prostate, Lung, Colorectal, and Ovarian (PLCO) Cancer Screening Trial using our proposed methods by integrating data from the National Health Interview Survey (NHIS) and cancer registries.	stat.ME	None
8	Why does inflation look single field to us?	Koki Tokeshi,Vincent Vennin	Most high-energy constructions that realise a phase of cosmic inflation contain many degrees of freedom. Yet, cosmological observations are all consistent with single-field embeddings. We show how volume selection effects explain this apparent paradox. Due to quantum diffusion, different regions of space inflate by different amounts. In regions that inflate most, and eventually dominate the volume of the universe, a generic mechanism is unveiled that diverts the inflationary dynamics towards single-field attractors. The formalism of constrained stochastic inflation is developed to this end.	astro-ph.CO	5 pages and 2 figures without appendices (total 17 pages, 6 figures)
9	Posterior Consistency for Missing Data in Variational Autoencoders	Timur Sudak,Sebastian Tschiatschek	We consider the problem of learning Variational Autoencoders (VAEs), i.e., a type of deep generative model, from data with missing values. Such data is omnipresent in real-world applications of machine learning because complete data is often impossible or too costly to obtain. We particularly focus on improving a VAE's amortized posterior inference, i.e., the encoder, which in the case of missing data can be susceptible to learning inconsistent posterior distributions regarding the missingness. To this end, we provide a formal definition of posterior consistency and propose an approach for regularizing an encoder's posterior distribution which promotes this consistency. We observe that the proposed regularization suggests a different training objective than that typically considered in the literature when facing missing values. Furthermore, we empirically demonstrate that our regularization leads to improved performance in missing value settings in terms of reconstruction quality and downstream tasks utilizing uncertainty in the latent space. This improved performance can be observed for many classes of VAEs including VAEs equipped with normalizing flows.	cs.LG	First published in ECML PKDD 2023, Proceedings, Part II, by Springer   Nature (https://doi.org/10.1007/978-3-031-43415-0_30). This version of the   work has been extended with the addition of an Appendix, which includes   proofs, the derivation of the posterior regularization, additional background   information on technical topics, an extended related work section, and   additional experimental results
0	Achieving Constraints in Neural Networks: A Stochastic Augmented Lagrangian Approach	Diogo Lavado,Cl√°udia Soares,Alessandra Micheletti	Regularizing Deep Neural Networks (DNNs) is essential for improving generalizability and preventing overfitting. Fixed penalty methods, though common, lack adaptability and suffer from hyperparameter sensitivity. In this paper, we propose a novel approach to DNN regularization by framing the training process as a constrained optimization problem. Where the data fidelity term is the minimization objective and the regularization terms serve as constraints. Then, we employ the Stochastic Augmented Lagrangian (SAL) method to achieve a more flexible and efficient regularization mechanism. Our approach extends beyond black-box regularization, demonstrating significant improvements in white-box models, where weights are often subject to hard constraints to ensure interpretability. Experimental results on image-based classification on MNIST, CIFAR10, and CIFAR100 datasets validate the effectiveness of our approach. SAL consistently achieves higher Accuracy while also achieving better constraint satisfaction, thus showcasing its potential for optimizing DNNs under constrained settings.	cs.LG	None
1	Model predictive control-based value estimation for efficient reinforcement learning	Qizhen Wu,Kexin Liu,Lei Chen	Reinforcement learning suffers from limitations in real practices primarily due to the numbers of required interactions with virtual environments. It results in a challenging problem that we are implausible to obtain an optimal strategy only with a few attempts for many learning method. Hereby, we design an improved reinforcement learning method based on model predictive control that models the environment through a data-driven approach. Based on learned environmental model, it performs multi-step prediction to estimate the value function and optimize the policy. The method demonstrates higher learning efficiency, faster convergent speed of strategies tending to the optimal value, and fewer sample capacity space required by experience replay buffers. Experimental results, both in classic databases and in a dynamic obstacle avoidance scenario for unmanned aerial vehicle, validate the proposed approaches.	cs.LG	None
2	Weak Solutions to the Degenerate Viscous Cahn-Hilliard Equation	Toai Luong	The Cahn--Hilliard equation is a common model to describe phase separation processes of a mixture of two components. In this paper, we study the viscous Cahn--Hilliard equation with degenerate phase-dependent mobility. We define a notion of weak solutions and prove the existence of such weak solutions by considering the limits of the viscous Cahn--Hilliard equation with positive mobility. Also, we prove that such weak solutions satisfy an energy dissipation inequality under some additional conditions.	math.AP	None
3	Angular Location of the $n^{th}$ Einstein Ring at large $n$	Spandan Minwalla	We perform a matched asymptotic expansion to find an analytic formula for the trajectory of a light ray in a Schwarzschild metric, in a power series expansion in the deviation of the impact parameter from its critical value. We present results valid to second sub leading order in this expansion. We use these results to find an analytic expansion for the angular location of the $n^{th}$ Einstein Ring (at large $n$) resulting from a star that lies directly behind a black hole but not necessarily far from it. The small parameter for this expansion is $e^{-\pi (2n+1) }$: our formulae are accurate to third order in this parameter.	gr-qc	32 Pages, 15 figures
4	Fully Eulerian models for the numerical simulation of capsules with an elastic bulk nucleus	Florian Desmons,Thomas Milcent,Anne-Virginie Salsac,Mirco Ciallella	In this paper, we present a computational framework based on fully Eulerian models for fluid-structure interaction for the numerical simulation of biological capsules. The flexibility of such models, given by the Eulerian treatment of the interface and deformations, allows us to easily deal with the large deformations experienced by the capsule. The modeling of the membrane is based on the full membrane elasticity model introduced in (Milcent, T., Maitre, E. (2016)) that is capable of capturing both area and shear variations thanks to the so-called backward characteristics. In the validation section several test cases are presented with the goal of comparing our results to others present in the literature. In this part, the comparisons are done with different well-known configurations (capsule in shear flow and square-section channel), and by deepening the effect of the elastic constitutive law and capillary number on the membrane dynamics. Finally, to show the potential of this framework we introduce a new test case that describes the relaxation of a capsule in an opening channel. In order to increase the challenges of this test we study the influence of an internal nucleus, modeled as a hyperelastic solid, on the membrane evolution. Several numerical simulations are presented to deeply study its influence by modifying the characteristic parameters of the nucleus (size and elastic parameter).	physics.flu-dyn	None
5	EmoCLIP: A Vision-Language Method for Zero-Shot Video Facial Expression Recognition	Niki Maria Foteinopoulou,Ioannis Patras	Facial Expression Recognition (FER) is a crucial task in affective computing, but its conventional focus on the seven basic emotions limits its applicability to the complex and expanding emotional spectrum. To address the issue of new and unseen emotions present in dynamic in-the-wild FER, we propose a novel vision-language model that utilises sample-level text descriptions (i.e. captions of the context, expressions or emotional cues) as natural language supervision, aiming to enhance the learning of rich latent representations, for zero-shot classification. To test this, we evaluate using zero-shot classification of the model trained on sample-level descriptions on four popular dynamic FER datasets. Our findings show that this approach yields significant improvements when compared to baseline methods. Specifically, for zero-shot video FER, we outperform CLIP by over 10\% in terms of Weighted Average Recall and 5\% in terms of Unweighted Average Recall on several datasets. Furthermore, we evaluate the representations obtained from the network trained using sample-level descriptions on the downstream task of mental health symptom estimation, achieving performance comparable or superior to state-of-the-art methods and strong agreement with human experts. Namely, we achieve a Pearson's Correlation Coefficient of up to 0.85 on schizophrenia symptom severity estimation, which is comparable to human experts' agreement. The code is publicly available at: https://github.com/NickyFot/EmoCLIP.	cs.CV	10 pages, 3 figures
6	Driving through the Concept Gridlock: Unraveling Explainability Bottlenecks	Jessica Echterhoff,An Yan,Kyungtae Han,Amr Abdelraouf,Rohit Gupta,Julian McAuley	Concept bottleneck models have been successfully used for explainable machine learning by encoding information within the model with a set of human-defined concepts. In the context of human-assisted or autonomous driving, explainability models can help user acceptance and understanding of decisions made by the autonomous vehicle, which can be used to rationalize and explain driver or vehicle behavior. We propose a new approach using concept bottlenecks as visual features for control command predictions and explanations of user and vehicle behavior. We learn a human-understandable concept layer that we use to explain sequential driving scenes while learning vehicle control commands. This approach can then be used to determine whether a change in a preferred gap or steering commands from a human (or autonomous vehicle) is led by an external stimulus or change in preferences. We achieve competitive performance to latent visual features while gaining interpretability within our model setup.	cs.CV	None
7	Covariate Shift Adaptation Robust to Density-Ratio Estimation	Masahiro Kato	Consider a scenario where we have access to train data with both covariates and outcomes while test data only contains covariates. In this scenario, our primary aim is to predict the missing outcomes of the test data. With this objective in mind, we train parametric regression models under a covariate shift, where covariate distributions are different between the train and test data. For this problem, existing studies have proposed covariate shift adaptation via importance weighting using the density ratio. This approach averages the train data losses, each weighted by an estimated ratio of the covariate densities between the train and test data, to approximate the test-data risk. Although it allows us to obtain a test-data risk minimizer, its performance heavily relies on the accuracy of the density ratio estimation. Moreover, even if the density ratio can be consistently estimated, the estimation errors of the density ratio also yield bias in the estimators of the regression model's parameters of interest. To mitigate these challenges, we introduce a doubly robust estimator for covariate shift adaptation via importance weighting, which incorporates an additional estimator for the regression function. Leveraging double machine learning techniques, our estimator reduces the bias arising from the density ratio estimation errors. We demonstrate the asymptotic distribution of the regression parameter estimator. Notably, our estimator remains consistent if either the density ratio estimator or the regression function is consistent, showcasing its robustness against potential errors in density ratio estimation. Finally, we confirm the soundness of our proposed method via simulation studies.	stat.ME	None
8	Combined experimental and theoretical studies on glasslike transitions in the frustrated molecular conductors $Œ∏$-(BEDT-TTF)$_2MM'$(SCN)$_4$	Yohei Saito,Owen Ganter,Chao Shang,Kenichiro Hashimoto,Takahiko Sasaki,Stephen M. Winter,Jens M√ºller,Michael Lang	We present results of the coefficient of thermal expansion for the frustrated quasi-two-dimensional molecular conductor $\theta$-(BEDT-TTF)$_2$RbZn(SCN)$_4$ for temperatures 1.5 K $\leq T \leq$ 290 K. A pronounced first-order phase transition anomaly is observed at the combined charge-order/structural transition at 215 K. Furthermore, clear evidence is found for two separate glasslike transitions at $T_{\mathrm{g}}$ = 90-100 K and $T_{\mathrm{g}}^\dagger$ = 120-130 K, similar to previous findings for $\theta$-(BEDT-TTF)$_2$CsZn(SCN)$_4$ and $\theta$-(BEDT-TTF)$_2$CsCo(SCN)$_4$, reported in T. Thomas et al., Phys. Rev. B 105, L041114 (2022), both of which lack the charge-order/structural transition. Our findings indicate that these glasslike transitions are common features for the $\theta$-(BEDT-TTF)$_2MM^\prime$(SCN)$_4$ family with $M$ = (Rb, Cs) and $M^\prime$ = (Co, Zn), irrespective of the presence or absence of charge order. These results are consistent with our model calculations on the glasslike dynamics associated with the flexible ethylene endgroups of the BEDT-TTF molecules for various $\theta$-(BEDT-TTF)$_2MM^\prime$(SCN)$_4$ salts, predicting two different conformational glass transitions. Moreover, calculations of the hopping integrals show a substantial degree of dependence on the endgroups' conformation, suggesting a significant coupling to the electronic degrees of freedom. Our findings support the possibility that the glassy freezing of the ethylene endgroups could drive or enhance glassy charge dynamics.	cond-mat.str-el	11 pages, 10 figures, 1 table
9	Photometric Redshifts with Copula Entropy	Jian Ma	In this paper we propose to apply copula entropy (CE) to photometric redshifts. CE is used to measure the correlations between photometric measurements and redshifts and then the measurements associated with high CEs are selected for predicting redshifts. We verified the proposed method on the SDSS quasar data. Experimental results show that the accuracy of photometric redshifts is improved with the selected measurements compared to the results with all the measurements used in the experiments, especially for the samples with high redshifts. The measurements selected with CE include luminosity magnitude, the brightness in ultraviolet band with standard deviation, and the brightness of the other four bands. Since CE is a rigorously defined mathematical concept, the models such derived is interpretable.	cs.LG	15 pages, 7 figures, 1 table
0	Inferring entropy production from time-dependent moments	Prashant Singh,Karel Proesmans	Measuring entropy production of a system directly from the experimental data is highly desirable since it gives a quantifiable measure of the time-irreversibility for non-equilibrium systems and can be used as a cost function to optimize the performance of the system. Although numerous methods are available to infer the entropy production of stationary systems, there are only a limited number of methods that have been proposed for time-dependent systems and, to the best of our knowledge, none of these methods have been applied to experimental systems. Herein, we develop a general non-invasive methodology to infer a lower bound on the mean total entropy production for arbitrary time-dependent continuous-state Markov systems in terms of the moments of the underlying state variables. The method gives surprisingly accurate estimates for the entropy production, both for theoretical toy models and for experimental bit erasure, even with a very limited amount of experimental data.	cond-mat.stat-mech	30 pages, 8 figures
1	Free-form Flows: Make Any Architecture a Normalizing Flow	Felix Draxler,Peter Sorrenson,Lea Zimmermann,Armand Rousselot,Ullrich K√∂the	Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing $E(n)$-equivariant networks. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures.	cs.LG	None
2	Comparison with model-independent and dependent analyses for pion charge radius	Kohei Sato,Hiromasa Watanabe,Takeshi Yamazaki	Traditionally, there has been a method to extract the charge radius of a hadron based on the fits of its form factor with some model assumptions. In contrast, a completely different method has been proposed, which does not depend on the models. In this report, we explore several improvements to this model-independent method for analyzing the pion charge radius. Furthermore, we compare the results of the pion charge radius obtained from $N_{f}=2+1$ lattice QCD data at $m_{\pi}=0.51$ GeV using the three different methods: the traditional model-dependent method, the original model-independent method, and our improved model-independent method. In this comparison, we take into account systematic errors estimated in each analysis.	hep-lat	7 pages, 4 figures, Proceedings of the 40th International Symposium   on Lattice Field Theory (Lattice 2023), July 31st - August 4th, 2023, Fermi   National Accelerator Laboratory
3	ArTST: Arabic Text and Speech Transformer	Hawau Olamide Toyin,Amirbek Djanibekov,Ajinkya Kulkarni,Hanan Aldarmaki	We present ArTST, a pre-trained Arabic text and speech transformer for supporting open-source speech technologies for the Arabic language. The model architecture follows the unified-modal framework, SpeechT5, that was recently released for English, and is focused on Modern Standard Arabic (MSA), with plans to extend the model for dialectal and code-switched Arabic in future editions. We pre-trained the model from scratch on MSA speech and text data, and fine-tuned it for the following tasks: Automatic Speech Recognition (ASR), Text-To-Speech synthesis (TTS), and spoken dialect identification. In our experiments comparing ArTST with SpeechT5, as well as with previously reported results in these tasks, ArTST performs on a par with or exceeding the current state-of-the-art in all three tasks. Moreover, we find that our pre-training is conducive for generalization, which is particularly evident in the low-resource TTS task. The pre-trained model as well as the fine-tuned ASR and TTS models are released for research use.	cs.CL	11 pages, 1 figure, SIGARAB ArabicNLP 2023
4	SpikingJelly: An open-source machine learning infrastructure platform for spike-based intelligence	Wei Fang,Yanqi Chen,Jianhao Ding,Zhaofei Yu,Timoth√©e Masquelier,Ding Chen,Liwei Huang,Huihui Zhou,Guoqi Li,Yonghong Tian	Spiking neural networks (SNNs) aim to realize brain-inspired intelligence on neuromorphic chips with high energy efficiency by introducing neural dynamics and spike properties. As the emerging spiking deep learning paradigm attracts increasing interest, traditional programming frameworks cannot meet the demands of the automatic differentiation, parallel computation acceleration, and high integration of processing neuromorphic datasets and deployment. In this work, we present the SpikingJelly framework to address the aforementioned dilemma. We contribute a full-stack toolkit for pre-processing neuromorphic datasets, building deep SNNs, optimizing their parameters, and deploying SNNs on neuromorphic chips. Compared to existing methods, the training of deep SNNs can be accelerated $11\times$, and the superior extensibility and flexibility of SpikingJelly enable users to accelerate custom models at low costs through multilevel inheritance and semiautomatic code generation. SpikingJelly paves the way for synthesizing truly energy-efficient SNN-based machine intelligence systems, which will enrich the ecology of neuromorphic computing.	cs.NE	Accepted in Science Advances   (https://www.science.org/doi/10.1126/sciadv.adi1480)
5	Study of the fastest classical nova, V1674 Her: Photoionization and Morpho-kinemetic model analysis	Gesesew R. Habtie,Ramkrishna Das,Ruchi Pandey,N. M. Ashok,Pavol A. Dubovsky	We present the results of the investigation of the nova V1674 Her (2021), recognised as the swiftest classical nova, with $t_2 \sim 0.90$ days. The distance to the nova is estimated to be 4.97 kpc. The mass and radius of the WD are calculated to be $\sim~1.36~M_\odot$ and $\sim 0.15~R_\oplus$, respectively. Over the course of one month following the outburst, V1674 Her traversed distinct phases -- pre-maxima, early decline, nebular, and coronal -- displaying a remarkably swift transformation. The nebular lines emerged on day 10.00, making it the classical nova with the earliest observed commencement to date. We modelled the observed optical spectrum using the photoionization code \textsc{cloudy}. From the best-fitting model we deduced different physical and chemical parameters associated withe the system. The temperature and luminosity of the central ionizing sources are found in the range of $1.99 - 2.34~\times 10^5$ K and $1.26 - 3.16~ \times 10^{38}$ \ergs, respectively. Elements such as He, O, N, and Ne are found to be overabundant compared to solar abundance in both the nebular and coronal phases. According to the model, Fe II abundance diminishes while Ne abundance increases, potentially elucidating the rare hybrid transition between Fe and He/N nova classes. The ejected mass across all epochs spanned from $3.42 - 7.04~ \times 10^{-5}~M_\odot$. Morpho-kinematic modelling utilising \textsc{shape} revealed that the nova V1674 Her possesses a bipolar structure with an equatorial ring at the centre and an inclination angle of i = 67$\pm$ 1.5$^{\circ}$.	astro-ph.SR	19 pages, 17 figures, 6 tables
6	Quantum Time: a novel resource for quantum information	M. Basil Altaie	Time in relativity theory has a status different from that adopted by standard quantum mechanics, where time is considered as a parameter measured with reference to an external absolute Newtonian frame. This status strongly restricts its role in the dynamics of systems and hinders any formulation to merge quantum mechanics with general relativity, speci?fically when considering quantum gravity. To overcome those limitations, several authors tried to construct an operator which is conjugate to the Hamiltonian of quantum systems implementing some essential features of the relativistic time. These formulations use the concept of internal or intrinsic time instead of the universal coordinate time used in textbooks. Furthermore, recently it is remarked that the consideration of time with relativistic features could enhance the analysis techniques in quantum information processing and have an impact on its status in causal orders and causal structures of quantum information. The role of clocks, their accuracy and stability has become an important issue in quantum information processing. This article present a substantiative review of recent works which reflect the possibility of utilizing quantum time, measured by quantum clock devised according to Page-Wootters scheme, to stand as a resource for quantum information processing.	quant-ph	29 pages, 3 figures
7	Context Does Matter: End-to-end Panoptic Narrative Grounding with Deformable Attention Refined Matching Network	Yiming Lin,Xiao-Bo Jin,Qiufeng Wang,Kaizhu Huang	Panoramic Narrative Grounding (PNG) is an emerging visual grounding task that aims to segment visual objects in images based on dense narrative captions. The current state-of-the-art methods first refine the representation of phrase by aggregating the most similar $k$ image pixels, and then match the refined text representations with the pixels of the image feature map to generate segmentation results. However, simply aggregating sampled image features ignores the contextual information, which can lead to phrase-to-pixel mis-match. In this paper, we propose a novel learning framework called Deformable Attention Refined Matching Network (DRMN), whose main idea is to bring deformable attention in the iterative process of feature learning to incorporate essential context information of different scales of pixels. DRMN iteratively re-encodes pixels with the deformable attention network after updating the feature representation of the top-$k$ most similar pixels. As such, DRMN can lead to accurate yet discriminative pixel representations, purify the top-$k$ most similar pixels, and consequently alleviate the phrase-to-pixel mis-match substantially.Experimental results show that our novel design significantly improves the matching results between text phrases and image pixels. Concretely, DRMN achieves new state-of-the-art performance on the PNG benchmark with an average recall improvement 3.5%. The codes are available in: https://github.com/JaMesLiMers/DRMN.	cs.CV	Accepted by ICDM 2023
9	Back Transcription as a Method for Evaluating Robustness of Natural Language Understanding Models to Speech Recognition Errors	Marek Kubis,Pawe≈Ç Sk√≥rzewski,Marcin Sowa≈Ñski,Tomasz Ziƒôtkiewicz	In a spoken dialogue system, an NLU model is preceded by a speech recognition system that can deteriorate the performance of natural language understanding. This paper proposes a method for investigating the impact of speech recognition errors on the performance of natural language understanding models. The proposed method combines the back transcription procedure with a fine-grained technique for categorizing the errors that affect the performance of NLU models. The method relies on the usage of synthesized speech for NLU evaluation. We show that the use of synthesized speech in place of audio recording does not change the outcomes of the presented technique in a significant way.	cs.CL	Accepted to EMNLP 2023 main conference
0	Performative Prediction: Past and Future	Moritz Hardt,Celestine Mendler-D√ºnner	Predictions in the social world generally influence the target of prediction, a phenomenon known as performativity. Self-fulfilling and self-negating predictions are examples of performativity. Of fundamental importance to economics, finance, and the social sciences, the notion has been absent from the development of machine learning. In machine learning applications, performativity often surfaces as distribution shift. A predictive model deployed on a digital platform, for example, influences consumption and thereby changes the data-generating distribution. We survey the recently founded area of performative prediction that provides a definition and conceptual framework to study performativity in machine learning. A consequence of performative prediction is a natural equilibrium notion that gives rise to new optimization challenges. Another consequence is a distinction between learning and steering, two mechanisms at play in performative prediction. The notion of steering is in turn intimately related to questions of power in digital markets. We review the notion of performative power that gives an answer to the question how much a platform can steer participants through its predictions. We end on a discussion of future directions, such as the role that performativity plays in contesting algorithmic systems.	cs.LG	None
1	On the Interplay between Fairness and Explainability	Stephanie Brandl,Emanuele Bugliarello,Ilias Chalkidis	In order to build reliable and trustworthy NLP applications, models need to be both fair across different demographics and explainable. Usually these two objectives, fairness and explainability, are optimized and/or examined independently of each other. Instead, we argue that forthcoming, trustworthy NLP systems should consider both. In this work, we perform a first study to understand how they influence each other: do fair(er) models rely on more plausible rationales? and vice versa. To this end, we conduct experiments on two English multi-class text classification datasets, BIOS and ECtHR, that provide information on gender and nationality, respectively, as well as human-annotated rationales. We fine-tune pre-trained language models with several methods for (i) bias mitigation, which aims to improve fairness; (ii) rationale extraction, which aims to produce plausible explanations. We find that bias mitigation algorithms do not always lead to fairer models. Moreover, we discover that empirical fairness and explainability are orthogonal.	cs.CL	15 pages (incl Appendix), 4 figures, 8 tables
2	AirFL-Mem: Improving Communication-Learning Trade-Off by Long-Term Memory	Haifeng Wen,Hong Xing,Osvaldo Simeone	Addressing the communication bottleneck inherent in federated learning (FL), over-the-air FL (AirFL) has emerged as a promising solution, which is, however, hampered by deep fading conditions. In this paper, we propose AirFL-Mem, a novel scheme designed to mitigate the impact of deep fading by implementing a \emph{long-term} memory mechanism. Convergence bounds are provided that account for long-term memory, as well as for existing AirFL variants with short-term memory, for general non-convex objectives. The theory demonstrates that AirFL-Mem exhibits the same convergence rate of federated averaging (FedAvg) with ideal communication, while the performance of existing schemes is generally limited by error floors. The theoretical results are also leveraged to propose a novel convex optimization strategy for the truncation threshold used for power control in the presence of Rayleigh fading channels. Experimental results validate the analysis, confirming the advantages of a long-term memory mechanism for the mitigation of deep fading.	cs.IT	8 pages, 3 figures, this is the full version of the conference   version that is submitted to IEEE WCNC2024 for possible publication
3	Distributionally Robust Unsupervised Dense Retrieval Training on Web Graphs	Peixuan Han,Zhenghao Liu,Zhiyuan Liu,Chenyan Xiong	This paper introduces Web-DRO, an unsupervised dense retrieval model, which clusters documents based on web structures and reweights the groups during contrastive training. Specifically, we first leverage web graph links and contrastively train an embedding model for clustering anchor-document pairs. Then we use Group Distributional Robust Optimization to reweight different clusters of anchor-document pairs, which guides the model to assign more weights to the group with higher contrastive loss and pay more attention to the worst case during training. Our experiments on MS MARCO and BEIR show that our model, Web-DRO, significantly improves the retrieval effectiveness in unsupervised scenarios. A comparison of clustering techniques shows that training on the web graph combining URL information reaches optimal performance on clustering. Further analysis confirms that group weights are stable and valid, indicating consistent model preferences as well as effective up-weighting of valuable groups and down-weighting of uninformative ones. The code of this paper can be obtained from https://github.com/OpenMatch/Web-DRO.	cs.IR	9 pages, 5 figures, 5 tables
4	Photon-photon correlation of condensed light in a microcavity	Yijun Tang,Himadri Shekhar Dhar,Rupert F. Oulton,Robert A. Nyman,Florian Mintert	The study of temporal coherence in a Bose-Einstein condensate of photons can be challenging, especially in the presence of correlations between the photonic modes. In this work, we use a microscopic, multimode model of photonic condensation inside a dye-filled microcavity and the quantum regression theorem, to derive an analytical expression for the equation of motion of the photon-photon correlation function. This allows us to derive the coherence time of the photonic modes and identify a nonmonotonic dependence of the temporal coherence of the condensed light with the cutoff frequency of the microcavity.	quant-ph	12 pages, 5 figures
5	Certifying Bimanual RRT Motion Plans in a Second	Alexandre Amice,Peter Werner,Russ Tedrake	We present an efficient method for certifying non-collision for piecewise-polynomial motion plans in algebraic reparametrizations of configuration space. Such motion plans include those generated by popular randomized methods including RRTs and PRMs, as well as those generated by many methods in trajectory optimization. Based on Sums-of-Squares optimization, our method provides exact, rigorous certificates of non-collision; it can never falsely claim that a motion plan containing collisions is collision-free. We demonstrate that our formulation is practical for real world deployment, certifying the safety of a twelve degree of freedom motion plan in just over a second. Moreover, the method is capable of discriminating the safety or lack thereof of two motion plans which differ by only millimeters.	cs.RO	7 pages, 5 figures, 1 table
6	Parcel loss prediction in last-mile delivery: deep and non-deep approaches with insights from Explainable AI	Jan de Leeuw,Zaharah Bukhsh,Yingqian Zhang	Within the domain of e-commerce retail, an important objective is the reduction of parcel loss during the last-mile delivery phase. The ever-increasing availability of data, including product, customer, and order information, has made it possible for the application of machine learning in parcel loss prediction. However, a significant challenge arises from the inherent imbalance in the data, i.e., only a very low percentage of parcels are lost. In this paper, we propose two machine learning approaches, namely, Data Balance with Supervised Learning (DBSL) and Deep Hybrid Ensemble Learning (DHEL), to accurately predict parcel loss. The practical implication of such predictions is their value in aiding e-commerce retailers in optimizing insurance-related decision-making policies. We conduct a comprehensive evaluation of the proposed machine learning models using one year data from Belgian shipments. The findings show that the DHEL model, which combines a feed-forward autoencoder with a random forest, achieves the highest classification performance. Furthermore, we use the techniques from Explainable AI (XAI) to illustrate how prediction models can be used in enhancing business processes and augmenting the overall value proposition for e-commerce retailers in the last mile delivery.	cs.LG	None
7	Balancing central and marginal rejection when combining independent significance tests	Chris Salahub,R. Wayne Oldford	A common approach to evaluating the significance of a collection of $p$-values combines them with a pooling function, in particular when the original data are not available. These pooled $p$-values convert a sample of $p$-values into a single number which behaves like a univariate $p$-value. To clarify discussion of these functions, a telescoping series of alternative hypotheses are introduced that communicate the strength and prevalence of non-null evidence in the $p$-values before general pooling formulae are discussed. A pattern noticed in the UMP pooled $p$-value for a particular alternative motivates the definition and discussion of central and marginal rejection levels at $\alpha$. It is proven that central rejection is always greater than or equal to marginal rejection, motivating a quotient to measure the balance between the two for pooled $p$-values. A combining function based on the $\chi^2_{\kappa}$ quantile transformation is proposed to control this quotient and shown to be robust to mis-specified parameters relative to the UMP. Different powers for different parameter settings motivate a map of plausible alternatives based on where this pooled $p$-value is minimized.	stat.ME	55 page, 18 figures, public technical report
8	Beyond IID weights: sparse and low-rank deep Neural Networks are also Gaussian Processes	Thiziri Nait-Saada,Alireza Naderi,Jared Tanner	The infinitely wide neural network has been proven a useful and manageable mathematical model that enables the understanding of many phenomena appearing in deep learning. One example is the convergence of random deep networks to Gaussian processes that allows a rigorous analysis of the way the choice of activation function and network weights impacts the training dynamics. In this paper, we extend the seminal proof of Matthews et al. (2018) to a larger class of initial weight distributions (which we call PSEUDO-IID), including the established cases of IID and orthogonal weights, as well as the emerging low-rank and structured sparse settings celebrated for their computational speed-up benefits. We show that fully-connected and convolutional networks initialized with PSEUDO-IID distributions are all effectively equivalent up to their variance. Using our results, one can identify the Edge-of-Chaos for a broader class of neural networks and tune them at criticality in order to enhance their training.	stat.ML	None
9	Constraining the slow-diffusion zone size and electron injection spectral index for the Geminga pulsar halo	Kun Fang	Measuring the electron diffusion coefficient is the most straightforward task in the study of gamma-ray pulsar halos. The updated measurements of the spatial morphology and spectrum of the Geminga halo by the HAWC experiment enable us to constrain parameters beyond the diffusion coefficient, including the size of the slow-diffusion zone and the electron injection spectrum from the pulsar wind nebulae (PWN). Based on the two-zone diffusion model, we find that the slow-diffusion zone size ($r_*$) around Geminga is within the range of $30-70$pc. The lower boundary of this range is determined by the goodness of fit of the model to the one-dimensional morphology of the Geminga halo. The upper limit is derived from fitting the gamma-ray spectrum of the Geminga halo, along with the expectations for the power-law index of the injection spectrum based on simulations and PWN observations, i.e., $p\gtrsim1$. With $r_*$ set at its lower limit of $30$~pc, we obtain the maximum $p$ permitted by the HAWC spectrum measurement, with an upper limit of $2.17$ at a $3\sigma$ significance. Moreover, we find that when $r_*=30$pc and $p=2.17$, the predicted positron spectrum generated by Geminga at Earth coincides with the AMS-02 measurement in the $50-500$GeV range.	astro-ph.HE	14 pages, 5 figures
0	$\mathbb{VD}$-$\mathbb{GR}$: Boosting $\mathbb{V}$isual $\mathbb{D}$ialog with Cascaded Spatial-Temporal Multi-Modal $\mathbb{GR}$aphs	Adnen Abdessaied,Lei Shi,Andreas Bulling	We propose $\mathbb{VD}$-$\mathbb{GR}$ - a novel visual dialog model that combines pre-trained language models (LMs) with graph neural networks (GNNs). Prior works mainly focused on one class of models at the expense of the other, thus missing out on the opportunity of combining their respective benefits. At the core of $\mathbb{VD}$-$\mathbb{GR}$ is a novel integration mechanism that alternates between spatial-temporal multi-modal GNNs and BERT layers, and that covers three distinct contributions: First, we use multi-modal GNNs to process the features of each modality (image, question, and dialog history) and exploit their local structures before performing BERT global attention. Second, we propose hub-nodes that link to all other nodes within one modality graph, allowing the model to propagate information from one GNN (modality) to the other in a cascaded manner. Third, we augment the BERT hidden states with fine-grained multi-modal GNN features before passing them to the next $\mathbb{VD}$-$\mathbb{GR}$ layer. Evaluations on VisDial v1.0, VisDial v0.9, VisDialConv, and VisPro show that $\mathbb{VD}$-$\mathbb{GR}$ achieves new state-of-the-art results across all four datasets.	cs.CV	WACV 2024
1	Polarization-entangled photons from a whispering gallery resonator	Sheng-Hsuan Huang,Thomas Dirmeier,Golnoush Shafiee,Kaisa Laiho,Dmitry V. Strekalov,Gerd Leuchs,Christoph Marquardt	Crystalline Whispering Gallery Mode Resonators (WGMRs) have been shown to facilitate versatile sources of quantum states that can efficiently interact with atomic systems. These features make WGMRs an efficient platform for quantum information processing. Here, we experimentally show that it is possible to generate polarization entanglement from WGMRs by using an interferometric scheme. Our scheme gives us the flexibility to control the phase of the generated entangled state by changing the relative phase of the interferometer. The S value of the Clauser-Horne-Shimony-Holt's inequality in the system is $2.45 \pm 0.07$, which violates the inequality by more than 6 standard deviations.	physics.optics	None
2	Adaptive Uncertainty Estimation via High-Dimensional Testing on Latent Representations	Tsai Hor Chan,Kin Wai Lau,Jiajun Shen,Guosheng Yin,Lequan Yu	Uncertainty estimation aims to evaluate the confidence of a trained deep neural network. However, existing uncertainty estimation approaches rely on low-dimensional distributional assumptions and thus suffer from the high dimensionality of latent features. Existing approaches tend to focus on uncertainty on discrete classification probabilities, which leads to poor generalizability to uncertainty estimation for other tasks. Moreover, most of the literature requires seeing the out-of-distribution (OOD) data in the training for better estimation of uncertainty, which limits the uncertainty estimation performance in practice because the OOD data are typically unseen. To overcome these limitations, we propose a new framework using data-adaptive high-dimensional hypothesis testing for uncertainty estimation, which leverages the statistical properties of the feature representations. Our method directly operates on latent representations and thus does not require retraining the feature encoder under a modified objective. The test statistic relaxes the feature distribution assumptions to high dimensionality, and it is more discriminative to uncertainties in the latent representations. We demonstrate that encoding features with Bayesian neural networks can enhance testing performance and lead to more accurate uncertainty estimation. We further introduce a family-wise testing procedure to determine the optimal threshold of OOD detection, which minimizes the false discovery rate (FDR). Extensive experiments validate the satisfactory performance of our framework on uncertainty estimation and task-specific prediction over a variety of competitors. The experiments on the OOD detection task also show satisfactory performance of our method when the OOD data are unseen in the training. Codes are available at https://github.com/HKU-MedAI/bnn_uncertainty.	cs.LG	NeurIPS 2023
3	Muon-induced background in a next-generation dark matter experiment based on liquid xenon	Viktor Pƒõƒç,Vitaly A. Kudryavtsev,Henrique M. Ara√∫jo,Timothy J. Sumner	Muon-induced neutrons can lead to potentially irreducible backgrounds in rare event search experiments. We have investigated the implication of laboratory depth on the muon-induced background in a future dark matter experiment capable of reaching the so-called neutrino floor. Our simulation study focused on a xenon-based detector with 70 tonnes of active mass, surrounded by additional veto systems plus a water shield. Two locations at the Boulby Underground Laboratory (UK) were analysed as examples: an experimental cavern in salt at a depth of 2850 m w. e. (similar to the location of the existing laboratory), and a deeper laboratory located in polyhalite rock at a depth of 3575 m w. e. Our results show that no cosmogenic background events are likely to survive standard analysis cuts for 10 years of operation at either location. The largest background component we identified comes from beta-delayed neutron emission from $^{17}$N which is produced from $^{19}$F in the fluoropolymer components of the experiment. Our results confirm that a dark matter search with sensitivity to the neutrino floor is viable (from the point of view of cosmogenic backgrounds) in underground laboratories at these levels of rock overburden. This work was conducted in 2019-21 in the context of a feasibility study to investigate the possibility of developing the Boulby Underground Laboratory to host a next-generation dark matter experiment; however, our findings are also relevant for other underground laboratories.	hep-ex	22 pages, 11 figures, related to arXiv:2211.07262
4	Tailoring Personality Traits in Large Language Models via Unsupervisedly-Built Personalized Lexicons	Tianlong Li,Xiaoqing Zheng,Xuanjing Huang	Personality plays a pivotal role in shaping human expression patterns, and empowering and manipulating large language models (LLMs) with personality traits holds significant promise in enhancing the user experience of LLMs. However, prior approaches either rely on fine-tuning LLMs on a corpus enriched with personalized expressions or necessitate the manual crafting of prompts to induce LLMs to produce personalized responses. The former approaches demand substantial time and resources for collecting sufficient training examples while the latter might fail in enabling the precise manipulation of the personality traits at a fine-grained level (e.g., achieving high agreeableness while reducing openness). In this study, we introduce a novel approach for tailoring personality traits within LLMs, allowing for the incorporation of any combination of the Big Five factors (i.e., openness, conscientiousness, extraversion, agreeableness, and neuroticism) in a pluggable manner. This is achieved by employing a set of Unsupervisedly-Built Personalized Lexicons (UBPL) that are utilized to adjust the probability of the next token predicted by the original LLMs during the decoding phase. This adjustment encourages the models to generate words present in the personalized lexicons while preserving the naturalness of the generated texts. Extensive experimentation demonstrates the effectiveness of our approach in finely manipulating LLMs' personality traits. Furthermore, our method can be seamlessly integrated into other LLMs without necessitating updates to their parameters.	cs.CL	Work in progress
5	Hybrid Minimax-MCTS and Difficulty Adjustment for General Game Playing	Marco Ant√¥nio Athayde de Aguiar Vieira,Anderson Rocha Tavares,Renato Perez Ribas	Board games are a great source of entertainment for all ages, as they create a competitive and engaging environment, as well as stimulating learning and strategic thinking. It is common for digital versions of board games, as any other type of digital games, to offer the option to select the difficulty of the game. This is usually done by customizing the search parameters of the AI algorithm. However, this approach cannot be extended to General Game Playing agents, as different games might require different parametrization for each difficulty level. In this paper, we present a general approach to implement an artificial intelligence opponent with difficulty levels for zero-sum games, together with a propose of a Minimax-MCTS hybrid algorithm, which combines the minimax search process with GGP aspects of MCTS. This approach was tested in our mobile application LoBoGames, an extensible board games platform, that is intended to have an broad catalog of games, with an emphasis on accessibility: the platform is friendly to visually-impaired users, and is compatible with more than 92\% of Android devices. The tests in this work indicate that both the hybrid Minimax-MCTS and the new difficulty adjustment system are promising GGP approaches that could be expanded in future work.	cs.AI	None
6	WSDMS: Debunk Fake News via Weakly Supervised Detection of Misinforming Sentences with Contextualized Social Wisdom	Ruichao Yang,Wei Gao,Jing Ma,Hongzhan Lin,Zhiwei Yang	In recent years, we witness the explosion of false and unconfirmed information (i.e., rumors) that went viral on social media and shocked the public. Rumors can trigger versatile, mostly controversial stance expressions among social media users. Rumor verification and stance detection are different yet relevant tasks. Fake news debunking primarily focuses on determining the truthfulness of news articles, which oversimplifies the issue as fake news often combines elements of both truth and falsehood. Thus, it becomes crucial to identify specific instances of misinformation within the articles. In this research, we investigate a novel task in the field of fake news debunking, which involves detecting sentence-level misinformation. One of the major challenges in this task is the absence of a training dataset with sentence-level annotations regarding veracity. Inspired by the Multiple Instance Learning (MIL) approach, we propose a model called Weakly Supervised Detection of Misinforming Sentences (WSDMS). This model only requires bag-level labels for training but is capable of inferring both sentence-level misinformation and article-level veracity, aided by relevant social media conversations that are attentively contextualized with news sentences. We evaluate WSDMS on three real-world benchmarks and demonstrate that it outperforms existing state-of-the-art baselines in debunking fake news at both the sentence and article levels.	cs.CL	None
7	Accelerating the analysis of optical quantum systems using the Koopman operator	Anna Hunstig,Sebastian Peitz,Hendrik Rose,Torsten Meier	The prediction of photon echoes is an important technique for gaining an understanding of optical quantum systems. However, this requires a large number of simulations with varying parameters and/or input pulses, which renders numerical studies expensive. This article investigates how we can use data-driven surrogate models based on the Koopman operator to accelerate this process. In order to be successful, we require a model that is accurate over a large number of time steps. To this end, we employ a bilinear Koopman model using extended dynamic mode decomposition and simulate the optical Bloch equations for an ensemble of inhomogeneously broadened two-level systems. Such systems are well suited to describe the excitation of excitonic resonances in semiconductor nanostructures, for example, ensembles of semiconductor quantum dots. We perform a detailed study on the required number of system simulations such that the resulting data-driven Koopman model is sufficiently accurate for a wide range of parameter settings. We analyze the L2 error and the relative error of the photon echo peak and investigate how the control positions relate to the stabilization. After proper training, the dynamics of the quantum ensemble can be predicted accurately and numerically very efficiently by our methods.	quant-ph	None
8	Adapt Anything: Tailor Any Image Classifiers across Domains And Categories Using Text-to-Image Diffusion Models	Weijie Chen,Haoyu Wang,Shicai Yang,Lei Zhang,Wei Wei,Yanning Zhang,Luojun Lin,Di Xie,Yueting Zhuang	We do not pursue a novel method in this paper, but aim to study if a modern text-to-image diffusion model can tailor any task-adaptive image classifier across domains and categories. Existing domain adaptive image classification works exploit both source and target data for domain alignment so as to transfer the knowledge learned from the labeled source data to the unlabeled target data. However, as the development of the text-to-image diffusion model, we wonder if the high-fidelity synthetic data from the text-to-image generator can serve as a surrogate of the source data in real world. In this way, we do not need to collect and annotate the source data for each domain adaptation task in a one-for-one manner. Instead, we utilize only one off-the-shelf text-to-image model to synthesize images with category labels derived from the corresponding text prompts, and then leverage the surrogate data as a bridge to transfer the knowledge embedded in the task-agnostic text-to-image generator to the task-oriented image classifier via domain adaptation. Such a one-for-all adaptation paradigm allows us to adapt anything in the world using only one text-to-image generator as well as the corresponding unlabeled target data. Extensive experiments validate the feasibility of the proposed idea, which even surpasses the state-of-the-art domain adaptation works using the source data collected and annotated in real world.	cs.CV	11 pages, 6 figures
9	Correctness Witness Validation by Abstract Interpretation	Simmo Saan,Michael Schwarz,Julian Erhard,Helmut Seidl,Sarah Tilscher,Vesal Vojdani	Witnesses record automated program analysis results and make them exchangeable. To validate correctness witnesses through abstract interpretation, we introduce a novel abstract operation unassume. This operator incorporates witness invariants into the abstract program state. Given suitable invariants, the unassume operation can accelerate fixpoint convergence and yield more precise results. We demonstrate the feasibility of this approach by augmenting an abstract interpreter with unassume operators and evaluating the impact of incorporating witnesses on performance and precision. Using manually crafted witnesses, we can confirm verification results for multi-threaded programs with a reduction in effort ranging from 7% to 47% in CPU time. More intriguingly, we discover that using witnesses from model checkers can guide our analyzer to verify program properties that it could not verify on its own.	cs.PL	29 pages, 4 figures, 2 tables, extended version of the paper which is   to appear at VMCAI 2024
0	Give Me the Facts! A Survey on Factual Knowledge Probing in Pre-trained Language Models	Paul Youssef,Osman Alperen Kora≈ü,Meijie Li,J√∂rg Schl√∂tterer,Christin Seifert	Pre-trained Language Models (PLMs) are trained on vast unlabeled data, rich in world knowledge. This fact has sparked the interest of the community in quantifying the amount of factual knowledge present in PLMs, as this explains their performance on downstream tasks, and potentially justifies their use as knowledge bases. In this work, we survey methods and datasets that are used to probe PLMs for factual knowledge. Our contributions are: (1) We propose a categorization scheme for factual probing methods that is based on how their inputs, outputs and the probed PLMs are adapted; (2) We provide an overview of the datasets used for factual probing; (3) We synthesize insights about knowledge retention and prompt optimization in PLMs, analyze obstacles to adopting PLMs as knowledge bases and outline directions for future work.	cs.CL	Accepted at EMNLP Findings 2023
1	Flow-Attention-based Spatio-Temporal Aggregation Network for 3D Mask Detection	Yuxin Cao,Yian Li,Yumeng Zhu,Derui Wang,Minhui Xue	Anti-spoofing detection has become a necessity for face recognition systems due to the security threat posed by spoofing attacks. Despite great success in traditional attacks, most deep-learning-based methods perform poorly in 3D masks, which can highly simulate real faces in appearance and structure, suffering generalizability insufficiency while focusing only on the spatial domain with single frame input. This has been mitigated by the recent introduction of a biomedical technology called rPPG (remote photoplethysmography). However, rPPG-based methods are sensitive to noisy interference and require at least one second (> 25 frames) of observation time, which induces high computational overhead. To address these challenges, we propose a novel 3D mask detection framework, called FASTEN (Flow-Attention-based Spatio-Temporal aggrEgation Network). We tailor the network for focusing more on fine-grained details in large movements, which can eliminate redundant spatio-temporal feature interference and quickly capture splicing traces of 3D masks in fewer frames. Our proposed network contains three key modules: 1) a facial optical flow network to obtain non-RGB inter-frame flow information; 2) flow attention to assign different significance to each frame; 3) spatio-temporal aggregation to aggregate high-level spatial features and temporal transition features. Through extensive experiments, FASTEN only requires five frames of input and outperforms eight competitors for both intra-dataset and cross-dataset evaluations in terms of multiple detection metrics. Moreover, FASTEN has been deployed in real-world mobile devices for practical 3D mask detection.	cs.CV	13 pages, 5 figures. Accepted to NeurIPS 2023
2	1-PAGER: One Pass Answer Generation and Evidence Retrieval	Palak Jain,Livio Baldini Soares,Tom Kwiatkowski	We present 1-Pager the first system that answers a question and retrieves evidence using a single Transformer-based model and decoding process. 1-Pager incrementally partitions the retrieval corpus using constrained decoding to select a document and answer string, and we show that this is competitive with comparable retrieve-and-read alternatives according to both retrieval and answer accuracy metrics. 1-Pager also outperforms the equivalent closed-book question answering model, by grounding predictions in an evidence corpus. While 1-Pager is not yet on-par with more expensive systems that read many more documents before generating an answer, we argue that it provides an important step toward attributed generation by folding retrieval into the sequence-to-sequence paradigm that is currently dominant in NLP. We also show that the search paths used to partition the corpus are easy to read and understand, paving a way forward for interpretable neural retrieval.	cs.CL	Accepted at EMNLP 2023 (Findings)
3	Model-enhanced Contrastive Reinforcement Learning for Sequential Recommendation	Chengpeng Li,Zhengyi Yang,Jizhi Zhang,Jiancan Wu,Dingxian Wang,Xiangnan He,Xiang Wang	Reinforcement learning (RL) has been widely applied in recommendation systems due to its potential in optimizing the long-term engagement of users. From the perspective of RL, recommendation can be formulated as a Markov decision process (MDP), where recommendation system (agent) can interact with users (environment) and acquire feedback (reward signals).However, it is impractical to conduct online interactions with the concern on user experience and implementation complexity, and we can only train RL recommenders with offline datasets containing limited reward signals and state transitions. Therefore, the data sparsity issue of reward signals and state transitions is very severe, while it has long been overlooked by existing RL recommenders.Worse still, RL methods learn through the trial-and-error mode, but negative feedback cannot be obtained in implicit feedback recommendation tasks, which aggravates the overestimation problem of offline RL recommender. To address these challenges, we propose a novel RL recommender named model-enhanced contrastive reinforcement learning (MCRL). On the one hand, we learn a value function to estimate the long-term engagement of users, together with a conservative value learning mechanism to alleviate the overestimation problem.On the other hand, we construct some positive and negative state-action pairs to model the reward function and state transition function with contrastive learning to exploit the internal structure information of MDP. Experiments demonstrate that the proposed method significantly outperforms existing offline RL and self-supervised RL methods with different representative backbone networks on two real-world datasets.	cs.IR	11 pages, 7 figures
4	Application of entropy analysis in the prediction of flow distribution in parallel channels	Toochukwu Aka,Shankar Narayan	Multiphase flow in parallel channels is often an efficient approach to manage heat and energy distribution in engineering systems. However, two-phase flow with heating in parallel channels is prone to maldistribution, resulting in sub-optimal performance and in some cases, permanent damage. This challenge requires accurate flow modeling in parallel channels to mitigate or design against the adverse effect of two-phase flow maldistribution. The nonlinear nature of multiphase flow results in a multiplicity of predicted solutions for the same condition, thereby creating significant challenges in modeling flow distribution. Therefore, this study focuses on solving this challenge by applying entropy generation analysis and the conservation of mass, momentum balance, and energy balance to predict two-phase flow distribution in a two-parallel-channel assembly with a numerical model. Both model predictions and experimental data show that equally distributed flow becomes severely maldistributed with a decrease in flow rate, resulting in significant change (>30%) in the entropy generation rate. We show that the entropy analysis can be applied in distinguishing between stable and unstable flow distribution, like the linear stability analysis used in previous studies. We also surpass the limit of applying linear stability analysis by using entropy analysis to identify the most feasible end state in a maldistribution process.	physics.flu-dyn	None
5	Quantum corrections and the minimal Yukawa sector of $SU(5)$	Ketan M. Patel,Saurabh K. Shukla	It is well-known that the $SU(5)$ grand unified theory, with the standard model quarks and leptons unified in $\overline{5}$ and $10$ and the electroweak Higgs doublet residing in $5$ dimensional representations, leads to relation, $Y_d=Y_e^T$, between the Yukawa couplings of the down-type quarks and the charged leptons. We show that this degeneracy can be lifted in a phenomenologically viable way when quantum corrections to the tree-level matching conditions are taken into account in the presence of one or more copies of gauge singlet fermions. The 1-loop threshold corrections arising from heavy leptoquark scalar and vector bosons, already present in the minimal model, and heavy singlet fermions can lead to realistic Yukawa couplings provided their masses differ by at least two orders of magnitude. The latter can also lead to a realistic light neutrino mass spectrum through the type I seesaw mechanism if the colour partner of the Higgs stays close to the Planck scale. Most importantly, our findings demonstrate the viability of the simplest Yukawa sector when quantum corrections are considered and sizeable threshold effects are present.	hep-ph	9 Pages, 2 Figures and 1 Table
6	An entropic understanding of flow maldistribution in thermally isolated parallel channels	Toochukwu Aka,Shankar Narayan	Flow across heated parallel channel systems exists in many applications. The performance of such systems experiencing multiphase flow could suffer from the deleterious effects of flow non-uniformity or maldistribution. Modeling the behavior of such systems is challenging due to the inherent non-linearity associated with the multiphase flow and the difficulty in determining the actual flow among several possible flow distributions. This study addresses the challenge by analyzing the entropy production in such systems. Using experiments on two thermally isolated, nominally identical, and externally heated parallel channels, we quantify irreversibility in the resulting multiphase flow by evaluating the entropy generation rate. Our experiments reveal that certain flow conditions result in severe maldistribution (flow ratio > 10) in the channels, associated with a sharp rise in entropy production. Such an increase is not predicted for uniform flow distribution across parallel channels, making maldistributed flow a thermodynamically favored state over equally distributed flow. We extend this understanding to non-identical parallel channels as well. With entropy analysis providing additional insight besides the fundamental equations governing mass, momentum, and energy conservation, this approach is valuable in predicting and controlling flow distribution in parallel channel systems.	physics.flu-dyn	None
7	Label Propagation for Graph Label Noise	Yao Cheng,Caihua Shan,Yifei Shen,Xiang Li,Siqiang Luo,Dongsheng Li	"Label noise is a common challenge in large datasets, as it can significantly degrade the generalization ability of deep neural networks. Most existing studies focus on noisy labels in computer vision; however, graph models encompass both node features and graph topology as input, and become more susceptible to label noise through message-passing mechanisms. Recently, only a few works have been proposed to tackle the label noise on graphs. One major limitation is that they assume the graph is homophilous and the labels are smoothly distributed. Nevertheless, real-world graphs may contain varying degrees of heterophily or even be heterophily-dominated, leading to the inadequacy of current methods. In this paper, we study graph label noise in the context of arbitrary heterophily, with the aim of rectifying noisy labels and assigning labels to previously unlabeled nodes. We begin by conducting two empirical analyses to explore the impact of graph homophily on graph label noise. Following observations, we propose a simple yet efficient algorithm, denoted as LP4GLN. Specifically, LP4GLN is an iterative algorithm with three steps: (1) reconstruct the graph to recover the homophily property, (2) utilize label propagation to rectify the noisy labels, (3) select high-confidence labels to retain for the next iteration. By iterating these steps, we obtain a set of correct labels, ultimately achieving high accuracy in the node classification task. The theoretical analysis is also provided to demonstrate its remarkable denoising ""effect"". Finally, we conduct experiments on 10 benchmark datasets under varying graph heterophily levels and noise types, comparing the performance of LP4GLN with 7 typical baselines. Our results illustrate the superior performance of the proposed LP4GLN."	cs.LG	None
8	A multiplicity formula for the Milnor number of smoothable curves	Andrei Bengu≈ü-Lasnier,Terence Gaffney,Antoni Rangachev	We derive a multiplicity formula for the Milnor number of a reduced smoothable curve singularity generalizing a well-known formula due to L\^e, Greuel and Teissier for complete intersection curves. We obtain a multiplicity characterization of Whitney equisingularity for families of locally smoothable curves.	math.AG	13 pages
9	Constraints on coasting cosmological models from gravitational-wave standard sirens	Peter Raffai,M√°ria P√°lfi,Gergely D√°lya,Rachel Gray	We present the first test of coasting cosmological models with gravitational-wave standard sirens observed in the first three observing runs of the LIGO-Virgo-KAGRA detector network. We apply the statistical galaxy catalog method adapted to coasting cosmologies and infer constraints on the $H_0$ Hubble constant for the three fixed values of the curvature parameter $k=\left\{ -1,0,+1 \right\}$ in $H_0^2 c^{-2}$ units. The maximum posteriors and $68.3\%$ highest density intervals we obtained from a combined analysis of $46$ dark siren detections and a single bright siren detection are $H_0=\left\{68.1^{+8.5}_{-5.6},67.5^{+8.3}_{-5.2},67.1^{+6.6}_{-5.8} \right\}~\mathrm{km\ s^{-1}\ Mpc^{-1}}$, respectively. All our constraints on $H_0$ are consistent within one sigma with the latest measurement of $H_0$ applying the differential age method, which provides a constraint on $H_0$ in coasting cosmologies independently from $k$. Our results constrain all cosmological models with $a(t)\propto t$ linear expansion in the luminosity distance and redshift range of the $47$ LIGO-Virgo detections, i.e. $d_\mathrm{L}\lesssim 5~\mathrm{Gpc}$ and $z\lesssim 0.8$, which practically include all (both strictly linear and quasi-linear) models in the coasting model family. As we have found, the coasting models and the $\Lambda$CDM model fit equally well to the applied set of gravitational-wave detections.	astro-ph.CO	7 pages, 3 figures, 1 table
0	Towards Information Theory-Based Discovery of Equivariances	Hippolyte Charvin,Nicola Catenacci Volpi,Daniel Polani	"The presence of symmetries imposes a stringent set of constraints on a system. This constrained structure allows intelligent agents interacting with such a system to drastically improve the efficiency of learning and generalization, through the internalisation of the system's symmetries into their information-processing. In parallel, principled models of complexity-constrained learning and behaviour make increasing use of information-theoretic methods. Here, we wish to marry these two perspectives and understand whether and in which form the information-theoretic lens can ""see"" the effect of symmetries of a system. For this purpose, we propose a novel variant of the Information Bottleneck principle, which has served as a productive basis for many principled studies of learning and information-constrained adaptive behaviour. We show (in the discrete case) that our approach formalises a certain duality between symmetry and information parsimony: namely, channel equivariances can be characterised by the optimal mutual information-preserving joint compression of the channel's input and output. This information-theoretic treatment furthermore suggests a principled notion of ""soft"" equivariance, whose ""coarseness"" is measured by the amount of input-output mutual information preserved by the corresponding optimal compression. This new notion offers a bridge between the field of bounded rationality and the study of symmetries in neural representations. The framework may also allow (exact and soft) equivariances to be automatically discovered."	cs.IT	19 pages, 0 figures
1	Abyss Aerosols	Xinghua Jiang,Lucas Rotily,Emmanuel Villermaux,Xiaofei Wang	Bubble bursting on water surfaces is believed to be a main mechanism to produce submicron drops, including sea spray aerosols, which play a critical role in forming cloud and transferring various biological and chemical substances from water to the air. Over the past century, drops production mechanisms from bubble bursting have been extensively studied. They usually involve the centrifugal fragmentation of liquid ligaments from the bubble cap during film rupture, the flapping of the cap film, and the disintegration of Worthington jets after cavity collapse. Here, we show that a dominant fraction of previously identified as 'bubble bursting' submicron drops are in fact generated via a new mechanism underwater, inside the bubbles themselves before they have reached the surface. These drops are then carried within the rising bubbles towards the water surface and are released in air at bubble bursting. Evidence suggests that these drops originate from the flapping instability of the film squeezed between underwater colliding bubbles. This finding fundamentally reshapes our understanding of sea spray aerosol production and establishes a new role for underwater bubble collisions regarding the nature of transfers through water-air interfaces.	physics.flu-dyn	50 pages, 4 figures, and 10 extended data figures
2	Dynamic Processing Neural Network Architecture For Hearing Loss Compensation	Szymon Drgas,Lars Bramsl√∏w,Archontis Politis,Gaurav Naithani,Tuomas Virtanen	This paper proposes neural networks for compensating sensorineural hearing loss. The aim of the hearing loss compensation task is to transform a speech signal to increase speech intelligibility after further processing by a person with a hearing impairment, which is modeled by a hearing loss model. We propose an interpretable model called dynamic processing network, which has a structure similar to band-wise dynamic compressor. The network is differentiable, and therefore allows to learn its parameters to maximize speech intelligibility. More generic models based on convolutional layers were tested as well. The performance of the tested architectures was assessed using spectro-temporal objective index (STOI) with hearing-threshold noise and hearing aid speech intelligibility (HASPI) metrics. The dynamic processing network gave a significant improvement of STOI and HASPI in comparison to popular compressive gain prescription rule Camfit. A large enough convolutional network could outperform the interpretable model with the cost of larger computational load. Finally, a combination of the dynamic processing network with convolutional neural network gave the best results in terms of STOI and HASPI.	cs.SD	None
3	Valley Polarization-Electric Dipole Interference and Nonlinear Chiral Selection Rules in Monolayer WSe$_2$	Paul Herrmann,Sebastian Klimmer,Till Weickhardt,Anastasios Papavasileiou,Kseniia Mosina,Zdenƒõk Sofer,Ioannis Paradisanos,Daniil Kartashov,Giancarlo Soavi	In monolayer transition metal dichalcogenides time-reversal symmetry, combined with space-inversion symmetry, defines the spin-valley degree of freedom. As such, engineering and control of time-reversal symmetry by optical or magnetic fields constitutes the foundation of valleytronics. Here, we propose a new approach for the detection of broken time-reversal symmetry and valley polarization in monolayer WSe$_2$ based on second harmonic generation. Our method can selectively and simultaneously generate and detect a valley polarization at the $\pm K$ valleys of transition metal dichalcogenides at room temperature. Furthermore, it allows to measure the interference between the real and imaginary parts of the intrinsic (electric dipole) and valley terms of the second order nonlinear susceptibility. This work demonstrates the potential and unique capabilities of nonlinear optics as a probe of broken time-reversal symmetry and as a tool for ultrafast and non-destructive valleytronic operations.	physics.optics	27 pages 6 figures
4	Terahertz-Enpowered Communications and Sensing in 6G Systems: Opportunities and Challenges	Wei Jiang,Hans D. Schotten	The current focus of academia and the telecommunications industry has been shifted to the development of the six-generation (6G) cellular technology, also formally referred to as IMT-2030. Unprecedented applications that 6G aims to accommodate demand extreme communications performance and, in addition, disruptive capabilities such as network sensing. Recently, there has been a surge of interest in terahertz (THz) frequencies as it offers not only massive spectral resources for communication but also distinct advantages in sensing, positioning, and imaging. The aim of this paper is to provide a brief outlook on opportunities opened by this under-exploited band and challenges that must be addressed to materialize the potential of THz-based communications and sensing in 6G systems.	cs.IT	2023 the 9th International Conference on Computer and Communications   (ICCC). arXiv admin note: text overlap with arXiv:2307.10321
5	AdaMEC: Towards a Context-Adaptive and Dynamically-Combinable DNN Deployment Framework for Mobile Edge Computing	Bowen Pang,Sicong Liu,Hongli Wang,Bin Guo,Yuzhan Wang,Hao Wang,Zhenli Sheng,Zhongyi Wang,Zhiwen Yu	With the rapid development of deep learning, recent research on intelligent and interactive mobile applications (e.g., health monitoring, speech recognition) has attracted extensive attention. And these applications necessitate the mobile edge computing scheme, i.e., offloading partial computation from mobile devices to edge devices for inference acceleration and transmission load reduction. The current practices have relied on collaborative DNN partition and offloading to satisfy the predefined latency requirements, which is intractable to adapt to the dynamic deployment context at runtime. AdaMEC, a context-adaptive and dynamically-combinable DNN deployment framework is proposed to meet these requirements for mobile edge computing, which consists of three novel techniques. First, once-for-all DNN pre-partition divides DNN at the primitive operator level and stores partitioned modules into executable files, defined as pre-partitioned DNN atoms. Second, context-adaptive DNN atom combination and offloading introduces a graph-based decision algorithm to quickly search the suitable combination of atoms and adaptively make the offloading plan under dynamic deployment contexts. Third, runtime latency predictor provides timely latency feedback for DNN deployment considering both DNN configurations and dynamic contexts. Extensive experiments demonstrate that AdaMEC outperforms state-of-the-art baselines in terms of latency reduction by up to 62.14% and average memory saving by 55.21%.	cs.DC	None
6	Multi-period Power System Risk Minimization under Wildfire Disruptions	Hanbin Yang,Noah Rhodes,Haoxiang Yang,Line Roald,Lewis Ntaimo	The frequency of wildfire disasters has surged five-fold in the past 50 years due to climate change. Preemptive de-energization is a potent strategy to mitigate wildfire risks but substantially impacts customers. We propose a multistage stochastic programming model for proactive de-energization planning, aiming to minimize economic loss while accomplishing a fair load delivery. We model wildfire disruptions as stochastic disruptions with varying timing and intensity, introduce a cutting-plane decomposition algorithm, and test our approach on the RTS-GLMC test case. Our model consistently offers a robust and fair de-energization plan that mitigates wildfire damage costs and minimizes load-shedding losses, particularly when pre-disruption restoration is considered.	math.OC	7 pages, 5 figures, conference. arXiv admin note: text overlap with   arXiv:2305.02933
7	ParisLuco3D: A high-quality target dataset for domain generalization of LiDAR perception	Jules Sanchez,Louis Soum-Fontez,Jean-Emmanuel Deschaud,Francois Goulette	LiDAR is a sensor system that supports autonomous driving by gathering precise geometric information about the scene. Exploiting this information for perception is interesting as the amount of available data increases.   As the quantitative performance of various perception tasks has improved, the focus has shifted from source-to-source perception to domain adaptation and domain generalization for perception. These new goals require access to a large variety of domains for evaluation. Unfortunately, the various annotation strategies of data providers complicate the computation of cross-domain performance based on the available data   This paper provides a novel dataset, specifically designed for cross-domain evaluation to make it easier to evaluate the performance of various source datasets. Alongside the dataset, a flexible online benchmark is provided to ensure a fair comparison across methods.	cs.CV	None
8	Dual Defense: Adversarial, Traceable, and Invisible Robust Watermarking against Face Swapping	Yunming Zhang,Dengpan Ye,Caiyun Xie,Long Tang,Chuanxi Chen,Ziyi Liu,Jiacheng Deng	The malicious applications of deep forgery, represented by face swapping, have introduced security threats such as misinformation dissemination and identity fraud. While some research has proposed the use of robust watermarking methods to trace the copyright of facial images for post-event traceability, these methods cannot effectively prevent the generation of forgeries at the source and curb their dissemination. To address this problem, we propose a novel comprehensive active defense mechanism that combines traceability and adversariality, called Dual Defense. Dual Defense invisibly embeds a single robust watermark within the target face to actively respond to sudden cases of malicious face swapping. It disrupts the output of the face swapping model while maintaining the integrity of watermark information throughout the entire dissemination process. This allows for watermark extraction at any stage of image tracking for traceability. Specifically, we introduce a watermark embedding network based on original-domain feature impersonation attack. This network learns robust adversarial features of target facial images and embeds watermarks, seeking a well-balanced trade-off between watermark invisibility, adversariality, and traceability through perceptual adversarial encoding strategies. Extensive experiments demonstrate that Dual Defense achieves optimal overall defense success rates and exhibits promising universality in anti-face swapping tasks and dataset generalization ability. It maintains impressive adversariality and traceability in both original and robust settings, surpassing current forgery defense methods that possess only one of these capabilities, including CMUA-Watermark, Anti-Forgery, FakeTagger, or PGD methods.	cs.CV	None
9	FedTherapist: Mental Health Monitoring with User-Generated Linguistic Expressions on Smartphones via Federated Learning	Jaemin Shin,Hyungjun Yoon,Seungjoo Lee,Sungjoon Park,Yunxin Liu,Jinho D. Choi,Sung-Ju Lee	Psychiatrists diagnose mental disorders via the linguistic use of patients. Still, due to data privacy, existing passive mental health monitoring systems use alternative features such as activity, app usage, and location via mobile devices. We propose FedTherapist, a mobile mental health monitoring system that utilizes continuous speech and keyboard input in a privacy-preserving way via federated learning. We explore multiple model designs by comparing their performance and overhead for FedTherapist to overcome the complex nature of on-device language model training on smartphones. We further propose a Context-Aware Language Learning (CALL) methodology to effectively utilize smartphones' large and noisy text for mental health signal sensing. Our IRB-approved evaluation of the prediction of self-reported depression, stress, anxiety, and mood from 46 participants shows higher accuracy of FedTherapist compared with the performance with non-language features, achieving 0.15 AUROC improvement and 8.21% MAE reduction.	cs.CL	Accepted to the 2023 Conference on Empirical Methods in Natural   Language Processing (EMNLP 2023)
0	A characterization of linear independence of THB-splines in $\mathbb{R}^n$ and application to B√©zier projection	Kevin Dijkstra,Deepesh Toshniwal	In this paper we propose a local projector for truncated hierarchical B-splines (THB-splines). The local THB-spline projector is an adaptation of the B\'ezier projector proposed by Thomas et al. (Comput Methods Appl Mech Eng 284, 2015) for B-splines and analysis-suitable T-splines (AS T-splines). For THB-splines, there are elements on which the restrictions of THB-splines are linearly dependent, contrary to B-splines and AS T-splines. Therefore, we cluster certain local mesh elements together such that the THB-splines with support over these clusters are linearly independent, and the B\'ezier projector is adapted to use these clusters. We introduce general extensions for which optimal convergence is shown theoretically and numerically. In addition, a simple adaptive refinement scheme is introduced and compared to Giust et al. (Comput. Aided Geom. Des. 80, 2020), where we find that our simple approach shows promise.	math.NA	28 pages, 11 figures
1	R$^3$ Prompting: Review, Rephrase and Resolve for Chain-of-Thought Reasoning in Large Language Models under Noisy Context	Qingyuan Tian,Hanlun Zhu,Lei Wang,Yang Li,Yunshi Lan	With the help of Chain-of-Thought (CoT) prompting, Large Language Models (LLMs) have achieved remarkable performance on various reasoning tasks. However, most of them have been evaluated under noise-free context and the dilemma for LLMs to produce inaccurate results under the noisy context has not been fully investigated. Existing studies utilize trigger sentences to encourage LLMs to concentrate on the relevant information but the trigger has limited effect on final answer prediction. Inspired by interactive CoT method, where intermediate reasoning steps are promoted by multiple rounds of interaction between users and LLMs, we propose a novel prompting method, namely R$^3$ prompting, for CoT reasoning under noisy context. Specifically, R$^3$ prompting interacts with LLMs to perform key sentence extraction, variable declaration and answer prediction, which corresponds to a thought process of reviewing, rephrasing and resolving. The responses generated at the last interaction will perform as hints to guide toward the responses of the next interaction. Our experiments show that R$^3$ prompting significantly outperforms existing CoT prompting methods on five reasoning tasks under noisy context. With GPT-3.5-turbo, we observe 3.7% accuracy improvement on average on the reasoning tasks under noisy context compared to the most competitive prompting baseline. More analyses and ablation studies show the robustness and generalization of R$^3$ prompting method in solving reasoning tasks in LLMs under noisy context.	cs.CL	None
2	An Early Evaluation of GPT-4V(ision)	Yang Wu,Shilong Wang,Hao Yang,Tian Zheng,Hongbo Zhang,Yanyan Zhao,Bing Qin	In this paper, we evaluate different abilities of GPT-4V including visual understanding, language understanding, visual puzzle solving, and understanding of other modalities such as depth, thermal, video, and audio. To estimate GPT-4V's performance, we manually construct 656 test instances and carefully evaluate the results of GPT-4V. The highlights of our findings are as follows: (1) GPT-4V exhibits impressive performance on English visual-centric benchmarks but fails to recognize simple Chinese texts in the images; (2) GPT-4V shows inconsistent refusal behavior when answering questions related to sensitive traits such as gender, race, and age; (3) GPT-4V obtains worse results than GPT-4 (API) on language understanding tasks including general language understanding benchmarks and visual commonsense knowledge evaluation benchmarks; (4) Few-shot prompting can improve GPT-4V's performance on both visual understanding and language understanding; (5) GPT-4V struggles to find the nuances between two similar images and solve the easy math picture puzzles; (6) GPT-4V shows non-trivial performance on the tasks of similar modalities to image, such as video and thermal. Our experimental results reveal the ability and limitations of GPT-4V and we hope our paper can provide some insights into the application and research of GPT-4V.	cs.CL	Technical Report. Data are available at   https://github.com/albertwy/GPT-4V-Evaluation
3	ATCA Study of Small Magellanic Cloud Supernova Remnant 1E 0102.2-7219	Rami Z. E. Alsaberi,M. D. Filipoviƒá,S. Dai,H. Sano,R. Kothes,J. L. Payne,L. M. Bozzetto,R. Brose,C. Collischon,E. J. Crawford,F. Haberl,T. Hill,P. J. Kavanagh,J. Knies,D. Leahy,P. J. Macgregor,P. Maggi,C. Maitra,P. Manojloviƒá,S. Mart√≠n,C. Matthew,N. O. Ralph,G. Rowell,A. J. Ruiter,M. Sasaki,I. R. Seitenzahl,K. Tokuda,N. F. H. Tothill,D. Uro≈°eviƒá,J. Th. van Loon,V. Veloviƒá,F. P. A. Vogt	We present new and archival Australia Telescope Compact Array and Atacama Large Millimeter/submillimeter Array data of the Small Magellanic Cloud supernova remnant 1E 0102.2-7219 at 2100, 5500, 9000, and 108000 MHz; as well as Hi data provided by the Australian Square Kilometre Array Pathfinder. The remnant shows a ring-like morphology with a mean radius of 6.2 pc. The 5500 MHz image reveals a bridge-like structure, seen for the first time in a radio image. This structure is also visible in both optical and X-ray images. In the 9000 MHz image we detect a central feature that has a flux density of 4.3 mJy but rule out a pulsar wind nebula origin, due to the lack of significant polarisation towards the central feature with an upper limit of 4 per cent. The mean fractional polarisation for 1E 0102.2-7219 is 7 +- 1 and 12 +- 2 per cent for 5500 and 9000 MHz, respectively. The spectral index for the entire remnant is -0.61 +- 0.01. We estimate the line-of-sight magnetic field strength in the direction of 1E 0102.2-7219 of ~44 microG with an equipartition field of 65 +- 5 microG. This latter model, uses the minimum energy of the sum of the magnetic field and cosmic ray electrons only. We detect an Hi cloud towards this remnant at the velocity range of ~160-180 km s-1 and a cavity-like structure at the velocity of 163.7-167.6 km s-1. We do not detect CO emission towards 1E 0102.2-7219.	astro-ph.HE	None
4	Learning Robust Deep Visual Representations from EEG Brain Recordings	Prajwal Singh,Dwip Dalal,Gautam Vashishtha,Krishna Miyapuram,Shanmuganathan Raman	Decoding the human brain has been a hallmark of neuroscientists and Artificial Intelligence researchers alike. Reconstruction of visual images from brain Electroencephalography (EEG) signals has garnered a lot of interest due to its applications in brain-computer interfacing. This study proposes a two-stage method where the first step is to obtain EEG-derived features for robust learning of deep representations and subsequently utilize the learned representation for image generation and classification. We demonstrate the generalizability of our feature extraction pipeline across three different datasets using deep-learning architectures with supervised and contrastive learning methods. We have performed the zero-shot EEG classification task to support the generalizability claim further. We observed that a subject invariant linearly separable visual representation was learned using EEG data alone in an unimodal setting that gives better k-means accuracy as compared to a joint representation learning between EEG and images. Finally, we propose a novel framework to transform unseen images into the EEG space and reconstruct them with approximation, showcasing the potential for image reconstruction from EEG signals. Our proposed image synthesis method from EEG shows 62.9% and 36.13% inception score improvement on the EEGCVPR40 and the Thoughtviz datasets, which is better than state-of-the-art performance in GAN.	cs.CV	Accepted in WACV 2024
5	Pretty Good Strategies and Where to Find Them	Wojciech Jamroga,Damian Kurpiewski	"Synthesis of bulletproof strategies in imperfect information scenarios is a notoriously hard problem. In this paper, we suggest that it is sometimes a viable alternative to aim at ""reasonably good"" strategies instead. This makes sense not only when an ideal strategy cannot be found due to the complexity of the problem, but also when no winning strategy exists at all. We propose an algorithm for synthesis of such ""pretty good"" strategies. The idea is to first generate a surely winning strategy with perfect information, and then iteratively improve it with respect to two criteria of dominance: one based on the amount of conflicting decisions in the strategy, and the other related to the tightness of its outcome set. We focus on reachability goals and evaluate the algorithm experimentally with very promising results."	cs.MA	None
6	Toward Practical Privacy-Preserving Convolutional Neural Networks Exploiting Fully Homomorphic Encryption	Jaiyoung Park,Donghwan Kim,Jongmin Kim,Sangpyo Kim,Wonkyung Jung,Jung Hee Cheon,Jung Ho Ahn	Incorporating fully homomorphic encryption (FHE) into the inference process of a convolutional neural network (CNN) draws enormous attention as a viable approach for achieving private inference (PI). FHE allows delegating the entire computation process to the server while ensuring the confidentiality of sensitive client-side data. However, practical FHE implementation of a CNN faces significant hurdles, primarily due to FHE's substantial computational and memory overhead. To address these challenges, we propose a set of optimizations, which includes GPU/ASIC acceleration, an efficient activation function, and an optimized packing scheme. We evaluate our method using the ResNet models on the CIFAR-10 and ImageNet datasets, achieving several orders of magnitude improvement compared to prior work and reducing the latency of the encrypted CNN inference to 1.4 seconds on an NVIDIA A100 GPU. We also show that the latency drops to a mere 0.03 seconds with a custom hardware design.	cs.CR	3 pages, 1 figure, appears at DISCC 2023 (2nd Workshop on Data   Integrity and Secure Cloud Computing, in conjunction with the 56th   International Symposium on Microarchitecture (MICRO 2023))
7	CUNI Submission to MRL 2023 Shared Task on Multi-lingual Multi-task Information Retrieval	Jind≈ôich Helcl,Jind≈ôich Libovick√Ω	We present the Charles University system for the MRL~2023 Shared Task on Multi-lingual Multi-task Information Retrieval. The goal of the shared task was to develop systems for named entity recognition and question answering in several under-represented languages. Our solutions to both subtasks rely on the translate-test approach. We first translate the unlabeled examples into English using a multilingual machine translation model. Then, we run inference on the translated data using a strong task-specific model. Finally, we project the labeled data back into the original language. To keep the inferred tags on the correct positions in the original language, we propose a method based on scoring the candidate positions using a label-sensitive translation model. In both settings, we experiment with finetuning the classification models on the translated data. However, due to a domain mismatch between the development data and the shared task validation and test sets, the finetuned models could not outperform our baselines.	cs.CL	8 pages, 2 figures; System description paper at the MRL 2023 workshop   at EMNLP 2023
8	Enhancing Document Information Analysis with Multi-Task Pre-training: A Robust Approach for Information Extraction in Visually-Rich Documents	Tofik Ali,Partha Pratim Roy	This paper introduces a deep learning model tailored for document information analysis, emphasizing document classification, entity relation extraction, and document visual question answering. The proposed model leverages transformer-based models to encode all the information present in a document image, including textual, visual, and layout information. The model is pre-trained and subsequently fine-tuned for various document image analysis tasks. The proposed model incorporates three additional tasks during the pre-training phase, including reading order identification of different layout segments in a document image, layout segments categorization as per PubLayNet, and generation of the text sequence within a given layout segment (text block). The model also incorporates a collective pre-training scheme where losses of all the tasks under consideration, including pre-training and fine-tuning tasks with all datasets, are considered. Additional encoder and decoder blocks are added to the RoBERTa network to generate results for all tasks. The proposed model achieved impressive results across all tasks, with an accuracy of 95.87% on the RVL-CDIP dataset for document classification, F1 scores of 0.9306, 0.9804, 0.9794, and 0.8742 on the FUNSD, CORD, SROIE, and Kleister-NDA datasets respectively for entity relation extraction, and an ANLS score of 0.8468 on the DocVQA dataset for visual question answering. The results highlight the effectiveness of the proposed model in understanding and interpreting complex document layouts and content, making it a promising tool for document analysis tasks.	cs.CV	None
9	Cyclic Directed Probabilistic Graphical Model: A Proposal Based on Structured Outcomes	Oleksii Sirotkin	In the process of building (structural learning) a probabilistic graphical model from a set of observed data, the directional, cyclic dependencies between the random variables of the model are often found. Existing graphical models such as Bayesian and Markov networks can reflect such dependencies. However, this requires complicating those models, such as adding additional variables or dividing the model graph into separate subgraphs. Herein, we describe a probabilistic graphical model - probabilistic relation network - that allows the direct capture of directional cyclic dependencies during structural learning. This model is based on the simple idea that each sample of the observed data can be represented by an arbitrary graph (structured outcome), which reflects the structure of the dependencies of the variables included in the sample. Each of the outcomes contains only a part of the graphical model structure; however, a complete graph of the probabilistic model is obtained by combining different outcomes. Such a graph, unlike Bayesian and Markov networks, can be directed and can have cycles. We explored the full joint distribution and conditional distribution and conditional independence properties of variables in the proposed model. We defined the algorithms for constructing of the model from the dataset and for calculating the conditional and full joint distributions. We also performed a numerical comparison with Bayesian and Markov networks. This model does not violate the probability axioms, and it supports learning from observed data. Notably, it supports probabilistic inference, making it a prospective tool in data analysis and in expert and design-making applications.	cs.LG	41 pages, 11 figures, arXiv:2206.06089v1
0	Can You Rely on Your Model Evaluation? Improving Model Evaluation with Synthetic Test Data	Boris van Breugel,Nabeel Seedat,Fergus Imrie,Mihaela van der Schaar	Evaluating the performance of machine learning models on diverse and underrepresented subgroups is essential for ensuring fairness and reliability in real-world applications. However, accurately assessing model performance becomes challenging due to two main issues: (1) a scarcity of test data, especially for small subgroups, and (2) possible distributional shifts in the model's deployment setting, which may not align with the available test data. In this work, we introduce 3S Testing, a deep generative modeling framework to facilitate model evaluation by generating synthetic test sets for small subgroups and simulating distributional shifts. Our experiments demonstrate that 3S Testing outperforms traditional baselines -- including real test data alone -- in estimating model performance on minority subgroups and under plausible distributional shifts. In addition, 3S offers intervals around its performance estimates, exhibiting superior coverage of the ground truth compared to existing approaches. Overall, these results raise the question of whether we need a paradigm shift away from limited real test data towards synthetic test data.	cs.LG	Advances in Neural Information Processing Systems 36 (NeurIPS 2023).   Van Breugel & Seedat contributed equally
1	Improving Diversity of Demographic Representation in Large Language Models via Collective-Critiques and Self-Voting	Preethi Lahoti,Nicholas Blumm,Xiao Ma,Raghavendra Kotikalapudi,Sahitya Potluri,Qijun Tan,Hansa Srinivasan,Ben Packer,Ahmad Beirami,Alex Beutel,Jilin Chen	A crucial challenge for generative large language models (LLMs) is diversity: when a user's prompt is under-specified, models may follow implicit assumptions while generating a response, which may result in homogenization of the responses, as well as certain demographic groups being under-represented or even erased from the generated responses. In this paper, we formalize diversity of representation in generative LLMs. We present evaluation datasets and propose metrics to measure diversity in generated responses along people and culture axes. We find that LLMs understand the notion of diversity, and that they can reason and critique their own responses for that goal. This finding motivated a new prompting technique called collective-critique and self-voting (CCSV) to self-improve people diversity of LLMs by tapping into its diversity reasoning capabilities, without relying on handcrafted examples or prompt tuning. Extensive empirical experiments with both human and automated evaluations show that our proposed approach is effective at improving people and culture diversity, and outperforms all baseline methods by a large margin.	cs.CL	To appear at EMNLP 2023 main conference
2	Towards Self-Interpretable Graph-Level Anomaly Detection	Yixin Liu,Kaize Ding,Qinghua Lu,Fuyi Li,Leo Yu Zhang,Shirui Pan	Graph-level anomaly detection (GLAD) aims to identify graphs that exhibit notable dissimilarity compared to the majority in a collection. However, current works primarily focus on evaluating graph-level abnormality while failing to provide meaningful explanations for the predictions, which largely limits their reliability and application scope. In this paper, we investigate a new challenging problem, explainable GLAD, where the learning objective is to predict the abnormality of each graph sample with corresponding explanations, i.e., the vital subgraph that leads to the predictions. To address this challenging problem, we propose a Self-Interpretable Graph aNomaly dETection model (SIGNET for short) that detects anomalous graphs as well as generates informative explanations simultaneously. Specifically, we first introduce the multi-view subgraph information bottleneck (MSIB) framework, serving as the design basis of our self-interpretable GLAD approach. This way SIGNET is able to not only measure the abnormality of each graph based on cross-view mutual information but also provide informative graph rationales by extracting bottleneck subgraphs from the input graph and its dual hypergraph in a self-supervised way. Extensive experiments on 16 datasets demonstrate the anomaly detection capability and self-interpretability of SIGNET.	cs.LG	23 pages; accepted to NeurIPS 2023
3	MsATL: a Tool for SAT-Based ATL Satisfiability Checking	Artur Niewiadomski,Magdalena Kacprzak,Damian Kurpiewski,Micha≈Ç Knapik,Wojciech Penczek,Wojciech Jamroga	We present MsATL: the first tool for deciding the satisfiability of Alternating-time Temporal Logic (ATL) with imperfect information. MsATL combines SAT Modulo Monotonic Theories solvers with existing ATL model checkers: MCMAS and STV. The tool can deal with various semantics of ATL, including perfect and imperfect information, and can handle additional practical requirements. MsATL can be applied for synthesis of games that conform to a given specification, with the synthesised game often being minimal.	cs.LO	None
4	OccuQuest: Mitigating Occupational Bias for Inclusive Large Language Models	Mingfeng Xue,Dayiheng Liu,Kexin Yang,Guanting Dong,Wenqiang Lei,Zheng Yuan,Chang Zhou,Jingren Zhou	The emergence of large language models (LLMs) has revolutionized natural language processing tasks. However, existing instruction-tuning datasets suffer from occupational bias: the majority of data relates to only a few occupations, which hampers the instruction-tuned LLMs to generate helpful responses to professional queries from practitioners in specific fields. To mitigate this issue and promote occupation-inclusive LLMs, we create an instruction-tuning dataset named \emph{OccuQuest}, which contains 110,000+ prompt-completion pairs and 30,000+ dialogues covering over 1,000 occupations in 26 occupational categories. We systematically request ChatGPT, organizing queries hierarchically based on Occupation, Responsibility, Topic, and Question, to ensure a comprehensive coverage of occupational specialty inquiries. By comparing with three commonly used datasets (Dolly, ShareGPT, and WizardLM), we observe that OccuQuest exhibits a more balanced distribution across occupations. Furthermore, we assemble three test sets for comprehensive evaluation, an occu-test set covering 25 occupational categories, an estate set focusing on real estate, and an occu-quora set containing real-world questions from Quora. We then fine-tune LLaMA on OccuQuest to obtain OccuLLaMA, which significantly outperforms state-of-the-art LLaMA variants (Vicuna, Tulu, and WizardLM) on professional questions in GPT-4 and human evaluations. Notably, on the occu-quora set, OccuLLaMA reaches a high win rate of 86.4\% against WizardLM.	cs.CL	None
5	Particle-based Variational Inference with Generalized Wasserstein Gradient Flow	Ziheng Cheng,Shiyue Zhang,Longlin Yu,Cheng Zhang	Particle-based variational inference methods (ParVIs) such as Stein variational gradient descent (SVGD) update the particles based on the kernelized Wasserstein gradient flow for the Kullback-Leibler (KL) divergence. However, the design of kernels is often non-trivial and can be restrictive for the flexibility of the method. Recent works show that functional gradient flow approximations with quadratic form regularization terms can improve performance. In this paper, we propose a ParVI framework, called generalized Wasserstein gradient descent (GWG), based on a generalized Wasserstein gradient flow of the KL divergence, which can be viewed as a functional gradient method with a broader class of regularizers induced by convex functions. We show that GWG exhibits strong convergence guarantees. We also provide an adaptive version that automatically chooses Wasserstein metric to accelerate convergence. In experiments, we demonstrate the effectiveness and efficiency of the proposed framework on both simulated and real data problems.	stat.ML	None
6	Solving and Applying Fractal Differential Equations: Exploring Fractal Calculus in Theory and Practice	Alireza Khalili Golmankhaneh,Donatella Bongiorno	In this paper, we delve into the fascinating realm of fractal calculus applied to fractal sets and fractal curves. Our study includes an exploration of the method analogues of the separable method and the integrating factor technique for solving $\alpha$-order differential equations. Notably, we extend our analysis to solve Fractal Bernoulli differential equations. The applications of our findings are then showcased through the solutions of problems such as fractal compound interest, the escape velocity of the earth in fractal space and time, and estimation of time of death incorporating fractal time. Visual representations of our results are also provided to enhance understanding.	math.GM	None
7	Non-equilibrium Dynamics of Vortices in Two-Dimensional Quantum Gases: Determining the Dynamical Scaling Region Using the Mahalanobis Distance	Richard Tattersall,Andrew Baggaley,Thomas Billam	When a two-dimensional system undergoes a rapid quench from a disordered to an ordered phase, it does not order instantly but instead relaxes towards equilibrium over time. During this relaxation, the dynamical scaling hypothesis predicts that the length scale of ordered regions increases, with later patterns statistically similar to earlier ones except for a change in global scale. Quantum gases are one of many systems in which such out of equilibrium behaviour is predicted to occur. Here we present a method for systematically testing when dynamical scaling is taking place, by quantifying the similarity of the rescaled two-point correlation function over time using the Mahalanobis distance. Data on the velocity field of a quantum fluid, generated from point vortex simulations, are used to illustrate the application of this method.	cond-mat.quant-gas	13 pages, 5 figures
8	Nonreciprocal Signal Growth in Space-Time Modulated Transmission Lines	Mohamed F. Hagag,Thomas R. Jones,Karim Seddik,Dimitrios Peroulis	We investigate nonreciprocal signal amplification in a space-time-modulated transmission line. By loading a transmission line with a sinusoidally time-modulated capacitor, reciprocal momentum band gaps (MPG) appear in the unit cell dispersion diagram (DD) at frequency ratio $F_{signal}= 0.5~F_{modulation}$. Due to the sole existence of complex frequencies in the MPG, waves propagating with a momentum that lies within the MPG are amplified. In addition to time modulation, the TL is space-modulated by imposing a modulation phase shift $-\theta_m$ between successive unit cells. As a result, forward and backward MPG locations in the DD shift from $F_{signal}= 0.5~F_{modulation}$ in opposite directions, causing nonreciprocal signal growth frequencies. Nonreciprocal amplification is confirmed by circuit modeling outcomes, which totally agree with DD results.	physics.app-ph	None
9	Joint Constraints on the Hubble Constant, Spatial Curvature, and Sound Horizon from the Late-time Universe with Cosmography	Kaituo Zhang,Tianyao Zhou,Bing Xu,Qihong Huang,Yangsheng Yuan	In this paper, using the latest Pantheon+ sample of Type Ia supernovae (SNe Ia), Baryon Acoustic Oscillation (BAO) measurements, and observational Hubble data (OHD), we carry out a joint constraint on the Hubble constant $H_0$, the spatial curvature $\Omega_{\rm K}$, and the sound horizon at the end of drag epoch $r_{\rm d}$. To be model-independent, four cosmography models, i.e., the Taylor series in terms of redshift $y_1=z/(1+z)$, $y_2=\arctan(z)$, $y_3=\ln(1+z)$, and the Pad\'e approximants, are used without the assumption of flat Universe. The results show that the $H_0$ is anti-correlated with $\Omega_{\rm K}$ and $r_{\rm d}$, indicating smaller $\Omega_{\rm K}$ or $r_{\rm d}$ would be helpful in alleviating the Hubble tension. And the values of $H_0$ and $r_{\rm d}$ are consistent with the estimate derived from the Planck Cosmic Microwave Background (CMB) data based on the flat $\Lambda$CDM model, but $H_0$ is in 2.3$\sim$3.0$\sigma$ tension with that obtained by \cite{Riess2022} in all these cosmographic approaches. Meanwhile, a flat Universe is preferred by the present observations under all approximations except the third order of $y_1$ and $y_2$ of the Taylor series. Furthermore, according to the values of the Bayesian evidence, we found that the flat $\Lambda$CDM remains to be the most favored model by the joint datasets, and the Pad\'e approximant of order (2,2), the third order of $y_3$ and $y_1$ are the top three cosmographic expansions that fit the datasets best, while the Taylor series in terms of $y_2$ are essentially ruled out.	astro-ph.CO	18 pages, 4 figures
0	Performance best practices using Java and AWS Lambda	Juan Mera Men√©ndez,Martin Bartlett	Despite its already widespread popularity, it continues to gain adoption. More and more developers and architects continue to adopt and apply the FaaS (Function as a Service) model in cloud solutions. The most extensively used FaaS service is AWS Lambda, provided by Amazon Web Services. Moreover, despite the new trends in programming languages, Java still maintains a significant share of usage. The main problem that arises when using these two technologies together is widely known: significant latencies and the dreaded cold start. However, it is possible to greatly mitigate this problem without dedicating too much effort. In this article, various techniques, strategies and approaches will be studied with the aim of reducing the cold start and significantly improving the performance of Lambda functions with Java. Starting from a system that involves AWS lambda, java, DynamoDB and Api Gateway. Each approach will be tested independently, analyzing its impact through load tests. Subsequently, they will be tested in combination in an effort to achieve the greatest possible performance improvement.	cs.SE	None
1	Information-theoretical analysis of event-triggered molecular communication	Wafa Labidi,Christian Deppe,Holger Boche	Numerous applications in the field of molecular communications (MC) such as healthcare systems are often event-driven. The conventional Shannon capacity may not be the appropriate metric for assessing performance in such cases. We propose the identification (ID) capacity as an alternative metric. Particularly, we consider randomized identification (RI) over the discrete-time Poisson channel (DTPC), which is typically used as a model for MC systems that utilize molecule-counting receivers. In the ID paradigm, the receiver's focus is not on decoding the message sent. However, he wants to determine whether a message of particular significance to him has been sent or not. In contrast to Shannon transmission codes, the size of ID codes for a Discrete Memoryless Channel (DMC) grows doubly exponentially fast with the blocklength, if randomized encoding is used. In this paper, we derive the capacity formula for RI over the DTPC subject to some peak and average power constraints. Furthermore, we analyze the case of state-dependent DTPC.	cs.IT	None
2	Identifying Reasons for Bias: An Argumentation-Based Approach	Madeleine Waller,Odinaldo Rodrigues,Oana Cocarascu	As algorithmic decision-making systems become more prevalent in society, ensuring the fairness of these systems is becoming increasingly important. Whilst there has been substantial research in building fair algorithmic decision-making systems, the majority of these methods require access to the training data, including personal characteristics, and are not transparent regarding which individuals are classified unfairly. In this paper, we propose a novel model-agnostic argumentation-based method to determine why an individual is classified differently in comparison to similar individuals. Our method uses a quantitative argumentation framework to represent attribute-value pairs of an individual and of those similar to them, and uses a well-known semantics to identify the attribute-value pairs in the individual contributing most to their different classification. We evaluate our method on two datasets commonly used in the fairness literature and illustrate its effectiveness in the identification of bias.	cs.LG	10 pages
3	Bootstrapping entanglement in quantum spin chains	Jiaju Zhang,Arash Jafarizadeh,M. A. Rajabpour	This paper aims to redefine how we understand and calculate the properties of quantum many-body systems, specifically focusing on entanglement in quantum spin systems. Traditional approaches necessitate the diagonalization of the system's Hamiltonian to ascertain properties such as eigenvalues, correlation functions, and quantum entanglement. In contrast, we employ the bootstrap method, a technique that leverages consistency relations rather than direct diagonalization, to estimate these properties. Our work extends the bootstrap approach to quantum spin systems, concentrating on the well-known Lipkin-Meshkov-Glick model with both transverse and longitudinal external magnetic fields. Unlike previous studies that have focused mainly on ground-state properties, our methodology allows for the calculation of a broad range of properties, including energy spectrum, angular momentum, concurrence, tangle, residual tangle, and quantum Fisher information (QFI), for all eigenstates. We show that this approach offers not only a new computational methodology but also a comprehensive view of both bipartite and multipartite entanglement properties across the entire spectrum of eigenstates. Specifically, we demonstrate that states typically found in the central region of the spectrum exhibit greater multipartite entanglement, as indicated by larger QFI values, compared to states at the edges of the spectrum. In contrast, concurrence displays the opposite trend. This observed behavior is in line with the monogamy principle governing quantum entanglement.	quant-ph	20 pages 4 figures
4	Assessing the overall and partial causal well-specification of nonlinear additive noise models	Christoph Schultheiss,Peter B√ºhlmann	We propose a method to detect model misspecifications in nonlinear causal additive and potentially heteroscedastic noise models. We aim to identify predictor variables for which we can infer the causal effect even in cases of such misspecification. We develop a general framework based on knowledge of the multivariate observational data distribution and we then propose an algorithm for finite sample data, discuss its asymptotic properties, and illustrate its performance on simulated and real data.	stat.ME	None
5	Simultaneously probing the sound speed and equation of state of the early Universe with pulsar timing arrays	Lang Liu,You Wu,Zu-Cheng Chen	Recently, several major pulsar timing array (PTA) collaborations have assembled strong evidence for the existence of a gravitational-wave background at frequencies around the nanohertz regime. Assuming that the PTA signal is attributed to scalar-induced gravitational waves, we jointly employ the PTA data from the NANOGrav 15-year data set, PPTA DR3, and EPTA DR2 to probe the conditions of the early Universe. Specifically, we explore the equation of state parameter ($w$), the sound speed ($c_s$), and the reheating temperature ($T_\mathrm{rh}$), finding $w=0.60^{+0.32}_{-0.39}$, $c_s\gtrsim 0.09$, and $T_\mathrm{rh}\lesssim 0.2\,\mathrm{GeV}$ for a lognormal power spectrum of the curvature perturbation. Furthermore, we compute Bayes factors to compare different models against the radiation domination model ($c_s^2 = w = 1/3$), effectively excluding the pressure-less fluid domination model. Our study underscores the significance of scalar-induced gravitational waves as a powerful tool to explore the nature of the early Universe.	astro-ph.CO	22 pages, 3 figures, 2 tables
6	Data Optimization in Deep Learning: A Survey	Ou Wu,Rujing Yao	Large-scale, high-quality data are considered an essential factor for the successful application of many deep learning techniques. Meanwhile, numerous real-world deep learning tasks still have to contend with the lack of sufficient amounts of high-quality data. Additionally, issues such as model robustness, fairness, and trustworthiness are also closely related to training data. Consequently, a huge number of studies in the existing literature have focused on the data aspect in deep learning tasks. Some typical data optimization techniques include data augmentation, logit perturbation, sample weighting, and data condensation. These techniques usually come from different deep learning divisions and their theoretical inspirations or heuristic motivations may seem unrelated to each other. This study aims to organize a wide range of existing data optimization methodologies for deep learning from the previous literature, and makes the effort to construct a comprehensive taxonomy for them. The constructed taxonomy considers the diversity of split dimensions, and deep sub-taxonomies are constructed for each dimension. On the basis of the taxonomy, connections among the extensive data optimization methods for deep learning are built in terms of four aspects. We probe into rendering several promising and interesting future directions. The constructed taxonomy and the revealed connections will enlighten the better understanding of existing methods and the design of novel data optimization techniques. Furthermore, our aspiration for this survey is to promote data optimization as an independent subdivision of deep learning. A curated, up-to-date list of resources related to data optimization in deep learning is available at \url{https://github.com/YaoRujing/Data-Optimization}.	cs.LG	None
7	Citizen participation: crowd-sensed sustainable indoor location services	Ioannis Nasios,Konstantinos Vogklis,Avleen Malhi,Anastasia Vayona,Panos Chatziadam,Vasilis Katos	In the present era of sustainable innovation, the circular economy paradigm dictates the optimal use and exploitation of existing finite resources. At the same time, the transition to smart infrastructures requires considerable investment in capital, resources and people. In this work, we present a general machine learning approach for offering indoor location awareness without the need to invest in additional and specialised hardware. We explore use cases where visitors equipped with their smart phone would interact with the available WiFi infrastructure to estimate their location, since the indoor requirement poses a limitation to standard GPS solutions. Results have shown that the proposed approach achieves a less than 2m accuracy and the model is resilient even in the case where a substantial number of BSSIDs are dropped.	cs.LG	Preprint submitted to Elsevier
8	Lang3DSG: Language-based contrastive pre-training for 3D Scene Graph prediction	Sebastian Koch,Pedro Hermosilla,Narunas Vaskevicius,Mirco Colosi,Timo Ropinski	D scene graphs are an emerging 3D scene representation, that models both the objects present in the scene as well as their relationships. However, learning 3D scene graphs is a challenging task because it requires not only object labels but also relationship annotations, which are very scarce in datasets. While it is widely accepted that pre-training is an effective approach to improve model performance in low data regimes, in this paper, we find that existing pre-training methods are ill-suited for 3D scene graphs. To solve this issue, we present the first language-based pre-training approach for 3D scene graphs, whereby we exploit the strong relationship between scene graphs and language. To this end, we leverage the language encoder of CLIP, a popular vision-language model, to distill its knowledge into our graph-based network. We formulate a contrastive pre-training, which aligns text embeddings of relationships (subject-predicate-object triplets) and predicted 3D graph features. Our method achieves state-of-the-art results on the main semantic 3D scene graph benchmark by showing improved effectiveness over pre-training baselines and outperforming all the existing fully supervised scene graph prediction methods by a significant margin. Furthermore, since our scene graph features are language-aligned, it allows us to query the language space of the features in a zero-shot manner. In this paper, we show an example of utilizing this property of the features to predict the room type of a scene without further training.	cs.CV	3DV 2024. Project page: https://kochsebastian.com/lang3dsg
9	On the Powerfulness of Textual Outlier Exposure for Visual OoD Detection	Sangha Park,Jisoo Mok,Dahuin Jung,Saehyung Lee,Sungroh Yoon	Successful detection of Out-of-Distribution (OoD) data is becoming increasingly important to ensure safe deployment of neural networks. One of the main challenges in OoD detection is that neural networks output overconfident predictions on OoD data, make it difficult to determine OoD-ness of data solely based on their predictions. Outlier exposure addresses this issue by introducing an additional loss that encourages low-confidence predictions on OoD data during training. While outlier exposure has shown promising potential in improving OoD detection performance, all previous studies on outlier exposure have been limited to utilizing visual outliers. Drawing inspiration from the recent advancements in vision-language pre-training, this paper venture out to the uncharted territory of textual outlier exposure. First, we uncover the benefits of using textual outliers by replacing real or virtual outliers in the image-domain with textual equivalents. Then, we propose various ways of generating preferable textual outliers. Our extensive experiments demonstrate that generated textual outliers achieve competitive performance on large-scale OoD and hard OoD benchmarks. Furthermore, we conduct empirical analyses of textual outliers to provide primary criteria for designing advantageous textual outliers: near-distribution, descriptiveness, and inclusion of visual semantics.	cs.CV	Accepted by NeurIPS 2023
0	TSONN: Time-stepping-oriented neural network for solving partial differential equations	Wenbo Cao,Weiwei Zhang	Deep neural networks (DNNs), especially physics-informed neural networks (PINNs), have recently become a new popular method for solving forward and inverse problems governed by partial differential equations (PDEs). However, these methods still face challenges in achieving stable training and obtaining correct results in many problems, since minimizing PDE residuals with PDE-based soft constraint make the problem ill-conditioned. Different from all existing methods that directly minimize PDE residuals, this work integrates time-stepping method with deep learning, and transforms the original ill-conditioned optimization problem into a series of well-conditioned sub-problems over given pseudo time intervals. The convergence of model training is significantly improved by following the trajectory of the pseudo time-stepping process, yielding a robust optimization-based PDE solver. Our results show that the proposed method achieves stable training and correct results in many problems that standard PINNs fail to solve, requiring only a simple modification on the loss function. In addition, we demonstrate several novel properties and advantages of time-stepping methods within the framework of neural network-based optimization approach, in comparison to traditional grid-based numerical method. Specifically, explicit scheme allows significantly larger time step, while implicit scheme can be implemented as straightforwardly as explicit scheme.	cs.LG	None
1	Climate-related Agricultural Productivity Losses through a Poverty Lens	Alkis Blanz	In this paper, we analyze the long-term distributive impact of climate change through rising food prices. We use a standard incomplete markets model and account for non-linear Engel curves for food consumption. For the calibration of our model, we rely on household data from 92 developing countries, representing 4.5 billion people. The results indicate that the short-term and long-term distributive impact of climate change differs. Including general equilibrium effects change the welfare outcome especially for the poorest quintile. In the presence of idiosyncratic risk, higher food prices increase precautionary savings, which through general equilibrium affect labor income of all agents. Furthermore, this paper studies the impact on inequality for different allocations of productivity losses across sectors. When climate impacts affects total factor productivity in both sectors of the economy, climate impacts increase also wealth inequality.	econ.GN	None
2	Latent event history models for quasi-reaction systems	Matteo Framba,Veronica Vinciotti,Ernst C. Wit	Various processes can be modelled as quasi-reaction systems of stochastic differential equations, such as cell differentiation and disease spreading. Since the underlying data of particle interactions, such as reactions between proteins or contacts between people, are typically unobserved, statistical inference of the parameters driving these systems is developed from concentration data measuring each unit in the system over time. While observing the continuous time process at a time scale as fine as possible should in theory help with parameter estimation, the existing Local Linear Approximation (LLA) methods fail in this case, due to numerical instability caused by small changes of the system at successive time points. On the other hand, one may be able to reconstruct the underlying unobserved interactions from the observed count data. Motivated by this, we first formalise the latent event history model underlying the observed count process. We then propose a computationally efficient Expectation-Maximation algorithm for parameter estimation, with an extended Kalman filtering procedure for the prediction of the latent states. A simulation study shows the performance of the proposed method and highlights the settings where it is particularly advantageous compared to the existing LLA approaches. Finally, we present an illustration of the methodology on the spreading of the COVID-19 pandemic in Italy.	stat.ME	None
3	Mean field theory for a general class of short-range interaction functionals	Guy Bouchitt√©,Rajesh Mahadevan	In models of $N$ interacting particles in $\R^d$ as in Density Functional Theory or crowd motion, the repulsive cost is usually described by a two-point function $c_\e(x,y) =\ell\Big(\frac{|x-y|}{\e}\Big)$ where $\ell: \R_+ \to [0,\infty]$ is decreasing to zero at infinity and parameter $\e>0$ scales the interaction distance. In this paper we identify the mean-field energy of such a model in the short-range regime $\e\ll 1$ under the sole assumption that $\exists r_0>0 \ : \ \int_{r_0}^\infty \ell(r) r^{d-1}\, dr <+\infty$. This extends recent results \cite{hardin2021, HardSerfLebl, Lewin} obtained in the homogeneous case $\ell(r) = r^{-s}$ where $s>d$.	math-ph	None
4	A Comprehensive Python Library for Deep Learning-Based Event Detection in Multivariate Time Series Data and Information Retrieval in NLP	Menouar Azib,Benjamin Renard,Philippe Garnier,Vincent G√©not,Nicolas Andr√©	Event detection in time series data is crucial in various domains, including finance, healthcare, cybersecurity, and science. Accurately identifying events in time series data is vital for making informed decisions, detecting anomalies, and predicting future trends. Despite extensive research exploring diverse methods for event detection in time series, with deep learning approaches being among the most advanced, there is still room for improvement and innovation in this field. In this paper, we present a new deep learning supervised method for detecting events in multivariate time series data. Our method combines four distinct novelties compared to existing deep-learning supervised methods. Firstly, it is based on regression instead of binary classification. Secondly, it does not require labeled datasets where each point is labeled; instead, it only requires reference events defined as time points or intervals of time. Thirdly, it is designed to be robust by using a stacked ensemble learning meta-model that combines deep learning models, ranging from classic feed-forward neural networks (FFNs) to state-of-the-art architectures like transformers. This ensemble approach can mitigate individual model weaknesses and biases, resulting in more robust predictions. Finally, to facilitate practical implementation, we have developed a Python package to accompany our proposed method. The package, called eventdetector-ts, can be installed through the Python Package Index (PyPI). In this paper, we present our method and provide a comprehensive guide on the usage of the package. We showcase its versatility and effectiveness through different real-world use cases from natural language processing (NLP) to financial security domains.	cs.LG	Accepted for the 22nd International Conference on Machine Learning   and Applications (ICMLA)
5	Subspace Chronicles: How Linguistic Information Emerges, Shifts and Interacts during Language Model Training	Max M√ºller-Eberstein,Rob van der Goot,Barbara Plank,Ivan Titov	Representational spaces learned via language modeling are fundamental to Natural Language Processing (NLP), however there has been limited understanding regarding how and when during training various types of linguistic information emerge and interact. Leveraging a novel information theoretic probing suite, which enables direct comparisons of not just task performance, but their representational subspaces, we analyze nine tasks covering syntax, semantics and reasoning, across 2M pre-training steps and five seeds. We identify critical learning phases across tasks and time, during which subspaces emerge, share information, and later disentangle to specialize. Across these phases, syntactic knowledge is acquired rapidly after 0.5% of full training. Continued performance improvements primarily stem from the acquisition of open-domain knowledge, while semantics and reasoning tasks benefit from later boosts to long-range contextualization and higher specialization. Measuring cross-task similarity further reveals that linguistically related tasks share information throughout training, and do so more during the critical phase of learning than before or after. Our findings have implications for model interpretability, multi-task learning, and learning from limited data.	cs.CL	Accepted at EMNLP 2023 (Findings)
6	Gramian Attention Heads are Strong yet Efficient Vision Learners	Jongbin Ryu,Dongyoon Han,Jongwoo Lim	We introduce a novel architecture design that enhances expressiveness by incorporating multiple head classifiers (\ie, classification heads) instead of relying on channel expansion or additional building blocks. Our approach employs attention-based aggregation, utilizing pairwise feature similarity to enhance multiple lightweight heads with minimal resource overhead. We compute the Gramian matrices to reinforce class tokens in an attention layer for each head. This enables the heads to learn more discriminative representations, enhancing their aggregation capabilities. Furthermore, we propose a learning algorithm that encourages heads to complement each other by reducing correlation for aggregation. Our models eventually surpass state-of-the-art CNNs and ViTs regarding the accuracy-throughput trade-off on ImageNet-1K and deliver remarkable performance across various downstream tasks, such as COCO object instance segmentation, ADE20k semantic segmentation, and fine-grained visual classification datasets. The effectiveness of our framework is substantiated by practical experimental results and further underpinned by generalization error bound. We release the code publicly at: https://github.com/Lab-LVM/imagenet-models.	cs.CV	None
7	Primordial Black Hole formation from overlapping cosmological fluctuations	Albert Escriv√†,Chul-Moon Yoo	We consider the formation of primordial black holes (PBHs), during the radiation-dominated Universe, generated from the collapse of super-horizon curvature fluctuations that are overlapped with others on larger scales. Using a set of different curvature profiles, we show that the threshold for PBH formation (defined as the critical peak of the compaction function) can be decreased by several percentages, thanks to the overlapping between the fluctuations. In the opposite case, when the fluctuations are sufficiently decoupled the threshold values behave as having the fluctuations isolated (isolated peaks). We find that the analytical estimates of arXiv:1907.13311 can be used accurately when applied to the corresponding peak that is leading to the gravitational collapse. We also study in detail the dynamics and estimate the final PBH mass for different initial configurations, showing that the profile dependence has a significant effect on that.	gr-qc	27 pages and 14 figures
8	Harris's method for non-conservative periodic semiflows and application to some non-local PDEs	Adil El Abdouni	In this paper we propose some Harris-like criteria in order to study the long time behavior of general positive and periodic semiflows. These criteria allow us to obtain new existence results of principal eigenelements, and their exponential attractiveness. We present applications to two biological models in a space-time varying environment: a non local selection-mutation equation and a growth-fragmentation equation. The particularity of this article is to study some inhomogeneous problems that are periodic in time, as it appears for instance when the environment changes, due for instance to the seasonal cycle or circadian rhythms.	math.AP	None
9	Modelling pyro-convection phenomenon during a mega-fire event in Portugal	C√°tia Campos,Flavio Tiago Couto,Jean-Baptiste Filippi,Roberta Baggio,Rui Salgado	The present study contributes to an increased understanding of pyro-convection phenomena by using a fire-atmosphere coupled simulation, and investigates in detail the large-scale meteorological conditions affecting Portugal during the occurrence of multiple mega-fires events on 15 October 2017. Two numerical simulations were performed using the MesoNH atmospheric model. The first simulation, was run for a large single domain (300 x 250 grid points) with a 15 km resolution. In the second one, the MesoNH was coupled to a fire propagation model (ForeFire) to study in detail the Quiaios's fire. To optimize both high resolution in the proximity of the fire region and computational efficiency, the simulation is set up using 3 nested domains (300 x 300 grid points) with horizontal resolution of 2000 m, 400 m, and 80 m respectively. The emission into the atmosphere of the heat and the water vapour fluxes caused by the evolving fire is managed by the ForeFire code. The fire spatio-temporal evolution is based on an assigned map, which follows what reported by public authorities. At the large scale, the simulation shows the evolution of the hurricane Ophelia, pointing out the influence of south/southwest winds on the rapid spread of active fires, as well as the subtropical moisture transport toward mainland Portugal in the early evening, when violent pyro-convective activity was observed in Central Portugal. The coupled simulation allowed to reproduce the formation of a PyroCu cloud inside the smoke plume. The convective updraughts caused by the fire led to the vertical transport of water vapour to higher levels and enhanced the development of a high-based cloud over a dry atmospheric layer within the smoke plume.	physics.ao-ph	None
0	Show from Tell: Audio-Visual Modelling in Clinical Settings	Jianbo Jiao,Mohammad Alsharid,Lior Drukker,Aris T. Papageorghiou,Andrew Zisserman,J. Alison Noble	Auditory and visual signals usually present together and correlate with each other, not only in natural environments but also in clinical settings. However, the audio-visual modelling in the latter case can be more challenging, due to the different sources of audio/video signals and the noise (both signal-level and semantic-level) in auditory signals -- usually speech. In this paper, we consider audio-visual modelling in a clinical setting, providing a solution to learn medical representations that benefit various clinical tasks, without human expert annotation. A simple yet effective multi-modal self-supervised learning framework is proposed for this purpose. The proposed approach is able to localise anatomical regions of interest during ultrasound imaging, with only speech audio as a reference. Experimental evaluations on a large-scale clinical multi-modal ultrasound video dataset show that the proposed self-supervised method learns good transferable anatomical representations that boost the performance of automated downstream clinical tasks, even outperforming fully-supervised solutions.	cs.CV	None
1	Symphony of experts: orchestration with adversarial insights in reinforcement learning	Matthieu Jonckheere,Chiara Mignacco,Gilles Stoltz	Structured reinforcement learning leverages policies with advantageous properties to reach better performance, particularly in scenarios where exploration poses challenges. We explore this field through the concept of orchestration, where a (small) set of expert policies guides decision-making; the modeling thereof constitutes our first contribution. We then establish value-functions regret bounds for orchestration in the tabular setting by transferring regret-bound results from adversarial settings. We generalize and extend the analysis of natural policy gradient in Agarwal et al. [2021, Section 5.3] to arbitrary adversarial aggregation strategies. We also extend it to the case of estimated advantage functions, providing insights into sample complexity both in expectation and high probability. A key point of our approach lies in its arguably more transparent proofs compared to existing methods. Finally, we present simulations for a stochastic matching toy model.	cs.LG	None
2	Understanding Impact of Angle in Urban Transportation	Kota Nagasaki,Toru Seo	Traffic congestion at urban-scale levels occurs when road network supply is insufficient compared with demand. Therefore, the relationship between supply and demand has been extensively investigated in the literature. Especially the impact of a network's topology (i.e., connectivity) on traffic congestion has been widely studied. On the other hand, only a few studies analyze the relationship between the physical shape of the road network (i.e., morphology), demand, and congestion. For example, angular indicators associated with links and trips can be utilized to characterize such morphology. However, statistical analysis of angular indicators requires a specialized methodology called Directional Statistics, and how to apply Directional Statistics to traffic data is not obvious. Here, this study develops a descriptive model of traffic congestion based on Directional Statistics. It describes direction-dependent congestion levels using angular distributions that characterize the shape of road network and travel demand. Specifically, the shape of road network is characterized by the distribution of angles of each road link in a specific region. Likewise, the travel demand is characterized by the distribution of angles of each trip in the region. Then, a statistical model that describes travel time for a trip with arbitrary direction by these two angular distribution is constructed by paying special attention to the fact that roads and demands from all angles would affect congestion. A simple estimation method for the proposed model is also presented. Finally, the model was estimated using actual data in Tokyo, and the relationship between the characteristics of the shape of the road network, the direction of demand, and congestion is analyzed from the new perspective of angles.	stat.AP	None
3	Sourcing the Kerr geometry	Ram Brustein,A. J. M. Medved	The Kerr metric is a vacuum solution of the Einstein equations outside of a rotating black hole, but what interior matter is actually rotating and sourcing the Kerr geometry? Here, we describe a rotating exotic matter which can source the Kerr geometry for the entire acceptable range of its spin parameter and be shown to saturate the radial null-energy condition at every point in the interior, while being free of any obvious pathologies. We do so by introducing the rotating frozen star, whose compactness is controlled by a perturbative parameter and whose outer surface can be arbitrarily close to the horizon of a Kerr black hole. The interior geometry modifies Kerr's such that there is neither an inner ergosphere nor an inner horizon, and the metric and Einstein tensors are regular everywhere except for a mild, removable singularity at the center of the star. The geometry of each radial slice of the interior is a nearly null surface with the same geometry, but different radial size, as that of the would-be horizon on the outermost slice. Moreover, the metric limits to that of the static frozen star as the spin is taken to zero. The integral of the energy density leads to a rest mass that is equal to the irreducible mass of a Kerr black hole, and the integral of the angular-momentum density confirms that the ratio of the angular momentum to the mass is equal to the Kerr spin parameter. Including the rotational energy in the standard way, we then obtain the total gravitational mass and angular momentum of a Kerr black hole with the same mass and spin parameters. We propose that the rotating frozen star provides a classical description of the highly quantum final state of gravitationally collapsed matter, which features a maximally entropic, stringy fluid as described by our polymer model for the black hole interior.	gr-qc	None
4	Learning Continuous Network Emerging Dynamics from Scarce Observations via Data-Adaptive Stochastic Processes	Jiaxu Cui,Bingyi Sun,Jiming Liu,Bo Yang	Learning network dynamics from the empirical structure and spatio-temporal observation data is crucial to revealing the interaction mechanisms of complex networks in a wide range of domains. However, most existing methods only aim at learning network dynamic behaviors generated by a specific ordinary differential equation instance, resulting in ineffectiveness for new ones, and generally require dense observations. The observed data, especially from network emerging dynamics, are usually difficult to obtain, which brings trouble to model learning. Therefore, how to learn accurate network dynamics with sparse, irregularly-sampled, partial, and noisy observations remains a fundamental challenge. We introduce Neural ODE Processes for Network Dynamics (NDP4ND), a new class of stochastic processes governed by stochastic data-adaptive network dynamics, to overcome the challenge and learn continuous network dynamics from scarce observations. Intensive experiments conducted on various network dynamics in ecological population evolution, phototaxis movement, brain activity, epidemic spreading, and real-world empirical systems, demonstrate that the proposed method has excellent data adaptability and computational efficiency, and can adapt to unseen network emerging dynamics, producing accurate interpolation and extrapolation with reducing the ratio of required observation data to only about 6\% and improving the learning speed for new dynamics by three orders of magnitude.	cs.LG	preprint
5	Covariance matrices for the Lyman-$Œ±$ forest using the lognormal approximation	Bhaskar Arya,Aseem Paranjape,Tirthankar Roy Choudhury	We investigate the nature of correlations in the small-scale flux statistics of the Lyman-$\alpha$ (Ly$\alpha$) forest across redshift bins. Understanding these correlations is important for unbiased cosmological and astrophysical parameter inference using the Ly$\alpha$ forest. We focus on the 1-dimensional flux power spectrum (FPS) and mean flux ($\bar F$) simulated using the semi-numerical lognormal model we developed in earlier work. The lognormal model can capture the effects of long wavelength modes with relative ease as compared to full smoothed particle hydrodynamical (SPH) simulations that are limited by box volume. For a single redshift bin of size $\Delta z\simeq 0.1$, we show that the lognormal model predicts positive cross-correlations between $k$-bins in the FPS, and a negative correlation for $\bar F\times$ FPS, in qualitative agreement with SPH simulations and theoretical expectations. For measurements across two neighbouring redshift bins of width $\Delta z$ each (obtained by 'splitting' skewers of length $2\Delta z$ in half), the lognormal model predicts an anti-correlation for FPS $\times$ FPS and a positive correlation for $\bar F\times$ FPS, caused by long wavelength modes. This is in contrast to SPH simulations which predict a negligible magnitude for cross-redshift correlations derived from such `split' skewers, and we discuss possible reasons for this difference. Finally, we perform a preliminary test of the impact of neglecting long wavelength modes on parameter inference, finding that whereas the correlation structure of neighbouring redshift bins has relatively little impact, the absence of long wavelength modes in the model can lead to $\gtrsim2-\sigma$ biases in the inference of astrophysical parameters. Our results motivate a more careful treatment of long wavelength modes in analyses that rely on the small scale Ly$\alpha$ forest for parameter inference.	astro-ph.CO	17 pages, 6 figures, to be submitted to JCAP
6	Constructing disjoint Steiner trees in Sierpi≈Ñski graphs	Chenxu Yang,Ping Li,Yaping Mao,Eddie Cheng,Ralf Klasing	Let $G$ be a graph and $S\subseteq V(G)$ with $|S|\geq 2$. Then the trees $T_1, T_2, \cdots, T_\ell$ in $G$ are \emph{internally disjoint Steiner trees} connecting $S$ (or $S$-Steiner trees) if $E(T_i) \cap E(T_j )=\emptyset$ and $V(T_i)\cap V(T_j)=S$ for every pair of distinct integers $i,j$, $1 \leq i, j \leq \ell$. Similarly, if we only have the condition $E(T_i) \cap E(T_j )=\emptyset$ but without the condition $V(T_i)\cap V(T_j)=S$, then they are \emph{edge-disjoint Steiner trees}. The \emph{generalized $k$-connectivity}, denoted by $\kappa_k(G)$, of a graph $G$, is defined as $\kappa_k(G)=\min\{\kappa_G(S)|S \subseteq V(G) \ \textrm{and} \ |S|=k \}$, where $\kappa_G(S)$ is the maximum number of internally disjoint $S$-Steiner trees. The \emph{generalized local edge-connectivity} $\lambda_{G}(S)$ is the maximum number of edge-disjoint Steiner trees connecting $S$ in $G$. The {\it generalized $k$-edge-connectivity} $\lambda_k(G)$ of $G$ is defined as $\lambda_k(G)=\min\{\lambda_{G}(S)\,|\,S\subseteq V(G) \ and \ |S|=k\}$. These measures are generalizations of the concepts of connectivity and edge-connectivity, and they and can be used as measures of vulnerability of networks. It is, in general, difficult to compute these generalized connectivities. However, there are precise results for some special classes of graphs. In this paper, we obtain the exact value of $\lambda_{k}(S(n,\ell))$ for $3\leq k\leq \ell^n$, and the exact value of $\kappa_{k}(S(n,\ell))$ for $3\leq k\leq \ell$, where $S(n, \ell)$ is the Sierpi\'{n}ski graphs with order $\ell^n$. As a direct consequence, these graphs provide additional interesting examples when $\lambda_{k}(S(n,\ell))=\kappa_{k}(S(n,\ell))$. We also study the some network properties of Sierpi\'{n}ski graphs.	math.CO	None
7	DualMatch: Robust Semi-Supervised Learning with Dual-Level Interaction	Cong Wang,Xiaofeng Cao,Lanzhe Guo2,Zenglin Shi	Semi-supervised learning provides an expressive framework for exploiting unlabeled data when labels are insufficient. Previous semi-supervised learning methods typically match model predictions of different data-augmented views in a single-level interaction manner, which highly relies on the quality of pseudo-labels and results in semi-supervised learning not robust. In this paper, we propose a novel SSL method called DualMatch, in which the class prediction jointly invokes feature embedding in a dual-level interaction manner. DualMatch requires consistent regularizations for data augmentation, specifically, 1) ensuring that different augmented views are regulated with consistent class predictions, and 2) ensuring that different data of one class are regulated with similar feature embeddings. Extensive experiments demonstrate the effectiveness of DualMatch. In the standard SSL setting, the proposal achieves 9% error reduction compared with SOTA methods, even in a more challenging class-imbalanced setting, the proposal can still achieve 6% error reduction. Code is available at https://github.com/CWangAI/DualMatch	cs.CV	14 pages, 8 figures, Accepted by ECMLPKDD 2023
8	Towards Explainability in Monocular Depth Estimation	Vasileios Arampatzakis,George Pavlidis,Kyriakos Pantoglou,Nikolaos Mitianoudis,Nikos Papamarkos	The estimation of depth in two-dimensional images has long been a challenging and extensively studied subject in computer vision. Recently, significant progress has been made with the emergence of Deep Learning-based approaches, which have proven highly successful. This paper focuses on the explainability in monocular depth estimation methods, in terms of how humans perceive depth. This preliminary study emphasizes on one of the most significant visual cues, the relative size, which is prominent in almost all viewed images. We designed a specific experiment to mimic the experiments in humans and have tested state-of-the-art methods to indirectly assess the explainability in the context defined. In addition, we observed that measuring the accuracy required further attention and a particular approach is proposed to this end. The results show that a mean accuracy of around 77% across methods is achieved, with some of the methods performing markedly better, thus, indirectly revealing their corresponding potential to uncover monocular depth cues, like relative size.	cs.CV	None
9	Pressure-induced non-monotonic crossover of steady relaxation dynamics in a metallic glass	Xin Zhang,Hongbo Lou,Beatrice Ruta,Yuriy Chushkin,Federico Zontone,Shubin Li,Dazhe Xu,Tao Liang,Zhidan Zeng,Ho-kwang Mao,Qiaoshi Zeng	Relaxation dynamics, as a key to understand glass formation and glassy properties, remains an elusive and challenging issue in condensed matter physics. In this work, in situ high-pressure synchrotron high-energy x-ray photon correlation spectroscopy has been developed to probe the atomic-scale relaxation dynamics of a cerium-based metallic glass during compression. Although the sample density continuously increases, the collective atomic motion initially slows down as generally expected and then counter-intuitively accelerates with further compression (density increase), showing an unusual non-monotonic pressure-induced steady relaxation dynamics crossover at ~3 GPa. Furthermore, by combining in situ high-pressure synchrotron x-ray diffraction, the relaxation dynamics anomaly is evidenced to closely correlate with the dramatic changes in local atomic structures during compression, rather than monotonically scaling with either sample density or overall stress level. These findings could provide new insight into relaxation dynamics and their relationship with local atomic structures of glasses.	cond-mat.mtrl-sci	21 pages, 4 figures
0	ClearMark: Intuitive and Robust Model Watermarking via Transposed Model Training	Torsten Krau√ü,Jasper Stang,Alexandra Dmitrienko	Due to costly efforts during data acquisition and model training, Deep Neural Networks (DNNs) belong to the intellectual property of the model creator. Hence, unauthorized use, theft, or modification may lead to legal repercussions. Existing DNN watermarking methods for ownership proof are often non-intuitive, embed human-invisible marks, require trust in algorithmic assessment that lacks human-understandable attributes, and rely on rigid thresholds, making it susceptible to failure in cases of partial watermark erasure.   This paper introduces ClearMark, the first DNN watermarking method designed for intuitive human assessment. ClearMark embeds visible watermarks, enabling human decision-making without rigid value thresholds while allowing technology-assisted evaluations. ClearMark defines a transposed model architecture allowing to use of the model in a backward fashion to interwove the watermark with the main task within all model parameters. Compared to existing watermarking methods, ClearMark produces visual watermarks that are easy for humans to understand without requiring complex verification algorithms or strict thresholds. The watermark is embedded within all model parameters and entangled with the main task, exhibiting superior robustness. It shows an 8,544-bit watermark capacity comparable to the strongest existing work. Crucially, ClearMark's effectiveness is model and dataset-agnostic, and resilient against adversarial model manipulations, as demonstrated in a comprehensive study performed with four datasets and seven architectures.	cs.LG	20 pages, 18 figures, 4 tables
1	Faithful Path Language Modelling for Explainable Recommendation over Knowledge Graph	Giacomo Balloccu,Ludovico Boratto,Christian Cancedda,Gianni Fenu,Mirko Marras	Path reasoning methods over knowledge graphs have gained popularity for their potential to improve transparency in recommender systems. However, the resulting models still rely on pre-trained knowledge graph embeddings, fail to fully exploit the interdependence between entities and relations in the KG for recommendation, and may generate inaccurate explanations. In this paper, we introduce PEARLM, a novel approach that efficiently captures user behaviour and product-side knowledge through language modelling. With our approach, knowledge graph embeddings are directly learned from paths over the KG by the language model, which also unifies entities and relations in the same optimisation space. Constraints on the sequence decoding additionally guarantee path faithfulness with respect to the KG. Experiments on two datasets show the effectiveness of our approach compared to state-of-the-art baselines. Source code and datasets: AVAILABLE AFTER GETTING ACCEPTED.	cs.IR	None
2	The Small-World Effect for Interferometer Networks	Benjamin Krawciw,Lincoln D. Carr,Cecilia Diniz Behn	Complex network theory has focused on properties of networks with real-valued edge weights. However, in signal transfer networks, such as those representing the transfer of light across an interferometer, complex-valued edge weights are needed to represent the manipulation of the signal in both magnitude and phase. These complex-valued edge weights introduce interference into the signal transfer, but it is unknown how such interference affects network properties such as small-worldness. To address this gap, we have introduced a small-world interferometer network model with complex-valued edge weights and generalized existing network measures to define the interferometric clustering coefficient, the apparent path length, and the interferometric small-world coefficient. Using high-performance computing resources, we generated a large set of small-world interferometers over a wide range of parameters in system size, nearest-neighbor count, and edge-weight phase and computed their interferometric network measures. We found that the interferometric small-world coefficient depends significantly on the amount of phase on complex-valued edge weights: for small edge-weight phases, constructive interference led to a higher interferometric small-world coefficient; while larger edge-weight phases induced destructive interference which led to a lower interferometric small-world coefficient. Thus, for the small-world interferometer model, interferometric measures are necessary to capture the effect of interference on signal transfer. This model is an example of the type of problem that necessitates interferometric measures, and applies to any wave-based network including quantum networks.	physics.soc-ph	None
3	CLEX: Continuous Length Extrapolation for Large Language Models	Guanzheng Chen,Xin Li,Zaiqiao Meng,Shangsong Liang,Lidong Bing	Transformer-based Large Language Models (LLMs) are pioneering advances in many natural language processing tasks, however, their exceptional capabilities are restricted within the preset context window of Transformer. Position Embedding (PE) scaling methods, while effective in extending the context window to a specific length, demonstrate either notable limitations in their extrapolation abilities or sacrificing partial performance within the context window. Length extrapolation methods, although theoretically capable of extending the context window beyond the training sequence length, often underperform in practical long-context applications. To address these challenges, we propose Continuous Length EXtrapolation (CLEX) for LLMs. We generalise the PE scaling approaches to model the continuous dynamics by ordinary differential equations over the length scaling factor, thereby overcoming the constraints of current PE scaling methods designed for specific lengths. Moreover, by extending the dynamics to desired context lengths beyond the training sequence length, CLEX facilitates the length extrapolation with impressive performance in practical tasks. We demonstrate that CLEX can be seamlessly incorporated into LLMs equipped with Rotary Position Embedding, such as LLaMA and GPT-NeoX, with negligible impact on training and inference latency. Experimental results reveal that CLEX can effectively extend the context window to over 4x or almost 8x training length, with no deterioration in performance. Furthermore, when evaluated on the practical LongBench benchmark, our model trained on a 4k length exhibits competitive performance against state-of-the-art open-source models trained on context lengths up to 32k.	cs.CL	None
4	ChimpACT: A Longitudinal Dataset for Understanding Chimpanzee Behaviors	Xiaoxuan Ma,Stephan P. Kaufhold,Jiajun Su,Wentao Zhu,Jack Terwilliger,Andres Meza,Yixin Zhu,Federico Rossano,Yizhou Wang	Understanding the behavior of non-human primates is crucial for improving animal welfare, modeling social behavior, and gaining insights into distinctively human and phylogenetically shared behaviors. However, the lack of datasets on non-human primate behavior hinders in-depth exploration of primate social interactions, posing challenges to research on our closest living relatives. To address these limitations, we present ChimpACT, a comprehensive dataset for quantifying the longitudinal behavior and social relations of chimpanzees within a social group. Spanning from 2015 to 2018, ChimpACT features videos of a group of over 20 chimpanzees residing at the Leipzig Zoo, Germany, with a particular focus on documenting the developmental trajectory of one young male, Azibo. ChimpACT is both comprehensive and challenging, consisting of 163 videos with a cumulative 160,500 frames, each richly annotated with detection, identification, pose estimation, and fine-grained spatiotemporal behavior labels. We benchmark representative methods of three tracks on ChimpACT: (i) tracking and identification, (ii) pose estimation, and (iii) spatiotemporal action detection of the chimpanzees. Our experiments reveal that ChimpACT offers ample opportunities for both devising new methods and adapting existing ones to solve fundamental computer vision tasks applied to chimpanzee groups, such as detection, pose estimation, and behavior analysis, ultimately deepening our comprehension of communication and sociality in non-human primates.	cs.CV	NeurIPS 2023
5	Diversity Enhanced Narrative Question Generation for Storybooks	Hokeun Yoon,JinYeong Bak	Question generation (QG) from a given context can enhance comprehension, engagement, assessment, and overall efficacy in learning or conversational environments. Despite recent advancements in QG, the challenge of enhancing or measuring the diversity of generated questions often remains unaddressed. In this paper, we introduce a multi-question generation model (mQG), which is capable of generating multiple, diverse, and answerable questions by focusing on context and questions. To validate the answerability of the generated questions, we employ a SQuAD2.0 fine-tuned question answering model, classifying the questions as answerable or not. We train and evaluate mQG on the FairytaleQA dataset, a well-structured QA dataset based on storybooks, with narrative questions. We further apply a zero-shot adaptation on the TellMeWhy and SQuAD1.1 datasets. mQG shows promising results across various evaluation metrics, among strong baselines.	cs.CL	Accepted to EMNLP 2023
6	Platonism, De Re, and (Philosophy of) Mathematical Practice	Marco Panza	"The chapter advances a reformulation of the classical problem of the nature of mathematical objects (if any), here called ""Plato's problem,"" in line with the program of a philosophy of mathematical practice. It then provides a sketch of a platonist solution, following the same perspective. This solution disregards as nonsensical the question of the existence of abstract, and specifically mathematical, objects, by rather focusing on the modalities of our access to them: objects (in general, both concrete and abstract) are regarded as individual contents that we have (or can have) a de re epistemic access to. The question of the existence of mathematical objects is then replaced by that of the modalities of our de re epistemic access to individual mathematical contents."	math.HO	None
7	Grokking in Linear Estimators -- A Solvable Model that Groks without Understanding	Noam Levi,Alon Beck,Yohai Bar-Sinai	"Grokking is the intriguing phenomenon where a model learns to generalize long after it has fit the training data. We show both analytically and numerically that grokking can surprisingly occur in linear networks performing linear tasks in a simple teacher-student setup with Gaussian inputs. In this setting, the full training dynamics is derived in terms of the training and generalization data covariance matrix. We present exact predictions on how the grokking time depends on input and output dimensionality, train sample size, regularization, and network initialization. We demonstrate that the sharp increase in generalization accuracy may not imply a transition from ""memorization"" to ""understanding"", but can simply be an artifact of the accuracy measure. We provide empirical verification for our calculations, along with preliminary results indicating that some predictions also hold for deeper networks, with non-linear activations."	stat.ML	17 pages, 6 figures
8	Optimal control for manipulating vibrational wave packets through polarizability interactions induced by non-resonant laser pulses	Reon Ishii,Tomotaro Namba,Hiroyuki Katsuki,Kenji Ohmori,Yukiyoshi Ohtsuki	On the basis of optimal control theory, we numerically study how to optimally manipulate molecular vibrational dynamics by using cycle-averaged polarizability interactions induced by mildly intense non-resonant laser (NR) pulses. As the essential elements to be controlled are the probability amplitudes, namely, the populations and the relative phases of the vibrational eigenstates, we consider three fundamental control objectives: selective population transfer, wave packet shaping that requires both population control and relative-phase control, and wave packet deformation suppression that solely requires relative-phase control while avoiding population redistribution. The non-trivial control of wave packet deformation suppression is an extension of our previous study on wave packet spreading suppression. Focusing on the vibrational dynamics in the B state of I2 as a case study, we adopt optimal control simulations and model analyses under the impulsive excitation approximation to systematically examine how to achieve the control objectives with shaped NR pulses. Optimal solutions are always given by NR pulse trains, in which each pulse interval and each pulse intensity are adjusted to cooperate with the vibrational dynamics to effectively utilize the quantum interferences to realize the control objectives with high probability.	quant-ph	30 pages, 12 figures
9	Baryons as Vortexes on the $Œ∑^{\prime}$ Domain Wall	Fan Lin,Yong-Liang Ma	We show that the recent construction of $N_f=1$ baryons on the $\eta^\prime$ domain wall can be understood as vortexes of the principal effective theory -- the Chern-Simons-Higgs theory -- on a 2+1-dimensional sheet. This theory has a series of vertex solutions, and the vortex with unit topological charge naturally spins $N_c/2$, which coincides with the spin of the one-flavor baryon in QCD. Since the $N_c$ scaling of the vortexes is the same as that of baryons, baryons can be regarded as vortexes. By virtue of the particle-vortex symmetry, the dual Zhang-Hansson-Kivelson theory indicates that the quark carries topological charge $1/N_c$ and obeys fractional statistics. The generalization to arbitrary $N_f$ is also discussed.	hep-th	13 pages
0	Non-isotropic Persistent Homology: Leveraging the Metric Dependency of PH	Vincent P. Grande,Michael T. Schaub	Persistent Homology is a widely used topological data analysis tool that creates a concise description of the topological properties of a point cloud based on a specified filtration. Most filtrations used for persistent homology depend (implicitly) on a chosen metric, which is typically agnostically chosen as the standard Euclidean metric on $\mathbb{R}^n$. Recent work has tried to uncover the 'true' metric on the point cloud using distance-to-measure functions, in order to obtain more meaningful persistent homology results. Here we propose an alternative look at this problem: we posit that information on the point cloud is lost when restricting persistent homology to a single (correct) distance function. Instead, we show how by varying the distance function on the underlying space and analysing the corresponding shifts in the persistence diagrams, we can extract additional topological and geometrical information. Finally, we numerically show that non-isotropic persistent homology can extract information on orientation, orientational variance, and scaling of randomly generated point clouds with good accuracy and conduct some experiments on real-world data.	math.AT	30 pages, 17 figures, comments welcome!
1	DDCoT: Duty-Distinct Chain-of-Thought Prompting for Multimodal Reasoning in Language Models	Ge Zheng,Bin Yang,Jiajin Tang,Hong-Yu Zhou,Sibei Yang	"A long-standing goal of AI systems is to perform complex multimodal reasoning like humans. Recently, large language models (LLMs) have made remarkable strides in such multi-step reasoning on the language modality solely by leveraging the chain of thought (CoT) to mimic human thinking. However, the transfer of these advancements to multimodal contexts introduces heightened challenges, including but not limited to the impractical need for labor-intensive annotation and the limitations in terms of flexibility, generalizability, and explainability. To evoke CoT reasoning in multimodality, this work first conducts an in-depth analysis of these challenges posed by multimodality and presents two key insights: ""keeping critical thinking"" and ""letting everyone do their jobs"" in multimodal CoT reasoning. Furthermore, this study proposes a novel DDCoT prompting that maintains a critical attitude through negative-space prompting and incorporates multimodality into reasoning by first dividing the reasoning responsibility of LLMs into reasoning and recognition and then integrating the visual recognition capability of visual models into the joint reasoning process. The rationales generated by DDCoT not only improve the reasoning abilities of both large and small language models in zero-shot prompting and fine-tuning learning, significantly outperforming state-of-the-art methods but also exhibit impressive generalizability and explainability."	cs.CV	24 pages, 13 figures, to be published in NeurIPS 2023
2	An Integrative Paradigm for Enhanced Stroke Prediction: Synergizing XGBoost and xDeepFM Algorithms	Weinan Dai,Yifeng Jiang,Chengjie Mou,Chongyu Zhang	Stroke prediction plays a crucial role in preventing and managing this debilitating condition. In this study, we address the challenge of stroke prediction using a comprehensive dataset, and propose an ensemble model that combines the power of XGBoost and xDeepFM algorithms. Our work aims to improve upon existing stroke prediction models by achieving higher accuracy and robustness. Through rigorous experimentation, we validate the effectiveness of our ensemble model using the AUC metric. Through comparing our findings with those of other models in the field, we gain valuable insights into the merits and drawbacks of various approaches. This, in turn, contributes significantly to the progress of machine learning and deep learning techniques specifically in the domain of stroke prediction.	cs.CV	None
3	Similarity-driven and Task-driven Models for Diversity of Opinion in Crowdsourcing Markets	Chen Jason Zhang,Yunrui Liu,Pengcheng Zeng,Ting Wu,Lei Chen,Pan Hui,Fei Hao	The recent boom in crowdsourcing has opened up a new avenue for utilizing human intelligence in the realm of data analysis. This innovative approach provides a powerful means for connecting online workers to tasks that cannot effectively be done solely by machines or conducted by professional experts due to cost constraints. Within the field of social science, four elements are required to construct a sound crowd - Diversity of Opinion, Independence, Decentralization and Aggregation. However, while the other three components have already been investigated and implemented in existing crowdsourcing platforms, 'Diversity of Opinion' has not been functionally enabled yet. From a computational point of view, constructing a wise crowd necessitates quantitatively modeling and taking diversity into account. There are usually two paradigms in a crowdsourcing marketplace for worker selection: building a crowd to wait for tasks to come and selecting workers for a given task. We propose similarity-driven and task-driven models for both paradigms. Also, we develop efficient and effective algorithms for recruiting a limited number of workers with optimal diversity in both models. To validate our solutions, we conduct extensive experiments using both synthetic datasets and real data sets.	stat.AP	32 pages, 10 figures
4	PromptAgent: Strategic Planning with Language Models Enables Expert-level Prompt Optimization	Xinyuan Wang,Chenxi Li,Zhen Wang,Fan Bai,Haotian Luo,Jiayou Zhang,Nebojsa Jojic,Eric P. Xing,Zhiting Hu	Highly effective, task-specific prompts are often heavily engineered by experts to integrate detailed instructions and domain insights based on a deep understanding of both instincts of large language models (LLMs) and the intricacies of the target task. However, automating the generation of such expert-level prompts remains elusive. Existing prompt optimization methods tend to overlook the depth of domain knowledge and struggle to efficiently explore the vast space of expert-level prompts. Addressing this, we present PromptAgent, an optimization method that autonomously crafts prompts equivalent in quality to those handcrafted by experts. At its core, PromptAgent views prompt optimization as a strategic planning problem and employs a principled planning algorithm, rooted in Monte Carlo tree search, to strategically navigate the expert-level prompt space. Inspired by human-like trial-and-error exploration, PromptAgent induces precise expert-level insights and in-depth instructions by reflecting on model errors and generating constructive error feedback. Such a novel framework allows the agent to iteratively examine intermediate prompts (states), refine them based on error feedbacks (actions), simulate future rewards, and search for high-reward paths leading to expert prompts. We apply PromptAgent to 12 tasks spanning three practical domains: BIG-Bench Hard (BBH), as well as domain-specific and general NLP tasks, showing it significantly outperforms strong Chain-of-Thought and recent prompt optimization baselines. Extensive analyses emphasize its capability to craft expert-level, detailed, and domain-insightful prompts with great efficiency and generalizability.	cs.CL	34 pages, 10 figures
5	Heat and Mass Transfer in the Porous Wick of a Capillary Evaporator	Laetitia Mottet,Typhaine Coquard,Marc Prat	Heat and mass transfer inside the porous wick of a capillary evaporator is studied using a mixed pore-network model. The impact of the thermal conductivity of the wick on the overheating limit (defined as the difference between the maximum temperature at the top of the metallic casing and the saturated temperature), breakthrough (which occurs when the vapor reaches the wick inlet) and the parasitic heat flux lost by conduction at the entrance of the wick (which decreases the efficiency of the evaporator) is investigated. The study suggests a bilayer wick as a possible better design to optimize the performance of the evaporator. With this design, the inlet layer is of low thermal conductivity with small pore size so as to reduce the parasitic heat flux. The inlet layer also plays a role of capillary lock limiting the risk of breakthrough. The second layer, right under the metallic casing, is more conductive with a high thermal conductivity and larger pores so as to limit the risk of overheating. It is shown that this design increases the range of heat loads which can be applied to the evaporator.	physics.flu-dyn	Proceedings of the 5th International Conference on Porous Media and   its Applications in Science and Engineering (ICPM5), June 22-27, 2014, Kona,   Hawaii, US
6	Pre-electoral coalition agreement from the Black-Scholes point of view	Darko Mitrovic	A political party can be considered as a company whose value depends on the voters support i.e. on the percentage of population supporting the party. Dynamics of the support is thus as a stochastic process with a deterministic growth rate perturbed by a white noise modeled through the Wiener process. This is in an analogy with the option modeling where the stock price behaves similarly as the voters' support. While in the option theory we have the question of fair price of an option, the question that we ask here is what is a reasonable level of support that the coalition of a major party (safely above the election threshold) and a minor party (under or around the election threshold) should achieve in order the minor party to get one more representative. We shall elaborate some of the conclusions in the case of recent elections in Montenegro (June, 2023) which are particularly interesting due to lots of political subjects entering the race.	math.AP	None
7	From port-based teleportation to Frobenius reciprocity theorem: partially reduced irreducible representations and their applications	Marek Mozrzymas,Micha≈Ç Horodecki,Micha≈Ç Studzi≈Ñski	In this paper, we present a connection of two concepts as induced representation and partially reduced irreducible representations (PRIR) appear in the context of port-based teleportation protocols. Namely, for a given finite group $G$ with arbitrary subgroup $H$, we consider a particular case of matrix irreducible representations, whose restriction to the subgroup $H$, as a matrix representation of $H$, is completely reduced to diagonal block form with an irreducible representation of $H$ in the blocks. The basic properties of such representations are given. Then as an application of this concept, we show that the spectrum of the port-based teleportation operator is connected in a very simple way with the spectrum of the corresponding Jucys-Murphy operator for symmetric groups $S(m-1)\subset S(m)$ - basic objects from the point of view of representation theory of the symmetric group. This shows a deep connection between the central object describing properties of deterministic PBT schemes and objects appearing naturally in the abstract representation theory of the symmetric group. As an additional but not trivial result, we give also purely matrix proof of the Frobenius reciprocity theorem for characters.	quant-ph	13 pages, 2 figures, 1 table
8	Graph Agent: Explicit Reasoning Agent for Graphs	Qinyong Wang,Zhenxiang Gao,Rong Xu	Graph embedding methods such as Graph Neural Networks (GNNs) and Graph Transformers have contributed to the development of graph reasoning algorithms for various tasks on knowledge graphs. However, the lack of interpretability and explainability of graph embedding methods has limited their applicability in scenarios requiring explicit reasoning. In this paper, we introduce the Graph Agent (GA), an intelligent agent methodology of leveraging large language models (LLMs), inductive-deductive reasoning modules, and long-term memory for knowledge graph reasoning tasks. GA integrates aspects of symbolic reasoning and existing graph embedding methods to provide an innovative approach for complex graph reasoning tasks. By converting graph structures into textual data, GA enables LLMs to process, reason, and provide predictions alongside human-interpretable explanations. The effectiveness of the GA was evaluated on node classification and link prediction tasks. Results showed that GA reached state-of-the-art performance, demonstrating accuracy of 90.65%, 95.48%, and 89.32% on Cora, PubMed, and PrimeKG datasets, respectively. Compared to existing GNN and transformer models, GA offered advantages of explicit reasoning ability, free-of-training, easy adaption to various graph reasoning tasks	cs.AI	None
9	Linear statistics for Coulomb gases: higher order cumulants	Benjamin De Bruyne,Pierre Le Doussal,Satya N. Majumdar,Gregory Schehr	We consider $N$ classical particles interacting via the Coulomb potential in spatial dimension $d$ and in the presence of an external trap, at equilibrium at inverse temperature $\beta$. In the large $N$ limit, the particles are confined within a droplet of finite size. We study smooth linear statistics, i.e. the fluctuations of sums of the form ${\cal L}_N = \sum_{i=1}^N f({\bf x}_i)$, where ${\bf x}_i$'s are the positions of the particles and where $f({\bf x}_i)$ is a sufficiently regular function. There exists at present standard results for the first and second moments of ${\cal L}_N$ in the large $N$ limit, as well as associated Central Limit Theorems in general dimension and for a wide class of confining potentials. Here we obtain explicit expressions for the higher order cumulants of ${\cal L}_N$ at large $N$, when the function $f({\bf x})=f(|{\bf x}|)$ and the confining potential are both rotationnally invariant. A remarkable feature of our results is that these higher cumulants depend only on the value of $f'(|{\bf x}|)$ and its higher order derivatives evaluated exactly at the boundary of the droplet, which in this case is a $d$-dimensional sphere. In the particular two-dimensional case $d=2$ at the special value $\beta=2$, a connection to the Ginibre ensemble allows us to derive these results in an alternative way using the tools of determinantal point processes. Finally we also obtain the large deviation form of the full probability distribution function of ${\cal L}_N$.	math-ph	19 pages
0	Open Knowledge Base Canonicalization with Multi-task Unlearning	Bingchen Liu,Shihao Hou,Weixin Zeng,Xiang Zhao,Shijun Liu,Li Pan	The construction of large open knowledge bases (OKBs) is integral to many applications in the field of mobile computing. Noun phrases and relational phrases in OKBs often suffer from redundancy and ambiguity, which calls for the investigation on OKB canonicalization. However, in order to meet the requirements of some privacy protection regulations and to ensure the timeliness of the data, the canonicalized OKB often needs to remove some sensitive information or outdated data. The machine unlearning in OKB canonicalization is an excellent solution to the above problem. Current solutions address OKB canonicalization by devising advanced clustering algorithms and using knowledge graph embedding (KGE) to further facilitate the canonicalization process. Effective schemes are urgently needed to fully synergise machine unlearning with clustering and KGE learning. To this end, we put forward a multi-task unlearning framework, namely MulCanon, to tackle machine unlearning problem in OKB canonicalization. Specifically, the noise characteristics in the diffusion model are utilized to achieve the effect of machine unlearning for data in OKB. MulCanon unifies the learning objectives of diffusion model, KGE and clustering algorithms, and adopts a two-step multi-task learning paradigm for training. A thorough experimental study on popular OKB canonicalization datasets validates that MulCanon achieves advanced machine unlearning effects.	cs.AI	None
1	Bour's theorem for helicoidal surfaces with singularities	Yuki Hattori,Atsufumi Honda,Tatsuya Morimoto	In this paper, generalizing the techniques of Bour's theorem, we prove that every generic cuspidal edge, more generally, generic $n$-type edge, which is invariant under a helicoidal motion in Euclidean $3$-space admits non-trivial isometric deformations. As a corollary, several geometric invariants, such as the limiting normal curvature, the cusp-directional torsion, the higher order cuspidal curvature and the bias, are proved to be extrinsic invariants.	math.DG	21 pages, 9 figures
2	Enhanced Simultaneous Machine Translation with Word-level Policies	Kang Kim,Hankyu Cho	Recent years have seen remarkable advances in the field of Simultaneous Machine Translation (SiMT) due to the introduction of innovative policies that dictate whether to READ or WRITE at each step of the translation process. However, a common assumption in many existing studies is that operations are carried out at the subword level, even though the standard unit for input and output in most practical scenarios is typically at the word level. This paper demonstrates that policies devised and validated at the subword level are surpassed by those operating at the word level, which process multiple subwords to form a complete word in a single step. Additionally, we suggest a method to boost SiMT models using language models (LMs), wherein the proposed word-level policy plays a vital role in addressing the subword disparity between LMs and SiMT models. Code is available at https://github.com/xl8-ai/WordSiMT.	cs.CL	EMNLP 2023 Findings
3	Chiral forces in longitudinally invariant dielectric photonic waveguides	Josep Mart√≠nez-Romeu,Iago D√≠ez,Sebastian Golat,Francisco J. Rodr√≠guez-Fortu√±o,Alejandro Mart√≠nez	Optical forces can be chiral when they exhibit opposite signs for the two enantiomeric versions of a chiral molecule or particle. Such forces could be eventually used to separate enantiomers, which could find application in numerous disciplines. Here, we analyze numerically the optical chiral forces arising in the basic element of photonic integrated circuitry: a dielectric waveguide with rectangular cross-section. Such waveguides are inherently lossless thus generating chiral forces that are invariant in the longitudinal direction and therefore enable enantiomeric separation over long (cm-scale) distances. Assuming Brownian motion in a liquid environment, we calculate first the force strength and time span needed to perform the separation of chiral nanoparticles as a function of the radii. Then we analyze the chiral forces produced by the fundamental quasi-TE guided mode in a silicon nitride waveguide and show that it can lead to enantiomeric separation via the transverse spin at short wavelengths (405 nm). At longer wavelengths (1310 nm), the proper combination of degenerate quasi-TE and quasi-TM modes would result in a quasi-circularly polarized mode with intrinsic chirality (helicity), leading to chiral gradient forces that also enable the enantiomeric separation of smaller nanoparticles. We report particle tracking simulations where the optical force field produced by a quasi-TE and a quasi-circular mode proved to separate enantiomers under a time span of two seconds. Our results suggest the viability of enantiomeric separation using simple photonic integrated circuits, though different wavelength windows should be selected according to the nanoparticle size.	physics.optics	19 pages, 6 figures
4	FlatMatch: Bridging Labeled Data and Unlabeled Data with Cross-Sharpness for Semi-Supervised Learning	Zhuo Huang,Li Shen,Jun Yu,Bo Han,Tongliang Liu	Semi-Supervised Learning (SSL) has been an effective way to leverage abundant unlabeled data with extremely scarce labeled data. However, most SSL methods are commonly based on instance-wise consistency between different data transformations. Therefore, the label guidance on labeled data is hard to be propagated to unlabeled data. Consequently, the learning process on labeled data is much faster than on unlabeled data which is likely to fall into a local minima that does not favor unlabeled data, leading to sub-optimal generalization performance. In this paper, we propose FlatMatch which minimizes a cross-sharpness measure to ensure consistent learning performance between the two datasets. Specifically, we increase the empirical risk on labeled data to obtain a worst-case model which is a failure case that needs to be enhanced. Then, by leveraging the richness of unlabeled data, we penalize the prediction difference (i.e., cross-sharpness) between the worst-case model and the original model so that the learning direction is beneficial to generalization on unlabeled data. Therefore, we can calibrate the learning process without being limited to insufficient label information. As a result, the mismatched learning performance can be mitigated, further enabling the effective exploitation of unlabeled data and improving SSL performance. Through comprehensive validation, we show FlatMatch achieves state-of-the-art results in many SSL settings.	cs.LG	NeurIPS 2023
5	Decoding Stumpers: Large Language Models vs. Human Problem-Solvers	Alon Goldstein,Miriam Havin,Roi Reichart,Ariel Goldstein	This paper investigates the problem-solving capabilities of Large Language Models (LLMs) by evaluating their performance on stumpers, unique single-step intuition problems that pose challenges for human solvers but are easily verifiable. We compare the performance of four state-of-the-art LLMs (Davinci-2, Davinci-3, GPT-3.5-Turbo, GPT-4) to human participants. Our findings reveal that the new-generation LLMs excel in solving stumpers and surpass human performance. However, humans exhibit superior skills in verifying solutions to the same problems. This research enhances our understanding of LLMs' cognitive abilities and provides insights for enhancing their problem-solving potential across various domains.	cs.CL	None
6	Multiple Key-value Strategy in Recommendation Systems Incorporating Large Language Model	Dui Wang,Xiangyu Hou,Xiaohui Yang,Bo Zhang,Renbing Chen,Daiyue Xue	Recommendation system (RS) plays significant roles in matching users information needs for Internet applications, and it usually utilizes the vanilla neural network as the backbone to handle embedding details. Recently, the large language model (LLM) has exhibited emergent abilities and achieved great breakthroughs both in the CV and NLP communities. Thus, it is logical to incorporate RS with LLM better, which has become an emerging research direction. Although some existing works have made their contributions to this issue, they mainly consider the single key situation (e.g. historical interactions), especially in sequential recommendation. The situation of multiple key-value data is simply neglected. This significant scenario is mainstream in real practical applications, where the information of users (e.g. age, occupation, etc) and items (e.g. title, category, etc) has more than one key. Therefore, we aim to implement sequential recommendations based on multiple key-value data by incorporating RS with LLM. In particular, we instruct tuning a prevalent open-source LLM (Llama 7B) in order to inject domain knowledge of RS into the pre-trained LLM. Since we adopt multiple key-value strategies, LLM is hard to learn well among these keys. Thus the general and innovative shuffle and mask strategies, as an innovative manner of data argument, are designed. To demonstrate the effectiveness of our approach, extensive experiments are conducted on the popular and suitable dataset MovieLens which contains multiple keys-value. The experimental results demonstrate that our approach can nicely and effectively complete this challenging issue.	cs.IR	Accepted by CIKM2023 workshop at GenRec'23
7	Quadrupole-octupole coupling and the onset of octupole collectivity	K. Nomura	Octupole deformation and collective excitations are studied within the interacting boson model. By using the results of the self-consistent mean-field calculations with a universal energy density functional, the Hamiltonian of the interacting $s$, $d$, and $f$ boson system is completely determined. A global systematic study confirms that significant octupole effects are present in actinide, lanthanide, and rare-earth nuclei corresponding to particular nucleon numbers for which octupole correlations are empirically suggested to be enhanced.	nucl-th	5 pages, 7 figures; Proceedings of the 17th International Symposium   on Capture Gamma-Ray Spectroscopy and Related Topics (CGS17), Grenoble, 17-21   July 2023
8	Information-Theoretic Generalization Analysis for Topology-aware Heterogeneous Federated Edge Learning over Noisy Channels	Zheshun Wu,Zenglin Xu,Hongfang Yu,Jie Liu	With the rapid growth of edge intelligence, the deployment of federated learning (FL) over wireless networks has garnered increasing attention, which is called Federated Edge Learning (FEEL). In FEEL, both mobile devices transmitting model parameters over noisy channels and collecting data in diverse environments pose challenges to the generalization of trained models. Moreover, devices can engage in decentralized FL via Device-to-Device communication while the communication topology of connected devices also impacts the generalization of models. Most recent theoretical studies overlook the incorporation of all these effects into FEEL when developing generalization analyses. In contrast, our work presents an information-theoretic generalization analysis for topology-aware FEEL in the presence of data heterogeneity and noisy channels. Additionally, we propose a novel regularization method called Federated Global Mutual Information Reduction (FedGMIR) to enhance the performance of models based on our analysis. Numerical results validate our theoretical findings and provide evidence for the effectiveness of the proposed method.	cs.IT	None
9	Challenges of Radio Frequency Fingerprinting: From Data Collection to Deployment	Saeif Alhazbi,Ahmed Hussain,Savio Sciancalepore,Gabriele Oligeri,Panos Papadimitratos	Radio Frequency Fingerprinting (RFF) techniques promise to authenticate wireless devices at the physical layer based on inherent hardware imperfections introduced during manufacturing. Such RF transmitter imperfections are reflected into over-the-air signals, allowing receivers to accurately identify the RF transmitting source. Recent advances in Machine Learning, particularly in Deep Learning (DL), have improved the ability of RFF systems to extract and learn complex features that make up the device-specific fingerprint. However, integrating DL techniques with RFF and operating the system in real-world scenarios presents numerous challenges. This article identifies and analyzes these challenges while considering the three reference phases of any DL-based RFF system: (i) data collection and preprocessing, (ii) training, and finally, (iii) deployment. Our investigation points out the current open problems that prevent real deployment of RFF while discussing promising future directions, thus paving the way for further research in the area.	cs.CR	7 pages, 1 table, and 4 figures
0	Binary State Recognition by Robots using Visual Question Answering of Pre-Trained Vision-Language Model	Kento Kawaharazuka,Yoshiki Obinata,Naoaki Kanazawa,Kei Okada,Masayuki Inaba	Recognition of the current state is indispensable for the operation of a robot. There are various states to be recognized, such as whether an elevator door is open or closed, whether an object has been grasped correctly, and whether the TV is turned on or off. Until now, these states have been recognized by programmatically describing the state of a point cloud or raw image, by annotating and learning images, by using special sensors, etc. In contrast to these methods, we apply Visual Question Answering (VQA) from a Pre-Trained Vision-Language Model (PTVLM) trained on a large-scale dataset, to such binary state recognition. This idea allows us to intuitively describe state recognition in language without any re-training, thereby improving the recognition ability of robots in a simple and general way. We summarize various techniques in questioning methods and image processing, and clarify their properties through experiments.	cs.RO	None
1	Video Referring Expression Comprehension via Transformer with Content-conditioned Query	Ji Jiang,Meng Cao,Tengtao Song,Long Chen,Yi Wang,Yuexian Zou	Video Referring Expression Comprehension (REC) aims to localize a target object in videos based on the queried natural language. Recent improvements in video REC have been made using Transformer-based methods with learnable queries. However, we contend that this naive query design is not ideal given the open-world nature of video REC brought by text supervision. With numerous potential semantic categories, relying on only a few slow-updated queries is insufficient to characterize them. Our solution to this problem is to create dynamic queries that are conditioned on both the input video and language to model the diverse objects referred to. Specifically, we place a fixed number of learnable bounding boxes throughout the frame and use corresponding region features to provide prior information. Also, we noticed that current query features overlook the importance of cross-modal alignment. To address this, we align specific phrases in the sentence with semantically relevant visual areas, annotating them in existing video datasets (VID-Sentence and VidSTG). By incorporating these two designs, our proposed model (called ConFormer) outperforms other models on widely benchmarked datasets. For example, in the testing split of VID-Sentence dataset, ConFormer achieves 8.75% absolute improvement on Accu.@0.6 compared to the previous state-of-the-art model.	cs.CV	Accepted to ACM International Conference on Multimedia Workshop (ACM   MM), 2023. arXiv admin note: substantial text overlap with arXiv:2210.02953
2	Graph Neural Networks with a Distribution of Parametrized Graphs	See Hian Lee,Feng Ji,Kelin Xia,Wee Peng Tay	Traditionally, graph neural networks have been trained using a single observed graph. However, the observed graph represents only one possible realization. In many applications, the graph may encounter uncertainties, such as having erroneous or missing edges, as well as edge weights that provide little informative value. To address these challenges and capture additional information previously absent in the observed graph, we introduce latent variables to parameterize and generate multiple graphs. We obtain the maximum likelihood estimate of the network parameters in an Expectation-Maximization (EM) framework based on the multiple graphs. Specifically, we iteratively determine the distribution of the graphs using a Markov Chain Monte Carlo (MCMC) method, incorporating the principles of PAC-Bayesian theory. Numerical experiments demonstrate improvements in performance against baseline models on node classification for heterogeneous graphs and graph regression on chemistry datasets.	cs.LG	None
3	Fuse Your Latents: Video Editing with Multi-source Latent Diffusion Models	Tianyi Lu,Xing Zhang,Jiaxi Gu,Hang Xu,Renjing Pei,Songcen Xu,Zuxuan Wu	Latent Diffusion Models (LDMs) are renowned for their powerful capabilities in image and video synthesis. Yet, video editing methods suffer from insufficient pre-training data or video-by-video re-training cost. In addressing this gap, we propose FLDM (Fused Latent Diffusion Model), a training-free framework to achieve text-guided video editing by applying off-the-shelf image editing methods in video LDMs. Specifically, FLDM fuses latents from an image LDM and an video LDM during the denoising process. In this way, temporal consistency can be kept with video LDM while high-fidelity from the image LDM can also be exploited. Meanwhile, FLDM possesses high flexibility since both image LDM and video LDM can be replaced so advanced image editing methods such as InstructPix2Pix and ControlNet can be exploited. To the best of our knowledge, FLDM is the first method to adapt off-the-shelf image editing methods into video LDMs for video editing. Extensive quantitative and qualitative experiments demonstrate that FLDM can improve the textual alignment and temporal consistency of edited videos.	cs.CV	None
4	Muonic hyperfine structure and the Bohr-Weisskopf effect	J. R. Persson	An update is given on the experimental values of the magnetic hyperfine structure and the Bohr-Weisskopf effect in muonic atoms. The need for more measurements and systematic calculations is discussed to allow the differentiation of different models of the Bohr-Weisskopf effect in nuclei.	nucl-th	14 pages
5	Learning Efficient Surrogate Dynamic Models with Graph Spline Networks	Chuanbo Hua,Federico Berto,Michael Poli,Stefano Massaroli,Jinkyoo Park	While complex simulations of physical systems have been widely used in engineering and scientific computing, lowering their often prohibitive computational requirements has only recently been tackled by deep learning approaches. In this paper, we present GraphSplineNets, a novel deep-learning method to speed up the forecasting of physical systems by reducing the grid size and number of iteration steps of deep surrogate models. Our method uses two differentiable orthogonal spline collocation methods to efficiently predict response at any location in time and space. Additionally, we introduce an adaptive collocation strategy in space to prioritize sampling from the most important regions. GraphSplineNets improve the accuracy-speedup tradeoff in forecasting various dynamical systems with increasing complexity, including the heat equation, damped wave propagation, Navier-Stokes equations, and real-world ocean currents in both regular and irregular domains.	math.NA	Published as a conference paper in NeurIPS 2023
6	The Residually Indistinguishable Case of Ribet's Method for GL2	Samit Dasgupta,Mahesh Kakde,Jesse Silliman,Jiuya Wang	Ribet's method provides a strategy for constructing nontrivial extension of a $p$-adic Galois representation $\rho_1$ by another such representation $\rho_2$. Suppose we are working over a local ring $(\mathbf{T}, \mathfrak{m})$. An important assumption that occurs throughout literature is that the representations $\rho_i$ are residually indistinguishable. The main theorem of this paper is a general version of Ribet's Lemma for $\rm{GL}_2$ where we do not impose the assumption that the associated characters are residually distinguished.	math.NT	47 pages
7	A note on no-hair properties of static black holes in four and higher dimensional spacetimes with cosmological constant	Akihiro Ishibashi,Satoshi Matsumoto,Yuichiro Yoneo	We study no-hair properties of static black holes in four and higher dimensional spacetimes with a cosmological constant. For the vanishing cosmological constant case, we show a no-hair theorem and also a no-short-hair theorem under certain conditions for the energy-momentum of matter fields. For the positive cosmological constant case, we discuss conditions for hairy static black holes to exist in terms of the energy density of matter fields evaluated at the black hole horizon and the cosmological horizon. For the negative cosmological constant case, we study conditions for hairy black holes by presenting a no-hair theorem in which the asymptotic structure is assumed to be determined by the true cosmological constant.	gr-qc	None
8	ZGUL: Zero-shot Generalization to Unseen Languages using Multi-source Ensembling of Language Adapters	Vipul Rathore,Rajdeep Dhingra,Parag Singla,Mausam	We tackle the problem of zero-shot cross-lingual transfer in NLP tasks via the use of language adapters (LAs). Most of the earlier works have explored training with adapter of a single source (often English), and testing either using the target LA or LA of another related language. Training target LA requires unlabeled data, which may not be readily available for low resource unseen languages: those that are neither seen by the underlying multilingual language model (e.g., mBERT), nor do we have any (labeled or unlabeled) data for them. We posit that for more effective cross-lingual transfer, instead of just one source LA, we need to leverage LAs of multiple (linguistically or geographically related) source languages, both at train and test-time - which we investigate via our novel neural architecture, ZGUL. Extensive experimentation across four language groups, covering 15 unseen target languages, demonstrates improvements of up to 3.2 average F1 points over standard fine-tuning and other strong baselines on POS tagging and NER tasks. We also extend ZGUL to settings where either (1) some unlabeled data or (2) few-shot training examples are available for the target language. We find that ZGUL continues to outperform baselines in these settings too.	cs.CL	None
9	Winning Prize Comes from Losing Tickets: Improve Invariant Learning by Exploring Variant Parameters for Out-of-Distribution Generalization	Zhuo Huang,Muyang Li,Li Shen,Jun Yu,Chen Gong,Bo Han,Tongliang Liu	Out-of-Distribution (OOD) Generalization aims to learn robust models that generalize well to various environments without fitting to distribution-specific features. Recent studies based on Lottery Ticket Hypothesis (LTH) address this problem by minimizing the learning target to find some of the parameters that are critical to the task. However, in OOD problems, such solutions are suboptimal as the learning task contains severe distribution noises, which can mislead the optimization process. Therefore, apart from finding the task-related parameters (i.e., invariant parameters), we propose Exploring Variant parameters for Invariant Learning (EVIL) which also leverages the distribution knowledge to find the parameters that are sensitive to distribution shift (i.e., variant parameters). Once the variant parameters are left out of invariant learning, a robust subnetwork that is resistant to distribution shift can be found. Additionally, the parameters that are relatively stable across distributions can be considered invariant ones to improve invariant learning. By fully exploring both variant and invariant parameters, our EVIL can effectively identify a robust subnetwork to improve OOD generalization. In extensive experiments on integrated testbed: DomainBed, EVIL can effectively and efficiently enhance many popular methods, such as ERM, IRM, SAM, etc.	cs.LG	27 pages, 9 figures
0	Evaluating Pre-trained Language Models for Repairing API Misuses	Ting Zhang,Ivana Clairine Irsan,Ferdian Thung,David Lo,Asankhaya Sharma,Lingxiao Jiang	API misuses often lead to software bugs, crashes, and vulnerabilities. While several API misuse detectors have been proposed, there are no automatic repair tools specifically designed for this purpose. In a recent study, test-suite-based automatic program repair (APR) tools were found to be ineffective in repairing API misuses. Still, since the study focused on non-learning-aided APR tools, it remains unknown whether learning-aided APR tools are capable of fixing API misuses. In recent years, pre-trained language models (PLMs) have succeeded greatly in many natural language processing tasks. There is a rising interest in applying PLMs to APR. However, there has not been any study that investigates the effectiveness of PLMs in repairing API misuse.   To fill this gap, we conduct a comprehensive empirical study on 11 learning-aided APR tools, which include 9 of the state-of-the-art general-purpose PLMs and two APR tools. We evaluate these models with an API-misuse repair dataset, consisting of two variants. Our results show that PLMs perform better than the studied APR tools in repairing API misuses. Among the 9 pre-trained models tested, CodeT5 is the best performer in the exact match. We also offer insights and potential exploration directions for future research.	cs.SE	Under review by TOSEM
1	MVFAN: Multi-View Feature Assisted Network for 4D Radar Object Detection	Qiao Yan,Yihan Wang	4D radar is recognized for its resilience and cost-effectiveness under adverse weather conditions, thus playing a pivotal role in autonomous driving. While cameras and LiDAR are typically the primary sensors used in perception modules for autonomous vehicles, radar serves as a valuable supplementary sensor. Unlike LiDAR and cameras, radar remains unimpaired by harsh weather conditions, thereby offering a dependable alternative in challenging environments. Developing radar-based 3D object detection not only augments the competency of autonomous vehicles but also provides economic benefits. In response, we propose the Multi-View Feature Assisted Network (\textit{MVFAN}), an end-to-end, anchor-free, and single-stage framework for 4D-radar-based 3D object detection for autonomous vehicles. We tackle the issue of insufficient feature utilization by introducing a novel Position Map Generation module to enhance feature learning by reweighing foreground and background points, and their features, considering the irregular distribution of radar point clouds. Additionally, we propose a pioneering backbone, the Radar Feature Assisted backbone, explicitly crafted to fully exploit the valuable Doppler velocity and reflectivity data provided by the 4D radar sensor. Comprehensive experiments and ablation studies carried out on Astyx and VoD datasets attest to the efficacy of our framework. The incorporation of Doppler velocity and RCS reflectivity dramatically improves the detection performance for small moving objects such as pedestrians and cyclists. Consequently, our approach culminates in a highly optimized 4D-radar-based 3D object detection capability for autonomous driving systems, setting a new standard in the field.	cs.CV	19 Pages, 7 figures, Accepted by ICONIP 2023
2	Deepfake Detection: Leveraging the Power of 2D and 3D CNN Ensembles	Aagam Bakliwal,Amit D. Joshi	In the dynamic realm of deepfake detection, this work presents an innovative approach to validate video content. The methodology blends advanced 2-dimensional and 3-dimensional Convolutional Neural Networks. The 3D model is uniquely tailored to capture spatiotemporal features via sliding filters, extending through both spatial and temporal dimensions. This configuration enables nuanced pattern recognition in pixel arrangement and temporal evolution across frames. Simultaneously, the 2D model leverages EfficientNet architecture, harnessing auto-scaling in Convolutional Neural Networks. Notably, this ensemble integrates Voting Ensembles and Adaptive Weighted Ensembling. Strategic prioritization of the 3-dimensional model's output capitalizes on its exceptional spatio-temporal feature extraction. Experimental validation underscores the effectiveness of this strategy, showcasing its potential in countering deepfake generation's deceptive practices.	cs.CV	6 pages, 2 figures
3	Frequency-Aware Transformer for Learned Image Compression	Han Li,Shaohui Li,Wenrui Dai,Chenglin Li,Junni Zou,Hongkai Xiong	Learned image compression (LIC) has gained traction as an effective solution for image storage and transmission in recent years. However, existing LIC methods are redundant in latent representation due to limitations in capturing anisotropic frequency components and preserving directional details. To overcome these challenges, we propose a novel frequency-aware transformer (FAT) block that for the first time achieves multiscale directional ananlysis for LIC. The FAT block comprises frequency-decomposition window attention (FDWA) modules to capture multiscale and directional frequency components of natural images. Additionally, we introduce frequency-modulation feed-forward network (FMFFN) to adaptively modulate different frequency components, improving rate-distortion performance. Furthermore, we present a transformer-based channel-wise autoregressive (T-CA) model that effectively exploits channel dependencies. Experiments show that our method achieves state-of-the-art rate-distortion performance compared to existing LIC methods, and evidently outperforms latest standardized codec VTM-12.1 by 14.5%, 15.1%, 13.0% in BD-rate on the Kodak, Tecnick, and CLIC datasets.	eess.IV	None
4	Quantum Parametric Amplification and NonClassical Correlations due to 45 nm nMOS Circuitry Effect	Ahmad Salmanogli,Amine Bermak	This study unveils a groundbreaking exploration of using semiconductor technology in quantum circuitry. Leveraging the unique operability of 45 nm CMOS technology at deep cryogenic temperatures (~ 300 mK), a novel quantum electronic circuit is meticulously designed. Through the intricate coupling of two matching circuits via a 45 nm nMOS transistor, operating as an open quantum system, the circuit quantum Hamiltonian and the related Heisenberg-Langevin equation are derived, setting the stage for a comprehensive quantum analysis. Central to this investigation are three pivotal coefficients derived, which are the coupling between the coupled oscillator charge and flux operators through the internal circuit of the transistor. These coefficients emerge as critical determinants, shaping both the circuit potential as a parametric amplifier and its impact on quantum properties. The study unfolds a delicate interplay between these coefficients, showcasing their profound influence on quantum discord and the gain of the parametric amplifier. Consequently, the assimilation of 45 nm CMOS technology with quantum circuitry makes it possible to potentially bridge the technological gap in quantum computing applications, where the parametric amplifier is a necessary and critical device. The designed novel quantum device serves not only as a quantum parametric amplifier to amplify quantum signals but also enhances the inherent quantum properties of the signals such as non-classicality. Therefore, one can create an effective parametric amplifier that simultaneously improves the quantum characteristics of the signals. The more interesting result is that if such a theory becomes applicable, the circuit implemented in the deep-cryogenic temperature can be easily compatible with the next step of circuitry while keeping the same electronic features compatibility with the quantum processor.	quant-ph	11 pages, 5 figures
5	Open-NeRF: Towards Open Vocabulary NeRF Decomposition	Hao Zhang,Fang Li,Narendra Ahuja	In this paper, we address the challenge of decomposing Neural Radiance Fields (NeRF) into objects from an open vocabulary, a critical task for object manipulation in 3D reconstruction and view synthesis. Current techniques for NeRF decomposition involve a trade-off between the flexibility of processing open-vocabulary queries and the accuracy of 3D segmentation. We present, Open-vocabulary Embedded Neural Radiance Fields (Open-NeRF), that leverage large-scale, off-the-shelf, segmentation models like the Segment Anything Model (SAM) and introduce an integrate-and-distill paradigm with hierarchical embeddings to achieve both the flexibility of open-vocabulary querying and 3D segmentation accuracy. Open-NeRF first utilizes large-scale foundation models to generate hierarchical 2D mask proposals from varying viewpoints. These proposals are then aligned via tracking approaches and integrated within the 3D space and subsequently distilled into the 3D field. This process ensures consistent recognition and granularity of objects from different viewpoints, even in challenging scenarios involving occlusion and indistinct features. Our experimental results show that the proposed Open-NeRF outperforms state-of-the-art methods such as LERF \cite{lerf} and FFD \cite{ffd} in open-vocabulary scenarios. Open-NeRF offers a promising solution to NeRF decomposition, guided by open-vocabulary queries, enabling novel applications in robotics and vision-language interaction in open-world 3D scenes.	cs.CV	Accepted by WACV 2024
6	Simple modules for untwisted affine Lie algebras induced from nilpotent loop subalgebras	Volodymyr Mazorchuk	We construct large families of simple modules for untwisted affine Lie algebras using induction from one-dimensional modules over nilpotent loop subalgebras. We also show that the vector space of the first self-extensions for these module has uncountable dimension and that generic tensor products of these modules are simple.	math.RT	None
7	A model for multi-attack classification to improve intrusion detection performance using deep learning approaches	Arun Kumar Silivery,Ram Mohan Rao Kovvur	This proposed model introduces novel deep learning methodologies. The objective here is to create a reliable intrusion detection mechanism to help identify malicious attacks. Deep learning based solution framework is developed consisting of three approaches. The first approach is Long-Short Term Memory Recurrent Neural Network (LSTM-RNN) with seven optimizer functions such as adamax, SGD, adagrad, adam, RMSprop, nadam and adadelta. The model is evaluated on NSL-KDD dataset and classified multi attack classification. The model has outperformed with adamax optimizer in terms of accuracy, detection rate and low false alarm rate. The results of LSTM-RNN with adamax optimizer is compared with existing shallow machine and deep learning models in terms of accuracy, detection rate and low false alarm rate. The multi model methodology consisting of Recurrent Neural Network (RNN), Long-Short Term Memory Recurrent Neural Network (LSTM-RNN), and Deep Neural Network (DNN). The multi models are evaluated on bench mark datasets such as KDD99, NSL-KDD, and UNSWNB15 datasets. The models self-learnt the features and classifies the attack classes as multi-attack classification. The models RNN, and LSTM-RNN provide considerable performance compared to other existing methods on KDD99 and NSL-KDD dataset	cs.NI	None
8	Evaluating General-Purpose AI with Psychometrics	Xiting Wang,Liming Jiang,Jose Hernandez-Orallo,Luning Sun,David Stillwell,Fang Luo,Xing Xie	Artificial intelligence (AI) has witnessed an evolution from task-specific to general-purpose systems that trend toward human versatility. As AI systems begin to play pivotal roles in society, it is important to ensure that they are adequately evaluated. Current AI benchmarks typically assess performance on collections of specific tasks. This has drawbacks when used for assessing general-purpose AI systems. First, it is difficult to predict whether AI systems could complete a new task it has never seen or that did not previously exist. Second, these benchmarks often focus on overall performance metrics, potentially overlooking the finer details crucial for making informed decisions. Lastly, there are growing concerns about the reliability of existing benchmarks and questions about what is being measured. To solve these challenges, this paper suggests that psychometrics, the science of psychological measurement, should be placed at the core of evaluating general-purpose AI. Psychometrics provides a rigorous methodology for identifying and measuring the latent constructs that underlie performance across multiple tasks. We discuss its merits, warn against potential pitfalls, and propose a framework for putting it into practice. Finally, we explore future opportunities to integrate psychometrics with AI.	cs.AI	Work in progress
9	Quantum interferometers: principles and applications	Rui-Bo Jin,Zi-Qi Zeng,Chenglong You,Chenzhi Yuan	Interference, which refers to the phenomenon associated with the superposition of waves, has played a crucial role in the advancement of physics and finds a wide range of applications in physical and engineering measurements. Interferometers are experimental setups designed to observe and manipulate interference. With the development of technology, many quantum interferometers have been discovered and have become cornerstone tools in the field of quantum physics. Quantum interferometers not only explore the nature of the quantum world but also have extensive applications in quantum information technology, such as quantum communication, quantum computing, and quantum measurement. In this review, we analyze and summarize three typical quantum interferometers: the Hong-Ou-Mandel (HOM) interferometer, the N00N state interferometer, and the Franson interferometer. We focus on the principles and applications of these three interferometers. In the principles section, we present the theoretical models for these interferometers, including single-mode theory and multi-mode theory. In the applications section, we review the applications of these interferometers in quantum communication, computation, and measurement. We hope that this review article will promote the development of quantum interference in both fundamental science and practical engineering applications.	quant-ph	64 pages, 40 figures. Comments are welcome
0	Nonlinear steering control under input magnitude and rate constraints with exponential convergence	Rin Suyama,Satoshi Satoh,Atsuo Maki	A ship steering control is designed for a nonlinear maneuvering model whose rudder manipulation is constrained in both magnitude and rate. In our method, the tracking problem of the target heading angle with input constraints is converted into the tracking problem for a strict-feedback system without any input constraints. To derive this system, hyperbolic tangent ($\tanh$) function and auxiliary variables are introduced to deal with the input constraints. Furthermore, using the feature of the derivative of $\tanh$ function, auxiliary systems are successfully derived in the strict-feedback form. The backstepping method is utilized to construct the feedback control law for the resulting cascade system. The proposed steering control is verified in numerical experiments, and the result shows that the tracking of the target heading angle is successful using the proposed control law.	eess.SY	12 pages, 6 figures, a preprint submitted to the Journal of Marine   Science and Technology
1	GADY: Unsupervised Anomaly Detection on Dynamic Graphs	Shiqi Lou,Qingyue Zhang,Shujie Yang,Yuyang Tian,Zhaoxuan Tan,Minnan Luo	Anomaly detection on dynamic graphs refers to detecting entities whose behaviors obviously deviate from the norms observed within graphs and their temporal information. This field has drawn increasing attention due to its application in finance, network security, social networks, and more. However, existing methods face two challenges: dynamic structure constructing challenge - difficulties in capturing graph structure with complex time information and negative sampling challenge - unable to construct excellent negative samples for unsupervised learning. To address these challenges, we propose Unsupervised Generative Anomaly Detection on Dynamic Graphs (GADY). To tackle the first challenge, we propose a continuous dynamic graph model to capture the fine-grained information, which breaks the limit of existing discrete methods. Specifically, we employ a message-passing framework combined with positional features to get edge embeddings, which are decoded to identify anomalies. For the second challenge, we pioneer the use of Generative Adversarial Networks to generate negative interactions. Moreover, we design a loss function to alter the training goal of the generator while ensuring the diversity and quality of generated samples. Extensive experiments demonstrate that our proposed GADY significantly outperforms the previous state-of-the-art method on three real-world datasets. Supplementary experiments further validate the effectiveness of our model design and the necessity of each module.	cs.LG	None
2	DyExplainer: Explainable Dynamic Graph Neural Networks	Tianchun Wang,Dongsheng Luo,Wei Cheng,Haifeng Chen,Xiang Zhang	Graph Neural Networks (GNNs) resurge as a trending research subject owing to their impressive ability to capture representations from graph-structured data. However, the black-box nature of GNNs presents a significant challenge in terms of comprehending and trusting these models, thereby limiting their practical applications in mission-critical scenarios. Although there has been substantial progress in the field of explaining GNNs in recent years, the majority of these studies are centered on static graphs, leaving the explanation of dynamic GNNs largely unexplored. Dynamic GNNs, with their ever-evolving graph structures, pose a unique challenge and require additional efforts to effectively capture temporal dependencies and structural relationships. To address this challenge, we present DyExplainer, a novel approach to explaining dynamic GNNs on the fly. DyExplainer trains a dynamic GNN backbone to extract representations of the graph at each snapshot, while simultaneously exploring structural relationships and temporal dependencies through a sparse attention technique. To preserve the desired properties of the explanation, such as structural consistency and temporal continuity, we augment our approach with contrastive learning techniques to provide priori-guided regularization. To model longer-term temporal dependencies, we develop a buffer-based live-updating scheme for training. The results of our extensive experiments on various datasets demonstrate the superiority of DyExplainer, not only providing faithful explainability of the model predictions but also significantly improving the model prediction accuracy, as evidenced in the link prediction task.	cs.LG	9 pages
3	Joint Distributional Learning via Cramer-Wold Distance	Seunghwan An,Jong-June Jeon	The assumption of conditional independence among observed variables, primarily used in the Variational Autoencoder (VAE) decoder modeling, has limitations when dealing with high-dimensional datasets or complex correlation structures among observed variables. To address this issue, we introduced the Cramer-Wold distance regularization, which can be computed in a closed-form, to facilitate joint distributional learning for high-dimensional datasets. Additionally, we introduced a two-step learning method to enable flexible prior modeling and improve the alignment between the aggregated posterior and the prior distribution. Furthermore, we provide theoretical distinctions from existing methods within this category. To evaluate the synthetic data generation performance of our proposed approach, we conducted experiments on high-dimensional datasets with multiple categorical variables. Given that many readily available datasets and data science applications involve such datasets, our experiments demonstrate the effectiveness of our proposed methodology.	cs.LG	None
4	Pauli resonance states in light nuclei: how they appear and how they can be eliminated	N. Kalzhigitov,V. S. Vasilevsky	Systematic analysis of parameters and properties of the Pauli resonance states are performed for light nuclei $^{6}$Li, $^{7}$Li, $^{8}$Be, $^{9}$Be and $^{10}$B, which are treated as two-cluster systems. The Pauli resonance states are redundant solutions of the resonating group method appearing when one try use more advanced description of the internal structure of interacting clusters. Our calculations are performed in a standard and advanced versions of the resonating group method. The standard version employs wave functions of many-particle shell model to describe internal motion of nucleons within each cluster. The advanced version is based on three-cluster resonating group method. As in the standard version, the internal wave functions of three clusters are approximated by wave functions of many-particle shell model model. However, in advanced version one of pair of clusters forms a bound state, and third cluster is considered to interact with such state. It is found that the Pauli resonance states in nuclei under consideration have energy between 11 and 46 MeV, and their widths vary from 8 keV to 6.7 MeV. Analysis of wave functions of Pauli resonance states and matrix elements of norm kernel allowed us to formulate an effective method for eliminating Pauli resonance states. It is demonstrated that this method effectively eliminate all determined the Pauli resonance states.	nucl-th	38 pages, 28 figures, to be submitted to Phys. Rev. C
5	A model for drift velocity mediated scalar eddy diffusivity in homogeneous turbulent flows	Omkar B. Shende,Liam Storan,Ali Mani	Low Stokes number particles at dilute concentrations in turbulent flows can reasonably be approximated as passive scalars. The added presence of a drift velocity due to buoyancy or gravity when considering the transport of such passive scalars can reduce the turbulent dispersion of the scalar via a diminution of the eddy diffusivity. In this work, we propose a model to describe this decay and use a recently developed technique to accurately and efficiently measure the eddy diffusivity using Eulerian fields and quantities. We then show a correspondence between this method and standard Lagrangian definitions of diffusivity and collect data across a range of drift velocities and Reynolds numbers. The proposed model agrees with data from these direct numerical simulations, offers some improvement to previous models in describing other computational and experimental data, and satisfies theoretical constraints that are independent of Reynolds number.	physics.flu-dyn	None
6	PartRePer-MPI: Combining Fault Tolerance and Performance for MPI Applications	Sarthak Joshi,Sathish Vadhiyar	As we have entered Exascale computing, the faults in high-performance systems are expected to increase considerably. To compensate for a higher failure rate, the standard checkpoint/restart technique would need to create checkpoints at a much higher frequency resulting in an excessive amount of overhead which would not be sustainable for many scientific applications. Replication allows for fast recovery from failures by simply dropping the failed processes and using their replicas to continue the regular operation of the application.   In this paper, we have implemented PartRePer-MPI, a novel fault-tolerant MPI library that adopts partial replication of some of the launched MPI processes in order to provide resilience from failures. The novelty of our work is that it combines both fault tolerance, due to the use of the User Level Failure Mitigation (ULFM) framework in the Open MPI library, and high performance, due to the use of communication protocols in the native MPI library that is generally fine-tuned for specific HPC platforms. We have implemented efficient and parallel communication strategies with computational and replica processes, and our library can seamlessly provide fault tolerance support to an existing MPI application. Our experiments using seven NAS Parallel Benchmarks and two scientific applications show that the failure-free overheads in PartRePer-MPI when compared to the baseline MVAPICH2, are only up to 6.4% for the NAS parallel benchmarks and up to 9.7% for the scientific applications.	cs.DC	None
7	Cut-free sequent calculi for the provability logic D	Ryo Kashima,Taishi Kurahashi,Sohei Iwata	We say that a Kripke model is a GL-model if the accessibility relation $\prec$ is transitive and converse well-founded. We say that a Kripke model is a D-model if it is obtained by attaching infinitely many worlds $t_1, t_2, \ldots$, and $t_\omega$ to a world $t_0$ of a GL-model so that $t_0 \succ t_1 \succ t_2 \succ \cdots \succ t_\omega$. A non-normal modal logic D, which was studied by Beklemishev (1999), is characterized as follows. A formula $\varphi$ is a theorem of D if and only if $\varphi$ is true at $t_\omega$ in any D-model. D is an intermediate logic between the provability logics GL and S. A Hilbert-style proof system for D is known, but there has been no sequent calculus. In this paper, we establish two sequent calculi for D, and show the cut-elimination theorem. We also introduce new Hilbert-style systems for D by interpreting the sequent calculi. Moreover we show a general result as follows. Let $X$ and $X^+$ be arbitrary modal logics. If the relationship between semantics of $X$ and semantics of $X^+$ is equal to that of GL and D, then $X^+$ can be axiomatized based on $X$ in the same way as the new axiomatization of D based on GL.	math.LO	None
8	Transformer-based Live Update Generation for Soccer Matches from Microblog Posts	Masashi Oshika,Kosuke Yamada,Ryohei Sasano,Koichi Takeda	It has been known to be difficult to generate adequate sports updates from a sequence of vast amounts of diverse live tweets, although the live sports viewing experience with tweets is gaining the popularity. In this paper, we focus on soccer matches and work on building a system to generate live updates for soccer matches from tweets so that users can instantly grasp a match's progress and enjoy the excitement of the match from raw tweets. Our proposed system is based on a large pre-trained language model and incorporates a mechanism to control the number of updates and a mechanism to reduce the redundancy of duplicate and similar updates.	cs.CL	EMNLP 2023
9	UniX-Encoder: A Universal $X$-Channel Speech Encoder for Ad-Hoc Microphone Array Speech Processing	Zili Huang,Yiwen Shao,Shi-Xiong Zhang,Dong Yu	The speech field is evolving to solve more challenging scenarios, such as multi-channel recordings with multiple simultaneous talkers. Given the many types of microphone setups out there, we present the UniX-Encoder. It's a universal encoder designed for multiple tasks, and worked with any microphone array, in both solo and multi-talker environments. Our research enhances previous multi-channel speech processing efforts in four key areas: 1) Adaptability: Contrasting traditional models constrained to certain microphone array configurations, our encoder is universally compatible. 2) Multi-Task Capability: Beyond the single-task focus of previous systems, UniX-Encoder acts as a robust upstream model, adeptly extracting features for diverse tasks including ASR and speaker recognition. 3) Self-Supervised Training: The encoder is trained without requiring labeled multi-channel data. 4) End-to-End Integration: In contrast to models that first beamform then process single-channels, our encoder offers an end-to-end solution, bypassing explicit beamforming or separation. To validate its effectiveness, we tested the UniX-Encoder on a synthetic multi-channel dataset from the LibriSpeech corpus. Across tasks like speech recognition and speaker diarization, our encoder consistently outperformed combinations like the WavLM model with the BeamformIt frontend.	eess.AS	Submitted to ICASSP 2024
0	Green's function and LDOS for non-relativistic electron pair	Tomasz M. Rusin	The Coulomb Green's function (GF) for non-relativistic charged particle in field of attractive Coulomb force is extended to describe the interaction of two non-relativistic electrons through repulsive Coulomb forces. Closed-form expressions for the GF, in the absence of electron spins, are derived as one-dimensional integrals. The results are then generalized to include electron spins and account for the Pauli exclusion principle. This leads to a final GF composed of two components, one even and the other odd with respect to exchange particles, with closed-form expressions represented as one-dimensional integrals. The Dyson equations for spin-independent potentials is presented. The local density of states (LDOS) is calculated, which is a combination of contributions from both even and odd GFs. This calculation reveals the dependence of LDOS on inter-electron distance and energy. Separate analysis of the impact of the Pauli exclusion principle is provided. An examination of the pseudo-LDOS, arising from the two-body contribution to the Green's function, is undertaken. Complete suppression of the LDOS at~$r=0$ is ensured by this term, which exhibits a restricted spatial extent. The reasons for the emergence of this pseudo-LDOS are elucidated.	quant-ph	13 pages and 5 figures
1	G-Invariant Representations using Coorbits: Injectivity Properties	Radu Balan,Efstratios Tsoukanis	Consider a real vector space $\mathcal{V}$ and a finite group $G$ acting unitarily on $\mathcal{V}$. We study the general problem of constructing a stable embedding whose domain is the quotient of the vector space modulo the group action, and whose target space is a Euclidean space.   We construct an embedding $\Psi$ and we study under which assumptions $\Psi$ is injective in the quotient vector space. The embedding scheme we introduce is based on selecting a fixed subset from the sorted orbit $\downarrow\langle{U_gw_i},{x}\rangle_{g \in G}$, where $w_i$ are appropriate vectors.	math.RT	None
2	Towards Large-scale Masked Face Recognition	Manyuan Zhang,Bingqi Ma,Guanglu Song,Yunxiao Wang,Hongsheng Li,Yu Liu	During the COVID-19 coronavirus epidemic, almost everyone is wearing masks, which poses a huge challenge for deep learning-based face recognition algorithms. In this paper, we will present our \textbf{championship} solutions in ICCV MFR WebFace260M and InsightFace unconstrained tracks. We will focus on four challenges in large-scale masked face recognition, i.e., super-large scale training, data noise handling, masked and non-masked face recognition accuracy balancing, and how to design inference-friendly model architecture. We hope that the discussion on these four aspects can guide future research towards more robust masked face recognition systems.	cs.CV	the top1 solution for ICCV2021-MFR challenge
3	Neural Potential Field for Obstacle-Aware Local Motion Planning	Muhammad Alhaddad,Konstantin Mironov,Aleksey Staroverov,Aleksandr Panov	Model predictive control (MPC) may provide local motion planning for mobile robotic platforms. The challenging aspect is the analytic representation of collision cost for the case when both the obstacle map and robot footprint are arbitrary. We propose a Neural Potential Field: a neural network model that returns a differentiable collision cost based on robot pose, obstacle map, and robot footprint. The differentiability of our model allows its usage within the MPC solver. It is computationally hard to solve problems with a very high number of parameters. Therefore, our architecture includes neural image encoders, which transform obstacle maps and robot footprints into embeddings, which reduce problem dimensionality by two orders of magnitude. The reference data for network training are generated based on algorithmic calculation of a signed distance function. Comparative experiments showed that the proposed approach is comparable with existing local planners: it provides trajectories with outperforming smoothness, comparable path length, and safe distance from obstacles. Experiment on Husky UGV mobile robot showed that our approach allows real-time and safe local planning. The code for our approach is presented at https://github.com/cog-isa/NPField together with demo video.	cs.RO	None
4	InstructPTS: Instruction-Tuning LLMs for Product Title Summarization	Besnik Fetahu,Zhiyu Chen,Oleg Rokhlenko,Shervin Malmasi	E-commerce product catalogs contain billions of items. Most products have lengthy titles, as sellers pack them with product attributes to improve retrieval, and highlight key product aspects. This results in a gap between such unnatural products titles, and how customers refer to them. It also limits how e-commerce stores can use these seller-provided titles for recommendation, QA, or review summarization.   Inspired by recent work on instruction-tuned LLMs, we present InstructPTS, a controllable approach for the task of Product Title Summarization (PTS). Trained using a novel instruction fine-tuning strategy, our approach is able to summarize product titles according to various criteria (e.g. number of words in a summary, inclusion of specific phrases, etc.). Extensive evaluation on a real-world e-commerce catalog shows that compared to simple fine-tuning of LLMs, our proposed approach can generate more accurate product name summaries, with an improvement of over 14 and 8 BLEU and ROUGE points, respectively.	cs.CL	Accepted by EMNLP 2023 (Industry Track)
5	From Simple to Complex: A Progressive Framework for Document-level Informative Argument Extraction	Quzhe Huang,Yanxi Zhang,Dongyan Zhao	"Document-level Event Argument Extraction (EAE) requires the model to extract arguments of multiple events from a single document. Considering the underlying dependencies between these events, recent efforts leverage the idea of ""memory"", where the results of already predicted events are cached and can be retrieved to help the prediction of upcoming events. These methods extract events according to their appearance order in the document, however, the event that appears in the first sentence does not mean that it is the easiest to extract. Existing methods might introduce noise to the extraction of upcoming events if they rely on an incorrect prediction of previous events. In order to provide more reliable memory, we propose a simple-to-complex progressive framework for document-level EAE. Specifically, we first calculate the difficulty of each event and then, we conduct the extraction following a simple-to-complex order. In this way, the memory will store the most certain results, and the model could use these reliable sources to help the prediction of more difficult events. Experiments on WikiEvents show that our model outperforms SOTA by 1.4% in F1, indicating the proposed simple-to-complex framework is useful in the EAE task."	cs.CL	Accepted to the Findings of EMNLP 2023 (Long Paper)
6	The Brans-Dicke field in Non-metricity gravity: Cosmological solutions and Conformal transformations	Andronikos Paliathanasis	We consider the Brans-Dicke theory in non-metricity gravity, which belongs to the family of symmetric teleparallel scalar-tensor theories. Our focus lies in exploring the implications of the conformal transformation, as we derive the conformal equivalent theory in the Einstein frame, distinct from the minimally coupled scalar field theory. The fundamental principle of the conformal transformation suggests the mathematical equivalence of the related theories. However, to thoroughly analyze the impact on physical variables, we investigate the spatially flat Friedmann--Lema\^{\i}tre--Robertson--Walker geometry, defining the connection in the non-coincidence gauge. We construct exact solutions for the cosmological model in one frame and compare the physical properties in the conformal related frame. Surprisingly, we find that the general physical properties of the exact solutions remain invariant under the conformal transformation. Finally, we construct, for the first time, an analytic solution for the symmetric teleparallel scalar-tensor cosmology.	gr-qc	25 pages, 1 figure
7	A Multi-Modal Multilingual Benchmark for Document Image Classification	Yoshinari Fujinuma,Siddharth Varia,Nishant Sankaran,Srikar Appalaraju,Bonan Min,Yogarshi Vyas	Document image classification is different from plain-text document classification and consists of classifying a document by understanding the content and structure of documents such as forms, emails, and other such documents. We show that the only existing dataset for this task (Lewis et al., 2006) has several limitations and we introduce two newly curated multilingual datasets WIKI-DOC and MULTIEURLEX-DOC that overcome these limitations. We further undertake a comprehensive study of popular visually-rich document understanding or Document AI models in previously untested setting in document image classification such as 1) multi-label classification, and 2) zero-shot cross-lingual transfer setup. Experimental results show limitations of multilingual Document AI models on cross-lingual transfer across typologically distant languages. Our datasets and findings open the door for future research into improving Document AI models.	cs.CL	Accepted to EMNLP 2023 (Findings)
8	Redco: A Lightweight Tool to Automate Distributed Training of LLMs on Any GPU-TPUs	Bowen Tan,Yun Zhu,Lijuan Liu,Hongyi Wang,Yonghao Zhuang,Jindong Chen,Eric Xing,Zhiting Hu	The recent progress of AI can be largely attributed to large language models (LLMs). However, their escalating memory requirements introduce challenges for machine learning (ML) researchers and engineers. Addressing this requires developers to partition a large model to distribute it across multiple GPUs or TPUs. This necessitates considerable coding and intricate configuration efforts with existing model parallel tools, such as Megatron-LM, DeepSpeed, and Alpa. These tools require users' expertise in machine learning systems (MLSys), creating a bottleneck in LLM development, particularly for developers without MLSys background. In this work, we present Redco, a lightweight and user-friendly tool crafted to automate distributed training and inference for LLMs, as well as to simplify ML pipeline development. The design of Redco emphasizes two key aspects. Firstly, to automate model parallism, our study identifies two straightforward rules to generate tensor parallel strategies for any given LLM. Integrating these rules into Redco facilitates effortless distributed LLM training and inference, eliminating the need of additional coding or complex configurations. We demonstrate the effectiveness by applying Redco on a set of LLM architectures, such as GPT-J, LLaMA, T5, and OPT, up to the size of 66B. Secondly, we propose a mechanism that allows for the customization of diverse ML pipelines through the definition of merely three functions, eliminating redundant and formulaic code like multi-host related processing. This mechanism proves adaptable across a spectrum of ML algorithms, from foundational language modeling to complex algorithms like meta-learning and reinforcement learning. Consequently, Redco implementations exhibit much fewer code lines compared to their official counterparts.	cs.LG	Released under Apache License 2.0 at   https://github.com/tanyuqian/redco
9	Fast Algorithms for Separable Linear Programs	Sally Dong,Gramoz Goranci,Lawrence Li,Sushant Sachdeva,Guanghao Ye	In numerical linear algebra, considerable effort has been devoted to obtaining faster algorithms for linear systems whose underlying matrices exhibit structural properties. A prominent success story is the method of generalized nested dissection~[Lipton-Rose-Tarjan'79] for separable matrices. On the other hand, the majority of recent developments in the design of efficient linear program (LP) solves do not leverage the ideas underlying these faster linear system solvers nor consider the separable structure of the constraint matrix.   We give a faster algorithm for separable linear programs. Specifically, we consider LPs of the form $\min_{\mathbf{A}\mathbf{x}=\mathbf{b}, \mathbf{l}\leq\mathbf{x}\leq\mathbf{u}} \mathbf{c}^\top\mathbf{x}$, where the graphical support of the constraint matrix $\mathbf{A} \in \mathbb{R}^{n\times m}$ is $O(n^\alpha)$-separable. These include flow problems on planar graphs and low treewidth matrices among others. We present an $\tilde{O}((m+m^{1/2 + 2\alpha}) \log(1/\epsilon))$ time algorithm for these LPs, where $\epsilon$ is the relative accuracy of the solution.   Our new solver has two important implications: for the $k$-multicommodity flow problem on planar graphs, we obtain an algorithm running in $\tilde{O}(k^{5/2} m^{3/2})$ time in the high accuracy regime; and when the support of $\mathbf{A}$ is $O(n^\alpha)$-separable with $\alpha \leq 1/4$, our algorithm runs in $\tilde{O}(m)$ time, which is nearly optimal. The latter significantly improves upon the natural approach of combining interior point methods and nested dissection, whose time complexity is lower bounded by $\Omega(\sqrt{m}(m+m^{\alpha\omega}))=\Omega(m^{3/2})$, where $\omega$ is the matrix multiplication constant. Lastly, in the setting of low-treewidth LPs, we recover the results of [DLY,STOC21] and [GS,22] with significantly simpler data structure machinery.	cs.DS	55 pages. To appear at SODA 2024
0	Unraveling Feature Extraction Mechanisms in Neural Networks	Xiaobing Sun,Jiaxi Li,Wei Lu	The underlying mechanism of neural networks in capturing precise knowledge has been the subject of consistent research efforts. In this work, we propose a theoretical approach based on Neural Tangent Kernels (NTKs) to investigate such mechanisms. Specifically, considering the infinite network width, we hypothesize the learning dynamics of target models may intuitively unravel the features they acquire from training data, deepening our insights into their internal mechanisms. We apply our approach to several fundamental models and reveal how these models leverage statistical features during gradient descent and how they are integrated into final decisions. We also discovered that the choice of activation function can affect feature extraction. For instance, the use of the \textit{ReLU} activation function could potentially introduce a bias in features, providing a plausible explanation for its replacement with alternative functions in recent pre-trained language models. Additionally, we find that while self-attention and CNN models may exhibit limitations in learning n-grams, multiplication-based models seem to excel in this area. We verify these theoretical findings through experiments and find that they can be applied to analyze language modeling tasks, which can be regarded as a special variant of classification. Our contributions offer insights into the roles and capacities of fundamental components within large language models, thereby aiding the broader understanding of these complex systems.	cs.CL	Accepted by EMNLP 2023
1	DiffRef3D: A Diffusion-based Proposal Refinement Framework for 3D Object Detection	Se-Ho Kim,Inyong Koo,Inyoung Lee,Byeongjun Park,Changick Kim	Denoising diffusion models show remarkable performances in generative tasks, and their potential applications in perception tasks are gaining interest. In this paper, we introduce a novel framework named DiffRef3D which adopts the diffusion process on 3D object detection with point clouds for the first time. Specifically, we formulate the proposal refinement stage of two-stage 3D object detectors as a conditional diffusion process. During training, DiffRef3D gradually adds noise to the residuals between proposals and target objects, then applies the noisy residuals to proposals to generate hypotheses. The refinement module utilizes these hypotheses to denoise the noisy residuals and generate accurate box predictions. In the inference phase, DiffRef3D generates initial hypotheses by sampling noise from a Gaussian distribution as residuals and refines the hypotheses through iterative steps. DiffRef3D is a versatile proposal refinement framework that consistently improves the performance of existing 3D object detection models. We demonstrate the significance of DiffRef3D through extensive experiments on the KITTI benchmark. Code will be available.	cs.CV	None
2	Classification of three-family flavoured DFSZ axion models that have no domain wall problem	Peter Cox,Matthew J. Dolan,Maaz Hayat,Andrea Thamm,Raymond R. Volkas	We provide an exhaustive classification of three-family DFSZ axion models that have no cosmological domain wall problem. This result is obtained by making the Peccei-Quinn symmetry flavour dependent in certain specific ways, thus reinforcing a possible connection between the strong CP problem and the flavour puzzle. Known DFSZ flavour variants such as the top-specific model emerge as special cases. Key features of the phenomenology of these models are briefly discussed.	hep-ph	20 pages, 3 tables
3	Transmitting Data Through Reconfigurable Intelligent Surface: A Spatial Sigma-Delta Modulation Approach	Wai-Yiu Keung,Hei Victor Cheng,Wing-Kin Ma	Transmitting data using the phases on reconfigurable intelligent surfaces (RIS) is a promising solution for future energy-efficient communication systems. Recent work showed that a virtual phased massive multiuser multiple-input-multiple-out (MIMO) transmitter can be formed using only one active antenna and a large passive RIS. In this paper, we are interested in using such a system to perform MIMO downlink precoding. In this context, we may not be able to apply conventional MIMO precoding schemes, such as the simple zero-forcing (ZF) scheme, and we typically need to design the phase signals by solving optimization problems with constant modulus constraints or with discrete phase constraints, which pose challenges with high computational complexities. In this work, we propose an alternative approach based on Sigma-Delta ($\Sigma\Delta$) modulation, which is classically famous for its noise-shaping ability. Specifically, first-order $\Sigma\Delta$ modulation is applied in the spatial domain to handle phase quantization in generating constant envelope signals. Under some mild assumptions, the proposed phased $\Sigma\Delta$ modulator allows us to use the ZF scheme to synthesize the RIS reflection phases with negligible complexity. The proposed approach is empirically shown to achieve comparable bit error rate performance to the unquantized ZF scheme.	eess.SP	None
4	The $ŒΩ_{R}$-philic scalar dark matter	Xun-Jie Xu,Siyu Zhou,Junyu Zhu	Right-handed neutrinos ($\nu_{R}$) offer an intriguing portal to new physics in hidden sectors where dark matter (DM) may reside. In this work, we delve into the simplest hidden sector involving only a real scalar exclusively coupled to $\nu_{R}$, referred to as the $\nu_{R}$-philic scalar. We investigate the viability of the $\nu_{R}$-philic scalar to serve as a DM candidate, under the constraint that the coupling of $\nu_{R}$ to the standard model is determined by the seesaw relation and is responsible for the observed DM abundance. By analyzing the DM decay channels and solving Boltzmann equations, we identify the viable parameter space. In particular, our study reveals a lower bound ($\sim10^{4}$ GeV) on the mass of $\nu_{R}$ for the $\nu_{R}$-philic scalar to be DM. The DM mass may vary from sub-keV to sub-GeV. Within the viable parameter space, monochromatic neutrino lines from DM decay can be an important signal for DM indirect detection.	hep-ph	21 pages, 5 figures
5	Constructing the Equation of State of QCD in a functional QCD based scheme	Yi Lu,Fei Gao,Bao-Chi Fu,Hui-Chao Song,Yu-Xin Liu	We construct the equation of state (EoS) of QCD based on the finite chemical potential information from the functional QCD approaches, with the assistance of the lattice QCD EoS. The obtained EoS is consistent with the up-to-date estimations of the QCD phase diagram, including a phase transition temperature at zero chemical potential of $T=157$ MeV, the curvature of the transition line $\kappa=0.016$ and also a critical end point at $(T,\mu_B)=(118, 600)$ MeV. In specific, the phase diagram mapping is achieved by incorporating the order parameters into the EoS, namely the dynamical quark mass for the chiral phase transition together with the Polyakov loop parameter for the deconfinement phase transition. We also implement the EoS in hydrodynamic simulations to compute the particle yields, ratios and collective flow, and find that our obtained EoS agrees well with the commonly used one based on the combination of lattice QCD simulation and hadron resonance gas model.	hep-ph	8 pages, 12 figures
6	A Comprehensive Evaluation of Constrained Text Generation for Large Language Models	Xiang Chen,Xiaojun Wan	Advancements in natural language generation (NLG) and large language models (LLMs) have led to proficient text generation in various tasks. However, integrating intricate constraints into neural text generation, due to LLMs' opacity, remains challenging. This study investigates constrained text generation for LLMs, where predefined constraints are applied during LLM's generation process. Our research examines multiple LLMs, including ChatGPT and GPT-4, categorizing constraints into lexical, structural, and relation-based types. We also present various benchmarks to facilitate fair evaluation. The study addresses some key research questions, including the extent of LLMs' compliance with constraints. Results illuminate LLMs' capacity and deficiency to incorporate constraints and provide insights for future developments in constrained text generation. Codes and datasets will be released upon acceptance.	cs.CL	Work in progress
7	Elevating Women in the Workplace: The Dual Influence of Spiritual Intelligence and Ethical Environments on Job Satisfaction	Ali Bai,Morteza Vahedian,Rashin Ghahreman,Hasan Piri	In today's rapidly evolving workplace, the dynamics of job satisfaction and its determinants have become a focal point of organizational studies. This research offers a comprehensive examination of the nexus between spiritual intelligence and job satisfaction among female employees, with particular emphasis on the moderating role of ethical work environments. Beginning with an exploration of the multifaceted nature of human needs, the study delves deep into the psychological underpinnings that drive job satisfaction. It elucidates how various tangible and intangible motivators, such as salary benefits and recognition, play pivotal roles in shaping employee attitudes and behaviors. Moreover, the research spotlights the unique challenges and experiences of female employees, advocating for a more inclusive understanding of their needs. An extensive review of the literature and empirical analysis culminates in the pivotal finding that integrating spiritual intelligence and ethical considerations within organizational practices can significantly enhance job satisfaction. Such a holistic approach, the paper posits, not only bolsters the well-being and contentment of female employees but also augments overall organizational productivity, retention rates, and morale.	econ.GN	None
8	RCAgent: Cloud Root Cause Analysis by Autonomous Agents with Tool-Augmented Large Language Models	Zefan Wang,Zichuan Liu,Yingying Zhang,Aoxiao Zhong,Lunting Fan,Lingfei Wu,Qingsong Wen	Large language model (LLM) applications in cloud root cause analysis (RCA) have been actively explored recently. However, current methods are still reliant on manual workflow settings and do not unleash LLMs' decision-making and environment interaction capabilities. We present RCAgent, a tool-augmented LLM autonomous agent framework for practical and privacy-aware industrial RCA usage. Running on an internally deployed model rather than GPT families, RCAgent is capable of free-form data collection and comprehensive analysis with tools. Our framework combines a variety of enhancements, including a unique Self-Consistency for action trajectories, and a suite of methods for context management, stabilization, and importing domain knowledge. Our experiments show RCAgent's evident and consistent superiority over ReAct across all aspects of RCA -- predicting root causes, solutions, evidence, and responsibilities -- and tasks covered or uncovered by current rules, as validated by both automated metrics and human evaluations. Furthermore, RCAgent has already been integrated into the diagnosis and issue discovery workflow of the Real-time Compute Platform for Apache Flink of Alibaba Cloud.	cs.SE	None
9	Exponential relaxation to equilibrium for a kinetic Fokker-Planck-Alignment equation with force	Vinh Nguyen	In this note, we consider a kinetic Fokker-Planck-Alignment equation with Rayleigh-type friction and self-propulsion force which is derived from general environmental averaging models. We show the exponential relaxation in time toward equilibrium of the solutions provided certain spectral gap conditions are satisfied. The result is proved by using Desvillettes-Villani's method for collisional models to establish the global hypocoercivity.	math.AP	None
0	Generative Pre-training for Speech with Flow Matching	Alexander H. Liu,Matt Le,Apoorv Vyas,Bowen Shi,Andros Tjandra,Wei-Ning Hsu	Generative models have gained more and more attention in recent years for their remarkable success in tasks that required estimating and sampling data distribution to generate high-fidelity synthetic data. In speech, text-to-speech synthesis and neural vocoder are good examples where generative models have shined. While generative models have been applied to different applications in speech, there exists no general-purpose generative model that models speech directly. In this work, we take a step toward this direction by showing a single pre-trained generative model can be adapted to different downstream tasks with strong performance. Specifically, we pre-trained a generative model, named SpeechFlow, on 60k hours of untranscribed speech with Flow Matching and masked conditions. Experiment results show the pre-trained generative model can be fine-tuned with task-specific data to match or surpass existing expert models on speech enhancement, separation, and synthesis. Our work suggested a foundational model for generation tasks in speech can be built with generative pre-training.	eess.AS	Preprint, under review
1	An extension of Thwaites method for turbulent boundary layers	Rahul Agrawal,Sanjeeb T. Bose,Kevin P. Griffin,Parviz Moin	Thwaites (1949) developed an approximate method for determining the evolution of laminar boundary layers. The approximation follows from an assumption that the growth of a laminar boundary layer in the presence of pressure gradients could be parameterized solely as a function of a flow parameter, $m = \theta^2/\nu \frac{dU_e}{ds}$, thus reducing the von Karman momentum integral to a first-order ordinary differential equation. This method is useful for the analysis of laminar flows, and in computational potential flow solvers to account for the viscous effects. However, for turbulent flows, a similar approximation for turbulent boundary layers subjected to pressure gradients does not yet exist. In this work, an approximate method for determining the momentum thickness of a two-dimensional, turbulent boundary layer is proposed. It is shown that the method provides good estimates of the momentum thickness, when compared to available high-fidelity simulation data, for multiple boundary layers including both favorable and adverse pressure gradient effects, up to the point of separation. In the limit of high Reynolds numbers, it is possible to derive a criterion for the onset of separation from the proposed model which is shown to be in agreement with prior empirical observations (Alber, \textit{$9^{th}$ Aerospace Sciences Meeting, 1971}). The sensitivity of the separation location with respect to upstream perturbations is also analyzed through this model for the NASA/Boeing speed bump and the transonic Bachalo-Johnson bump	physics.flu-dyn	21 pages, 13 figures. Under consideration for publication in J. Fluid   Mech
2	SMURF-THP: Score Matching-based UnceRtainty quantiFication for Transformer Hawkes Process	Zichong Li,Yanbo Xu,Simiao Zuo,Haoming Jiang,Chao Zhang,Tuo Zhao,Hongyuan Zha	Transformer Hawkes process models have shown to be successful in modeling event sequence data. However, most of the existing training methods rely on maximizing the likelihood of event sequences, which involves calculating some intractable integral. Moreover, the existing methods fail to provide uncertainty quantification for model predictions, e.g., confidence intervals for the predicted event's arrival time. To address these issues, we propose SMURF-THP, a score-based method for learning Transformer Hawkes process and quantifying prediction uncertainty. Specifically, SMURF-THP learns the score function of events' arrival time based on a score-matching objective that avoids the intractable computation. With such a learned score function, we can sample arrival time of events from the predictive distribution. This naturally allows for the quantification of uncertainty by computing confidence intervals over the generated samples. We conduct extensive experiments in both event type prediction and uncertainty quantification of arrival time. In all the experiments, SMURF-THP outperforms existing likelihood-based methods in confidence calibration while exhibiting comparable prediction accuracy.	cs.LG	None
3	Defense Against Model Extraction Attacks on Recommender Systems	Sixiao Zhang,Hongzhi Yin,Hongxu Chen,Cheng Long	The robustness of recommender systems has become a prominent topic within the research community. Numerous adversarial attacks have been proposed, but most of them rely on extensive prior knowledge, such as all the white-box attacks or most of the black-box attacks which assume that certain external knowledge is available. Among these attacks, the model extraction attack stands out as a promising and practical method, involving training a surrogate model by repeatedly querying the target model. However, there is a significant gap in the existing literature when it comes to defending against model extraction attacks on recommender systems. In this paper, we introduce Gradient-based Ranking Optimization (GRO), which is the first defense strategy designed to counter such attacks. We formalize the defense as an optimization problem, aiming to minimize the loss of the protected target model while maximizing the loss of the attacker's surrogate model. Since top-k ranking lists are non-differentiable, we transform them into swap matrices which are instead differentiable. These swap matrices serve as input to a student model that emulates the surrogate model's behavior. By back-propagating the loss of the student model, we obtain gradients for the swap matrices. These gradients are used to compute a swap loss, which maximizes the loss of the student model. We conducted experiments on three benchmark datasets to evaluate the performance of GRO, and the results demonstrate its superior effectiveness in defending against model extraction attacks.	cs.LG	None
4	AccoMontage-3: Full-Band Accompaniment Arrangement via Sequential Style Transfer and Multi-Track Function Prior	Jingwei Zhao,Gus Xia,Ye Wang	We propose AccoMontage-3, a symbolic music automation system capable of generating multi-track, full-band accompaniment based on the input of a lead melody with chords (i.e., a lead sheet). The system contains three modular components, each modelling a vital aspect of full-band composition. The first component is a piano arranger that generates piano accompaniment for the lead sheet by transferring texture styles to the chords using latent chord-texture disentanglement and heuristic retrieval of texture donors. The second component orchestrates the piano accompaniment score into full-band arrangement according to the orchestration style encoded by individual track functions. The third component, which connects the previous two, is a prior model characterizing the global structure of orchestration style over the whole piece of music. From end to end, the system learns to generate full-band accompaniment in a self-supervised fashion, applying style transfer at two levels of polyphonic composition: texture and orchestration. Experiments show that our system outperforms the baselines significantly, and the modular design offers effective controls in a musically meaningful way.	cs.SD	None
5	Scalable Optimal Power Management for Large-Scale Battery Energy Storage Systems	Amir Farakhor,Di Wu,Yebin Wang,Huazhen Fang	Large-scale battery energy storage systems (BESS) are helping transition the world towards sustainability with their broad use, among others, in electrified transportation, power grid, and renewables. However, optimal power management for them is often computationally formidable. To overcome this challenge, we develop a scalable approach in the paper. The proposed approach partitions the constituting cells of a large-scale BESS into clusters based on their state-of-charge (SoC), temperature, and internal resistance. Each cluster is characterized by a representative model that approximately captures its collective SoC and temperature dynamics, as well as its overall power losses in charging/discharging. Based on the clusters, we then formulate a problem of receding-horizon optimal power control to minimize the power losses while promoting SoC and temperature balancing. The cluster-based power optimization will decide the power quota for each cluster, and then every cluster will split the quota among the constituent cells. Since the number of clusters is much fewer than the number of cells, the proposed approach significantly reduces the computational costs, allowing optimal power management to scale up to large-scale BESS. Extensive simulations are performed to evaluate the proposed approach. The obtained results highlight a significant computational overhead reduction by more than 60% for a small-scale and 98% for a large-scale BESS compared to the conventional cell-level optimization. Experimental validation based on a 20-cell prototype further demonstrates its effectiveness and utility.	eess.SY	IEEE Transactions on Transportation Electrification
6	Corrupting Neuron Explanations of Deep Visual Features	Divyansh Srivastava,Tuomas Oikarinen,Tsui-Wei Weng	The inability of DNNs to explain their black-box behavior has led to a recent surge of explainability methods. However, there are growing concerns that these explainability methods are not robust and trustworthy. In this work, we perform the first robustness analysis of Neuron Explanation Methods under a unified pipeline and show that these explanations can be significantly corrupted by random noises and well-designed perturbations added to their probing data. We find that even adding small random noise with a standard deviation of 0.02 can already change the assigned concepts of up to 28% neurons in the deeper layers. Furthermore, we devise a novel corruption algorithm and show that our algorithm can manipulate the explanation of more than 80% neurons by poisoning less than 10% of probing data. This raises the concern of trusting Neuron Explanation Methods in real-life safety and fairness critical applications.	cs.LG	None
7	CoheSentia: A Novel Benchmark of Incremental versus Holistic Assessment of Coherence in Generated Texts	Aviya Maimon,Reut Tsarfaty	Coherence is a linguistic term that refers to the relations between small textual units (sentences, propositions), which make the text logically consistent and meaningful to the reader. With the advances of generative foundational models in NLP, there is a pressing need to automatically assess the human-perceived coherence of automatically generated texts. Up until now, little work has been done on explicitly assessing the coherence of generated texts and analyzing the factors contributing to (in)coherence. Previous work on the topic used other tasks, e.g., sentence reordering, as proxies of coherence, rather than approaching coherence detection heads on. In this paper, we introduce {\sc CoheSentia}, a novel benchmark of human-perceived coherence of automatically generated texts. Our annotation protocol reflects two perspectives; one is global, assigning a single coherence score, and the other is incremental, scoring sentence by sentence. The incremental method produces an (in)coherence score for each text fragment and also pinpoints reasons for incoherence at that point. Our benchmark contains 500 automatically-generated and human-annotated paragraphs, each annotated in both methods, by multiple raters. Our analysis shows that the inter-annotator agreement in the incremental mode is higher than in the holistic alternative, and our experiments show that standard LMs fine-tuned for coherence detection show varied performance on the different factors contributing to (in)coherence. All in all, these models yield unsatisfactory performance, emphasizing the need for developing more reliable methods for coherence assessment.	cs.CL	None
8	The effects of Thomson scattering and chemical mixing on early-time light curves of double peaked type IIb supernovae	Seong Hyun Park,Sung-Chul Yoon,Sergei Blinnikov	Previous numerical simulations of double-peaked SNe IIb light curves have demonstrated that the radius and mass of the hydrogen-rich envelope of the progenitor star can significantly influence the brightness and timescale of the early-time light curve around the first peak. In this study, we investigate how Thomson scattering and chemical mixing in the SN ejecta affect the optical light curves during the early stages of the SNe IIb using radiation hydrodynamics simulations. By comparing the results from two different numerical codes (i.e., \stella{} and \snec{}), we find that the optical brightness of the first peak can be reduced by more than a factor of 3 due to the effect of Thomson scattering that causes the thermalization depth to be located below the Rosseland-mean photosphere, compared to the corresponding case where this effect is ignored. We also observe a short-lived plateau-like feature lasting for a few days in the early-time optical light curves of our models, in contrast to typical observed SNe IIb that show a quasi-linear decrease in optical magnitudes after the first peak. A significant degree of chemical mixing between the hydrogen-rich envelope and the helium core in SN ejecta is required to reconcile this discrepancy between the model prediction and observation. Meanwhile, to properly reproduce the first peak, a significant mixing of \nifs{} into the hydrogen-rich outermost layers should be restricted. Our findings indicate that inferring the SN IIb progenitor structure from a simplified approach that ignores these two factors may introduce substantial uncertainty.	astro-ph.HE	28 pages, 21 figures, accepted for ApJ
9	Reinforcement Learning for SBM Graphon Games with Re-Sampling	Peihan Huo,Oscar Peralta,Junyu Guo,Qiaomin Xie,Andreea Minca	The Mean-Field approximation is a tractable approach for studying large population dynamics. However, its assumption on homogeneity and universal connections among all agents limits its applicability in many real-world scenarios. Multi-Population Mean-Field Game (MP-MFG) models have been introduced in the literature to address these limitations. When the underlying Stochastic Block Model is known, we show that a Policy Mirror Ascent algorithm finds the MP-MFG Nash Equilibrium. In more realistic scenarios where the block model is unknown, we propose a re-sampling scheme from a graphon integrated with the finite N-player MP-MFG model. We develop a novel learning framework based on a Graphon Game with Re-Sampling (GGR-S) model, which captures the complex network structures of agents' connections. We analyze GGR-S dynamics and establish the convergence to dynamics of MP-MFG. Leveraging this result, we propose an efficient sample-based N-player Reinforcement Learning algorithm for GGR-S without population manipulation, and provide a rigorous convergence analysis with finite sample guarantee.	cs.GT	None
0	Electron EDM and LFV decays in the light of Muon $(g-2)_Œº$ with U(2) flavor symmetry	Morimitsu Tanimoto,Kei Yamamoto	We study the interplay of New Physics (NP) among the lepton magnetic moment, the lepton flavor violation (LFV) and the electron electric dipole moment (EDM) in the light of recent data of the muon $(g-2)_\mu$. The NP is discussed in the leptonic dipole operator with the $U(2)$ flavor symmetry of the charged leptons, where possible CP violating phases of the three family space are taken into account. It is remarked that the third-family contributes significantly to the LFV decay, $\mu \to e\gamma$, and the electron EDM. The experimental upper-bound of the $\mu \to e\gamma$ decay gives a severe constraint for parameters of the flavor model. The predicted electron EDM is rather large due to CP violating phases in the three family space. In addition, we also study $(g-2)_{e,\tau}$ of the electron and tauon, and EDMs of the muon and tauon as well as the $\tau \to e \gamma$ and $\tau \to \mu \gamma$ decays. The $\tau_R \to \mu_L \gamma$ decay is predicted close to the experimental upper-bound. The $\tau_R \to e_L \gamma$ decay is not suppressed.	hep-ph	25 pages, 14 figures
1	Extracting Design Knowledge from Optimization Data: Enhancing Engineering Design in Fluid Based Thermal Management Systems	Saeid Bayat,Nastaran Shahmansouri,Satya RT Peddada,Alex Tessier,Adrian Butscher,James T Allison	As mechanical systems become more complex and technological advances accelerate, the traditional reliance on heritage designs for engineering endeavors is being diminished in its effectiveness. Considering the dynamic nature of the design industry where new challenges are continually emerging, alternative sources of knowledge need to be sought to guide future design efforts. One promising avenue lies in the analysis of design optimization data, which has the potential to offer valuable insights and overcome the limitations of heritage designs. This paper presents a step toward extracting knowledge from optimization data in multi-split fluid-based thermal management systems using different classification machine learning methods, so that designers can use it to guide decisions in future design efforts. This approach offers several advantages over traditional design heritage methods, including applicability in cases where there is no design heritage and the ability to derive optimal designs. We showcase our framework through four case studies with varying levels of complexity. These studies demonstrate its effectiveness in enhancing the design of complex thermal management systems. Our results show that the knowledge extracted from the configuration design optimization data provides a good basis for more general design of complex thermal management systems. It is shown that the objective value of the estimated optimal configuration closely approximates the true optimal configuration with less than 1 percent error, achieved using basic features based on the system heat loads without involving the corresponding optimal open loop control (OLOC) features. This eliminates the need to solve the OLOC problem, leading to reduced computation costs.	eess.SY	13 pages, 20 figures
2	Samsung R&D Institute Philippines at WMT 2023	Jan Christian Blaise Cruz	In this paper, we describe the constrained MT systems submitted by Samsung R&D Institute Philippines to the WMT 2023 General Translation Task for two directions: en$\rightarrow$he and he$\rightarrow$en. Our systems comprise of Transformer-based sequence-to-sequence models that are trained with a mix of best practices: comprehensive data preprocessing pipelines, synthetic backtranslated data, and the use of noisy channel reranking during online decoding. Our models perform comparably to, and sometimes outperform, strong baseline unconstrained systems such as mBART50 M2M and NLLB 200 MoE despite having significantly fewer parameters on two public benchmarks: FLORES-200 and NTREX-128.	cs.CL	To appear in Proceedings of the Eighth Conference on Machine   Translation 2023 (WMT)
3	Neuromorphic cameras for Atmospheric Cherenkov Telescopes and fast optical astronomy: new paradigm, challenges and opportunities	John Hoang	The astronomy community has witnessed an explosive growth in the use of deep-learning techniques based on neural networks since the mid-2010s. The widespread adoption of these nature-inspired technologies has helped astronomers tackle previously insurmountable problems and provided an unprecedented opportunity for new discoveries. However, one of the primary tools of today's optical astronomy is neither natural nor efficient: their photo-sensing devices. Specifically, the modern CCD camera - like that of the cutting-edge Rubin Observatory - requires an internal clock to regularly expose the sensor to light, consumes a large amount of energy and information bandwidth, and has a limited dynamic range. On the contrary, biological eyes lack an internal clock and a shutter, have much higher pixel density but consume significantly less energy and bandwidth, and can adapt to bright and low light conditions. Inspired by the nature of the eyes, M. Mahowald and C. Mead introduced the revolutionary concept of a silicon retina sensor in 1991. Also known as event-based cameras (EBCs), these types of devices operate in a vastly different way compared to conventional CCD-based imaging sensors. EBCs mimic the operating principles of optic nerves and continuously produce a stream of events, with each event generated only when a pixel detects a change in light intensity. EBCs do not have fixed exposure times, have high dynamic range, require low power for operation, and can capture high-speed phenomena. These properties are important requirements for Cherenkov telescopes as well as other high-speed optical astronomy. This work presents the opportunities and challenges of using EBCs in those cases, and proposes a low-cost approach to experimentally assess the feasibility of this innovative technique.	astro-ph.IM	None
4	Enhancing Low-Precision Sampling via Stochastic Gradient Hamiltonian Monte Carlo	Ziyi Wang,Yujie Chen,Qifan Song,Ruqi Zhang	Low-precision training has emerged as a promising low-cost technique to enhance the training efficiency of deep neural networks without sacrificing much accuracy. Its Bayesian counterpart can further provide uncertainty quantification and improved generalization accuracy. This paper investigates low-precision sampling via Stochastic Gradient Hamiltonian Monte Carlo (SGHMC) with low-precision and full-precision gradient accumulators for both strongly log-concave and non-log-concave distributions. Theoretically, our results show that, to achieve $\epsilon$-error in the 2-Wasserstein distance for non-log-concave distributions, low-precision SGHMC achieves quadratic improvement ($\widetilde{\mathbf{O}}\left({\epsilon^{-2}{\mu^*}^{-2}\log^2\left({\epsilon^{-1}}\right)}\right)$) compared to the state-of-the-art low-precision sampler, Stochastic Gradient Langevin Dynamics (SGLD) ($\widetilde{\mathbf{O}}\left({{\epsilon}^{-4}{\lambda^{*}}^{-1}\log^5\left({\epsilon^{-1}}\right)}\right)$). Moreover, we prove that low-precision SGHMC is more robust to the quantization error compared to low-precision SGLD due to the robustness of the momentum-based update w.r.t. gradient noise. Empirically, we conduct experiments on synthetic data, and {MNIST, CIFAR-10 \& CIFAR-100} datasets, which validate our theoretical findings. Our study highlights the potential of low-precision SGHMC as an efficient and accurate sampling method for large-scale and resource-limited machine learning.	stat.ML	None
5	Sum-of-Parts Models: Faithful Attributions for Groups of Features	Weiqiu You,Helen Qu,Marco Gatti,Bhuvnesh Jain,Eric Wong	"An explanation of a machine learning model is considered ""faithful"" if it accurately reflects the model's decision-making process. However, explanations such as feature attributions for deep learning are not guaranteed to be faithful, and can produce potentially misleading interpretations. In this work, we develop Sum-of-Parts (SOP), a class of models whose predictions come with grouped feature attributions that are faithful-by-construction. This model decomposes a prediction into an interpretable sum of scores, each of which is directly attributable to a sparse group of features. We evaluate SOP on benchmarks with standard interpretability metrics, and in a case study, we use the faithful explanations from SOP to help astrophysicists discover new knowledge about galaxy formation."	cs.LG	None
6	Understanding Code Semantics: An Evaluation of Transformer Models in Summarization	Debanjan Mondal,Abhilasha Lodha,Ankita Sahoo,Beena Kumari	This paper delves into the intricacies of code summarization using advanced transformer-based language models. Through empirical studies, we evaluate the efficacy of code summarization by altering function and variable names to explore whether models truly understand code semantics or merely rely on textual cues. We have also introduced adversaries like dead code and commented code across three programming languages (Python, Javascript, and Java) to further scrutinize the model's understanding. Ultimately, our research aims to offer valuable insights into the inner workings of transformer-based LMs, enhancing their ability to understand code and contributing to more efficient software development practices and maintenance workflows.	cs.LG	All authors are co-first authors and have equal contributions
7	Score Matching-based Pseudolikelihood Estimation of Neural Marked Spatio-Temporal Point Process with Uncertainty Quantification	Zichong Li,Qunzhi Xu,Zhenghao Xu,Yajun Mei,Tuo Zhao,Hongyuan Zha	Spatio-temporal point processes (STPPs) are potent mathematical tools for modeling and predicting events with both temporal and spatial features. Despite their versatility, most existing methods for learning STPPs either assume a restricted form of the spatio-temporal distribution, or suffer from inaccurate approximations of the intractable integral in the likelihood training objective. These issues typically arise from the normalization term of the probability density function. Moreover, current techniques fail to provide uncertainty quantification for model predictions, such as confidence intervals for the predicted event's arrival time and confidence regions for the event's location, which is crucial given the considerable randomness of the data. To tackle these challenges, we introduce SMASH: a Score MAtching-based pSeudolikeliHood estimator for learning marked STPPs with uncertainty quantification. Specifically, our framework adopts a normalization-free objective by estimating the pseudolikelihood of marked STPPs through score-matching and offers uncertainty quantification for the predicted event time, location and mark by computing confidence regions over the generated samples. The superior performance of our proposed framework is demonstrated through extensive experiments in both event prediction and uncertainty quantification.	cs.LG	None
8	Constant Curvature 3-branes in 5-D f(R) Bulk	Shafaq Gulzar Elahi,Soumya Samrat Mandal,Soumitra SenGupta	Braneworld models remain the most promising candidates to address several important questions in low-energy particle phenomenology and cosmology. The role of the moduli field(s) and its stabilization is an integral part of this question. In this work, we show that a 5-dimensional warped braneworld model with higher curvature gravity in bulk admits de-Sitter and anti de-Sitter solutions on the branes. The remarkable feature of having a positive vacuum energy on the visible brane is the presence of a metastable minimum and a global minimum for the modulus potential. While the metastable minimum leads to a consistent cosmological model of a bouncing universe, the concomitant existence of the global minimum provides a vacuum for the modulus to roll down to stability. Further, this model is shown to be consistent with the swampland conjecture to qualify as a viable candidate in the low energy description of string landscape	hep-th	7 Pages, 4 Figures
9	Diffusion model approach to simulating electron-proton scattering events	Peter Devlin,Jian-Wei Qiu,Felix Ringer,Nobuo Sato	Generative AI is a fast-growing area of research offering various avenues for exploration in high-energy nuclear physics. In this work, we explore the use of generative models for simulating electron-proton collisions relevant to experiments like CEBAF and the future Electron-Ion Collider (EIC). These experiments play a critical role in advancing our understanding of nucleons and nuclei in terms of quark and gluon degrees of freedom. The use of generative models for simulating collider events faces several challenges such as the sparsity of the data, the presence of global or event-wide constraints, and steeply falling particle distributions. In this work, we focus on the implementation of diffusion models for the simulation of electron-proton scattering events at EIC energies. Our results demonstrate that diffusion models can accurately reproduce relevant observables such as momentum distributions and correlations of particles, momentum sum rules, and the leading electron kinematics, all of which are of particular interest in electron-proton collisions. Although the sampling process is relatively slow compared to other machine learning architectures, we find diffusion models can generate high-quality samples. We foresee various applications of our work including inference for nuclear structure, interpretable generative machine learning, and searches of physics beyond the Standard Model.	hep-ph	14 pages, 10 figures
0	The physical origin of the periodic activity for FRB 20180916B	Hao-Tian Lan,Zhen-Yin Zhao,Yu-Jia Wei,F. Y. Wang	Fast radio bursts (FRBs) are transient radio signals with millisecond-duration, large dispersion measure (DM) and extremely high brightness temperature. Among them, FRB 20180916B has been found to have a 16-day periodic activity. However, the physical origin of the periodicity is still a mystery. Here, we utilize the comprehensive observational data to diagnose the periodic models. We find that the ultra-long rotation model is the most probable one for the periodic activity. However, this model cannot reproduce the observed rotation measure (RM) variations. We propose a self-consistent model, i.e., a massive binary containing a slowly rotational neutron star and a massive star with large mass loss, which can naturally accommodate the wealth of observational features for FRB 20180916B. In this model, the RM variation is periodic, which can be tested by future observations.	astro-ph.HE	12 pages, 8 figures
1	Generation of $Œ≥$ photons with extremely large orbital angular momenta	Ren-Tong Guo,Mamutjan Ababekri,Qian Zhao,Yousef I. Salamin,Liang-Liang Ji,Zhi-Gang Bu,Zhong-Feng Xu,Xiu-Feng Weng,Jian-Xing Li	Vortex $\gamma$ photons, which carry large intrinsic orbital angular momenta (OAM), have significant applications in nuclear, atomic, hadron, particle and astro-physics, but their production remains unclear. In this work, we investigate the generation of such photons from nonlinear Compton scattering of circularly polarized monochromatic lasers on vortex electrons. We develop a quantum radiation theory for ultrarelativistic vortex electrons in lasers by using the harmonics expansion and spin eigenfunctions, which allows us to explore the kinematical characteristics, angular momentum transfer mechanisms, and formation conditions of vortex $\gamma$ photons. The multiphoton absorption of electrons enables the vortex $\gamma$ photons, with fixed polarizations and energies, to exist in mixed states comprised of multiple harmonics. Each harmonic represents a vortex eigenmode and has transverse momentum broadening due to transverse momenta of the vortex electrons. The large topological charges associated with vortex electrons offer the possibility for $\gamma$ photons to carry adjustable OAM quantum numbers from tens to thousands of units, even at moderate laser intensities. $\gamma$ photons with large OAM and transverse coherence length can assist in influencing quantum selection rules and extracting phase of the scattering amplitude in scattering processes.	hep-ph	7 pages, 4 figures
2	Dolfin: Diffusion Layout Transformers without Autoencoder	Yilin Wang,Zeyuan Chen,Liangjun Zhong,Zheng Ding,Zhizhou Sha,Zhuowen Tu	In this paper, we introduce a novel generative model, Diffusion Layout Transformers without Autoencoder (Dolfin), which significantly improves the modeling capability with reduced complexity compared to existing methods. Dolfin employs a Transformer-based diffusion process to model layout generation. In addition to an efficient bi-directional (non-causal joint) sequence representation, we further propose an autoregressive diffusion model (Dolfin-AR) that is especially adept at capturing rich semantic correlations for the neighboring objects, such as alignment, size, and overlap. When evaluated against standard generative layout benchmarks, Dolfin notably improves performance across various metrics (fid, alignment, overlap, MaxIoU and DocSim scores), enhancing transparency and interoperability in the process. Moreover, Dolfin's applications extend beyond layout generation, making it suitable for modeling geometric structures, such as line segments. Our experiments present both qualitative and quantitative results to demonstrate the advantages of Dolfin.	cs.CV	None
3	Deep Learning Approach to Photometric Redshift Estimation	Krishna Chunduri,Mithun Mahesh	Photometric redshift estimation, an essential process in astronomy for distance estimation, obtains the redshift of celestial structures by utilizing the magnitude of objects in varying wavelength filters. This research capitalized on a dataset of 50,000 objects from the Sloan Digital Sky Survey, comprising 5 bands of magnitudes and their corresponding redshift labels. Typically, studies use spectral distribution templates (SED) for redshift prediction. However, these templates are expensive and hard to obtain, especially with larger datasets. The paper explores approaches for Data-Driven methodology instead of template based prediction. Adopting both a decision tree regression model and a Fully Connected Neural Network (FCN) for analysis, the FCN significantly outperformed the decision tree regressor, achieving an impressive root mean square error (RMSE) of 0.009 compared to the decision tree's RMSE above 0.16. The strong performance of the FCN highlights its ability to capture intricate relationships in astronomical data, holding the potential for data-driven redshift estimation, which will help advance next generation surveys.	astro-ph.IM	None
4	URL-BERT: Training Webpage Representations via Social Media Engagements	Ayesha Qamar,Chetan Verma,Ahmed El-Kishky,Sumit Binnani,Sneha Mehta,Taylor Berg-Kirkpatrick	Understanding and representing webpages is crucial to online social networks where users may share and engage with URLs. Common language model (LM) encoders such as BERT can be used to understand and represent the textual content of webpages. However, these representations may not model thematic information of web domains and URLs or accurately capture their appeal to social media users. In this work, we introduce a new pre-training objective that can be used to adapt LMs to understand URLs and webpages. Our proposed framework consists of two steps: (1) scalable graph embeddings to learn shallow representations of URLs based on user engagement on social media and (2) a contrastive objective that aligns LM representations with the aforementioned graph-based representation. We apply our framework to the multilingual version of BERT to obtain the model URL-BERT. We experimentally demonstrate that our continued pre-training approach improves webpage understanding on a variety of tasks and Twitter internal and external benchmarks.	cs.CL	None
5	Imperfect Digital Twin Assisted Low Cost Reinforcement Training for Multi-UAV Networks	Xiucheng Wang,Nan Cheng,Longfei Ma,Zhisheng Yin,Tom. Luan,Ning Lu	Deep Reinforcement Learning (DRL) is widely used to optimize the performance of multi-UAV networks. However, the training of DRL relies on the frequent interactions between the UAVs and the environment, which consumes lots of energy due to the flying and communication of UAVs in practical experiments. Inspired by the growing digital twin (DT) technology, which can simulate the performance of algorithms in the digital space constructed by coping features of the physical space, the DT is introduced to reduce the costs of practical training, e.g., energy and hardware purchases. Different from previous DT-assisted works with an assumption of perfect reflecting real physics by virtual digital, we consider an imperfect DT model with deviations for assisting the training of multi-UAV networks. Remarkably, to trade off the training cost, DT construction cost, and the impact of deviations of DT on training, the natural and virtually generated UAV mixing deployment method is proposed. Two cascade neural networks (NN) are used to optimize the joint number of virtually generated UAVs, the DT construction cost, and the performance of multi-UAV networks. These two NNs are trained by unsupervised and reinforcement learning, both low-cost label-free training methods. Simulation results show the training cost can significantly decrease while guaranteeing the training performance. This implies that an efficient decision can be made with imperfect DTs in multi-UAV networks.	cs.LG	None
6	Is ChatGPT a Good Multi-Party Conversation Solver?	Chao-Hong Tan,Jia-Chen Gu,Zhen-Hua Ling	Large Language Models (LLMs) have emerged as influential instruments within the realm of natural language processing; nevertheless, their capacity to handle multi-party conversations (MPCs) -- a scenario marked by the presence of multiple interlocutors involved in intricate information exchanges -- remains uncharted. In this paper, we delve into the potential of generative LLMs such as ChatGPT and GPT-4 within the context of MPCs. An empirical analysis is conducted to assess the zero-shot learning capabilities of ChatGPT and GPT-4 by subjecting them to evaluation across three MPC datasets that encompass five representative tasks. The findings reveal that ChatGPT's performance on a number of evaluated MPC tasks leaves much to be desired, whilst GPT-4's results portend a promising future. Additionally, we endeavor to bolster performance through the incorporation of MPC structures, encompassing both speaker and addressee architecture. This study provides an exhaustive evaluation and analysis of applying generative LLMs to MPCs, casting a light upon the conception and creation of increasingly effective and robust MPC agents. Concurrently, this work underscores the challenges implicit in the utilization of LLMs for MPCs, such as deciphering graphical information flows and generating stylistically consistent responses.	cs.CL	Accepted by Findings of EMNLP 2023
7	FoundLoc: Vision-based Onboard Aerial Localization in the Wild	Yao He,Ivan Cisneros,Nikhil Keetha,Jay Patrikar,Zelin Ye,Ian Higgins,Yaoyu Hu,Parv Kapoor,Sebastian Scherer	Robust and accurate localization for Unmanned Aerial Vehicles (UAVs) is an essential capability to achieve autonomous, long-range flights. Current methods either rely heavily on GNSS, face limitations in visual-based localization due to appearance variances and stylistic dissimilarities between camera and reference imagery, or operate under the assumption of a known initial pose. In this paper, we developed a GNSS-denied localization approach for UAVs that harnesses both Visual-Inertial Odometry (VIO) and Visual Place Recognition (VPR) using a foundation model. This paper presents a novel vision-based pipeline that works exclusively with a nadir-facing camera, an Inertial Measurement Unit (IMU), and pre-existing satellite imagery for robust, accurate localization in varied environments and conditions. Our system demonstrated average localization accuracy within a $20$-meter range, with a minimum error below $1$ meter, under real-world conditions marked by drastic changes in environmental appearance and with no assumption of the vehicle's initial pose. The method is proven to be effective and robust, addressing the crucial need for reliable UAV localization in GNSS-denied environments, while also being computationally efficient enough to be deployed on resource-constrained platforms.	cs.RO	None
8	Ghost-free Higher Derivative Gravity on Branes and Various Constraints	Rong-Xin Miao	Inspired by DGP gravity, this paper investigates the higher derivative gravity localized on the brane. Generally, the higher derivative gravity in bulk is renormalizable but suffers the ghost problem. Remarkably, we find the brane-localized higher derivative gravity can be ghost-free for suitable parameters, at least at the level of squared action. Physically, that is because the boundary theory is not independent but the induced gravity on the brane. It is coupled with bulk gravity, and bulk Einstein equations and boundary conditions rule out the potential ghost.   Furthermore, we discuss various constraints on parameters of brane-localized gravity in AdS/BCFT and wedge holography, respectively. They include the tachyon-free and ghost-free conditions of Kaluza-Klein and brane bending modes, the positive definiteness of boundary central charges and entanglement entropy. The tachyon-free condition imposes the most substantial restrictions for DGP gravity and brane-localized Gauss-Bonnet gravity. As for the brane-localized higher derivative gravity such as $R_{ij} R^{ij}$, the ghost-free condition imposes additional constraints. The other constraints are weaker than the tachyon-free and ghost-free conditions. Finally, we briefly discuss the applications of our results.	hep-th	47 pages, 16 figures
9	Instance-wise Linearization of Neural Network for Model Interpretation	Zhimin Li,Shusen Liu,Kailkhura Bhavya,Timo Bremer,Valerio Pascucci	Neural network have achieved remarkable successes in many scientific fields. However, the interpretability of the neural network model is still a major bottlenecks to deploy such technique into our daily life. The challenge can dive into the non-linear behavior of the neural network, which rises a critical question that how a model use input feature to make a decision. The classical approach to address this challenge is feature attribution, which assigns an important score to each input feature and reveal its importance of current prediction. However, current feature attribution approaches often indicate the importance of each input feature without detail of how they are actually processed by a model internally. These attribution approaches often raise a concern that whether they highlight correct features for a model prediction.   For a neural network model, the non-linear behavior is often caused by non-linear activation units of a model. However, the computation behavior of a prediction from a neural network model is locally linear, because one prediction has only one activation pattern. Base on the observation, we propose an instance-wise linearization approach to reformulates the forward computation process of a neural network prediction. This approach reformulates different layers of convolution neural networks into linear matrix multiplication. Aggregating all layers' computation, a prediction complex convolution neural network operations can be described as a linear matrix multiplication $F(x) = W \cdot x + b$. This equation can not only provides a feature attribution map that highlights the important of the input features but also tells how each input feature contributes to a prediction exactly. Furthermore, we discuss the application of this technique in both supervise classification and unsupervised neural network learning parametric t-SNE dimension reduction.	cs.LG	None
0	Producer-Side Experiments Based on Counterfactual Interleaving Designs for Online Recommender Systems	Yan Wang,Shan Ba	Recommender systems have become an integral part of online platforms, providing personalized suggestions for purchasing items, consuming contents, and connecting with individuals. An online recommender system consists of two sides of components: the producer side comprises product sellers, content creators, or service providers, etc., and the consumer side includes buyers, viewers, or guests, etc. To optimize an online recommender system, A/B tests serve as the golden standard for comparing different ranking models and evaluating their impact on both the consumers and producers. While consumer-side experiments are relatively straightforward to design and commonly used to gauge the impact of ranking changes on the behavior of consumers (buyers, viewers, etc.), designing producer-side experiments presents a considerable challenge because producer items in the treatment and control groups need to be ranked by different models and then merged into a single ranking for the recommender to show to each consumer. In this paper, we review issues with the existing methods, propose new design principles for producer-side experiments, and develop a rigorous solution based on counterfactual interleaving designs for accurately measuring the effects of ranking changes on the producers (sellers, creators, etc.).	stat.ME	None
1	Dyson-Schwinger equations towards cold-dense QCD matter with improved truncations	Zhan Bai,Yu-Xin Liu	We take the Dyson-Schwinger equation (DSE) approach of QCD to study the phase transition and the equation of state of cold dense matter. Besides the bare vertex and Gauss gluon model, we take into account an improved truncation scheme, the CLRQ vertex and infrared-constant gluon model. For the dynamical chiral symmetry breaking solution of the DSE, we require that the emergence of quark number density to be at the chemical potential for the nuclear liquid-gas phase transition to take place, by incorporating a chemical potential dependent modification factor to the gluon model. The result shows that our modified scheme can not only describe the phase transition of the cold dense matter well but also the deduced equation of state of the matter can describe the recent astronomical observations consistently.	hep-ph	arXiv admin note: text overlap with arXiv:2105.03947
2	Fair Adaptive Experiments	Waverly Wei,Xinwei Ma,Jingshen Wang	Randomized experiments have been the gold standard for assessing the effectiveness of a treatment or policy. The classical complete randomization approach assigns treatments based on a prespecified probability and may lead to inefficient use of data. Adaptive experiments improve upon complete randomization by sequentially learning and updating treatment assignment probabilities. However, their application can also raise fairness and equity concerns, as assignment probabilities may vary drastically across groups of participants. Furthermore, when treatment is expected to be extremely beneficial to certain groups of participants, it is more appropriate to expose many of these participants to favorable treatment. In response to these challenges, we propose a fair adaptive experiment strategy that simultaneously enhances data use efficiency, achieves an envy-free treatment assignment guarantee, and improves the overall welfare of participants. An important feature of our proposed strategy is that we do not impose parametric modeling assumptions on the outcome variables, making it more versatile and applicable to a wider array of applications. Through our theoretical investigation, we characterize the convergence rate of the estimated treatment effects and the associated standard deviations at the group level and further prove that our adaptive treatment assignment algorithm, despite not having a closed-form expression, approaches the optimal allocation rule asymptotically. Our proof strategy takes into account the fact that the allocation decisions in our design depend on sequentially accumulated data, which poses a significant challenge in characterizing the properties and conducting statistical inference of our method. We further provide simulation evidence to showcase the performance of our fair adaptive experiment strategy.	stat.ME	None
3	Semiclassical gravity beyond coherent states	Shahnewaz Ahmed,Caroline Lima,Eduardo Mart√≠n-Mart√≠nez	We show that it is possible to still use semiclassical gravity together with quantum field theory beyond the regimes where the field state is coherent. In particular, we identify families of cat states (superposition of almost-distinguishable coherent states that have very non-classical features) for which the gravitational backreaction can be modeled by semiclassical gravity.	quant-ph	9 pages, 1 Appendix. RevTeX 4.2
4	MotionAGFormer: Enhancing 3D Human Pose Estimation with a Transformer-GCNFormer Network	Soroush Mehraban,Vida Adeli,Babak Taati	Recent transformer-based approaches have demonstrated excellent performance in 3D human pose estimation. However, they have a holistic view and by encoding global relationships between all the joints, they do not capture the local dependencies precisely. In this paper, we present a novel Attention-GCNFormer (AGFormer) block that divides the number of channels by using two parallel transformer and GCNFormer streams. Our proposed GCNFormer module exploits the local relationship between adjacent joints, outputting a new representation that is complementary to the transformer output. By fusing these two representation in an adaptive way, AGFormer exhibits the ability to better learn the underlying 3D structure. By stacking multiple AGFormer blocks, we propose MotionAGFormer in four different variants, which can be chosen based on the speed-accuracy trade-off. We evaluate our model on two popular benchmark datasets: Human3.6M and MPI-INF-3DHP. MotionAGFormer-B achieves state-of-the-art results, with P1 errors of 38.4mm and 16.2mm, respectively. Remarkably, it uses a quarter of the parameters and is three times more computationally efficient than the previous leading model on Human3.6M dataset. Code and models are available at https://github.com/TaatiTeam/MotionAGFormer.	cs.CV	None
5	Towards Streaming Speech-to-Avatar Synthesis	Tejas S. Prabhune,Peter Wu,Bohan Yu,Gopala K. Anumanchipalli	Streaming speech-to-avatar synthesis creates real-time animations for a virtual character from audio data. Accurate avatar representations of speech are important for the visualization of sound in linguistics, phonetics, and phonology, visual feedback to assist second language acquisition, and virtual embodiment for paralyzed patients. Previous works have highlighted the capability of deep articulatory inversion to perform high-quality avatar animation using electromagnetic articulography (EMA) features. However, these models focus on offline avatar synthesis with recordings rather than real-time audio, which is necessary for live avatar visualization or embodiment. To address this issue, we propose a method using articulatory inversion for streaming high quality facial and inner-mouth avatar animation from real-time audio. Our approach achieves 130ms average streaming latency for every 0.1 seconds of audio with a 0.792 correlation with ground truth articulations. Finally, we show generated mouth and tongue animations to demonstrate the efficacy of our methodology.	cs.SD	Submitted to ICASSP 2024
6	Homological stability for generalized Hurwitz spaces and Selmer groups in quadratic twist families over function fields	Jordan S. Ellenberg,Aaron Landesman	"We prove a version of the Bhargava-Kane-Lenstra-Poonen-Rains heuristics for Selmer groups of quadratic twist families of abelian varieties over global function fields. As a consequence, we derive a result towards the ""minimalist conjecture"" on Selmer ranks of abelian varieties in such families. More precisely, we show that the probabilities predicted in these two conjectures are correct to within an error term in the size of the constant field, $q$, which goes to $0$ as $q$ grows. Two key inputs are a new homological stability theorem for a generalized version of Hurwitz spaces parameterizing covers of punctured Riemann surfaces of arbitrary genus, and an expression of average sizes of Selmer groups in terms of the number of rational points on these Hurwitz spaces over finite fields."	math.NT	None
7	Removing Dust from CMB Observations with Diffusion Models	David Heurtel-Depeiges,Blakesley Burkhart,Ruben Ohana,Bruno R√©galdo-Saint Blancard	In cosmology, the quest for primordial $B$-modes in cosmic microwave background (CMB) observations has highlighted the critical need for a refined model of the Galactic dust foreground. We investigate diffusion-based modeling of the dust foreground and its interest for component separation. Under the assumption of a Gaussian CMB with known cosmology (or covariance matrix), we show that diffusion models can be trained on examples of dust emission maps such that their sampling process directly coincides with posterior sampling in the context of component separation. We illustrate this on simulated mixtures of dust emission and CMB. We show that common summary statistics (power spectrum, Minkowski functionals) of the components are well recovered by this process. We also introduce a model conditioned by the CMB cosmology that outperforms models trained using a single cosmology on component separation. Such a model will be used in future work for diffusion-based cosmological inference.	astro-ph.CO	"5+6 pages, 2+3 figures, submitted to ""Machine Learning and the   Physical Sciences"" NeurIPS Workshop"
8	Bayesian Image Mediation Analysis	Yuliang Xu,Jian Kang	Mediation analysis aims to separate the indirect effect through mediators from the direct effect of the exposure on the outcome. It is challenging to perform mediation analysis with neuroimaging data which involves high dimensionality, complex spatial correlations, sparse activation patterns and relatively low signal-to-noise ratio. To address these issues, we develop a new spatially varying coefficient structural equation model for Bayesian Image Mediation Analysis (BIMA). We define spatially varying mediation effects within the potential outcome framework, employing the soft-thresholded Gaussian process prior for functional parameters. We establish the posterior consistency for spatially varying mediation effects along with selection consistency on important regions that contribute to the mediation effects. We develop an efficient posterior computation algorithm scalable to analysis of large-scale imaging data. Through extensive simulations, we show that BIMA can improve the estimation accuracy and computational efficiency for high-dimensional mediation analysis over the existing methods. We apply BIMA to analyze the behavioral and fMRI data in the Adolescent Brain Cognitive Development (ABCD) study with a focus on inferring the mediation effects of the parental education level on the children's general cognitive ability that are mediated through the working memory brain activities.	stat.ME	None
9	Modeling and Analysis of the Lead-Lag Network of Economic Indicators	Amanda Goodrick,Hiroki Sayama	We propose a method of analyzing multivariate time series data that investigates lead-lag relationships among economic indicators during the COVID-19 era with a weighted directed network of lagged variables. The analysis includes a stock index, average unemployment, and several variables that are used to calculate inflation. Three complex networks are created, with these variables and several lags of each as the network nodes. Network edges are weighted based on three relationship metrics: correlation, mutual information, and transfer entropy. In each network, nodes are merged, and edges are aggregated to simplify the weighted directed graph. Pagerank is used to determine the most influential and the most influenced node over the time period. Results were reasonably robust within each network, but they were heavily dependent on the choice of metric.	cs.SI	14 pages, 7 figures, 1 table; peer reviewed and accepted for   presentation at International Conference on Data Science, Computation and   Security (IDSCS-2023)
0	Improving Robust Decisions with Data	Xiaoyu Cheng	A decision-maker (DM) faces uncertainty governed by a data-generating process (DGP), which is only known to belong to a set of sequences of independent but possibly non-identical distributions. A robust decision maximizes the DM's expected payoff against the worst possible DGP in this set. This paper studies how such robust decisions can be improved with data, where improvement is measured by expected payoff under the true DGP. In this paper, I fully characterize when and how such an improvement can be guaranteed under all possible DGPs and develop inference methods to achieve it. These inference methods are needed because, as this paper shows, common inference methods (e.g., maximum likelihood or Bayesian) often fail to deliver such an improvement. Importantly, the developed inference methods are given by simple augmentations to standard inference procedures, and are thus easy to implement in practice.	econ.TH	A substantially revised version of arXiv:2205.04573
1	XFEVER: Exploring Fact Verification across Languages	Yi-Chen Chang,Canasai Kruengkrai,Junichi Yamagishi	This paper introduces the Cross-lingual Fact Extraction and VERification (XFEVER) dataset designed for benchmarking the fact verification models across different languages. We constructed it by translating the claim and evidence texts of the Fact Extraction and VERification (FEVER) dataset into six languages. The training and development sets were translated using machine translation, whereas the test set includes texts translated by professional translators and machine-translated texts. Using the XFEVER dataset, two cross-lingual fact verification scenarios, zero-shot learning and translate-train learning, are defined, and baseline models for each scenario are also proposed in this paper. Experimental results show that the multilingual language model can be used to build fact verification models in different languages efficiently. However, the performance varies by language and is somewhat inferior to the English case. We also found that we can effectively mitigate model miscalibration by considering the prediction similarity between the English and target languages. The XFEVER dataset, code, and model checkpoints are available at https://github.com/nii-yamagishilab/xfever.	cs.CL	Accepted for an oral presentation at the 35th Conference on   Computational Linguistics and Speech Processing (ROCLING 2023)
2	Bayesian Domain Invariant Learning via Posterior Generalization of Parameter Distributions	Shiyu Shen,Bin Pan,Tianyang Shi,Tao Li,Zhenwei Shi	Domain invariant learning aims to learn models that extract invariant features over various training domains, resulting in better generalization to unseen target domains. Recently, Bayesian Neural Networks have achieved promising results in domain invariant learning, but most works concentrate on aligning features distributions rather than parameter distributions. Inspired by the principle of Bayesian Neural Network, we attempt to directly learn the domain invariant posterior distribution of network parameters. We first propose a theorem to show that the invariant posterior of parameters can be implicitly inferred by aggregating posteriors on different training domains. Our assumption is more relaxed and allows us to extract more domain invariant information. We also propose a simple yet effective method, named PosTerior Generalization (PTG), that can be used to estimate the invariant parameter distribution. PTG fully exploits variational inference to approximate parameter distributions, including the invariant posterior and the posteriors on training domains. Furthermore, we develop a lite version of PTG for widespread applications. PTG shows competitive performance on various domain generalization benchmarks on DomainBed. Additionally, PTG can use any existing domain generalization methods as its prior, and combined with previous state-of-the-art method the performance can be further improved. Code will be made public.	cs.LG	None
3	Complexity of Government response to Covid-19 pandemic: A perspective of coupled dynamics on information heterogeneity and epidemic outbreak	Xiaoqi Zhang,Jie Fu,Sheng Hua,Han Liang,Zi-Ke Zhang	This study aims at modeling the universal failure in preventing the outbreak of COVID-19 via real-world data from the perspective of complexity and network science. Through formalizing information heterogeneity and government intervention in the coupled dynamics of epidemic and infodemic spreading; first, we find that information heterogeneity and its induced variation in human responses significantly increase the complexity of the government intervention decision. The complexity results in a dilemma between the socially optimal intervention that is risky for the government and the privately optimal intervention that is safer for the government but harmful to the social welfare. Second, via counterfactual analysis against the COVID-19 crisis in Wuhan, 2020, we find that the intervention dilemma becomes even worse if the initial decision time and the decision horizon vary. In the short horizon, both socially and privately optimal interventions agree with each other and require blocking the spread of all COVID-19-related information, leading to a negligible infection ratio 30 days after the initial reporting time. However, if the time horizon is prolonged to 180 days, only the privately optimal intervention requires information blocking, which would induce a catastrophically higher infection ratio than that in the counter-factual world where the socially optimal intervention encourages early-stage information spread. These findings contribute to the literature by revealing the complexity incurred by the coupled infodemic-epidemic dynamics and information heterogeneity to the governmental intervention decision, which also sheds insight into the design of an effective early warning system against the epidemic crisis in the future.	physics.soc-ph	This version contains the full-resolution figures for the paper DOI:   10.1007/s11071-023-08427-5
4	Deep Learning for Plant Identification and Disease Classification from Leaf Images: Multi-prediction Approaches	Jianping Yao,Son N. Tran,Saurabh Garg,Samantha Sawyer	Deep learning plays an important role in modern agriculture, especially in plant pathology using leaf images where convolutional neural networks (CNN) are attracting a lot of attention. While numerous reviews have explored the applications of deep learning within this research domain, there remains a notable absence of an empirical study to offer insightful comparisons due to the employment of varied datasets in the evaluation. Furthermore, a majority of these approaches tend to address the problem as a singular prediction task, overlooking the multifaceted nature of predicting various aspects of plant species and disease types. Lastly, there is an evident need for a more profound consideration of the semantic relationships that underlie plant species and disease types. In this paper, we start our study by surveying current deep learning approaches for plant identification and disease classification. We categorise the approaches into multi-model, multi-label, multi-output, and multi-task, in which different backbone CNNs can be employed. Furthermore, based on the survey of existing approaches in plant pathology and the study of available approaches in machine learning, we propose a new model named Generalised Stacking Multi-output CNN (GSMo-CNN). To investigate the effectiveness of different backbone CNNs and learning approaches, we conduct an intensive experiment on three benchmark datasets Plant Village, Plant Leaves, and PlantDoc. The experimental results demonstrate that InceptionV3 can be a good choice for a backbone CNN as its performance is better than AlexNet, VGG16, ResNet101, EfficientNet, MobileNet, and a custom CNN developed by us. Interestingly, empirical results support the hypothesis that using a single model can be comparable or better than using two models. Finally, we show that the proposed GSMo-CNN achieves state-of-the-art performance on three benchmark datasets.	cs.CV	Jianping and Son are joint first authors (equal contribution)
5	CycleAlign: Iterative Distillation from Black-box LLM to White-box Models for Better Human Alignment	Jixiang Hong,Quan Tu,Changyu Chen,Xing Gao,Ji Zhang,Rui Yan	Language models trained on large-scale corpus often generate content that is harmful, toxic, or contrary to human preferences, making their alignment with human values a critical concern. Reinforcement learning from human feedback (RLHF) with algorithms like PPO is a prevalent approach for alignment but is often complex, unstable, and resource-intensive. Recently, ranking-based alignment methods have emerged, offering stability and effectiveness by replacing the RL framework with supervised fine-tuning, but they are costly due to the need for annotated data. Considering that existing large language models (LLMs) like ChatGPT are already relatively well-aligned and cost-friendly, researchers have begun to align the language model with human preference from AI feedback. The common practices, which unidirectionally distill the instruction-following responses from LLMs, are constrained by their bottleneck. Thus we introduce CycleAlign to distill alignment capabilities from parameter-invisible LLMs (black-box) to a parameter-visible model (white-box) in an iterative manner. With in-context learning (ICL) as the core of the cycle, the black-box models are able to rank the model-generated responses guided by human-craft instruction and demonstrations about their preferences. During iterative interaction, the white-box models also have a judgment about responses generated by them. Consequently, the agreement ranking could be viewed as a pseudo label to dynamically update the in-context demonstrations and improve the preference ranking ability of black-box models. Through multiple interactions, the CycleAlign framework could align the white-box model with the black-box model effectively in a low-resource way. Empirical results illustrate that the model fine-tuned by CycleAlign remarkably exceeds existing methods, and achieves the state-of-the-art performance in alignment with human value.	cs.CL	None
6	Attention Lens: A Tool for Mechanistically Interpreting the Attention Head Information Retrieval Mechanism	Mansi Sakarvadia,Arham Khan,Aswathy Ajith,Daniel Grzenda,Nathaniel Hudson,Andr√© Bauer,Kyle Chard,Ian Foster	Transformer-based Large Language Models (LLMs) are the state-of-the-art for natural language tasks. Recent work has attempted to decode, by reverse engineering the role of linear layers, the internal mechanisms by which LLMs arrive at their final predictions for text completion tasks. Yet little is known about the specific role of attention heads in producing the final token prediction. We propose Attention Lens, a tool that enables researchers to translate the outputs of attention heads into vocabulary tokens via learned attention-head-specific transformations called lenses. Preliminary findings from our trained lenses indicate that attention heads play highly specialized roles in language models. The code for Attention Lens is available at github.com/msakarvadia/AttentionLens.	cs.CL	None
7	Multilingual Coarse Political Stance Classification of Media. The Editorial Line of a ChatGPT and Bard Newspaper	Cristina Espa√±a-Bonet	Neutrality is difficult to achieve and, in politics, subjective. Traditional media typically adopt an editorial line that can be used by their potential readers as an indicator of the media bias. Several platforms currently rate news outlets according to their political bias. The editorial line and the ratings help readers in gathering a balanced view of news. But in the advent of instruction-following language models, tasks such as writing a newspaper article can be delegated to computers. Without imposing a biased persona, where would an AI-based news outlet lie within the bias ratings? In this work, we use the ratings of authentic news outlets to create a multilingual corpus of news with coarse stance annotations (Left and Right) along with automatically extracted topic annotations. We show that classifiers trained on this data are able to identify the editorial line of most unseen newspapers in English, German, Spanish and Catalan. We then apply the classifiers to 101 newspaper-like articles written by ChatGPT and Bard in the 4 languages at different time periods. We observe that, similarly to traditional newspapers, ChatGPT editorial line evolves with time and, being a data-driven system, the stance of the generated articles differs among languages.	cs.CL	To be published at EMNLP 2023 (Findings)
8	Differential nature of inelastic collisions facilitating runaway electron generation in weakly-ionized plasmas	Y. Lee,P. Aleynikov,P. C. de Vries,H. -T. Kim,J. Lee,M. Hoppe,J. -K. Park,G. J. Choi,Y. -S. Na	We report extention of the Dreicer generation theory to situation where the small energy exchange no more predominates. In weakly-ionized plamsas, the Dreicer mechanism can be severely underestimated due to the broken assumption of dominant small energy exchange. This Letter numerically demonstrates that the differential nature of inelastic collisions facilitates the Dreicer generation by developing the new Fokker-Planck-Boltzmann operator of electron-hydrogen atom collisions based on experimental data. This work is envisaged to predict runaway electron generations in future fusion reactors.	physics.plasm-ph	None
9	SCB-ST-Dataset4: Extending the Spatio-Temporal Behavior Dataset in Student Classroom Scenarios Through Image Dataset Method	Fan Yang,Xiaofei Wang	Using deep learning methods to detect students' classroom behavior automatically is a promising approach for analyzing their class performance and improving teaching effectiveness. However, the lack of publicly available spatio-temporal datasets on student behavior, as well as the high cost of manually labeling such datasets, pose significant challenges for researchers in this field. To address this issue, we proposed a method for extending the spatio-temporal behavior dataset in Student Classroom Scenarios (SCB-ST-Dataset4) through image dataset. Our SCB-ST-Dataset4 comprises 754094 images with 25670 labels, focusing on 3 behaviors: hand-raising, reading, writing. Our proposed method can rapidly generate spatio-temporal behavioral datasets without requiring annotation. Furthermore, we proposed a Behavior Similarity Index (BSI) to explore the similarity of behaviors. We evaluated the dataset using the YOLOv5, YOLOv7, YOLOv8, and SlowFast algorithms, achieving a mean average precision (map) of up to 82.3%. The experiment further demonstrates the effectiveness of our method. This dataset provides a robust foundation for future research in student behavior detection, potentially contributing to advancements in this field. The SCB-ST-Dataset4 is available for download at: https://github.com/Whiffe/SCB-dataset.	cs.CV	arXiv admin note: substantial text overlap with arXiv:2310.02522;   text overlap with arXiv:2306.03318
0	Fully kinetic study of facility pressure effects on RF-source magnetic nozzles	Raoul Andriulli,Shaun Andrews,Nabil Souhair,Mirko Magarotto,Fabrizio Ponti	A fully kinetic 2D axisymmetric Particle-in-Cell (PIC) model is used to examine the effects of background facility pressure on the plasma transport and propulsive efficiency of magnetic nozzles. Simulations are performed for a low-power (150 W class) cathode-less radio-frequency (RF) plasma thruster, operating with xenon, between background pressures up to 10$^{-2}$ Pa and average electron discharge temperatures of 4 - 16 eV. When the electron temperature within the near-plume region reaches 8 eV, a decisive reduction in performance occurs: at 10$^{-2}$ Pa, in-plume power losses surpass 25% of the discharge energy flux. Given that the ionization energy for Xe is 12 eV, the 8 eV threshold indicates that a consistent percentage of electrons has energy enough to trigger ionization. On the other hand, when the temperature is below such threshold, the primary collisions are charge-exchange and inelastic ion scattering, and the power loss remains less than 10%. It is established that losses in the considered HPT are significant if the facility pressure is greater than 10$^{-3}$ Pa, at absorbed powers larger than 130 W. At the nominal 150 W, this results in a 15% thrust reduction. When facility pressure is taken into consideration over ideal vacuum simulations, numerical error is reduced to <30% when compared to experimental thrust measurements at 10$^{-3}$ Pa.	physics.plasm-ph	45 pages, 10 figures, 5 tables. Submitted to Acta Astronautica
1	Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation	Jiexin Wang,Liuwen Cao,Xitong Luo,Zhiping Zhou,Jiayuan Xie,Adam Jatowt,Yi Cai	Large language models (LLMs) have brought significant advancements to code generation, benefiting both novice and experienced developers. However, their training using unsanitized data from open-source repositories, like GitHub, introduces the risk of inadvertently propagating security vulnerabilities. To effectively mitigate this concern, this paper presents a comprehensive study focused on evaluating and enhancing code LLMs from a software security perspective. We introduce SecuCoGen\footnote{SecuCoGen has been uploaded as supplemental material and will be made publicly available after publication.}, a meticulously curated dataset targeting 21 critical vulnerability types. SecuCoGen comprises 180 samples and serves as the foundation for conducting experiments on three crucial code-related tasks: code generation, code repair and vulnerability classification, with a strong emphasis on security. Our experimental results reveal that existing models often overlook security concerns during code generation, leading to the generation of vulnerable code. To address this, we propose effective approaches to mitigate the security vulnerabilities and enhance the overall robustness of code generated by LLMs. Moreover, our study identifies weaknesses in existing models' ability to repair vulnerable code, even when provided with vulnerability information. Additionally, certain vulnerability types pose challenges for the models, hindering their performance in vulnerability classification. Based on these findings, we believe our study will have a positive impact on the software engineering community, inspiring the development of improved methods for training and utilizing LLMs, thereby leading to safer and more trustworthy model deployment.	cs.SE	None
2	rTisane: Externalizing conceptual models for data analysis increases engagement with domain knowledge and improves statistical model quality	Eunice Jun,Edward Misback,Jeffrey Heer,Ren√© Just	Statistical models should accurately reflect analysts' domain knowledge about variables and their relationships. While recent tools let analysts express these assumptions and use them to produce a resulting statistical model, it remains unclear what analysts want to express and how externalization impacts statistical model quality. This paper addresses these gaps. We first conduct an exploratory study of analysts using a domain-specific language (DSL) to express conceptual models. We observe a preference for detailing how variables relate and a desire to allow, and then later resolve, ambiguity in their conceptual models. We leverage these findings to develop rTisane, a DSL for expressing conceptual models augmented with an interactive disambiguation process. In a controlled evaluation, we find that rTisane's DSL helps analysts engage more deeply with and accurately externalize their assumptions. rTisane also leads to statistical models that match analysts' assumptions, maintain analysis intent, and better fit the data.	cs.HC	None
3	The Distributional Hypothesis Does Not Fully Explain the Benefits of Masked Language Model Pretraining	Ting-Rui Chiang,Dani Yogatama	We analyze the masked language modeling pretraining objective function from the perspective of the distributional hypothesis. We investigate whether better sample efficiency and the better generalization capability of models pretrained with masked language modeling can be attributed to the semantic similarity encoded in the pretraining data's distributional property. Via a synthetic dataset, our analysis suggests that distributional property indeed leads to the better sample efficiency of pretrained masked language models, but does not fully explain the generalization capability. We also conduct analyses over two real-world datasets and demonstrate that the distributional property does not explain the generalization ability of pretrained natural language models either. Our results illustrate our limited understanding of model pretraining and provide future research directions.	cs.CL	EMNLP 2023
4	Private Estimation and Inference in High-Dimensional Regression with FDR Control	Zhanrui Cai,Sai Li,Xintao Xia,Linjun Zhang	This paper presents novel methodologies for conducting practical differentially private (DP) estimation and inference in high-dimensional linear regression. We start by proposing a differentially private Bayesian Information Criterion (BIC) for selecting the unknown sparsity parameter in DP-Lasso, eliminating the need for prior knowledge of model sparsity, a requisite in the existing literature. Then we propose a differentially private debiased LASSO algorithm that enables privacy-preserving inference on regression parameters. Our proposed method enables accurate and private inference on the regression parameters by leveraging the inherent sparsity of high-dimensional linear regression models. Additionally, we address the issue of multiple testing in high-dimensional linear regression by introducing a differentially private multiple testing procedure that controls the false discovery rate (FDR). This allows for accurate and privacy-preserving identification of significant predictors in the regression model. Through extensive simulations and real data analysis, we demonstrate the efficacy of our proposed methods in conducting inference for high-dimensional linear models while safeguarding privacy and controlling the FDR.	stat.ME	None
5	The effective QCD running coupling constant and a Dirac model for the charmonium spectrum	M. De Sanctis	The QCD effective charge extracted from the experimental data is used to construct the vector interaction of a Dirac relativistic model for the charmonium spectrum. The process required to fit the spectrum is discussed and the relationship with a previous study of the vector interaction is analyzed.	hep-ph	16 pages, 2 figures
6	A Causal Disentangled Multi-Granularity Graph Classification Method	Yuan Li,Li Liu,Penggang Chen,Youmin Zhang,Guoyin Wang	Graph data widely exists in real life, with large amounts of data and complex structures. It is necessary to map graph data to low-dimensional embedding. Graph classification, a critical graph task, mainly relies on identifying the important substructures within the graph. At present, some graph classification methods do not combine the multi-granularity characteristics of graph data. This lack of granularity distinction in modeling leads to a conflation of key information and false correlations within the model. So, achieving the desired goal of a credible and interpretable model becomes challenging. This paper proposes a causal disentangled multi-granularity graph representation learning method (CDM-GNN) to solve this challenge. The CDM-GNN model disentangles the important substructures and bias parts within the graph from a multi-granularity perspective. The disentanglement of the CDM-GNN model reveals important and bias parts, forming the foundation for its classification task, specifically, model interpretations. The CDM-GNN model exhibits strong classification performance and generates explanatory outcomes aligning with human cognitive patterns. In order to verify the effectiveness of the model, this paper compares the three real-world datasets MUTAG, PTC, and IMDM-M. Six state-of-the-art models, namely GCN, GAT, Top-k, ASAPool, SUGAR, and SAT are employed for comparison purposes. Additionally, a qualitative analysis of the interpretation results is conducted.	cs.LG	None
7	UAV-Sim: NeRF-based Synthetic Data Generation for UAV-based Perception	Christopher Maxey,Jaehoon Choi,Hyungtae Lee,Dinesh Manocha,Heesung Kwon	Tremendous variations coupled with large degrees of freedom in UAV-based imaging conditions lead to a significant lack of data in adequately learning UAV-based perception models. Using various synthetic renderers in conjunction with perception models is prevalent to create synthetic data to augment the learning in the ground-based imaging domain. However, severe challenges in the austere UAV-based domain require distinctive solutions to image synthesis for data augmentation. In this work, we leverage recent advancements in neural rendering to improve static and dynamic novelview UAV-based image synthesis, especially from high altitudes, capturing salient scene attributes. Finally, we demonstrate a considerable performance boost is achieved when a state-ofthe-art detection model is optimized primarily on hybrid sets of real and synthetic data instead of the real or synthetic data separately.	cs.CV	Video Link: https://www.youtube.com/watch?v=ucPzbPLqqpI
8	Directional Differentiability of the Generalized Metric Projection in Hilbert spaces and Hilbertian Bochner spaces	Jinlu Li,Li Cheng,Lishan Liu,Linsen Xie	Let $H$ be a real Hilbert space and $C$ a nonempty closed and convex subset of $H$. Let $P_C: H\rightarrow C$ denote the (standard) metric projection operator. In this paper, we study the G\^ateaux directional differentiability of $P_C$ and investigate some of its properties. The G\^ateaux directionally derivatives of $P_C$ are precisely given for the following cases of the considered subset $C$: 1. closed and convex subsets; 2. closed balls; 3. closed and convex cones (including proper closed subspaces). For special Hilbert spaces, we consider directional differentiability of $P_C$ for some Hilbert spaces with orthonormal bases and the real Hilbert space $L^2([-\pi,\pi])$ with the trigonometric orthonormal basis.	math.FA	This article has been accepted for publication
9	ConDefects: A New Dataset to Address the Data Leakage Concern for LLM-based Fault Localization and Program Repair	Yonghao Wu,Zheng Li,Jie M. Zhang,Yong Liu	"With the growing interest on Large Language Models (LLMs) for fault localization and program repair, ensuring the integrity and generalizability of the LLM-based methods becomes paramount. The code in existing widely-adopted benchmarks for these tasks was written before the the bloom of LLMs and may be included in the training data of existing popular LLMs, thereby suffering from the threat of data leakage, leading to misleadingly optimistic performance metrics. To address this issue, we introduce ""ConDefects"", a novel dataset of real faults meticulously curated to eliminate such overlap. ConDefects contains 1,254 Java faulty programs and 1,625 Python faulty programs. All these programs are sourced from the online competition platform AtCoder and were produced between October 2021 and September 2023. We pair each fault with fault locations and the corresponding repaired code versions, making it tailored for in fault localization and program repair related research. We also provide interfaces for selecting subsets based on different time windows and coding task difficulties. While inspired by LLM-based tasks, ConDefects can be adopted for benchmarking ALL types of fault localization and program repair methods. The dataset is publicly available, and a demo video can be found at https://www.youtube.com/watch?v=22j15Hj5ONk."	cs.SE	5pages, 3 figures
0	Near-Optimal Pure Exploration in Matrix Games: A Generalization of Stochastic Bandits & Dueling Bandits	Arnab Maiti,Ross Boczar,Kevin Jamieson,Lillian J. Ratliff	We study the sample complexity of identifying the pure strategy Nash equilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally, we are given a stochastic model where any learner can sample an entry $(i,j)$ of the input matrix $A\in[-1,1]^{n\times m}$ and observe $A_{i,j}+\eta$ where $\eta$ is a zero-mean 1-sub-Gaussian noise. The aim of the learner is to identify the PSNE of $A$, whenever it exists, with high probability while taking as few samples as possible. Zhou et al. (2017) presents an instance-dependent sample complexity lower bound that depends only on the entries in the row and column in which the PSNE lies. We design a near-optimal algorithm whose sample complexity matches the lower bound, up to log factors. The problem of identifying the PSNE also generalizes the problem of pure exploration in stochastic multi-armed bandits and dueling bandits, and our result matches the optimal bounds, up to log factors, in both the settings.	cs.LG	22 pages, 5 figures
1	Speakerly: A Voice-based Writing Assistant for Text Composition	Dhruv Kumar,Vipul Raheja,Alice Kaiser-Schatzlein,Robyn Perry,Apurva Joshi,Justin Hugues-Nuger,Samuel Lou,Navid Chowdhury	We present Speakerly, a new real-time voice-based writing assistance system that helps users with text composition across various use cases such as emails, instant messages, and notes. The user can interact with the system through instructions or dictation, and the system generates a well-formatted and coherent document. We describe the system architecture and detail how we address the various challenges while building and deploying such a system at scale. More specifically, our system uses a combination of small, task-specific models as well as pre-trained language models for fast and effective text composition while supporting a variety of input modes for better usability.	cs.CL	Accepted at EMNLP 2023 Industry Track
2	Radiation-dominated bouncing model with slow contraction and inflation	Piero A. P. Molinari,Paola C. M. Delgado,Rodrigo F. Pinheiro,Nelson Pinto-Neto	A very simple non-singular inflationary model is presented where the unique matter content is a radiation fluid. The model slowly contracts from a very large, almost empty and flat spacetime and realizes a bounce. It is then launched to a quasi-de Sitter inflationary expansion with more than sixty e-folds, which smoothly changes to the usual classical, decelerated radiation-dominated expansion before nucleosynthesis. The initial contracting and final expanding phases are classical, but the intermediate bounce and inflationary phases are induced by quantum cosmological effects emerging from a Gaussian wave function quickly moving in configuration space. During this quantum era, a huge number of photons is created. The scale factor describing all this rich evolution is a surprisingly simple analytic function of conformal time. The cosmological scalar perturbations arising from quantum vacuum fluctuations in the far past of the model present an almost scale invariant spectrum with an amplitude compatible with observations for reasonable values of the free parameters of the model.	gr-qc	14 pages, 5 figures
3	A clustering tool for interrogating finite element models based on eigenvectors of graph adjacency	Ramaseshan Kannan	This note introduces an unsupervised learning algorithm to debug errors in finite element (FE) simulation models and details how it was productionised. The algorithm clusters degrees of freedom in the FE model using numerical properties of the adjacency of its stiffness matrix. The algorithm has been deployed as a tool called `Model Stability Analysis' tool within the commercial structural FE suite Oasys GSA (www.oasys-software.com/gsa). It has been used successfully by end-users for debugging real world FE models and we present examples of the tool in action.	cs.CE	None
4	GlotLID: Language Identification for Low-Resource Languages	Amir Hossein Kargaran,Ayyoob Imani,Fran√ßois Yvon,Hinrich Sch√ºtze	Several recent papers have published good solutions for language identification (LID) for about 300 high-resource and medium-resource languages. However, there is no LID available that (i) covers a wide range of low-resource languages, (ii) is rigorously evaluated and reliable and (iii) efficient and easy to use. Here, we publish GlotLID-M, an LID model that satisfies the desiderata of wide coverage, reliability and efficiency. It identifies 1665 languages, a large increase in coverage compared to prior work. In our experiments, GlotLID-M outperforms four baselines (CLD3, FT176, OpenLID and NLLB) when balancing F1 and false positive rate (FPR). We analyze the unique challenges that low-resource LID poses: incorrect corpus metadata, leakage from high-resource languages, difficulty separating closely related languages, handling of macrolanguage vs varieties and in general noisy data. We hope that integrating GlotLID-M into dataset creation pipelines will improve quality and enhance accessibility of NLP technology for low-resource languages and cultures. GlotLID-M model, code, and list of data sources are available: https://github.com/cisnlp/GlotLID.	cs.CL	EMNLP 2023
5	Design of General Purpose Minimal-Auxiliary Ising Machines	Isaac K. Martin,Andrew G. Moore,John T. Daly,Jess J. Meyer,Teresa M. Ranadive	Ising machines are a form of quantum-inspired processing-in-memory computer which has shown great promise for overcoming the limitations of traditional computing paradigms while operating at a fraction of the energy use. The process of designing Ising machines is known as the reverse Ising problem. Unfortunately, this problem is in general computationally intractable: it is a nonconvex mixed-integer linear programming problem which cannot be naively brute-forced except in the simplest cases due to exponential scaling of runtime with number of spins. We prove new theoretical results which allow us to reduce the search space to one with quadratic scaling. We utilize this theory to develop general purpose algorithmic solutions to the reverse Ising problem. In particular, we demonstrate Ising formulations of 3-bit and 4-bit integer multiplication which use fewer total spins than previously known methods by a factor of more than three. Our results increase the practicality of implementing such circuits on modern Ising hardware, where spins are at a premium.	math.OC	14 pages, 3 figures, submitted to IEEE International Conference on   Rebooting Computing 2023
6	Global existence of Weak Solutions for a model of nematic liquid crystal-colloidal interactions	Zhiyuan Geng,Arnab Roy,ArghirZarnescu	In this paper we study a mathematical model describing the movement of a colloidal particle in a fixed, bounded three dimensional container filled with a nematic liquid crystal fluid. The motion of the fluid is governed by the Beris-Edwards model for nematohydrodynamics equations, which couples the incompressible Navier-Stokes equations with a parabolic system. The dynamics of colloidal particle within the nematic liquid crystal is described by the conservation laws of linear and angular momentum. We prove the existence of global weak solutions for the coupled system.	math.AP	None
7	ZzzGPT: An Interactive GPT Approach to Enhance Sleep Quality	Yonchanok Khaokaew,Thuc Hanh Nguyen,Kaixin Ji,Hiruni Kegalle,Marwah Alaofi	In today's world, sleep quality is pivotal for overall well-being. While wearable sensors offer real-time monitoring, they often lack actionable insights, leading to user abandonment. This paper delves into the role of technology in understanding sleep patterns. We introduce a two-stage framework, utilizing Large Language Models (LLMs), aiming to provide accurate sleep predictions with actionable feedback. Leveraging the GLOBEM dataset and synthetic data from LLMs, we highlight enhanced results with models like XGBoost. Our approach merges advanced machine learning with user-centric design, blending scientific accuracy with practicality.	cs.LG	None
8	Task Grouping for Automated Multi-Task Machine Learning via Task Affinity Prediction	Afiya Ayman,Ayan Mukhopadhyay,Aron Laszka	When a number of similar tasks have to be learned simultaneously, multi-task learning (MTL) models can attain significantly higher accuracy than single-task learning (STL) models. However, the advantage of MTL depends on various factors, such as the similarity of the tasks, the sizes of the datasets, and so on; in fact, some tasks might not benefit from MTL and may even incur a loss of accuracy compared to STL. Hence, the question arises: which tasks should be learned together? Domain experts can attempt to group tasks together following intuition, experience, and best practices, but manual grouping can be labor-intensive and far from optimal. In this paper, we propose a novel automated approach for task grouping. First, we study the affinity of tasks for MTL using four benchmark datasets that have been used extensively in the MTL literature, focusing on neural network-based MTL models. We identify inherent task features and STL characteristics that can help us to predict whether a group of tasks should be learned together using MTL or if they should be learned independently using STL. Building on this predictor, we introduce a randomized search algorithm, which employs the predictor to minimize the number of MTL trainings performed during the search for task groups. We demonstrate on the four benchmark datasets that our predictor-driven search approach can find better task groupings than existing baseline approaches.	cs.LG	None
9	Mixture-of-Linguistic-Experts Adapters for Improving and Interpreting Pre-trained Language Models	Raymond Li,Gabriel Murray,Giuseppe Carenini	In this work, we propose a method that combines two popular research areas by injecting linguistic structures into pre-trained language models in the parameter-efficient fine-tuning (PEFT) setting. In our approach, parallel adapter modules encoding different linguistic structures are combined using a novel Mixture-of-Linguistic-Experts architecture, where Gumbel-Softmax gates are used to determine the importance of these modules at each layer of the model. To reduce the number of parameters, we first train the model for a fixed small number of steps before pruning the experts based on their importance scores. Our experiment results with three different pre-trained models show that our approach can outperform state-of-the-art PEFT methods with a comparable number of parameters. In addition, we provide additional analysis to examine the experts selected by each model at each layer to provide insights for future studies.	cs.CL	14 pages, 3 figures, Camera-Ready for EMNLP 2023 Findings (Long   Paper)
0	Efficient GPU-accelerated fitting of observational health-scaled stratified and time-varying Cox models	Jianxiao Yang,Martijn J. Schuemie,Marc A. Suchard	The Cox proportional hazards model stands as a widely-used semi-parametric approach for survival analysis in medical research and many other fields. Numerous extensions of the Cox model have further expanded its versatility. Statistical computing challenges arise, however, when applying many of these extensions with the increasing complexity and volume of modern observational health datasets. To address these challenges, we demonstrate how to employ massive parallelization through graphics processing units (GPU) to enhance the scalability of the stratified Cox model, the Cox model with time-varying covariates, and the Cox model with time-varying coefficients. First we establish how the Cox model with time-varying coefficients can be transformed into the Cox model with time-varying covariates when using discrete time-to-event data. We then demonstrate how to recast both of these into a stratified Cox model and identify their shared computational bottleneck that results when evaluating the now segmented partial likelihood and its gradient with respect to regression coefficients at scale. These computations mirror a highly transformed segmented scan operation. While this bottleneck is not an immediately obvious target for multi-core parallelization, we convert it into an un-segmented operation to leverage the efficient many-core parallel scan algorithm. Our massively parallel implementation significantly accelerates model fitting on large-scale and high-dimensional Cox models with stratification or time-varying effect, delivering an order of magnitude speedup over traditional central processing unit-based implementations.	stat.CO	None
1	An entropy stable discontinuous Galerkin method for the spherical thermal shallow water equations	Kieran Ricardo,Kenneth Duru,David Lee	We develop a novel discontinuous Galerkin method for solving the rotating thermal shallow water equations (TRSW) on a curvilinear mesh. Our method is provably entropy stable, conserves mass, buoyancy and vorticity, while also semi-discretely conserving energy. This is achieved by using novel numerical fluxes and splitting the pressure and convection operators. We implement our method on a cubed sphere mesh and numerically verify our theoretical results. Our experiments demonstrate the robustness of the method for a regime of well developed turbulence, where it can be run stably without any dissipation. The entropy stable fluxes are sufficient to control the grid scale noise generated by geostrophic turbulence, eliminating the need for artificial stabilization.	math.NA	None
2	Space-time structure of particle emission and femtoscopy scales in ultrarelativistic heavy-ion collisions	Yu. M. Sinyukov,V. M. Shapoval,M. D. Adzhymambetov	The analysis of the spatiotemporal picture of particle radiation in relativistic heavy-ion collisions in terms of correlation femtoscopy scales, emission and source functions allows one to probe the character of evolution of the system created in the collision. Realistic models, like the integrated hydrokinetic model (iHKM), used in the present work, are able to simulate the entire evolution process of strongly interacting matter produced in high-energy nuclear collision. The mentioned model describes all the stages of the system's evolution, including formation of the very initial state and its consequent gradual thermalization, hydrodynamic expansion and afterburner hadronic cascade, that can help researchers to figure out the specific details of the process and better understand the formation mechanisms of certain observables. In the current paper we investigate the behavior of the pion and kaon interferometry radii and their connection with emission functions in ultrarelativistic heavy-ion collisions at the Large Hadron Collider within iHKM. We are focusing on the study of the emission time scales at different energies for both particle species (pions and kaons) aiming to get deeper insight into relation of these scales and the peculiarities of the mentioned system's collective expansion and decay with the experimentally observed femtoscopy radii. One of our main interests is the problem of the total system's lifetime estimation based on the femtoscopy analysis.	nucl-th	"28 pages, 9 figures. ""Author edition"" of the recently published   article"
3	Attention-Based Ensemble Pooling for Time Series Forecasting	Dhruvit Patel,Alexander Wikner	A common technique to reduce model bias in time-series forecasting is to use an ensemble of predictive models and pool their output into an ensemble forecast. In cases where each predictive model has different biases, however, it is not always clear exactly how each model forecast should be weighed during this pooling. We propose a method for pooling that performs a weighted average over candidate model forecasts, where the weights are learned by an attention-based ensemble pooling model. We test this method on two time-series forecasting problems: multi-step forecasting of the dynamics of the non-stationary Lorenz `63 equation, and one-step forecasting of the weekly incident deaths due to COVID-19. We find that while our model achieves excellent valid times when forecasting the non-stationary Lorenz `63 equation, it does not consistently perform better than the existing ensemble pooling when forecasting COVID-19 weekly incident deaths.	cs.LG	9 pages, 5 figures
4	Global Impact and Balancing Act: Deciphering the Effect of Fluorination on B1s Binding Energies in Fluorinated $h$-BN Nanosheets	Yang Xiao,Jun-Rong Zhang,Sheng-Yu Wang,Weijie Hua	X-ray photoelectron spectroscopy (XPS) plays an important characterization role in the pursuit of controllable fluorination of two-dimensional hexagonal boron nitride ($h$-BN). However, there is a lack of clear spectral interpretation and seemingly conflicting measurements exist. To discern the structure-spectroscopy relation, we performed a comprehensive first-principles study on the boron 1s edge XPS of fluorinated $h$-BN (F-BN) nanosheets. By gradually introducing 1--6 fluorine atoms into different boron or nitrogen sites, we created various F-BN structures with doping ratios ranging from 1-6%. Our calculations reveal that fluorines landed at boron or nitrogen sites exert competitive effects on the B1s binding energies (BEs), leading to red or blue shifts in different measurements. Our calculations affirmed the hypothesis that fluorination affects 1s BEs of all borons in the $\pi$-conjugated system, undermining the transferability from $h$-BN to F-BN. Additionally, we observe that the BE generally increases with higher fluorine concentration when both boron and nitrogen atoms are non-exclusively fluorinated. These findings provide critical insights into how fluorination affects boron's 1s BEs, contributing to a better understanding of fluorination functionalization processes in $h$-BN and its potential applications in materials science.	cond-mat.mtrl-sci	6 pages, 4 figures
5	On the Foundations of Shortcut Learning	Katherine L. Hermann,Hossein Mobahi,Thomas Fel,Michael C. Mozer	Deep-learning models can extract a rich assortment of features from data. Which features a model uses depends not only on predictivity-how reliably a feature indicates train-set labels-but also on availability-how easily the feature can be extracted, or leveraged, from inputs. The literature on shortcut learning has noted examples in which models privilege one feature over another, for example texture over shape and image backgrounds over foreground objects. Here, we test hypotheses about which input properties are more available to a model, and systematically study how predictivity and availability interact to shape models' feature use. We construct a minimal, explicit generative framework for synthesizing classification datasets with two latent features that vary in predictivity and in factors we hypothesize to relate to availability, and quantify a model's shortcut bias-its over-reliance on the shortcut (more available, less predictive) feature at the expense of the core (less available, more predictive) feature. We find that linear models are relatively unbiased, but introducing a single hidden layer with ReLU or Tanh units yields a bias. Our empirical findings are consistent with a theoretical account based on Neural Tangent Kernels. Finally, we study how models used in practice trade off predictivity and availability in naturalistic datasets, discovering availability manipulations which increase models' degree of shortcut bias. Taken together, these findings suggest that the propensity to learn shortcut features is a fundamental characteristic of deep nonlinear architectures warranting systematic study given its role in shaping how models solve tasks.	cs.LG	None
6	Dynamical aspects of Galactic habitability in N-body simulations	A. Mitra≈°inoviƒá,B. Vukotiƒá,M. Micic,M. M. ƒÜirkoviƒá	Recent studies of Galactic evolution revealed that the dynamics of the stellar component might be one of the key factors when considering galactic habitability. We run an N-body simulation model of the Milky Way, which we evolve for 10 Gyr, to study the secular evolution of stellar orbits and the resulting galactic habitability-related properties, i.e., the density of the stellar component and close stellar encounters. The results indicate that radial migrations are not negligible, even in a simple axisymmetric model with mild levels of dynamical heating, and that the net outward diffusion of the stellar component can populate galactic outskirts with habitable systems. Habitable environment is also likely even at sub-Solar galactocentric radii, because the rate of close encounters should not significantly degrade habitability. Stars that evolve from non-circular to stable nearly-circular orbits typically migrate outwards, settling down in a broad Solar neighborhood. The region between $R \approx 3$ kpc and $R \approx 12$ kpc represents the zone of radial mixing, which can blur the boundaries of the Galactic Habitable Zone, as it has been conventionally understood. The present-day stable population of the stars in the Solar neighborhood originates from this radial mixing zone, with most of the stars coming from the inner regions. The Solar system can be considered as a typical Milky Way habitable system because it migrated outwards from the metal-rich inner regions of the Disk and has a circular orbit in the present epoch. We conclude that the boundaries of the Galactic Habitable Zone cannot be sharply confined for a given epoch because of the mixing caused by the stellar migrations and secular evolution of stellar orbits.	astro-ph.GA	Accepted for publication in PASA
7	TiC-CLIP: Continual Training of CLIP Models	Saurabh Garg,Mehrdad Farajtabar,Hadi Pouransari,Raviteja Vemulapalli,Sachin Mehta,Oncel Tuzel,Vaishaal Shankar,Fartash Faghri	Keeping large foundation models up to date on latest data is inherently expensive. To avoid the prohibitive costs of constantly retraining, it is imperative to continually train these models. This problem is exacerbated by the lack of any large scale continual learning benchmarks or baselines. We introduce the first set of web-scale Time-Continual (TiC) benchmarks for training vision-language models: TiC-DataCompt, TiC-YFCC, and TiC-RedCaps with over 12.7B timestamped image-text pairs spanning 9 years (2014--2022). We first use our benchmarks to curate various dynamic evaluations to measure temporal robustness of existing models. We show OpenAI's CLIP (trained on data up to 2020) loses $\approx 8\%$ zero-shot accuracy on our curated retrieval task from 2021--2022 compared with more recently trained models in OpenCLIP repository. We then study how to efficiently train models on time-continuous data. We demonstrate that a simple rehearsal-based approach that continues training from the last checkpoint and replays old data reduces compute by $2.5\times$ when compared to the standard practice of retraining from scratch.	cs.CV	None
8	CleanCoNLL: A Nearly Noise-Free Named Entity Recognition Dataset	Susanna R√ºcker,Alan Akbik	The CoNLL-03 corpus is arguably the most well-known and utilized benchmark dataset for named entity recognition (NER). However, prior works found significant numbers of annotation errors, incompleteness, and inconsistencies in the data. This poses challenges to objectively comparing NER approaches and analyzing their errors, as current state-of-the-art models achieve F1-scores that are comparable to or even exceed the estimated noise level in CoNLL-03. To address this issue, we present a comprehensive relabeling effort assisted by automatic consistency checking that corrects 7.0% of all labels in the English CoNLL-03. Our effort adds a layer of entity linking annotation both for better explainability of NER labels and as additional safeguard of annotation quality. Our experimental evaluation finds not only that state-of-the-art approaches reach significantly higher F1-scores (97.1%) on our data, but crucially that the share of correct predictions falsely counted as errors due to annotation noise drops from 47% to 6%. This indicates that our resource is well suited to analyze the remaining errors made by state-of-the-art models, and that the theoretical upper bound even on high resource, coarse-grained NER is not yet reached. To facilitate such analysis, we make CleanCoNLL publicly available to the research community.	cs.CL	EMNLP 2023 camera-ready version
9	Poison is Not Traceless: Fully-Agnostic Detection of Poisoning Attacks	Xinglong Chang,Katharina Dost,Gillian Dobbie,J√∂rg Wicker	The performance of machine learning models depends on the quality of the underlying data. Malicious actors can attack the model by poisoning the training data. Current detectors are tied to either specific data types, models, or attacks, and therefore have limited applicability in real-world scenarios. This paper presents a novel fully-agnostic framework, DIVA (Detecting InVisible Attacks), that detects attacks solely relying on analyzing the potentially poisoned data set. DIVA is based on the idea that poisoning attacks can be detected by comparing the classifier's accuracy on poisoned and clean data and pre-trains a meta-learner using Complexity Measures to estimate the otherwise unknown accuracy on a hypothetical clean dataset. The framework applies to generic poisoning attacks. For evaluation purposes, in this paper, we test DIVA on label-flipping attacks.	cs.CR	8 pages
0	Impacts of thermal aging and associated heat losses on the performance of a Pyromark 2500-coated concentrated solar power central receiver	Katie Bezdjian,Mathieu Francoeur	Pyromark 2500 is a widely used coating for concentrated solar power central receiver systems due to its high absorptivity, ease in application, and relatively low cost. Pyromark's performance is quantified by its figure of merit (FOM), which relates the coating's heat losses to its solar-to-thermal conversion efficiency. After long-term exposure to high temperatures (>750{\deg}C) and irradiance levels, Pyromark's absorptivity and FOM decrease. The aim of this research is to evaluate changes in Pyromark's absorptivity, heat losses, and FOM as a function of thermal aging. This work also compares the most common FOM expression, which neglects convection losses, to an FOM that includes all heat losses experienced by a central receiver. Isothermal aging experiments are conducted on Pyromark-coated Inconel 600 substrates at 750{\deg}C. The spectral, hemispherical absorptivity of the samples is measured at room temperature with a spectrophotometer and input into a finite element analysis model that includes radiation and convection boundary conditions. The heat flux and temperature output by the model are used to determine the heat losses and FOM of the Pyromark samples. After 151 h of thermal aging, the sample with the thinnest Pyromark coat maintains the most stable total, hemispherical absorptivity. Conversely, the total, hemispherical absorptivity of the sample with the thickest Pyromark coat drops by a maximum of 1.73%, and the corresponding maximum drop in FOM is 1.90% when windy conditions (which are expected around central receivers) are assumed. In windy conditions, convection losses constitute between 21% and 24% of the samples' total heat loss; thus, the most common FOM expression in the literature overestimates the samples' FOM by ~4.40%. An analysis of the samples' heat losses indicates that reflection losses exceed emission losses when the absorptivity declines significantly.	physics.app-ph	36 pages, 6 figures, 2 tables
1	Hierarchical Randomized Smoothing	Yan Scholten,Jan Schuchardt,Aleksandar Bojchevski,Stephan G√ºnnemann	Real-world data is complex and often consists of objects that can be decomposed into multiple entities (e.g. images into pixels, graphs into interconnected nodes). Randomized smoothing is a powerful framework for making models provably robust against small changes to their inputs - by guaranteeing robustness of the majority vote when randomly adding noise before classification. Yet, certifying robustness on such complex data via randomized smoothing is challenging when adversaries do not arbitrarily perturb entire objects (e.g. images) but only a subset of their entities (e.g. pixels). As a solution, we introduce hierarchical randomized smoothing: We partially smooth objects by adding random noise only on a randomly selected subset of their entities. By adding noise in a more targeted manner than existing methods we obtain stronger robustness guarantees while maintaining high accuracy. We initialize hierarchical smoothing using different noising distributions, yielding novel robustness certificates for discrete and continuous domains. We experimentally demonstrate the importance of hierarchical smoothing in image and node classification, where it yields superior robustness-accuracy trade-offs. Overall, hierarchical smoothing is an important contribution towards models that are both - certifiably robust to perturbations and accurate.	cs.LG	None
2	Knowledge Editing for Large Language Models: A Survey	Song Wang,Yaochen Zhu,Haochen Liu,Zaiyi Zheng,Chen Chen,Jundong L	Large language models (LLMs) have recently transformed both the academic and industrial landscapes due to their remarkable capacity to understand, analyze, and generate texts based on their vast knowledge and reasoning ability. Nevertheless, one major drawback of LLMs is their substantial computational cost for pre-training due to their unprecedented amounts of parameters. The disadvantage is exacerbated when new knowledge frequently needs to be introduced into the pre-trained model. Therefore, it is imperative to develop effective and efficient techniques to update pre-trained LLMs. Traditional methods encode new knowledge in pre-trained LLMs through direct fine-tuning. However, naively re-training LLMs can be computationally intensive and risks degenerating valuable pre-trained knowledge irrelevant to the update in the model. Recently, Knowledge-based Model Editing (KME) has attracted increasing attention, which aims to precisely modify the LLMs to incorporate specific knowledge, without negatively influencing other irrelevant knowledge. In this survey, we aim to provide a comprehensive and in-depth overview of recent advances in the field of KME. We first introduce a general formulation of KME to encompass different KME strategies. Afterward, we provide an innovative taxonomy of KME techniques based on how the new knowledge is introduced into pre-trained LLMs, and investigate existing KME strategies while analyzing key insights, advantages, and limitations of methods from each category. Moreover, representative metrics, datasets, and applications of KME are introduced accordingly. Finally, we provide an in-depth analysis regarding the practicality and remaining challenges of KME and suggest promising research directions for further advancement in this field.	cs.CL	31 pages
3	Information-Theoretically Secret Reed-Muller Identification with Affine Designs	Mattia Spandri,Roberto Ferrara,Christian Deppe,Moritz Wiese,Holger Boche	We consider the problem of information-theoretic secrecy in identification schemes rather than transmission schemes. In identification, large identities are encoded into small challenges sent with the sole goal of allowing at the receiver reliable verification of whether the challenge could have been generated by a (possibly different) identity of his choice. One of the reasons to consider identification is that it trades decoding for an exponentially larger rate, however this may come with such encoding complexity and latency that it can render this advantage unusable. Identification still bears one unique advantage over transmission in that practical implementation of information-theoretic secrecy becomes possible, even considering that the information-theoretic secrecy definition needed in identification is that of semantic secrecy. Here, we implement a family of encryption schemes, recently shown to achieve semantic-secrecy capacity, and apply it to a recently-studied family of identification codes, confirming that, indeed, adding secrecy to identification comes at essentially no cost. While this is still within the one-way communication scenario, it is a necessary step into implementing semantic secrecy with two-way communication, where the information-theoretic assumptions are more realistic.	cs.IT	6 pages, 3 figures, accepted at European Wireless 2023
4	Performance Tuning for GPU-Embedded Systems: Machine-Learning-based and Analytical Model-driven Tuning Methodologies	Adrian Perez Dieguez,Margarita Amor Lopez	GPU-embedded systems have gained popularity across various domains due to their efficient power consumption. However, in order to meet the demands of real-time or time-consuming applications running on these systems, it is crucial for them to be tuned to exhibit high performance. This paper addresses the issue by developing and comparing two tuning methodologies on GPU-embedded systems, and also provides performance insights for developers and researchers seeking to optimize applications running on these architectures. We focus on parallel prefix operations, such as FFT, scan primitives, and tridiagonal system solvers, which are performance-critical components in many applications. The study introduces an analytical model-driven tuning methodology and a Machine Learning (ML)-based tuning methodology. We evaluate the performance of the two tuning methodologies for different parallel prefix implementations of the BPLG library in an NVIDIA Jetson system, and compare their performance to the ones achieved through an exhaustive search. The findings shed light on the best strategies for handling the open challenge of performance portability for major computational patterns among server and embedded devices, providing practical guidance for offline and online tuning. We also address the existing gap in performance studies for parallel computational patterns in GPU-embedded systems by comparing the BPLG performance against other state-of-the-art libraries, including CUSPARSE, CUB, and CUFFT.	cs.DC	None
5	Bayes factor functions	Saptati Datta,Rachael Shudde,Valen E. Johnson	We describe Bayes factors functions based on z, t, $\chi^2$, and F statistics and the prior distributions used to define alternative hypotheses. The non-local alternative prior distributions are centered on standardized effects, which index the Bayes factor function. The prior densities include a dispersion parameter that models the variation of effect sizes across replicated experiments. We examine the convergence rates of Bayes factor functions under true null and true alternative hypotheses. Several examples illustrate the application of the Bayes factor functions to replicated experimental designs and compare the conclusions from these analyses to other default Bayes factor methods.	stat.ME	None
6	ShadowSense: Unsupervised Domain Adaptation and Feature Fusion for Shadow-Agnostic Tree Crown Detection from RGB-Thermal Drone Imagery	Rudraksh Kapil,Seyed Mojtaba Marvasti-Zadeh,Nadir Erbilgin,Nilanjan Ray	Accurate detection of individual tree crowns from remote sensing data poses a significant challenge due to the dense nature of forest canopy and the presence of diverse environmental variations, e.g., overlapping canopies, occlusions, and varying lighting conditions. Additionally, the lack of data for training robust models adds another limitation in effectively studying complex forest conditions. This paper presents a novel method for detecting shadowed tree crowns and provides a challenging dataset comprising roughly 50k paired RGB-thermal images to facilitate future research for illumination-invariant detection. The proposed method (ShadowSense) is entirely self-supervised, leveraging domain adversarial training without source domain annotations for feature extraction and foreground feature alignment for feature pyramid networks to adapt domain-invariant representations by focusing on visible foreground regions, respectively. It then fuses complementary information of both modalities to effectively improve upon the predictions of an RGB-trained detector and boost the overall accuracy. Extensive experiments demonstrate the superiority of the proposed method over both the baseline RGB-trained detector and state-of-the-art techniques that rely on unsupervised domain adaptation or early image fusion. Our code and data are available: https://github.com/rudrakshkapil/ShadowSense	cs.CV	Accepted in IEEE/CVF Winter Applications of Computer Vision (WACV)   2024 main conference! 8 pages (11 with bibliography), 5 figures, 3 tables
7	Resource Allocation for UAV-Assisted Industrial IoT User with Finite Blocklength	Atefeh Rezaei,Ata Khalili,Falko Dressler	We consider a relay system empowered by an unmanned aerial vehicle (UAV) that facilitates downlink information delivery while adhering to finite blocklength requirements. The setup involves a remote controller transmitting information to both a UAV and an industrial Internet of Things (IIoT) or remote device, employing the non-orthogonal multiple access (NOMA) technique in the first phase. Subsequently, the UAV decodes and forwards this information to the remote device in the second phase. Our primary objective is to minimize the decoding error probability (DEP) at the remote device, which is influenced by the DEP at the UAV. To achieve this goal, we optimize the blocklength, transmission power, and location of the UAV. However, the underlying problem is highly non-convex and generally intractable to be solved directly. To overcome this challenge, we adopt an alternative optimization (AO) approach and decompose the original problem into three sub-problems. This approach leads to a sub-optimal solution, which effectively mitigates the non-convexity issue. In our simulations, we compare the performance of our proposed algorithm with baseline schemes. The results reveal that the proposed framework outperforms the baseline schemes, demonstrating its superiority in achieving lower DEP at the remote device. Furthermore, the simulation results illustrate the rapid convergence of our proposed algorithm, indicating its efficiency and effectiveness in solving the optimization problem.	eess.SP	This paper is accepted by IEEE VTC 2023-Fall, Hong Kong, China
8	Sea-Land-Cloud Segmentation in Satellite Hyperspectral Imagery by Deep Learning	Jon Alvarez Justo,Joseph Landon Garrett,Mariana-Iuliana Georgescu,Jesus Gonzalez-Llorente,Radu Tudor Ionescu,Tor Arne Johansen	Satellites are increasingly adopting on-board Artificial Intelligence (AI) techniques to enhance platforms' autonomy through edge inference. In this context, the utilization of deep learning (DL) techniques for segmentation in HS satellite imagery offers advantages for remote sensing applications, and therefore, we train 16 different models, whose codes are made available through our study, which we consider to be relevant for on-board multi-class segmentation of HS imagery, focusing on classifying oceanic (sea), terrestrial (land), and cloud formations. We employ the HYPSO-1 mission as an illustrative case for sea-land-cloud segmentation, and to demonstrate the utility of the segments, we introduce a novel sea-land-cloud ranking application scenario. Our system prioritizes HS image downlink based on sea, land, and cloud coverage levels from the segmented images. We comparatively evaluate the models for in-orbit deployment, considering performance, parameter count, and inference time. The models include both shallow and deep models, and after we propose four new DL models, we demonstrate that segmenting single spectral signatures (1D) outperforms 3D data processing comprising both spectral (1D) and spatial (2D) contexts. We conclude that our lightweight DL model, called 1D-Justo-LiuNet, consistently surpasses state-of-the-art models for sea-land-cloud segmentation, such as U-Net and its variations, in terms of performance (0.93 accuracy) and parameter count (4,563). However, the 1D models present longer inference time (15s) in the tested processing architecture, which is clearly suboptimal. Finally, after demonstrating that in-orbit image segmentation should occur post L1b radiance calibration rather than on raw data, we additionally show that reducing spectral channels down to 3 lowers models' parameters and inference time, at the cost of weaker segmentation performance.	cs.CV	Remote Sensing, Satellite Imagery, Hyperspectral Imaging, Deep   Learning, Segmentation
9	Electronic structures and transport properties of cove-edged graphene nanoribbons	David M T Kuo	In this comprehensive study, we undertake a thorough theoretical examination of the electronic subband structures within cove-edged zigzag graphene nanoribbons (CZGNRs) using the tight-binding model. These unique nanostructures arise from the systematic removal of carbon atoms along the zigzag edges of conventional zigzag graphene nanoribbons (ZGNRs). Notably, CZGNRs that exhibit intriguing band gaps can be conceptualized as interconnected graphene quantum dots (GQDs). An essential finding of our investigation is the inverse relationship between the size of GQDs and the band gaps of CZGNRs, a relationship that remains consistent regardless of the number of GQDs present. Additionally, we delve into the examination of electron effective masses in proximity to the edges of the first conduction subband of CZGNRs as GQD sizes expand. We observe a significant increase in electron effective masses as GQDs become larger, which is attributed to the increasing similarity between larger GQDs and ZGNRs. To further understand the practical implications, we explore the transport properties of finite CZGNRs when connected to electrodes through line contacts. The presence of edge defects introduces intriguing asymmetries in the tunneling current, leading to a significant reduction in its magnitude. Notably, we observe that the saturation current magnitude is less influenced by the length of CZGNRs and is instead more sensitive to the choice of materials used for the contacted electrodes. Lastly, we investigate the tunneling currents through GQDs featuring boron nitride textures within the Coulomb blockade region, unveiling an irregular staircase-like pattern in the tunneling current behavior.	cond-mat.mes-hall	10 pages and 11 figures
0	Propensity score weighting plus an adjusted proportional hazards model does not equal doubly robust away from the null	Erin E Gabriel,Michael C Sachs,Ingeborg Waernbaum,Els Goetghebeur,Paul F Blanche,Stijn Vansteelandt,Arvid Sj√∂lander,Thomas Scheike	Recently it has become common for applied works to combine commonly used survival analysis modeling methods, such as the multivariable Cox model, and propensity score weighting with the intention of forming a doubly robust estimator that is unbiased in large samples when either the Cox model or the propensity score model is correctly specified. This combination does not, in general, produce a doubly robust estimator, even after regression standardization, when there is truly a causal effect. We demonstrate via simulation this lack of double robustness for the semiparametric Cox model, the Weibull proportional hazards model, and a simple proportional hazards flexible parametric model, with both the latter models fit via maximum likelihood. We provide a novel proof that the combination of propensity score weighting and a proportional hazards survival model, fit either via full or partial likelihood, is consistent under the null of no causal effect of the exposure on the outcome under particular censoring mechanisms if either the propensity score or the outcome model is correctly specified and contains all confounders. Given our results suggesting that double robustness only exists under the null, we outline two simple alternative estimators that are doubly robust for the survival difference at a given time point (in the above sense), provided the censoring mechanism can be correctly modeled, and one doubly robust method of estimation for the full survival curve. We provide R code to use these estimators for estimation and inference in the supplementary materials.	stat.ME	None
1	Generalizations of Mezhirov's game semantics to predicate superintuitionistic logics and the Casari formula	Ivan Pyltsyn	Game semantics allows us to look at basic logical concepts from another side. This approach to logic has a long history, there are plenty of different types of games: provability games, semantic games, etc. And there is an interesting type of provability games called Mezhirov's game proposed by Iliya Mezhirov for intuitionistic logic of propositions and Grzegorczyk modal logic. Mezhirov's game semantics for intuitionistic logic is interesting because of its simplicity and strong connection with Kripke semantics and Kripke models. In my study, I try to generalize Mezhirov's result in two directions: to generalize to intuitionistic logic of predicates (or to some its extensions) and to the case of a connection not only between the game and tautologies of logic, but also between the game and entailment from infinite sets of formulas.	math.LO	None
2	Multivariate Dynamic Mediation Analysis under a Reinforcement Learning Framework	Lan Luo,Chengchun Shi,Jitao Wang,Zhenke Wu,Lexin Li	Mediation analysis is an important analytic tool commonly used in a broad range of scientific applications. In this article, we study the problem of mediation analysis when there are multivariate and conditionally dependent mediators, and when the variables are observed over multiple time points. The problem is challenging, because the effect of a mediator involves not only the path from the treatment to this mediator itself at the current time point, but also all possible paths pointed to this mediator from its upstream mediators, as well as the carryover effects from all previous time points. We propose a novel multivariate dynamic mediation analysis approach. Drawing inspiration from the Markov decision process model that is frequently employed in reinforcement learning, we introduce a Markov mediation process paired with a system of time-varying linear structural equation models to formulate the problem. We then formally define the individual mediation effect, built upon the idea of simultaneous interventions and intervention calculus. We next derive the closed-form expression and propose an iterative estimation procedure under the Markov mediation process model. We study both the asymptotic property and the empirical performance of the proposed estimator, and further illustrate our method with a mobile health application.	stat.ME	None
3	Existence of solution to a system of PDEs modeling the crystal growth inside lithium batteries	Omar Lakkis,Alexandros Skouras,Vanessa Styles	The life-cycle of electric batteries depends on a complex system of interacting electrochemical and growth phenomena that produce dendritic structures during the discharge cycle. We study herein a system of 3 partial differential equations combining an Allen--Cahn phase-field model (simulating the dendrite-electrolyte interface) with the Poisson--Nernst--Planck systems simulating the electrodynamics and leading to the formation of such dendritic structures. We prove novel existence, uniqueness and stability results for this system and use it to produce simulations based on a finite element code.	math.AP	27 pages, 22 figures, free software and open source code available
4	A Convex Parameterization of Controllers Constrained to use only Relative Measurements	Walden Marshall,Bassam Bamieh,Emily Jensen	We consider the optimal controller design problem for distributed systems in which subsystems are equipped with sensors that measure only differences of quantities such as relative (rather than absolute) positions and velocities. While such problems can be set up as a standard problem of robust output feedback control, we illustrate with a counterexample that this may be undesirable and then propose an alternate equivalent formulation. In particular, we provide an example of sparsity constraints that are not quadratically-invariant with respect to a standard formulation of a given plant, but that can be written as quadratically-invariant constraints with respect to a transformed version of this problem. In effect, our transformation provides a path to convert the controller design problem to an equivalent convex program. This problem transformation relies on a novel parameterization of controllers with general relative measurement structures that we derive here. We further illustrate the usefulness of this novel parameterization through an example of optimal consensus design with prescribed communication delays within the controller.	eess.SY	8 pages, 3 figures
5	Homogeneous control design using invariant ellipsoid method	Siyuan Wang,Andrey Polyakov,Gang Zheng,Xubin Ping,Driss Boutat	The invariant ellipsoid method is aimed at minimization of the smallest invariant and attractive set of a linear control system operating under bounded external disturbances. This paper extends this technique to a class of the so-called generalized homogeneous system by defining the $\dn-$homogeneous invariant/attractive ellipsoid. The generalized homogeneous optimal (in the sense of invariant ellipsoid) controller allows further improvement of the control system providing a faster convergence and better precision. Theoretical results are supported by numerical simulations and experiments.	math.OC	None
6	Background Summarization of Event Timelines	Adithya Pratapa,Kevin Small,Markus Dreyer	Generating concise summaries of news events is a challenging natural language processing task. While journalists often curate timelines to highlight key sub-events, newcomers to a news event face challenges in catching up on its historical context. In this paper, we address this need by introducing the task of background news summarization, which complements each timeline update with a background summary of relevant preceding events. We construct a dataset by merging existing timeline datasets and asking human annotators to write a background summary for each timestep of each news event. We establish strong baseline performance using state-of-the-art summarization systems and propose a query-focused variant to generate background summaries. To evaluate background summary quality, we present a question-answering-based evaluation metric, Background Utility Score (BUS), which measures the percentage of questions about a current event timestep that a background summary answers. Our experiments show the effectiveness of instruction fine-tuned systems such as Flan-T5, in addition to strong zero-shot performance using GPT-3.5.	cs.CL	EMNLP 2023 camera-ready
7	Electrothermal Actuation of NEMS Resonators: Modeling and Experimental Validation	Monan Ma,Kamil L. Ekinci	We study the electrothermal actuation of nanomechanical motion using a combination of numerical simulations and analytical solutions. The nanoelectrothermal actuator structure is a u-shaped gold nanoresistor that is patterned on the anchor of a doubly-clamped nanomechanical beam or a microcantilever resonator. This design has been used in recent experiments successfully. In our finite-element analysis (FEA) based model, our input is an ac current; we first calculate the temperature oscillations due to Joule heating using Ohm's Law and the heat equation; we then determine the thermally induced bending moment and the displacement profile of the beam by coupling the temperature field to Euler-Bernoulli beam theory with tension. Our model efficiently combines transient and frequency-domain analyses: we compute the temperature field using a transient approach and then impose this temperature field as a harmonic perturbation for determining the mechanical response in the frequency domain. This unique modeling method offers lower computational complexity and improved accuracy, and is faster than a fully transient FEA approach. Our dynamical model computes the temperature and displacement fields in time domain over a broad range of actuation frequencies and amplitudes. We validate the numerical results by directly comparing them with experimentally measured displacement amplitudes of NEMS beams around their eigenmodes in vacuum. Our model predicts a thermal time constant of 1.9 ns in vacuum for our particular structures, indicating that electrothermal actuation is efficient up to ~80 MHz. We also investigate the thermal response of the actuator when immersed in a variety of fluids.	cond-mat.mes-hall	None
8	Systematic Physics-Compliant Analysis of Over-the-Air Channel Equalization in RIS-Parametrized Wireless Networks-on-Chip	Jean Tapie,Hugo Prod'homme,Mohammadreza F. Imani,Philipp del Hougne	"Wireless networks-on-chip (WNoCs) are an enticing complementary interconnect technology for multi-core chips but face severe resource constraints. Being limited to simple on-off-keying modulation, the reverberant nature of the chip enclosure imposes limits on allowed modulation speeds in sight of inter-symbol interference, casting doubts on the competitiveness of WNoCs as interconnect technology. Fortunately, this vexing problem was recently overcome by parametrizing the on-chip radio environment with a reconfigurable intelligent surface (RIS). By suitably configuring the RIS, selected channel impulse responses (CIRs) can be tuned to be (almost) pulse-like despite rich scattering thanks to judiciously tailored multi-bounce path interferences. However, the exploration of this ""over-the-air"" (OTA) equalization is thwarted by (i) the overwhelming complexity of the propagation environment, and (ii) the non-linear dependence of the CIR on the RIS configuration, requiring a costly and lengthy full-wave simulation for every optimization step. Here, we show that a reduced-basis physics-compliant model for RIS-parametrized WNoCs can be calibrated with a single full-wave simulation. Thereby, we unlock the possibility of predicting the CIR for any RIS configuration almost instantaneously without any additional full-wave simulation. We leverage this new tool to systematically explore OTA equalization in RIS-parametrized WNoCs regarding the optimal choice of delay time for the RIS-shaped CIR's peak. We also study the simultaneous optimization of multiple on-chip wireless links for broadcasting. Looking forward, the introduced tools will enable the efficient exploration of various types of OTA analog computing in RIS-parametrized WNoCs."	physics.app-ph	10 pages, 7 figures, submitted to an IEEE Journal
9	Learning Low-Rank Latent Spaces with Simple Deterministic Autoencoder: Theoretical and Empirical Insights	Alokendu Mazumder,Tirthajit Baruah,Bhartendu Kumar,Rishab Sharma,Vishwajeet Pattanaik,Punit Rathore	The autoencoder is an unsupervised learning paradigm that aims to create a compact latent representation of data by minimizing the reconstruction loss. However, it tends to overlook the fact that most data (images) are embedded in a lower-dimensional space, which is crucial for effective data representation. To address this limitation, we propose a novel approach called Low-Rank Autoencoder (LoRAE). In LoRAE, we incorporated a low-rank regularizer to adaptively reconstruct a low-dimensional latent space while preserving the basic objective of an autoencoder. This helps embed the data in a lower-dimensional space while preserving important information. It is a simple autoencoder extension that learns low-rank latent space. Theoretically, we establish a tighter error bound for our model. Empirically, our model's superiority shines through various tasks such as image generation and downstream classification. Both theoretical and practical outcomes highlight the importance of acquiring low-dimensional embeddings.	cs.LG	Accepted @ IEEE/CVF WACV 2024
0	Length is a Curse and a Blessing for Document-level Semantics	Chenghao Xiao,Yizhi Li,G Thomas Hudson,Chenghua Lin,Noura Al Moubayed	In recent years, contrastive learning (CL) has been extensively utilized to recover sentence and document-level encoding capability from pre-trained language models. In this work, we question the length generalizability of CL-based models, i.e., their vulnerability towards length-induced semantic shift. We verify not only that length vulnerability is a significant yet overlooked research gap, but we can devise unsupervised CL methods solely depending on the semantic signal provided by document length. We first derive the theoretical foundations underlying length attacks, showing that elongating a document would intensify the high intra-document similarity that is already brought by CL. Moreover, we found that isotropy promised by CL is highly dependent on the length range of text exposed in training. Inspired by these findings, we introduce a simple yet universal document representation learning framework, LA(SER)$^{3}$: length-agnostic self-reference for semantically robust sentence representation learning, achieving state-of-the-art unsupervised performance on the standard information retrieval benchmark.	cs.CL	Accepted at EMNLP 2023. Our code is publicly available at   https://github.com/gowitheflow-1998/LA-SER-cubed
1	The role of tropical and extra-tropical waves in the Hadley circulation	ABS Thakur,Jai Sukhatme,Nili Harnik	The tropical overturning circulation is examined in a moist aquaplanet general circulation model forced using a non-interactive sea surface temperature (SST) distribution that varies between a present-day Earth-like profile and one that is globally uniform. A traditional Hadley Cell (HC)-like flow is observed in all experiments along with the poleward transport of heat and angular momentum. In simulations with non-zero SST gradients, latent heat released from organized convection near the equator sets up a deep tropical cell; midlatitude baroclinic Rossby waves flux heat and angular momentum poleward, reinforcing the thermally direct circulation. As the imposed SST gradient is weakened, the HC transitions from a thermally and eddy-driven regime to one that's completely eddy-driven. When the SST is globally uniform, equatorial waves concentrate precipitation in the tropics and facilitate the lower-level convergence necessary for the ascending branch of the HC. Conventional midlatitude Rossby waves become very weak, but upper-level baroclinicity generates waves that cause equatorward transport of heat and poleward transport of momentum. Moreover, these upper-level waves induce a circulation that opposes the time-mean HC, thus highlighting the role of tropical waves in driving a traditional overturning flow for uniform SSTs. In all cases, anomalies associated with the tropical waves closely resemble those that sum to give the upper-level zonal mean divergent outflow. Through their ability to modulate tropical rainfall and the related latent heating, equatorial waves cause considerable hemispheric asymmetry in the HC and impart synoptic and intraseasonal variability to the tropical overturning circulation.	physics.ao-ph	30 pages, 12 figures, submitted to QJRMS
2	Multilayer Environment and Toolchain for Holistic NetwOrk Design and Analysis	Filip Rezabek,Kilian Glas,Richard von Seck,Achraf Aroua,Tizian Leonhardt,Georg Carle	The recent developments and research in distributed ledger technologies and blockchain have contributed to the increasing adoption of distributed systems. To collect relevant insights into systems' behavior, we observe many evaluation frameworks focusing mainly on the system under test throughput. However, these frameworks often need more comprehensiveness and generality, particularly in adopting a distributed applications' cross-layer approach. This work analyses in detail the requirements for distributed systems assessment. We summarize these findings into a structured methodology and experimentation framework called TURBO. Our approach emphasizes setting up and assessing a broader spectrum of distributed systems and addresses a notable research gap. We showcase the effectiveness of the framework by evaluating four distinct systems and their interaction, leveraging a diverse set of eight carefully selected metrics and 12 essential parameters. Through experimentation and analysis we demonstrate the framework's capabilities to provide valuable insights across various use cases. For instance, we identify that a combination of Trusted Execution Environments with threshold signature scheme FROST introduces minimal overhead on the performance with average latency around \SI{40}{\ms}. We showcase an emulation of realistic systems behavior, e.g., Maximal Extractable Value is possible and could be used to further model such dynamics. The TURBO framework enables a deeper understanding of distributed systems and is a powerful tool for researchers and practitioners navigating the complex landscape of modern computing infrastructures.	cs.DC	None
3	Beyond Jacobian-based tasks: Extended set-based tasks for multi-task execution and prioritization	Gennaro Notomista,Mario Selvaggio,Mar√≠a Santos,Siddharth Mayya,Francesca Pagano,Vincenzo Lippiello,Cristian Secchi	The ability of executing multiple tasks simultaneously is an important feature of redundant robotic systems. As a matter of fact, complex behaviors can often be obtained as a result of the execution of several tasks. Moreover, in safety-critical applications, tasks designed to ensure the safety of the robot and its surroundings have to be executed along with other nominal tasks. In such cases, it is also important to prioritize the former over the latter. In this paper, we formalize the definition of extended set-based tasks, i.e., tasks which can be executed by rendering subsets of the task space asymptotically stable or forward invariant. We propose a mathematical representation of such tasks that allows for the execution of more complex and time-varying prioritized stacks of tasks using kinematic and dynamic robot models alike. We present and analyze an optimization-based framework which is computationally efficient, accounts for input bounds, and allows for the stable execution of time-varying prioritized stacks of extended set-based tasks. The proposed framework is validated using extensive simulations and experiments with robotic manipulators.	eess.SY	None
4	Breaking of a floating particle raft by water waves	Louis Saddier,Ambre Palotai,Matheo Aksil,Michel Tsamados,Michael Berhanu	When particles of a few tens of microns are spread on the surface of water, they aggregate under the action of capillary forces and form a thin floating membrane, a particle raft. In a tank with a raft made of graphite powder, we generate in the laboratory gravity surface waves, whose wavelength is very large compared to the thickness of the raft. For a sufficiently strong wave amplitude, the raft breaks up progressively by developing cracks and producing fragments whose sizes decrease on a time scale long compared to the period of the wave. We characterize the breaking mechanisms. Then, we investigate the area distribution of the fragments produced during the fragmentation process. The visual appearance of the fragments distributed in size and surrounded by open water bears a striking resemblance to the floes produced by the fracturing of sea ice by waves in the polar oceans. Fragmentation concepts and morphological tools built for sea ice floes can be applied to our macroscopic analog, on which the entire dynamic evolution is accessible.	physics.flu-dyn	None
5	Efficient deep data assimilation with sparse observations and time-varying sensors	Sibo Cheng,Che Liu,Yike Guo,Rossella Arcucci	Variational Data Assimilation (DA) has been broadly used in engineering problems for field reconstruction and prediction by performing a weighted combination of multiple sources of noisy data. In recent years, the integration of deep learning (DL) techniques in DA has shown promise in improving the efficiency and accuracy in high-dimensional dynamical systems. Nevertheless, existing deep DA approaches face difficulties in dealing with unstructured observation data, especially when the placement and number of sensors are dynamic over time. We introduce a novel variational DA scheme, named Voronoi-tessellation Inverse operator for VariatIonal Data assimilation (VIVID), that incorporates a DL inverse operator into the assimilation objective function. By leveraging the capabilities of the Voronoi-tessellation and convolutional neural networks, VIVID is adept at handling sparse, unstructured, and time-varying sensor data. Furthermore, the incorporation of the DL inverse operator establishes a direct link between observation and state space, leading to a reduction in the number of minimization steps required for DA. Additionally, VIVID can be seamlessly integrated with Proper Orthogonal Decomposition (POD) to develop an end-to-end reduced-order DA scheme, which can further expedite field reconstruction. Numerical experiments in a fluid dynamics system demonstrate that VIVID can significantly outperform existing DA and DL algorithms. The robustness of VIVID is also accessed through the application of various levels of prior error, the utilization of varying numbers of sensors, and the misspecification of error covariance in DA.	cs.LG	None
6	Image Segmentation using U-Net Architecture for Powder X-ray Diffraction Images	Howard Yanxon,Eric Roberts,Hannah Parraga,James Weng,Wenqian Xu,Uta Ruett,Alexander Hexemer,Petrus Zwart,Nickolas Schwarz	Scientific researchers frequently use the in situ synchrotron high-energy powder X-ray diffraction (XRD) technique to examine the crystallographic structures of materials in functional devices such as rechargeable battery materials. We propose a method for identifying artifacts in experimental XRD images. The proposed method uses deep learning convolutional neural network architectures, such as tunable U-Nets to identify the artifacts. In particular, the predicted artifacts are evaluated against the corresponding ground truth (manually implemented) using the overall true positive rate or recall. The result demonstrates that the U-Nets can consistently produce great recall performance at 92.4% on the test dataset, which is not included in the training, with a 34% reduction in average false positives in comparison to the conventional method. The U-Nets also reduce the time required to identify and separate artifacts by more than 50%. Furthermore, the exclusion of the artifacts shows major changes in the integrated 1D XRD pattern, enhancing further analysis of the post-processing XRD data.	cs.LG	10 pages, 4 figures, 3 tables
7	Shimura varieties	Sophie Morel	These are the notes of a course on Shimura varieties that I gave at the 2022 IHES summer school on the Langlands program. Lecture 1 gives an introduction to Shimura varieties over the complex numbers (defined here as a special type of locally symmetric spaces) and to the general theory of canonical models; it also discusses in more detail the example of the Siegel modular varieties. Lecture 2 presents some families of Shimura varieties (PEL type, Hodge type, abelian type) and the results that are known about their canonical and integral models. Finally, lecture 3 discusses the cohomology of Shimura varieties, concentrating mostly on the compact non-endoscopic case.	math.NT	64 pages, to appear in Proceedings of Symposia in Pure Mathematics
8	BLP 2023 Task 2: Sentiment Analysis	Md. Arid Hasan,Firoj Alam,Anika Anjum,Shudipta Das,Afiyat Anjum	We present an overview of the BLP Sentiment Shared Task, organized as part of the inaugural BLP 2023 workshop, co-located with EMNLP 2023. The task is defined as the detection of sentiment in a given piece of social media text. This task attracted interest from 71 participants, among whom 29 and 30 teams submitted systems during the development and evaluation phases, respectively. In total, participants submitted 597 runs. However, a total of 15 teams submitted system description papers. The range of approaches in the submitted systems spans from classical machine learning models, fine-tuning pre-trained models, to leveraging Large Language Model (LLMs) in zero- and few-shot settings. In this paper, we provide a detailed account of the task setup, including dataset development and evaluation setup. Additionally, we provide a brief overview of the systems submitted by the participants. All datasets and evaluation scripts from the shared task have been made publicly available for the research community, to foster further research in this domain	cs.CL	Accepted in BLP Workshop at EMNLP-23
9	Transplant arteriosclerosis: an enigmatic disease due to a misnomer	Vladimir M. Subbotin,Michael V. Subotin	Solid organ transplantation across the allogeneic barrier, pioneered by Thomas Starzl, has by now become a common medical procedure. Unfortunately, the number of donor organs lost due to transplant arteriosclerosis (chronic rejection), remains significant and unchanged for decades. We argue that designation of transplant arteriosclerosis as chronic rejection, and its classification as a delayed long-lasting reaction of recipient immune effectors against donor alloantigens have given us a wrong impression that we have identified the necessary cause/pathogenesis of the tissue pathology. However, whatever treatment options we have in the anti-rejection toolbox, despite their success in treating classical rejection, do not work for the transplant arteriosclerosis. Yet, the scientific community has continued to conceptualize and approach the pathology within the alloimmunity model. Due to unproductive research from the alloimmunity and rejection perspective, the number of transplanted hearts lost due to this pathology today is almost the same as it was fifty years ago. We believe that this phenomenon falls under the rubric of linguistic relativity, and that language we chose to name the disease has restricted our cognitive ability to solve the problem. While the initial perception of the transplant arteriosclerosis as chronic rejection was logical and scientific, the subsequent experience revealed that such perception and approach have been fruitless, and likely are incorrect. Considering our tragic failure to prevent and treat the delayed arterial pathology of donor organs using all available knowledge on alloimmunity and rejection, we must finally disassociate the former from the latter. The only way to start this uncomfortable process is to change the words we are using; particularly, the words we chose to name the disease. We have to step out of the alloimmunity rejection box.	q-bio.TO	19 pages, 2 figures
0	Nonlinear theory remedies the lack of invertibility in time periodic fluid flows	Felix Brandt,Matthias Hieber,Arnab Roy	This paper provides a framework to strong time periodic solutions of quasilinear evolution equations. The novelty of this approach is that zero is allowed to be a spectral value of the underlying linearized operator. This approach is then applied to time periodic problems associated to the Navier-Stokes equations, generalized Newtonian fluids, quasilinear reaction-diffusion systems as well as to magneto-hydrodynamics.	math.AP	None
1	Temperature-induced reversal effects of kink dynamics in carbon nanotube on flat substrate	Alexander V. Savin,Margarita Kovaleva	Carbon nanotubes are nano-objects with quite anisotropic properties, for example the mechanical properties in longitudinal and radial directions differ significantly. This feature of the carbon nanotubes yields many interesting phenomena investigated in last decades. One of them is the ability to form both hollow and collapsed states if the radius of the nanotube is large enough. The transitions between the two states have been also reported. In our study we present single-walled carbon nanotube interacting with a plane substrate and characterize the energy of interaction with the substrate using effective Lennard-Jones-type potential. We show energy of the homogeneous open and collapsed states depending on the radius of the carbon nanotube and report on the bi-stability in some range of the nanotube diameters. Using the molecular-dynamical simulations we look at the evolution of the initial half-opened, half-collapsed state and demonstrate that the transition area from one state to another is spatially localized having features of topological soliton (kink or anti-kink). We show that the value and the direction of the kink propagation speed depend significantly on the nanotube diameter as well as on the temperature of the system. We also discuss the mechanism of the process using a simplified model with asymmetric double-well potential and show the entropic nature of the transition.	cond-mat.mes-hall	9 pages, 8 figures
2	Correction with Backtracking Reduces Hallucination in Summarization	Zhenzhen Liu,Chao Wan,Varsha Kishore,Jin Peng Zhou,Minmin Chen,Kilian Q. Weinberger	Abstractive summarization aims at generating natural language summaries of a source document that are succinct while preserving the important elements. Despite recent advances, neural text summarization models are known to be susceptible to hallucinating (or more correctly confabulating), that is to produce summaries with details that are not grounded in the source document. In this paper, we introduce a simple yet efficient technique, CoBa, to reduce hallucination in abstractive summarization. The approach is based on two steps: hallucination detection and mitigation. We show that the former can be achieved through measuring simple statistics about conditional word probabilities and distance to context words. Further, we demonstrate that straight-forward backtracking is surprisingly effective at mitigation. We thoroughly evaluate the proposed method with prior art on three benchmark datasets for text summarization. The results show that CoBa is effective and efficient in reducing hallucination, and offers great adaptability and flexibility.	cs.CL	None
3	G-CASCADE: Efficient Cascaded Graph Convolutional Decoding for 2D Medical Image Segmentation	Md Mostafijur Rahman,Radu Marculescu	In recent years, medical image segmentation has become an important application in the field of computer-aided diagnosis. In this paper, we are the first to propose a new graph convolution-based decoder namely, Cascaded Graph Convolutional Attention Decoder (G-CASCADE), for 2D medical image segmentation. G-CASCADE progressively refines multi-stage feature maps generated by hierarchical transformer encoders with an efficient graph convolution block. The encoder utilizes the self-attention mechanism to capture long-range dependencies, while the decoder refines the feature maps preserving long-range information due to the global receptive fields of the graph convolution block. Rigorous evaluations of our decoder with multiple transformer encoders on five medical image segmentation tasks (i.e., Abdomen organs, Cardiac organs, Polyp lesions, Skin lesions, and Retinal vessels) show that our model outperforms other state-of-the-art (SOTA) methods. We also demonstrate that our decoder achieves better DICE scores than the SOTA CASCADE decoder with 80.8% fewer parameters and 82.3% fewer FLOPs. Our decoder can easily be used with other hierarchical encoders for general-purpose semantic and medical image segmentation tasks.	eess.IV	13 pages, IEEE/CVF Winter Conference on Applications of Computer   Vision (WACV 2024)
4	On the Convergence and Sample Complexity Analysis of Deep Q-Networks with $Œµ$-Greedy Exploration	Shuai Zhang,Hongkang Li,Meng Wang,Miao Liu,Pin-Yu Chen,Songtao Lu,Sijia Liu,Keerthiram Murugesan,Subhajit Chaudhury	This paper provides a theoretical understanding of Deep Q-Network (DQN) with the $\varepsilon$-greedy exploration in deep reinforcement learning. Despite the tremendous empirical achievement of the DQN, its theoretical characterization remains underexplored. First, the exploration strategy is either impractical or ignored in the existing analysis. Second, in contrast to conventional Q-learning algorithms, the DQN employs the target network and experience replay to acquire an unbiased estimation of the mean-square Bellman error (MSBE) utilized in training the Q-network. However, the existing theoretical analysis of DQNs lacks convergence analysis or bypasses the technical challenges by deploying a significantly overparameterized neural network, which is not computationally efficient. This paper provides the first theoretical convergence and sample complexity analysis of the practical setting of DQNs with $\epsilon$-greedy policy. We prove an iterative procedure with decaying $\epsilon$ converges to the optimal Q-value function geometrically. Moreover, a higher level of $\epsilon$ values enlarges the region of convergence but slows down the convergence, while the opposite holds for a lower level of $\epsilon$ values. Experiments justify our established theoretical insights on DQNs.	cs.LG	None
5	Astrophysical Parameter Inference on Accreting White Dwarf Binaries using Gravitational Waves	Sophia Yi,Shu Yan Lau,Kent Yagi,Phil Arras	Accreting binary white dwarf systems are among the sources expected to emanate gravitational waves that the Laser Interferometer Space Antenna (LISA) will detect. We investigate how accurately the binary parameters may be measured from LISA observations. We complement previous studies by performing our parameter estimation on binaries containing a low-mass donor with a thick, hydrogen-rich envelope. The evolution is followed from the early, pre-period minimum stage, in which the donor is non-degenerate, to a later, post-period minimum stage with a largely degenerate donor. We present expressions for the gravitational wave amplitude, frequency, and frequency derivative in terms of white dwarf parameters (masses, donor radius, etc.), where binary evolution is driven by gravitational wave radiation and accretion torques, and the donor radius and logarithmic change in radius ($\eta_{\rm d}$) due to mass loss are treated as model parameters. We then perform a Fisher analysis to reveal the accuracy of parameter measurements, using models from Modules for Experiments in Stellar Astrophysics (MESA) to estimate realistic fiducial values at which we evaluate the measurement errors. We find that the donor radius can be measured relatively well with LISA observations alone, while we can further measure the individual masses if we have an independent measurement of the luminosity distance from electromagnetic observations. When applied to the parameters of the recently-discovered white dwarf binary ZTF J0127+5258, our Fisher analysis suggests that we will be able to constrain the system's individual masses and donor radius using LISA's observations, given ZTF's measurement of the luminosity distance.	astro-ph.HE	Submitted to MNRAS
6	A Bayesian model calibration framework for stochastic compartmental models with both time-varying and time-invariant parameters	Brandon Robinson,Philippe Bisaillon,Jodi D. Edwards,Tetyana Kendzerska,Mohammad Khalil,Dominique Poirel,Abhijit Sarkar	We consider state and parameter estimation for compartmental models having both time-varying and time-invariant parameters. Though the described Bayesian computational framework is general, we look at a specific application to the susceptible-infectious-removed (SIR) model which describes a basic mechanism for the spread of infectious diseases through a system of coupled nonlinear differential equations. The SIR model consists of three states, namely, the three compartments, and two parameters which control the coupling among the states. The deterministic SIR model with time-invariant parameters has shown to be overly simplistic for modelling the complex long-term dynamics of diseases transmission. Recognizing that certain model parameters will naturally vary in time due to seasonal trends, non-pharmaceutical interventions, and other random effects, the estimation procedure must systematically permit these time-varying effects to be captured, without unduly introducing artificial dynamics into the system. To this end, we leverage the robustness of the Markov Chain Monte Carlo (MCMC) algorithm for the estimation of time-invariant parameters alongside nonlinear filters for the joint estimation of the system state and time-varying parameters. We demonstrate performance of the framework by first considering a series of examples using synthetic data, followed by an exposition on public health data collected in the province of Ontario.	cs.CE	None
7	Role of Multifidelity Data in Sequential Active Learning Materials Discovery Campaigns: Case Study of Electronic Bandgap	Ryan Jacobs,Philip E. Goins,Dane Morgan	Materials discovery and design typically proceeds through iterative evaluation (both experimental and computational) to obtain data, generally targeting improvement of one or more properties under one or more constraints (e.g., time or budget). However, there can be great variation in the quality and cost of different data, and when they are mixed together in what we here call multifidelity data the optimal approaches to their utilization are not established. It is therefore important to develop strategies to acquire and use multifidelity data to realize the most efficient iterative materials exploration. In this work, we assess the impact of using multifidelity data through mock demonstration of designing solar cell materials, using the electronic bandgap as the target property. We propose a new approach of using multifidelity data through leveraging machine learning models of both low- and high-fidelity data, where using predicted low-fidelity data as an input feature in the high-fidelity model can improve the impact of a multifidelity data approach. We show how tradeoffs of low- versus high-fidelity measurement cost and acquisition can impact the materials discovery process, and find that the use of multifidelity data has maximal impact on the materials discovery campaign when approximately five low-fidelity measurements per high-fidelity measurement are performed, and when the cost of low-fidelity measurements is approximately 5% or less than that of high-fidelity measurements. This work provides practical guidance and useful qualitative measures for improving materials discovery campaigns that involve multifidelity data.	cond-mat.mtrl-sci	None
8	iNVS: Repurposing Diffusion Inpainters for Novel View Synthesis	Yash Kant,Aliaksandr Siarohin,Michael Vasilkovsky,Riza Alp Guler,Jian Ren,Sergey Tulyakov,Igor Gilitschenski	We present a method for generating consistent novel views from a single source image. Our approach focuses on maximizing the reuse of visible pixels from the source image. To achieve this, we use a monocular depth estimator that transfers visible pixels from the source view to the target view. Starting from a pre-trained 2D inpainting diffusion model, we train our method on the large-scale Objaverse dataset to learn 3D object priors. While training we use a novel masking mechanism based on epipolar lines to further improve the quality of our approach. This allows our framework to perform zero-shot novel view synthesis on a variety of objects. We evaluate the zero-shot abilities of our framework on three challenging datasets: Google Scanned Objects, Ray Traced Multiview, and Common Objects in 3D. See our webpage for more details: https://yashkant.github.io/invs/	cs.CV	Accepted to SIGGRAPH Asia, 2023 (Conference Papers)
9	Generalized Staircase Codes with Arbitrary Bit Degree	Mohannad Shehadeh,Frank R. Kschischang,and Alvin Y. Sukmadji	We introduce a natural generalization of staircase codes in which each bit is protected by arbitrarily many component codewords rather than two. This enables powerful energy-efficient FEC based on iterative decoding of Hamming components.	cs.IT	Submitted to 2024 Optical Fiber Communication Conference (OFC 2024)
0	Conversational Challenges in AI-Powered Data Science: Obstacles, Needs, and Design Opportunities	Bhavya Chopra,Ananya Singha,Anna Fariha,Sumit Gulwani,Chris Parnin,Ashish Tiwari,Austin Z. Henley	Large Language Models (LLMs) are being increasingly employed in data science for tasks like data preprocessing and analytics. However, data scientists encounter substantial obstacles when conversing with LLM-powered chatbots and acting on their suggestions and answers. We conducted a mixed-methods study, including contextual observations, semi-structured interviews (n=14), and a survey (n=114), to identify these challenges. Our findings highlight key issues faced by data scientists, including contextual data retrieval, formulating prompts for complex tasks, adapting generated code to local environments, and refining prompts iteratively. Based on these insights, we propose actionable design recommendations, such as data brushing to support context selection, and inquisitive feedback loops to improve communications with AI-based assistants in data-science tools.	cs.HC	24 pages, 8 figures
1	Brainchop: Next Generation Web-Based Neuroimaging Application	Mohamed Masoud,Pratyush Reddy,Farfalla Hu,Sergey Plis	Performing volumetric image processing directly within the browser, particularly with medical data, presents unprecedented challenges compared to conventional backend tools. These challenges arise from limitations inherent in browser environments, such as constrained computational resources and the availability of frontend machine learning libraries. Consequently, there is a shortage of neuroimaging frontend tools capable of providing comprehensive end-to-end solutions for whole brain preprocessing and segmentation while preserving end-user data privacy and residency. In light of this context, we introduce Brainchop (http://www.brainchop.org) as a groundbreaking in-browser neuroimaging tool that enables volumetric analysis of structural MRI using pre-trained full-brain deep learning models, all without requiring technical expertise or intricate setup procedures. Beyond its commitment to data privacy, this frontend tool offers multiple features, including scalability, low latency, user-friendly operation, cross-platform compatibility, and enhanced accessibility. This paper outlines the processing pipeline of Brainchop and evaluates the performance of models across various software and hardware configurations. The results demonstrate the practicality of client-side processing for volumetric data, owing to the robust MeshNet architecture, even within the resource-constrained environment of web browsers.	cs.LG	None
2	MyriadAL: Active Few Shot Learning for Histopathology	Nico Schiavone,Jingyi Wang,Shuangzhi Li,Roger Zemp,Xingyu Li	Active Learning (AL) and Few Shot Learning (FSL) are two label-efficient methods which have achieved excellent results recently. However, most prior arts in both learning paradigms fail to explore the wealth of the vast unlabelled data. In this study, we address this issue in the scenario where the annotation budget is very limited, yet a large amount of unlabelled data for the target task is available. We frame this work in the context of histopathology where labelling is prohibitively expensive. To this end, we introduce an active few shot learning framework, Myriad Active Learning (MAL), including a contrastive-learning encoder, pseudo-label generation, and novel query sample selection in the loop. Specifically, we propose to massage unlabelled data in a self-supervised manner, where the obtained data representations and clustering knowledge form the basis to activate the AL loop. With feedback from the oracle in each AL cycle, the pseudo-labels of the unlabelled data are refined by optimizing a shallow task-specific net on top of the encoder. These updated pseudo-labels serve to inform and improve the active learning query selection process. Furthermore, we introduce a novel recipe to combine existing uncertainty measures and utilize the entire uncertainty list to reduce sample redundancy in AL. Extensive experiments on two public histopathology datasets show that MAL has superior test accuracy, macro F1-score, and label efficiency compared to prior works, and can achieve a comparable test accuracy to a fully supervised algorithm while labelling only 5% of the dataset.	cs.CV	9 pages, 2 figures, 6 tables
3	Single-shot error correction on toric codes with high-weight stabilizers	Yingjia Lin,Shilin Huang,Kenneth R. Brown	For quantum error correction codes the required number of measurement rounds typically increases with the code distance when measurements are faulty. Single-shot error correction allows for an error threshold with only one round of noisy syndrome measurements regardless of the code size. Here we implement single-shot check operators for toric codes. The single-shot checks are constructed by Gaussian elimination following Campbell [Campbell, 2019]. The single-shot check operators result in a sustainable threshold at 5.62% for an error model with noisy measurements, outperforming the conventional toric code check operators with multiple rounds of noisy measurement. The cost of the transformation is non-local high-weight stabilizer generators. We then consider a gate-based error model that leads to increased measurement error with stabilizer weight. Here we find no single-shot threshold behavior and instead find the code family will have an optimal code size for a fixed error rate. For this error model, the conventional check operators with multiple measurements yields a lower logical error rate.	quant-ph	None
4	Context-aware feature attribution through argumentation	Jinfeng Zhong,Elsa Negre	Feature attribution is a fundamental task in both machine learning and data analysis, which involves determining the contribution of individual features or variables to a model's output. This process helps identify the most important features for predicting an outcome. The history of feature attribution methods can be traced back to General Additive Models (GAMs), which extend linear regression models by incorporating non-linear relationships between dependent and independent variables. In recent years, gradient-based methods and surrogate models have been applied to unravel complex Artificial Intelligence (AI) systems, but these methods have limitations. GAMs tend to achieve lower accuracy, gradient-based methods can be difficult to interpret, and surrogate models often suffer from stability and fidelity issues. Furthermore, most existing methods do not consider users' contexts, which can significantly influence their preferences. To address these limitations and advance the current state-of-the-art, we define a novel feature attribution framework called Context-Aware Feature Attribution Through Argumentation (CA-FATA). Our framework harnesses the power of argumentation by treating each feature as an argument that can either support, attack or neutralize a prediction. Additionally, CA-FATA formulates feature attribution as an argumentation procedure, and each computation has explicit semantics, which makes it inherently interpretable. CA-FATA also easily integrates side information, such as users' contexts, resulting in more accurate predictions.	cs.LG	None
5	Breaking the Curse of Dimensionality in Deep Neural Networks by Learning Invariant Representations	Leonardo Petrini	Artificial intelligence, particularly the subfield of machine learning, has seen a paradigm shift towards data-driven models that learn from and adapt to data. This has resulted in unprecedented advancements in various domains such as natural language processing and computer vision, largely attributed to deep learning, a special class of machine learning models. Deep learning arguably surpasses traditional approaches by learning the relevant features from raw data through a series of computational layers.   This thesis explores the theoretical foundations of deep learning by studying the relationship between the architecture of these models and the inherent structures found within the data they process. In particular, we ask What drives the efficacy of deep learning algorithms and allows them to beat the so-called curse of dimensionality-i.e. the difficulty of generally learning functions in high dimensions due to the exponentially increasing need for data points with increased dimensionality? Is it their ability to learn relevant representations of the data by exploiting their structure? How do different architectures exploit different data structures? In order to address these questions, we push forward the idea that the structure of the data can be effectively characterized by its invariances-i.e. aspects that are irrelevant for the task at hand.   Our methodology takes an empirical approach to deep learning, combining experimental studies with physics-inspired toy models. These simplified models allow us to investigate and interpret the complex behaviors we observe in deep learning systems, offering insights into their inner workings, with the far-reaching goal of bridging the gap between theory and practice.	cs.LG	PhD Thesis @ EPFL
6	FLTrojan: Privacy Leakage Attacks against Federated Language Models Through Selective Weight Tampering	Md Rafi Ur Rashid,Vishnu Asutosh Dasu,Kang Gu,Najrin Sultana,Shagufta Mehnaz	Federated learning (FL) is becoming a key component in many technology-based applications including language modeling -- where individual FL participants often have privacy-sensitive text data in their local datasets. However, realizing the extent of privacy leakage in federated language models is not straightforward and the existing attacks only intend to extract data regardless of how sensitive or naive it is. To fill this gap, in this paper, we introduce two novel findings with regard to leaking privacy-sensitive user data from federated language models. Firstly, we make a key observation that model snapshots from the intermediate rounds in FL can cause greater privacy leakage than the final trained model. Secondly, we identify that privacy leakage can be aggravated by tampering with a model's selective weights that are specifically responsible for memorizing the sensitive training data. We show how a malicious client can leak the privacy-sensitive data of some other user in FL even without any cooperation from the server. Our best-performing method improves the membership inference recall by 29% and achieves up to 70% private data reconstruction, evidently outperforming existing attacks with stronger assumptions of adversary capabilities.	cs.CR	22 pages (including bibliography and Appendix), Submitted to USENIX   Security '24
7	Generation of high concentration nanobubbles based on friction tubes	Taekeun Yoo,Young-Ho Yoo,Suk-Joo Byun,A-Ram You,Chang-Hee Park,Dae-Hyun Choi,Eun-Hee Jun	Nanobubble-related technologies have been confirmed to be useful in various fields such as climate change and the environment as well as water-based industries such as water purification, crops, horticulture, medical care, bio, and sterilization. However, a method of mass production in real time enough to apply nano-bubbles to the industry has not yet been developed. We explored the mechanism of nano-bubble water generation by friction between water and walls and developed a tube device applying the shape of the flow path to maximize the friction in the fluid passing through the flow path. It also describes the case of real-time and low-power mass production of nanobubbles and its technical utility. We found that the friction of nanotubes alone can easily and quickly improve the production of nanobubbles with small particle size in real time; by increasing the shearing pressure while increasing the effective friction constant value, the particle size of nanobubbles can be smaller while increasing the particle concentration.	physics.flu-dyn	24 pages, 24 figures, 6 tables
8	Photo-induced modification and relaxation dynamics of Weyl-semimetals	Jakub ≈†ebesta,Oscar Gr√•n√§s	The use of ultrashort laser pulses to investigate the response of materials on femtosecond time-scales enables detailed tracking of charge, spin and lattice degrees of freedom. When pushing the limits of the experimental resolution, connection to theoretical modeling becomes increasingly important in order to infer causality relations. Weyl-semimetals is particular class of materials of recent focus due to the topological protection of the Weyl-nodes, resulting in a number of fundamentally interesting phenomena. In this work, we provide a first-principles framework based on time-dependent density-functional theory for tracking the distribution of Weyl-nodes in the Brillouin-zone following an excitation by a laser pulse. For the material TaAs, we show that residual shifts in the Weyl-Nodes' position and energy distribution is induced by a photo-excitation within femto-seconds, even when the laser-frequency is off-resonant with the Weyl-node. Further, we provide information about the relaxation pathway of the photoexcited bands through lattice vibrations.	cond-mat.mtrl-sci	None
9	Yin Yang Convolutional Nets: Image Manifold Extraction by the Analysis of Opposites	Augusto Seben da Rosa,Frederico Santos de Oliveira,Anderson da Silva Soares,Arnaldo Candido Junior	Computer vision in general presented several advances such as training optimizations, new architectures (pure attention, efficient block, vision language models, generative models, among others). This have improved performance in several tasks such as classification, and others. However, the majority of these models focus on modifications that are taking distance from realistic neuroscientific approaches related to the brain. In this work, we adopt a more bio-inspired approach and present the Yin Yang Convolutional Network, an architecture that extracts visual manifold, its blocks are intended to separate analysis of colors and forms at its initial layers, simulating occipital lobe's operations. Our results shows that our architecture provides State-of-the-Art efficiency among low parameter architectures in the dataset CIFAR-10. Our first model reached 93.32\% test accuracy, 0.8\% more than the older SOTA in this category, while having 150k less parameters (726k in total). Our second model uses 52k parameters, losing only 3.86\% test accuracy. We also performed an analysis on ImageNet, where we reached 66.49\% validation accuracy with 1.6M parameters. We make the code publicly available at: https://github.com/NoSavedDATA/YinYang_CNN.	cs.CV	12 pages, 5 tables and 6 figures
0	PreWoMe: Exploiting Presuppositions as Working Memory for Long Form Question Answering	Wookje Han,Jinsol Park,Kyungjae Lee	Information-seeking questions in long-form question answering (LFQA) often prove misleading due to ambiguity or false presupposition in the question. While many existing approaches handle misleading questions, they are tailored to limited questions, which are insufficient in a real-world setting with unpredictable input characteristics. In this work, we propose PreWoMe, a unified approach capable of handling any type of information-seeking question. The key idea of PreWoMe involves extracting presuppositions in the question and exploiting them as working memory to generate feedback and action about the question. Our experiment shows that PreWoMe is effective not only in tackling misleading questions but also in handling normal ones, thereby demonstrating the effectiveness of leveraging presuppositions, feedback, and action for real-world QA settings.	cs.CL	11 pages 3 figures, Accepted to EMNLP 2023 (short)
1	Clinfo.ai: An Open-Source Retrieval-Augmented Large Language Model System for Answering Medical Questions using Scientific Literature	Alejandro Lozano,Scott L Fleming,Chia-Chun Chiang,Nigam Shah	The quickly-expanding nature of published medical literature makes it challenging for clinicians and researchers to keep up with and summarize recent, relevant findings in a timely manner. While several closed-source summarization tools based on large language models (LLMs) now exist, rigorous and systematic evaluations of their outputs are lacking. Furthermore, there is a paucity of high-quality datasets and appropriate benchmark tasks with which to evaluate these tools. We address these issues with four contributions: we release Clinfo.ai, an open-source WebApp that answers clinical questions based on dynamically retrieved scientific literature; we specify an information retrieval and abstractive summarization task to evaluate the performance of such retrieval-augmented LLM systems; we release a dataset of 200 questions and corresponding answers derived from published systematic reviews, which we name PubMed Retrieval and Synthesis (PubMedRS-200); and report benchmark results for Clinfo.ai and other publicly available OpenQA systems on PubMedRS-200.	cs.IR	Preprint of an article published in Pacific Symposium on Biocomputing   copyright 2024 World Scientific Publishing Co., Singapore,   http://psb.stanford.edu/
2	Positive Almost-Sure Termination -- Complexity and Proof Rules	Rupak Majumdar,V. R. Sathiyanarayana	We study the recursion-theoretic complexity of Positive Almost-Sure Termination ($\mathsf{PAST}$) in an imperative programming language with rational variables, bounded nondeterministic choice, and discrete probabilistic choice. A program terminates positive almost-surely if, for every scheduler, the program terminates almost-surely and the expected runtime to termination is finite. We show that $\mathsf{PAST}$ for our language is complete for the (lightface) co-analytic sets ($\Pi^1_1$-complete) - this is in contrast to the related notions of Almost-Sure Termination ($\mathsf{AST}$) and Bounded Termination ($\mathsf{BAST}$), both of which are arithmetical ($\Pi^0_2$ and $\Sigma^0_2$ complete respectively).   Our upper bound implies an effective procedure to reduce reasoning about probabilistic termination to non-probabilistic fair termination in a model with bounded nondeterminism, and to simple program termination in models with unbounded nondeterminism. Our lower bound shows the opposite: for every program with unbounded nondeterministic choice, there is an effectively computable probabilistic program with bounded choice such that the original program is terminating $iff$ the transformed program is $\mathsf{PAST}$.   We show that every program has an effectively computable normal form, in which each probabilistic choice either continues or terminates execution. For normal form programs, we provide the first sound and complete proof rule for $\mathsf{PAST}$. Our proof rule uses transfinite ordinals. We show that reasoning about $\mathsf{PAST}$ requires transfinite ordinals up to $\omega^{CK}_1$; thus, existing techniques for probabilistic termination based on ranking supermartingales that map program states to reals do not suffice to reason about $\mathsf{PAST}$.	cs.PL	None
3	ROM-Based Stochastic Optimization for a Continuous Manufacturing Process	Raul Cruz-Oliver,Luis Monzon,Edgar Ramirez-Laboreo,Jose-Manuel Rodriguez-Fortun	This paper proposes a model-based optimization method for the production of automotive seals in an extrusion process. The high production throughput, coupled with quality constraints and the inherent uncertainty of the process, encourages the search for operating conditions that minimize nonconformities. The main uncertainties arise from the process variability and from the raw material itself. The proposed method, based on Bayesian optimization, takes these factors into account and obtains a robust set of process parameters. Due to the high computational cost and complexity of performing detailed simulations, a reduced order model is used to address the optimization. The proposal has been evaluated in a virtual environment where it is shown that the performance of the solution found minimizes the effects of process uncertainties.	eess.SY	7 pages, 8 figures
4	A Language Model with Limited Memory Capacity Captures Interference in Human Sentence Processing	William Timkey,Tal Linzen	Two of the central factors believed to underpin human sentence processing difficulty are expectations and retrieval from working memory. A recent attempt to create a unified cognitive model integrating these two factors relied on the parallels between the self-attention mechanism of transformer language models and cue-based retrieval theories of working memory in human sentence processing (Ryu and Lewis 2021). While Ryu and Lewis show that attention patterns in specialized attention heads of GPT-2 are consistent with similarity-based interference, a key prediction of cue-based retrieval models, their method requires identifying syntactically specialized attention heads, and makes the cognitively implausible assumption that hundreds of memory retrieval operations take place in parallel. In the present work, we develop a recurrent neural language model with a single self-attention head, which more closely parallels the memory system assumed by cognitive theories. We show that our model's single attention head captures semantic and syntactic interference effects observed in human experiments.	cs.CL	To appear in Findings of the Association for Computational   Linguistics: EMNLP 2023
5	Context-aware explainable recommendations over knowledge graphs	Jinfeng Zhong,Elsa Negre	Knowledge graphs contain rich semantic relationships related to items and incorporating such semantic relationships into recommender systems helps to explore the latent connections of items, thus improving the accuracy of prediction and enhancing the explainability of recommendations. However, such explainability is not adapted to users' contexts, which can significantly influence their preferences. In this work, we propose CA-KGCN (Context-Aware Knowledge Graph Convolutional Network), an end-to-end framework that can model users' preferences adapted to their contexts and can incorporate rich semantic relationships in the knowledge graph related to items. This framework captures users' attention to different factors: contexts and features of items. More specifically, the framework can model users' preferences adapted to their contexts and provide explanations adapted to the given context. Experiments on three real-world datasets show the effectiveness of our framework: modeling users' preferences adapted to their contexts and explaining the recommendations generated.	cs.IR	None
6	IA Para el Mantenimiento Predictivo en Canteras: Modelado	Fernando Marcos,Rodrigo Tamaki,Mateo C√°mara,Virginia Yag√ºe,Jos√© Luis Blanco	Dependence on raw materials, especially in the mining sector, is a key part of today's economy. Aggregates are vital, being the second most used raw material after water. Digitally transforming this sector is key to optimizing operations. However, supervision and maintenance (predictive and corrective) are challenges little explored in this sector, due to the particularities of the sector, machinery and environmental conditions. All this, despite the successes achieved in other scenarios in monitoring with acoustic and contact sensors. We present an unsupervised learning scheme that trains a variational autoencoder model on a set of sound records. This is the first such dataset collected during processing plant operations, containing information from different points of the processing line. Our results demonstrate the model's ability to reconstruct and represent in latent space the recorded sounds, the differences in operating conditions and between different equipment. In the future, this should facilitate the classification of sounds, as well as the detection of anomalies and degradation patterns in the operation of the machinery.	eess.AS	10 pages, in Spanish language, 5 figures. Presented in Tecniacustica   2023 conference (Cuenca, Spain)
7	Pix2HDR -- A pixel-wise acquisition and deep learning-based synthesis approach for high-speed HDR videos	Caixin Wang,Jie Zhang,Matthew A. Wilson,Ralph Etienne-Cummings	Accurately capturing dynamic scenes with wide-ranging motion and light intensity is crucial for many vision applications. However, acquiring high-speed high dynamic range (HDR) video is challenging because the camera's frame rate restricts its dynamic range. Existing methods sacrifice speed to acquire multi-exposure frames. Yet, misaligned motion in these frames can still pose complications for HDR fusion algorithms, resulting in artifacts. Instead of frame-based exposures, we sample the videos using individual pixels at varying exposures and phase offsets. Implemented on a pixel-wise programmable image sensor, our sampling pattern simultaneously captures fast motion at a high dynamic range. We then transform pixel-wise outputs into an HDR video using end-to-end learned weights from deep neural networks, achieving high spatiotemporal resolution with minimized motion blurring. We demonstrate aliasing-free HDR video acquisition at 1000 FPS, resolving fast motion under low-light conditions and against bright backgrounds - both challenging conditions for conventional cameras. By combining the versatility of pixel-wise sampling patterns with the strength of deep neural networks at decoding complex scenes, our method greatly enhances the vision system's adaptability and performance in dynamic conditions.	eess.IV	14 pages, 14 figures
8	Codebook-based Uplink Transmission Enhancement in 5G Advanced: Sub-band Precoding	Liu Cao,Yahia Shabara,Parisa Cheraghi	The transformative enhancements of fifth-generation (5G) mobile devices bring about new challenges to achieve better uplink (UL) performance. Particularly, in codebook-based transmission, the wide-band (WB) precoding and the legacy UL codebook may become main bottlenecks for higher efficient data transmission. In this paper, we investigate the codebook-based UL single-layer transmission performance using fully coherent antenna ports in the context of sub-band (SB) precoding. We analyze the SB precoder selection criteria and design an UL codebook used for SB precoding by increasing the number of relative phase shifts of each port. Via link-level simulations, we verify that the UL SB precoding can improve up to 2 dB performance gain in terms of the block error rate (BLER) compared with the UL WB precoding which is the current UL precoding scheme. We also show that UL performance gain is sensitive to the SB size selection as well as the relative phase shift diversity.	cs.IT	This work has been accepted by IEEE VCC 2023. 5 pages, 7 figures
9	Analyzing Disparity and Temporal Progression of Internet Quality through Crowdsourced Measurements with Bias-Correction	Hyeongseong Lee,Udit Paul,Arpit Gupta,Elizabeth Belding,Mengyang Gu	Crowdsourced speedtest measurements are an important tool for studying internet performance from the end user perspective. Nevertheless, despite the accuracy of individual measurements, simplistic aggregation of these data points is problematic due to their intrinsic sampling bias. In this work, we utilize a dataset of nearly 1 million individual Ookla Speedtest measurements, correlate each datapoint with 2019 Census demographic data, and develop new methods to present a novel analysis to quantify regional sampling bias and the relationship of internet performance to demographic profile. We find that the crowdsourced Ookla Speedtest data points contain significant sampling bias across different census block groups based on a statistical test of homogeneity. We introduce two methods to correct the regional bias by the population of each census block group. Whereas the sampling bias leads to a small discrepancy in the overall cumulative distribution function of internet speed in a city between estimation from original samples and bias-corrected estimation, the discrepancy is much smaller compared to the size of the sampling heterogeneity across regions. Further, we show that the sampling bias is strongly associated with a few demographic variables, such as income, education level, age, and ethnic distribution. Through regression analysis, we find that regions with higher income, younger populations, and lower representation of Hispanic residents tend to measure faster internet speeds along with substantial collinearity amongst socioeconomic attributes and ethnic composition. Finally, we find that average internet speed increases over time based on both linear and nonlinear analysis from state space models, though the regional sampling bias may result in a small overestimation of the temporal increase of internet speed.	stat.AP	None
0	Can You Follow Me? Testing Situational Understanding in ChatGPT	Chenghao Yang,Allyson Ettinger	"Understanding sentence meanings and updating information states appropriately across time -- what we call ""situational understanding"" (SU) -- is a critical ability for human-like AI agents. SU is essential in particular for chat models, such as ChatGPT, to enable consistent, coherent, and effective dialogue between humans and AI. Previous works have identified certain SU limitations in non-chatbot Large Language models (LLMs), but the extent and causes of these limitations are not well understood, and capabilities of current chat-based models in this domain have not been explored. In this work we tackle these questions, proposing a novel synthetic environment for SU testing which allows us to do controlled and systematic testing of SU in chat-oriented models, through assessment of models' ability to track and enumerate environment states. Our environment also allows for close analysis of dynamics of model performance, to better understand underlying causes for performance patterns. We apply our test to ChatGPT, the state-of-the-art chatbot, and find that despite the fundamental simplicity of the task, the model's performance reflects an inability to retain correct environment states across time. Our follow-up analyses suggest that performance degradation is largely because ChatGPT has non-persistent in-context memory (although it can access the full dialogue history) and it is susceptible to hallucinated updates -- including updates that artificially inflate accuracies. Our findings suggest overall that ChatGPT is not currently equipped for robust tracking of situation states, and that trust in the impressive dialogue performance of ChatGPT comes with risks. We release the codebase for reproducing our test environment, as well as all prompts and API responses from ChatGPT, at https://github.com/yangalan123/SituationalTesting."	cs.CL	EMNLP 2023 Main Paper (Camera Ready)
1	The renormalization of the shell-model GT operator starting from the effective field theory for nuclear systems	L. Coraggio,N. Itaco,G. De Gregorio,A. Gargano,Z. H. Cheng,Y. Z. Ma,F. R. Xu,M. Viviani	For the first time, we approach in this work the problem of the renormalization of the GT-decay operator for nuclear shell-model calculations starting from a nuclear Hamiltonian and electroweak currents derived consistently by way of the chiral perturbation theory. These are the inputs we need to construct effective shell-model Hamiltonians and decay operators with the many-body perturbation theory. The goal is to assess the role of both electroweak currents and many-body correlations as the origins of the well-known problem of the quenching of the axial coupling constant gA. To this end, the calculation of observables related to the GT transitions has been performed for several nuclear systems outside the 40Ca and 56Ni closed cores and compared with the available data.	nucl-th	15 pages, 13 figures, 3 tables, to be published in Physical Review C
2	GenKIE: Robust Generative Multimodal Document Key Information Extraction	Panfeng Cao,Ye Wang,Qiang Zhang,Zaiqiao Meng	Key information extraction (KIE) from scanned documents has gained increasing attention because of its applications in various domains. Although promising results have been achieved by some recent KIE approaches, they are usually built based on discriminative models, which lack the ability to handle optical character recognition (OCR) errors and require laborious token-level labelling. In this paper, we propose a novel generative end-to-end model, named GenKIE, to address the KIE task. GenKIE is a sequence-to-sequence multimodal generative model that utilizes multimodal encoders to embed visual, layout and textual features and a decoder to generate the desired output. Well-designed prompts are leveraged to incorporate the label semantics as the weakly supervised signals and entice the generation of the key information. One notable advantage of the generative model is that it enables automatic correction of OCR errors. Besides, token-level granular annotation is not required. Extensive experiments on multiple public real-world datasets show that GenKIE effectively generalizes over different types of documents and achieves state-of-the-art results. Our experiments also validate the model's robustness against OCR errors, making GenKIE highly applicable in real-world scenarios.	cs.CL	Accepted by EMNLP 2023, Findings paper
3	Functional estimation in high-dimensional and infinite-dimensional models	Vladimir Koltchinskii,Minghao Li	Let ${\mathcal P}$ be a family of probability measures on a measurable space $(S,{\mathcal A}).$ Given a Banach space $E,$ a functional $f:E\mapsto {\mathbb R}$ and a mapping $\theta: {\mathcal P}\mapsto E,$ our goal is to estimate $f(\theta(P))$ based on i.i.d. observations $X_1,\dots, X_n\sim P, P\in {\mathcal P}.$ In particular, if ${\mathcal P}=\{P_{\theta}: \theta\in \Theta\}$ is an identifiable statistical model with parameter set $\Theta\subset E,$ one can consider the mapping $\theta(P)=\theta$ for $P\in {\mathcal P}, P=P_{\theta},$ resulting in a problem of estimation of $f(\theta)$ based on i.i.d. observations $X_1,\dots, X_n\sim P_{\theta}, \theta\in \Theta.$ Given a smooth functional $f$ and estimators $\hat \theta_n(X_1,\dots, X_n), n\geq 1$ of $\theta(P),$ we use these estimators, the sample split and the Taylor expansion of $f(\theta(P))$ of a proper order to construct estimators $T_f(X_1,\dots, X_n)$ of $f(\theta(P)).$ For these estimators and for a functional $f$ of smoothness $s\geq 1,$ we prove upper bounds on the $L_p$-errors of estimator $T_f(X_1,\dots, X_n)$ under certain moment assumptions on the base estimators $\hat \theta_n.$ We study the performance of estimators $T_f(X_1,\dots, X_n)$ in several concrete problems, showing their minimax optimality and asymptotic efficiency. In particular, this includes functional estimation in high-dimensional models with many low dimensional components, functional estimation in high-dimensional exponential families and estimation of functionals of covariance operators in infinite-dimensional subgaussian models.	math.ST	None
4	Octopus: A Multitask Model and Toolkit for Arabic Natural Language Generation	AbdelRahim Elmadany,El Moatez Billah Nagoudi,Muhammad Abdul-Mageed	Understanding Arabic text and generating human-like responses is a challenging endeavor. While many researchers have proposed models and solutions for individual problems, there is an acute shortage of a comprehensive Arabic natural language generation toolkit that is capable of handling a wide range of tasks. In this work, we present a novel Arabic text-to-text Transformer model, namely AraT5v2. Our new model is methodically trained on extensive and diverse data, utilizing an extended sequence length of 2,048 tokens. We explore various pretraining strategies including unsupervised, supervised, and joint pertaining, under both single and multitask settings. Our models outperform competitive baselines with large margins. We take our work one step further by developing and publicly releasing Octopus, a Python-based package and command-line toolkit tailored for eight Arabic generation tasks all exploiting a single model. We release the models and the toolkit on our public repository.	cs.CL	None
5	Jacobi-Lie Models and Supergravity Equations	Ladislav Hlavat√Ω,Ivo Petr	We investigate three- and four-dimensional sigma models corresponding to six-dimensional Leibniz algebras with $f_b{}^{ba}\neq 0$, $Z^a=0$. We show that these algebras are plural one to another and, moreover, to an algebra with $f_b{}^{ba}= 0$, $Z^a=0$.   It was conjectured that these models should satisfy Generalized Supergravity Equations. We have found examples of such models. On the other hand, we show that there are also models corresponding to algebras with $f_b{}^{ba}\neq 0$, $Z^a=0$ that satisfy usual Supergravity Equations, i.e. vanishing beta function equations.	hep-th	None
6	Online Thermal Field Prediction for Metal Additive Manufacturing of Thin Walls	Yifan Tang,M. Rahmani Dehaghani,Pouyan Sajadi,Shahriar Bakrani Balani,Akshay Dhalpe,Suraj Panicker,Di Wu,Eric Coatanea,G. Gary Wang	This paper aims to study a practical issue in metal AM, i.e., how to predict the thermal field of yet-to-print parts online when only a few sensors are available. This work proposes an online thermal field prediction method using mapping and reconstruction, which could be integrated into a metal AM process for online performance control. Based on the similarity of temperature curves (curve segments of a temperature profile of one point), the thermal field mapping applies an artificial neural network to estimate the temperature curves of points on the yet-to-print layer from measured temperatures of certain points on the previously printed layer. With measured/predicted temperature profiles of several points on the same layer, the thermal field reconstruction proposes a reduced order model (ROM) to construct the temperature profiles of all points on the same layer, which could be used to build the temperature field of the entire layer. The training of ROM is performed with an extreme learning machine (ELM) for computational efficiency. Fifteen wire arc AM experiments and nine simulations are designed for thin walls with a fixed length and unidirectional printing of each layer. The test results indicate that the proposed prediction method could construct the thermal field of a yet-to-print layer within 0.1 seconds on a low-cost desktop. Meanwhile, the method has acceptable generalization capability in most cases from lower layers to higher layers in the same simulation and from one simulation to a new simulation on different AM process parameters. More importantly, after fine-tuning the proposed method with limited experimental data, the relative errors of all predicted temperature profiles on a new experiment are sufficiently small, demonstrating the applicability and generalization of the proposed thermal field prediction method in online applications for metal AM.	cs.LG	36 pages, 26 figures, 5 tables
7	Dwindling Surface Cooling of a Rotating Jovian Planet Leads to a Convection Zone that Grows to a Finite Depth	Bradley W. Hindman,J. R. Fuentes	"Recent measurements of Jupiter's gravitational field (by Juno) and seismology of Saturn's rings (by Cassini) strongly suggest that both planets have a stably-stratified core that still possesses a primordial gradient in the concentration of heavy elements. The existence of such a ""diffusely"" stratified core has been a surprise as it was long expected that the Jovian planets should be fully convective and hence fully mixed. A vigorous zone of convection, driven by surface cooling, forms at the surface and deepens through entrainment of fluid from underneath. In fact, it was believed that this convection zone should grow so rapidly that the entire planet would be consumed in less than a million years. Here we suggest that two processes, acting in concert, present a solution to this puzzle. All of the giant planets are rapidly rotating and have a cooling rate that declines with time. Both of these effects reduce the rate of fluid entrainment into the convection zone. Through the use of an analytic prescription of entrainment in giant planets, we demonstrate that these two effects, rotation and dwindling surface cooling, result in a convection zone which initially grows but eventually stalls. The depth to which the convective interface asymptotes depends on the rotation rate and on the stratification of the stable interior. Conversely, in a nonrotating planet, or in a planet that maintains a higher level of cooling than current models suggest, the convection zone deepens forever, eventually spanning the entire planet."	astro-ph.EP	7 pages, 2 figures, accepted for publication by Astrophysical Journal   Letters
8	A Performance-Portable SYCL Implementation of CRK-HACC for Exascale	Esteban M. Rangel,S. John Pennycook,Adrian Pope,Nicholas Frontiere,Zhiqiang Ma,Varsha Madananth	The first generation of exascale systems will include a variety of machine architectures, featuring GPUs from multiple vendors. As a result, many developers are interested in adopting portable programming models to avoid maintaining multiple versions of their code. It is necessary to document experiences with such programming models to assist developers in understanding the advantages and disadvantages of different approaches.   To this end, this paper evaluates the performance portability of a SYCL implementation of a large-scale cosmology application (CRK-HACC) running on GPUs from three different vendors: AMD, Intel, and NVIDIA. We detail the process of migrating the original code from CUDA to SYCL and show that specializing kernels for specific targets can greatly improve performance portability without significantly impacting programmer productivity. The SYCL version of CRK-HACC achieves a performance portability of 0.96 with a code divergence of almost 0, demonstrating that SYCL is a viable programming model for performance-portable applications.	cs.PF	12 pages, 13 figures, 2023 International Workshop on Performance,   Portability & Productivity in HPC
9	19 Parameters Is All You Need: Tiny Neural Networks for Particle Physics	Alexander Bogatskiy,Timothy Hoffman,Jan T. Offermann	As particle accelerators increase their collision rates, and deep learning solutions prove their viability, there is a growing need for lightweight and fast neural network architectures for low-latency tasks such as triggering. We examine the potential of one recent Lorentz- and permutation-symmetric architecture, PELICAN, and present its instances with as few as 19 trainable parameters that outperform generic architectures with tens of thousands of parameters when compared on the binary classification task of top quark jet tagging.	hep-ph	"5 pages, submitted to the ""Machine Learning and the Physical   Sciences"" NeurIPS 2023 Workshop"
0	Alquist 5.0: Dialogue Trees Meet Generative Models. A Novel Approach for Enhancing SocialBot Conversations	Ond≈ôej Kobza,Jan ƒåuhel,Tommaso Gargiani,David Herel,Petr Marek	We present our SocialBot -- Alquist~5.0 -- developed for the Alexa Prize SocialBot Grand Challenge~5. Building upon previous versions of our system, we introduce the NRG Barista and outline several innovative approaches for integrating Barista into our SocialBot, improving the overall conversational experience. Additionally, we extend our SocialBot to support multimodal devices. This paper offers insights into the development of Alquist~5.0, which meets evolving user expectations while maintaining empathetic and knowledgeable conversational abilities across diverse topics.	cs.LG	None
1	Precise Cosmological Constraints from BOSS Galaxy Clustering with a Simulation-Based Emulator of the Wavelet Scattering Transform	Georgios Valogiannis,Sihan Yuan,Cora Dvorkin	We perform a reanalysis of the BOSS CMASS DR12 galaxy dataset using a simulation-based emulator for the Wavelet Scattering Transform (WST) coefficients. Moving beyond our previous works, which laid the foundation for the first galaxy clustering application of this estimator, we construct a neural net-based emulator for the cosmological dependence of the WST coefficients and the 2-point correlation function multipoles, trained from the state-of-the-art suite of \textsc{AbacusSummit} simulations combined with a flexible Halo Occupation Distribution (HOD) galaxy model. In order to confirm the accuracy of our pipeline, we subject it to a series of thorough internal and external mock parameter recovery tests, before applying it to reanalyze the CMASS observations in the redshift range $0.46<z<0.57$. We find that a joint WST + 2-point correlation function likelihood analysis allows us to obtain marginalized 1$\sigma$ errors on the $\Lambda$CDM parameters that are tighter by a factor of $2.5-6$, compared to the 2-point correlation function, and by a factor of $1.4-2.5$ compared to the WST-only results. This corresponds to a competitive $0.9\%$, $2.3\%$ and $1\%$ level of determination for parameters $\omega_c$, $\sigma_8$ $\&$ $n_s$, respectively, and also to a $0.7\%$ $\&$ $2.5 \%$ constraint on derived parameters h and $f(z)\sigma_8(z)$, in agreement with the \textit{Planck} 2018 results. Our results reaffirm the constraining power of the WST and highlight the exciting prospect of employing higher-order statistics in order to fully exploit the power of upcoming Stage-IV spectroscopic observations.	astro-ph.CO	25 pages, 17 figures, 4 tables
2	Wakening Past Concepts without Past Data: Class-Incremental Learning from Online Placebos	Yaoyao Liu,Yingying Li,Bernt Schiele,Qianru Sun	"Not forgetting old class knowledge is a key challenge for class-incremental learning (CIL) when the model continuously adapts to new classes. A common technique to address this is knowledge distillation (KD), which penalizes prediction inconsistencies between old and new models. Such prediction is made with almost new class data, as old class data is extremely scarce due to the strict memory limitation in CIL. In this paper, we take a deep dive into KD losses and find that ""using new class data for KD"" not only hinders the model adaption (for learning new classes) but also results in low efficiency for preserving old class knowledge. We address this by ""using the placebos of old classes for KD"", where the placebos are chosen from a free image stream, such as Google Images, in an automatical and economical fashion. To this end, we train an online placebo selection policy to quickly evaluate the quality of streaming images (good or bad placebos) and use only good ones for one-time feed-forward computation of KD. We formulate the policy training process as an online Markov Decision Process (MDP), and introduce an online learning algorithm to solve this MDP problem without causing much computation costs. In experiments, we show that our method 1) is surprisingly effective even when there is no class overlap between placebos and original old class data, 2) does not require any additional supervision or memory budget, and 3) significantly outperforms a number of top-performing CIL methods, in particular when using lower memory budgets for old class exemplars, e.g., five exemplars per class."	cs.CV	Accepted to WACV 2024. Code:   https://github.com/yaoyao-liu/online-placebos
3	Granular packing simulation protocols: tap, press and relax	A. P. Santos,Ishan Srivastava,Leonardo E. Silbert,Jeremy B. Lechman,Gary S. Grest	Granular matter takes many paths to pack. Gentle compression, compaction or repetitive tapping can happen in natural and industrial processes. The path influences the packing microstructure, and thus macroscale properties, particularly for frictional grains. We perform discrete element modeling simulations to construct packings of frictional spheres implementing a range of stress-controlled protocols with 3D periodic boundary conditions. A volume-controlled over-compression method is compared to four stress-controlled methods, including over-compression and release, gentle under-compression and cyclical compression and release. The packing volume fraction of each method depends on the pressure, initial kinetic energy and protocol parameters. A non-monotonic pressure dependence in the volume fraction, but not the coordination number occurs when dilute particles initialized with a non-zero kinetic energy are compressed, but can be reduced with the inclusion of drag. The fraction of frictional contacts correlates with the volume fraction minimum. Packings were cyclically compressed 1000 times. Response to compression depends on pressure; low pressure packings have a constant volume fraction regime, while high pressure packings continue to get dense with number of cycles. The capability of stress-controlled, bulk-like particle simulations to capture different protocols is showcased, and the ability to pack at low pressures demonstrates unexpected behavior.	cond-mat.soft	None
4	Compressed representation of brain genetic transcription	James K Ruffle,Henry Watkins,Robert J Gray,Harpreet Hyare,Michel Thiebaut de Schotten,Parashkev Nachev	The architecture of the brain is too complex to be intuitively surveyable without the use of compressed representations that project its variation into a compact, navigable space. The task is especially challenging with high-dimensional data, such as gene expression, where the joint complexity of anatomical and transcriptional patterns demands maximum compression. Established practice is to use standard principal component analysis (PCA), whose computational felicity is offset by limited expressivity, especially at great compression ratios. Employing whole-brain, voxel-wise Allen Brain Atlas transcription data, here we systematically compare compressed representations based on the most widely supported linear and non-linear methods-PCA, kernel PCA, non-negative matrix factorization (NMF), t-stochastic neighbour embedding (t-SNE), uniform manifold approximation and projection (UMAP), and deep auto-encoding-quantifying reconstruction fidelity, anatomical coherence, and predictive utility with respect to signalling, microstructural, and metabolic targets. We show that deep auto-encoders yield superior representations across all metrics of performance and target domains, supporting their use as the reference standard for representing transcription patterns in the human brain.	cs.LG	21 pages, 5 main figures, 1 supplementary figure
5	Towards long-tailed, multi-label disease classification from chest X-ray: Overview of the CXR-LT challenge	Gregory Holste,Yiliang Zhou,Song Wang,Ajay Jaiswal,Mingquan Lin,Sherry Zhuge,Yuzhe Yang,Dongkyun Kim,Trong-Hieu Nguyen-Mau,Minh-Triet Tran,Jaehyup Jeong,Wongi Park,Jongbin Ryu,Feng Hong,Arsh Verma,Yosuke Yamagishi,Changhyun Kim,Hyeryeong Seo,Myungjoo Kang,Leo Anthony Celi,Zhiyong Lu,Ronald M. Summers,George Shih,Zhangyang Wang,Yifan Peng	"Many real-world image recognition problems, such as diagnostic medical imaging exams, are ""long-tailed"" $\unicode{x2013}$ there are a few common findings followed by many more relatively rare conditions. In chest radiography, diagnosis is both a long-tailed and multi-label problem, as patients often present with multiple findings simultaneously. While researchers have begun to study the problem of long-tailed learning in medical image recognition, few have studied the interaction of label imbalance and label co-occurrence posed by long-tailed, multi-label disease classification. To engage with the research community on this emerging topic, we conducted an open challenge, CXR-LT, on long-tailed, multi-label thorax disease classification from chest X-rays (CXRs). We publicly release a large-scale benchmark dataset of over 350,000 CXRs, each labeled with at least one of 26 clinical findings following a long-tailed distribution. We synthesize common themes of top-performing solutions, providing practical recommendations for long-tailed, multi-label medical image classification. Finally, we use these insights to propose a path forward involving vision-language foundation models for few- and zero-shot disease classification."	cs.CV	None
6	Locally Differentially Private Document Generation Using Zero Shot Prompting	Saiteja Utpala,Sara Hooker,Pin Yu Chen	Numerous studies have highlighted the privacy risks associated with pretrained large language models. In contrast, our research offers a unique perspective by demonstrating that pretrained large language models can effectively contribute to privacy preservation. We propose a locally differentially private mechanism called DP-Prompt, which leverages the power of pretrained large language models and zero-shot prompting to counter author de-anonymization attacks while minimizing the impact on downstream utility. When DP-Prompt is used with a powerful language model like ChatGPT (gpt-3.5), we observe a notable reduction in the success rate of de-anonymization attacks, showing that it surpasses existing approaches by a considerable margin despite its simpler design. For instance, in the case of the IMDB dataset, DP-Prompt (with ChatGPT) perfectly recovers the clean sentiment F1 score while achieving a 46\% reduction in author identification F1 score against static attackers and a 26\% reduction against adaptive attackers. We conduct extensive experiments across six open-source large language models, ranging up to 7 billion parameters, to analyze various effects of the privacy-utility tradeoff.	cs.CL	Accepted at EMNLP 2023 (Findings)
7	The New Physics Case for Beam-Dump Experiments with Accelerated Muon Beams	Cari Cesarotti,Rikab Gambhir	As the field examines a future muon collider as a possible successor to the LHC, we must consider how to fully utilize not only the high-energy particle collisions, but also any lower-energy staging facilities necessary in the R&D process. An economical and efficient possibility is to use the accelerated muon beam from either the full experiment or from cooling and acceleration tests in beam-dump experiments.Beam-dump experiments are complementary to the main collider as they achieve sensitivity to very small couplings with minimal instrumentation. We demonstrate the utility of muon beam-dump experiments for new physics searches at energies from 10 GeV to 5 TeV. We find that, even at low energies like those accessible at staging or demonstrator facilities, it is possible to probe new regions of parameter space for a variety of generic BSM models, including muonphilic, leptophilic, $L_\mu - L_\tau$, and dark photon scenarios. Such experiments could therefore provide opportunities for discovery of new physics well before the completion of the full multi-TeV collider.	hep-ph	22 pages and 10 figures + 11 pages and 10 figures
8	Complex Image Generation SwinTransformer Network for Audio Denoising	Youshan Zhang,Jialu Li	Achieving high-performance audio denoising is still a challenging task in real-world applications. Existing time-frequency methods often ignore the quality of generated frequency domain images. This paper converts the audio denoising problem into an image generation task. We first develop a complex image generation SwinTransformer network to capture more information from the complex Fourier domain. We then impose structure similarity and detailed loss functions to generate high-quality images and develop an SDR loss to minimize the difference between denoised and clean audios. Extensive experiments on two benchmark datasets demonstrate that our proposed model is better than state-of-the-art methods.	cs.SD	None
9	Precise Distributed Satellite Navigation: Differential GPS with Sensor-Coupling for Integer Ambiguity Resolution	Samuel Y W Low,Simone D'Amico	Precise relative navigation is a critical enabler for distributed satellites to achieve new mission objectives impossible for a monolithic spacecraft. Carrier phase differential GPS (CDGPS) with integer ambiguity resolution (IAR) is a promising means of achieving cm-level accuracy for high-precision Rendezvous, Proximity-Operations and Docking (RPOD), In-Space Servicing, Assembly and Manufacturing (ISAM) as well as satellite formation flying and swarming. However, IAR is sensitive to received GPS signal noise, especially under severe multi-path or high thermal noise. This paper proposes a sensor-fusion approach to achieve IAR under such conditions in two coupling stages. A loose coupling stage fuses through an Extended Kalman Filter the CDGPS measurements with on-board sensor measurements such as range from cross-links, and vision-based bearing angles. A second tight-coupling stage augments the cost function of the integer weighted least-squares minimization with a soft constraint function using noise-weighted observed-minus-computed residuals from these external sensor measurements. Integer acceptance tests are empirically modified to reflect added constraints. Partial IAR is applied to graduate integer fixing. These proposed techniques are packaged into flight-capable software, with ground truths simulated by the Stanford Space Rendezvous Laboratory's S3 library using state-of-the-art force modelling with relevant sources of errors, and validated in two scenarios: (1) a high multi-path scenario involving rendezvous and docking in low Earth orbit, and (2) a high thermal noise scenario relying only on GPS side-lobe signals during proximity operations in geostationary orbit. This study demonstrates successful IAR in both cases, using the proposed sensor-fusion approach, thus demonstrating potential for high-precision state estimation under adverse signal-to-noise conditions.	eess.SY	15 pages, 20 figures, IEEE AERO 2024 (pre-print)
0	Physicality of evolution and statistical contractivity are equivalent notions of maps	Matteo Scandi,Paolo Abiuso,Dario De Santis,Jacopo Surace	Statistical quantifiers are generically required to contract under physical evolutions, following the intuition that information should be lost under noisy transformations. This principle is very relevant in statistics, and it even allows to derive uniqueness results based on it: by imposing their contractivity under any physical maps, the Chentsov-Petz theorem singles out a unique family of metrics on the space of probability distributions (or density matrices) called the Fisher information metrics. This result might suggest that statistical quantifiers are a derived concept, as their very definition is based on physical maps. The aim of this work is to disprove this belief. Indeed, we present a result dual to the Chentsov-Petz theorem, proving that among all possible linear maps, the only ones that contract the Fisher information are exactly the physical ones. This result shows that, contrary to the common opinion, there is no fundamental hierarchy between physical maps and canonical statistical quantifiers, as either of them can be defined in terms of the other.	quant-ph	None
1	Decentralized Learning over Wireless Networks with Broadcast-Based Subgraph Sampling	Daniel P√©rez Herrera,Zheng Chen,Erik G. Larsson	This work centers on the communication aspects of decentralized learning over wireless networks, using consensus-based decentralized stochastic gradient descent (D-SGD). Considering the actual communication cost or delay caused by in-network information exchange in an iterative process, our goal is to achieve fast convergence of the algorithm measured by improvement per transmission slot. We propose BASS, an efficient communication framework for D-SGD over wireless networks with broadcast transmission and probabilistic subgraph sampling. In each iteration, we activate multiple subsets of non-interfering nodes to broadcast model updates to their neighbors. These subsets are randomly activated over time, with probabilities reflecting their importance in network connectivity and subject to a communication cost constraint (e.g., the average number of transmission slots per iteration). During the consensus update step, only bi-directional links are effectively preserved to maintain communication symmetry. In comparison to existing link-based scheduling methods, the inherent broadcasting nature of wireless channels offers intrinsic advantages in speeding up convergence of decentralized learning by creating more communicated links with the same number of transmission slots.	cs.LG	6 pages, 4 figures, submitted for possible conference publication
2	Planetary Engulfment Prognosis within the $œÅ$ CrB System	Stephen R. Kane	Exoplanets have been detected around stars at various stages of their lives, ranging from young stars emerging from formation, to latter stages of evolution, including white dwarfs and neutron stars. Post main sequence stellar evolution can result in dramatic, and occasionally traumatic, alterations to the planetary system architecture, such as tidal disruption of planets and engulfment by the host star. The $\rho$ CrB system is a particularly interesting case of advanced main sequence evolution, due to the relative late age and brightness of the host star, its similarity to solar properties, and the harboring of four known planets. Here, we use stellar evolution models to estimate the expected trajectory of the $\rho$ CrB stellar properties, especially over the coming 1.0-1.5 billion years as it evolves off the main sequence. We show that the inner three planets (e, b, and c) are engulfed during the red giant phase and asymptotic giant branch, likely destroying those planets via either evaporation or tidal disruption at the fluid body Roche limit. The outer planet, planet d, is briefly engulfed by the star several times toward the end of the asymptotic giant branch, but the stellar mass loss and subsequent changing planetary orbit may allow the survival of the planet into the white dwarf phase of the stellar evolution. We discuss the implications of this outcome for similar systems, and describe the consequences for planets that may lie within the Habitable Zone of the system.	astro-ph.EP	10 pages, 3 figures, 1 table, accepted for publication in the   Astronomical Journal
3	LaksNet: an end-to-end deep learning model for self-driving cars in Udacity simulator	Lakshmikar R. Polamreddy,Youshan Zhang	The majority of road accidents occur because of human errors, including distraction, recklessness, and drunken driving. One of the effective ways to overcome this dangerous situation is by implementing self-driving technologies in vehicles. In this paper, we focus on building an efficient deep-learning model for self-driving cars. We propose a new and effective convolutional neural network model called `LaksNet' consisting of four convolutional layers and two fully connected layers. We conduct extensive experiments using our LaksNet model with the training data generated from the Udacity simulator. Our model outperforms many existing pre-trained ImageNet and NVIDIA models in terms of the duration of the car for which it drives without going off the track on the simulator.	cs.CV	None
4	Learned, Uncertainty-driven Adaptive Acquisition for Photon-Efficient Multiphoton Microscopy	Cassandra Tong Ye,Jiashu Han,Kunzan Liu,Anastasios Angelopoulos,Linda Griffith,Kristina Monakhova,Sixian You	Multiphoton microscopy (MPM) is a powerful imaging tool that has been a critical enabler for live tissue imaging. However, since most multiphoton microscopy platforms rely on point scanning, there is an inherent trade-off between acquisition time, field of view (FOV), phototoxicity, and image quality, often resulting in noisy measurements when fast, large FOV, and/or gentle imaging is needed. Deep learning could be used to denoise multiphoton microscopy measurements, but these algorithms can be prone to hallucination, which can be disastrous for medical and scientific applications. We propose a method to simultaneously denoise and predict pixel-wise uncertainty for multiphoton imaging measurements, improving algorithm trustworthiness and providing statistical guarantees for the deep learning predictions. Furthermore, we propose to leverage this learned, pixel-wise uncertainty to drive an adaptive acquisition technique that rescans only the most uncertain regions of a sample. We demonstrate our method on experimental noisy MPM measurements of human endometrium tissues, showing that we can maintain fine features and outperform other denoising methods while predicting uncertainty at each pixel. Finally, with our adaptive acquisition technique, we demonstrate a 120X reduction in acquisition time and total light dose while successfully recovering fine features in the sample. We are the first to demonstrate distribution-free uncertainty quantification for a denoising task with real experimental data and the first to propose adaptive acquisition based on reconstruction uncertainty	eess.IV	None
5	Accuracy analysis for explicit-implicit finite volume schemes on cut cell meshes	Sandra May,Fabian Laakmann	The solution of time-dependent hyperbolic conservation laws on cut cell meshes causes the small cell problem: standard schemes are not stable on the arbitrarily small cut cells if an explicit time stepping scheme is used and the time step size is chosen based on the size of the background cells. In [J. Sci. Comput. 71, 919-943 (2017)], the mixed explicit implicit approach in general and MUSCL-Trap in particular have been introduced to solve this problem by using implicit time stepping on the cut cells. Theoretical and numerical results have indicated that this might lead to a loss in accuracy when switching between the explicit and implicit time stepping. In this contribution we examine this in more detail and will prove in one dimension that the specific combination MUSCL-Trap of an explicit second-order and an implicit second-order scheme results in a fully second-order mixed scheme. As this result is unlikely to hold in two dimensions, we also introduce two new versions of mixed explicit implicit schemes based on exchanging the explicit scheme. We present numerical tests in two dimensions where we compare the new versions with the original MUSCL-Trap scheme.	math.NA	None
6	Deep Feature Registration for Unsupervised Domain Adaptation	Youshan Zhang,Brian D. Davison	While unsupervised domain adaptation has been explored to leverage the knowledge from a labeled source domain to an unlabeled target domain, existing methods focus on the distribution alignment between two domains. However, how to better align source and target features is not well addressed. In this paper, we propose a deep feature registration (DFR) model to generate registered features that maintain domain invariant features and simultaneously minimize the domain-dissimilarity of registered features and target features via histogram matching. We further employ a pseudo label refinement process, which considers both probabilistic soft selection and center-based hard selection to improve the quality of pseudo labels in the target domain. Extensive experiments on multiple UDA benchmarks demonstrate the effectiveness of our DFR model, resulting in new state-of-the-art performance.	cs.CV	None
7	Anatomically-aware Uncertainty for Semi-supervised Image Segmentation	Sukesh Adiga V,Jose Dolz,Herve Lombaert	Semi-supervised learning relaxes the need of large pixel-wise labeled datasets for image segmentation by leveraging unlabeled data. A prominent way to exploit unlabeled data is to regularize model predictions. Since the predictions of unlabeled data can be unreliable, uncertainty-aware schemes are typically employed to gradually learn from meaningful and reliable predictions. Uncertainty estimation methods, however, rely on multiple inferences from the model predictions that must be computed for each training step, which is computationally expensive. Moreover, these uncertainty maps capture pixel-wise disparities and do not consider global information. This work proposes a novel method to estimate segmentation uncertainty by leveraging global information from the segmentation masks. More precisely, an anatomically-aware representation is first learnt to model the available segmentation masks. The learnt representation thereupon maps the prediction of a new segmentation into an anatomically-plausible segmentation. The deviation from the plausible segmentation aids in estimating the underlying pixel-level uncertainty in order to further guide the segmentation network. The proposed method consequently estimates the uncertainty using a single inference from our representation, thereby reducing the total computation. We evaluate our method on two publicly available segmentation datasets of left atria in cardiac MRIs and of multiple organs in abdominal CTs. Our anatomically-aware method improves the segmentation accuracy over the state-of-the-art semi-supervised methods in terms of two commonly used evaluation metrics.	cs.CV	Accepted at Medical Image Analysis. Code is available at:   $\href{https://github.com/adigasu/Anatomically-aware_Uncertainty_for_Semi-supervised_Segmentation}{Github}$
8	Bounding the approach to oligarchy in a variant of the yard-sale model	David W. Cohen,Bruce M. Boghosian	We present analytical results for the Gini coefficient of economic inequality under the dynamics of a modified Yard-Sale Model of kinetic asset exchange. A variant of the Yard-Sale Model is introduced by modifying the underlying binary transaction of the classical system. It is shown that the Gini coefficient is monotone under the resulting dynamics but the approach to oligarchy, as measured by the Gini index, can be bounded by a first-order differential inequality used in conjunction with the differential Gronwall inequality. The asymptotics of the modified system, with a redistributive tax, are derived and shown to agree with the original, taxed Yard-Sale Model, which implies the modified system is as suitable for matching real wealth distributions.	cond-mat.stat-mech	None
9	Beware the recent past: a bias in spectral energy distribution modelling due to bursty star formation	P. Haskell,S. Das,D. J. B. Smith,R. K. Cochrane,C. C. Hayward,D. Angl√©s-Alc√°zar	We investigate how the recovery of galaxy star formation rates (SFRs) using energy-balance spectral energy distribution (SED) fitting codes depends on their recent star formation histories (SFHs). We use the Magphys and Prospector codes to fit 6,706 synthetic spectral energy distributions (SEDs) of simulated massive galaxies at $1 < z < 8$ from the Feedback in Realistic Environments (FIRE) project. We identify a previously unknown systematic error in the Magphys results due to bursty star formation: the SFR estimates of individual galaxies can differ from the true values by as much as 1 dex, at large statistical significance ($>5\sigma$), depending on the details of their recent SFH. The SFRs inferred using Prospector do not exhibit this trend, likely because unlike Magphys, Prospector uses non-parametric SFHs. We urge caution when using Magphys, or other codes assuming parametric SFHs, to study galaxies where the average SFR may have changed significantly over the last $\sim$100 Myr, such as those which have recently quenched their star formation or those experiencing an ongoing burst. This concern is especially relevant, for example, when fitting JWST observations of very high-redshift galaxies.	astro-ph.GA	5 pages, 3 figures, submitted to MNRAS Letters
0	SN 2022jox: An extraordinarily ordinary Type II SN with Flash Spectroscopy	Jennifer E. Andrews,Jeniveve Pearson,Griffin Hosseinzadeh,K. Azalee Bostroem,Yize Dong,Manisha Shrestha,Jacob E. Jencson,David J. Sand,S. Valenti,Emily Hoang,Daryl Janzen,M. J. Lundquist,Nicolas Meza,Samuel Wyatt,Saurabh W. Jha,Chris Simpson,Joseph Farah,Estefania Padilla Gonzalez,D. Andrew Howell,Curtis McCully,Megan Newsome,Craig Pellegrino,Giacomo Terreran	We present high cadence optical and ultraviolet observations of the Type II supernova (SN), SN 2022jox which exhibits early spectroscopic high ionization flash features of \ion{H}{1}, \ion{He}{2}, \ion{C}{4}, and \ion{N}{4} that disappear within the first few days after explosion. SN 2022jox was discovered by the Distance Less than 40 Mpc (DLT40) survey $\sim$0.75 days after explosion with followup spectra and UV photometry obtained within minutes of discovery. The SN reached a peak brightness of M$_V \sim$ $-$17.3 mag, and has an estimated $^{56}$Ni mass of 0.04 M$_{\odot}$, typical values for normal Type II SNe. The modeling of the early lightcurve and the strong flash signatures present in the optical spectra indicate interaction with circumstellar material (CSM) created from a progenitor with a mass loss rate of $\dot{M} \sim 10^{-3}-10^{-2}\ M_\odot\ \mathrm{yr}^{-1}$. There may also be some indication of late-time CSM interaction in the form of an emission line blueward of H$\alpha$ seen in spectra around 200 days. The mass-loss rate is much higher than the values typically associated with quiescent mass loss from red supergiants, the known progenitors of Type II SNe, but is comparable to inferred values from similar core collapse SNe with flash features, suggesting an eruptive event or a superwind in the progenitor in the months or years before explosion.	astro-ph.HE	Submitted to ApJ
1	Smooth generalized symmetries of quantum field theories	Ben Gripaios,Oscar Randal-Williams,Joseph Tooby-Smith	Dynamical quantum field theories (QFTs), such as those in which spacetimes are equipped with a metric and/or a field in the form of a smooth map to a target manifold, can be formulated axiomatically using the language of $\infty$-categories. According to a geometric version of the cobordism hypothesis, such QFTs collectively assemble themselves into objects in an $\infty$-topos of smooth spaces. We show how this allows one to define and study generalized global symmetries of such QFTs. The symmetries are themselves smooth, so the `higher-form' symmetry groups can be endowed with, e.g., a Lie group structure.   Among the more surprising general implications for physics are, firstly, that QFTs in spacetime dimension $d$, considered collectively, can have $d$-form symmetries, going beyond the known $(d-1)$-form symmetries of individual QFTs and, secondly, that a global symmetry of a QFT can be anomalous even before we try to gauge it, due to a failure to respect either smoothness (in that a symmetry of an individual QFT does not smoothly extend to QFTs collectively) or locality (in that a symmetry of an unextended QFT does not extend to an extended one).   Smoothness anomalies are shown to occur even in 2-state systems in quantum mechanics (here formulated axiomatically by equipping $d=1$ spacetimes with a metric, an orientation, and perhaps some unitarity structure). Locality anomalies are shown to occur even for invertible QFTs defined on $d=1$ spacetimes equipped with an orientation and a smooth map to a target manifold. These correspond in physics to topological actions for a particle moving on the target and the relation to an earlier classification of such actions using invariant differential cohomology is elucidated.	hep-th	72 pages
2	Physical Properties of 5,000 Cool LMC Supergiants with Gaia XP Spectra: A Detailed Portrait of the Upper HR Diagram Hints at Missing Supernova Progenitors	Trevor Z. Dorn-Wallenstein,Kathryn F. Neugent,Emily M. Levesque	Characterizing the physical properties of cool supergiants allows us to probe the final stages of a massive star's evolution before it undergoes core collapse. Despite their importance, the fundamental properties for these stars -- $T_{\rm eff}$ and $\log L/L_\odot$ -- are only known for a limited number of objects. The third data release of the Gaia mission contains precise photometry and low-resolution spectroscopy of hundreds of cool supergiants in the LMC with well-constrained properties. Using these data, we train a simple and easily-interpretable machine learning model to regress effective temperatures and luminosities with high accuracy and precision comparable to the training data. We then apply our model to 5000 cool supergiants, many of which have no previously-published $T_{\rm eff}$ or $L$ estimates. The resulting Hertzprung-Russell diagram is well-populated, allowing us to study the distribution of cool supergiants in great detail. Examining the luminosity functions of our sample, we find a notable flattening in the luminosity function of yellow supergiants above $\log L/L_\odot=5$, and a corresponding steepening of the red supergiant luminosity function. We place this finding in context with previous results, and present its implications for the infamous red supergiant problem.	astro-ph.SR	Accepted to ApJ. 26 pages, 13 figures. Our catalog of temperatures   and luminosities will be made publicly available online
3	Gauged cooling of topological excitations and emergent fermions on quantum simulators	Gilad Kishony,Mark S. Rudner,Achim Rosch,Erez Berg	"Simulated cooling is a robust method for preparing low-energy states of many-body Hamiltonians on near-term quantum simulators. In such schemes, a subset of the simulator's spins (or qubits) are treated as a ""bath,"" which extracts energy and entropy from the system of interest. However, such protocols are inefficient when applied to systems whose excitations are highly non-local in terms of the microscopic degrees of freedom, such as topological phases of matter; such excitations are difficult to extract by a local coupling to a bath. We explore a route to overcome this obstacle by encoding of the system's degrees of freedom into those of the quantum simulator in a non-local manner. To illustrate the approach, we show how to efficiently cool the ferromagnetic phase of the quantum Ising model, whose excitations are domain walls, via a ""gauged cooling"" protocol in which the Ising spins are coupled to a $Z_2$ gauge field that simultaneously acts as a reservoir for removing excitations. We show that our protocol can prepare the ground states of the ferromagnetic and paramagnetic phases equally efficiently. The gauged cooling protocol naturally extends to (interacting) fermionic systems, where it is equivalent to cooling by coupling to a fermionic bath via single-fermion hopping."	cond-mat.str-el	None
4	Particle detector models from path integrals of localized quantum fields	Bruno de S. L. Torres	Using the Schwinger-Keldysh path integral, we draw a connection between localized quantum field theories and more commonly used models of local probes in Relativistic Quantum Information (RQI). By integrating over and then tracing out the inaccessible modes of the localized field being used as a probe, we show that, at leading order in perturbation theory, the dynamics of any finite number of modes of the probe field is exactly that of a finite number of harmonic-oscillator Unruh-DeWitt (UDW) detectors. The equivalence is valid for a rather general class of input states of the probe-target field system, as well as for any arbitrary number of modes included as detectors. The path integral also provides a closed-form expression which gives us a systematic way of obtaining the corrections to the UDW model at higher orders in perturbation theory due to the existence of the additional modes that have been traced out. This approach vindicates and extends a recently proposed bridge between detector-based and field-theory-based measurement frameworks for quantum field theory [arXiv:2308.11698], and also points to potential connections between particle detector models in RQI and other areas of physics where path integral methods are more commonplace -- in particular, the Wilsonian approach to the renormalization group and effective field theories.	quant-ph	15 pages + references, 1 appendix. RevTeX 4.2
5	Dynamical Spectral Response of Fractonic Quantum Matter	Philip Zechmann,Julian Boesl,Johannes Feldmeier,Michael Knap	Quantum many-body systems with fractonic excitations can realize fascinating phases of matter. Here, we study the low-energy excitations of a constrained Bose-Hubbard model in one dimension, which conserves the center of mass or, equivalently, the dipole moment in addition to the particle number. This model is known to realize fractonic phases, including a dipole Mott insulator, a dipole Luttinger liquid, and a metastable dipole supersolid. We use tensor network methods to compute spectral functions from the dynamical response of the system and verify predictions from low-energy field theories of the corresponding ground state phases. We demonstrate the existence of gapped excitations compatible with strong coupling results in a dipole Mott insulator, linear sound modes characteristic of a Luttinger liquid of dipoles, and soft quadratic modes at both zero and finite momenta in a supersolid state with charge density wave order and phase coherence at non-integer filling.	cond-mat.quant-gas	11 pages, 4 figures
6	Formation of quenched massive galaxies in FIRE cosmological zoom-in simulations with multi-channel AGN feedback	Lindsey Byrne,Claude-Andr√© Faucher-Gigu√®re,Sarah Wellons,Philip F. Hopkins,Daniel Angl√©s-Alc√°zar,Imran Sultan,Nastasha Wijers,Jorge Moreno,Sam Ponnada	Feedback from supermassive black holes (SMBHs) is believed to be a critical driver of the observed quenching of star formation and color bimodality of galaxies above the Milky Way mass scale. In recent years, various forms of SMBH feedback have been implemented as subgrid models in galaxy formation simulations, but most implementations have involved simplified prescriptions or coarse-grained models of the interstellar medium (ISM). We present the first set of FIRE-3 cosmological zoom-in simulations with AGN feedback evolved to $z\sim0$, examining a set of galaxies with halos in the mass range $10^{12}-10^{13}\,{\rm M_{\odot}}$. These high-resolution simulations combine detailed stellar and ISM physics with multi-channel AGN feedback including radiative feedback, mechanical outflows, and in some simulations, cosmic rays. We find that massive (>L*) galaxies in these simulations can match local scaling relations including the stellar mass-halo mass relation, the $M_{\rm BH}$-$\sigma$ relation, the size-mass relation, and the Faber-Jackson relation. Many of the massive galaxies in the simulations with AGN feedback have quenched star formation and elliptical morphologies, in qualitative agreement with observations. In contrast, simulations at the massive end without AGN feedback produce galaxies that are too massive and form stars at too high rates, are order-of-magnitude too compact, and have velocity dispersions well above Faber-Jackson. Despite these successes, the AGN physics models analyzed do not necessarily produce uniformly realistic galaxies across the full mass range studied when the feedback parameters are held constant, indicating that further refinements of the black hole modeling may be warranted.	astro-ph.GA	17 pages, 8 figures, submitted to ApJ
7	Extending preferred axion models via heavy-quark induced early matter domination	Andrew Cheek,Jacek K. Osi≈Ñski,Leszek Roszkowski	We examine the cosmological consequences of the heavy quarks in KSVZ-type axion models. We find that their presence often causes an early matter domination phase, altering the evolution of the Universe. This extends the axion mass into the region where standard cosmology leads to overproduction, and allows for a greater number of axion models with non-renormalizable terms to be viable. Quantitatively, we find that decays proceeding through effective terms of up to dimension 9 ($d=9$) remain consistent with cosmological constraints, in contrast with the result $d\leq5$ previously found in the literature. As a consequence, the heavy quarks can be much heavier and the axion mass window with the correct relic density for dark matter is extended by orders of magnitude, down to $m_a\approx 6\times 10^{-9} \,{\rm eV}$. This is achieved without resorting to fine-tuning of the initial misalignment angle, bolstering the motivation for many future axion haloscope experiments. Additionally, we explore how these models can be probed through measurements of the number of relativistic degrees of freedom at recombination.	hep-ph	24 pages, 6 figures
8	The Magic Renormalisability of Affine Gaudin Models	Falk Hassler,Sylvain Lacroix,Benoit Vicedo	We study the renormalisation of a large class of integrable $\sigma$-models obtained in the framework of affine Gaudin models. They are characterised by a simple Lie algebra $\mathfrak{g}$ and a rational twist function $\varphi(z)$ with simple zeros, a double pole at infinity but otherwise no further restrictions on the pole structure. The crucial tool used in our analysis is the interpretation of these integrable theories as $\mathcal{E}$-models, which are $\sigma$-models studied in the context of Poisson-Lie T-duality and which are known to be at least one- and two-loop renormalisable. The moduli space of $\mathcal{E}$-models still contains many non-integrable theories. We identify the submanifold formed by affine Gaudin models and relate its tangent space to curious matrices and semi-magic squares. In particular, these results provide a criteria for the stability of these integrable models under the RG-flow. At one loop, we show that this criteria is satisfied and derive a very simple expression for the RG-flow of the twist function, proving a conjecture made earlier in the literature.	hep-th	29 pages, 1 figure
9	Disorder effects in spiral spin liquids: Long-range spin textures, Friedel-like oscillations, and spiral spin glasses	Pedro M. C√¥nsoli,Matthias Vojta	Spiral spin liquids are correlated states of matter in which a frustrated magnetic system evades order by fluctuating between a set of (nearly) degenerate spin spirals. Here, we investigate the response of spiral spin liquids to quenched disorder in a $J_1$-$J_2$ honeycomb-lattice Heisenberg model. At the single-impurity level, we identify different order-by-quenched-disorder phenomena and analyze the ensuing spin textures. In particular, we show that the latter generally display Friedel-like oscillations, which encode direct information about the spiral contour, i.e., the classical ground-state manifold. At finite defect concentrations, we perform extensive numerical simulations and characterize the resulting phases at zero temperature. As a result, we find that the competition between incompatible order-by-quenched-disorder mechanisms can lead to spiral spin glass states already at low to moderate disorder. Finally, we discuss extensions of our conclusions to nonzero temperatures and higher-dimensional systems, as well as their applications to experiments.	cond-mat.str-el	15+11 pages, 12+6 figures
0	Synthetic Data as Validation	Qixin Hu,Alan Yuille,Zongwei Zhou	This study leverages synthetic data as a validation set to reduce overfitting and ease the selection of the best model in AI development. While synthetic data have been used for augmenting the training set, we find that synthetic data can also significantly diversify the validation set, offering marked advantages in domains like healthcare, where data are typically limited, sensitive, and from out-domain sources (i.e., hospitals). In this study, we illustrate the effectiveness of synthetic data for early cancer detection in computed tomography (CT) volumes, where synthetic tumors are generated and superimposed onto healthy organs, thereby creating an extensive dataset for rigorous validation. Using synthetic data as validation can improve AI robustness in both in-domain and out-domain test sets. Furthermore, we establish a new continual learning framework that continuously trains AI models on a stream of out-domain data with synthetic tumors. The AI model trained and validated in dynamically expanding synthetic data can consistently outperform models trained and validated exclusively on real-world data. Specifically, the DSC score for liver tumor segmentation improves from 26.7% (95% CI: 22.6%-30.9%) to 34.5% (30.8%-38.2%) when evaluated on an in-domain dataset and from 31.1% (26.0%-36.2%) to 35.4% (32.1%-38.7%) on an out-domain dataset. Importantly, the performance gain is particularly significant in identifying very tiny liver tumors (radius < 5mm) in CT volumes, with Sensitivity improving from 33.1% to 55.4% on an in-domain dataset and 33.9% to 52.3% on an out-domain dataset, justifying the efficacy in early detection of cancer. The application of synthetic data, from both training and validation perspectives, underlines a promising avenue to enhance AI robustness when dealing with data from varying domains.	cs.CV	None
1	Sketched Nanoscale KTaO3-Based Superconducting Quantum Interference Device	Muqing Yu,Nicholas Hougland,Qianheng Du,Junyi Yang,Sayanwita Biswas,Ranjani Ramachandran,Dengyu Yang,Anand Bhattacharya,David Pekker,Patrick Irvin,Jeremy Levy	The discovery of two-dimensional superconductivity in LAO/KTO (111) and (110) interfaces has raised significant interest in this system. Here we report the fabrication of nanoscale direct current superconducting quantum interference devices (DC-SQUID), created by using a conductive atomic force microscope (c-AFM) to lithographically control the conductivity at the LAO/KTO(110) interface. The field modulation of its critical current, I_c (B), corresponds well with our theoretical modeling, which is consistent with a large kinetic inductance of the superconducting 2DEG in KTO. The kinetic inductance of the SQUID is tunable by electrical gating from the back, due to the large dielectric constant of KTO. The demonstration of SQUID effect in KTO opens up the possibilities for probing the underlying physics of KTO superconductivity, such as the role of spin-orbit-coupling, pairing symmetry, and inhomogeneity. It also further implies that KTO could serve as a foundation for future quantum devices.	cond-mat.supr-con	31 pages, 16 figures
2	EquivAct: SIM(3)-Equivariant Visuomotor Policies beyond Rigid Object Manipulation	Jingyun Yang,Congyue Deng,Jimmy Wu,Rika Antonova,Leonidas Guibas,Jeannette Bohg	If a robot masters folding a kitchen towel, we would also expect it to master folding a beach towel. However, existing works for policy learning that rely on data set augmentations are still limited in achieving this level of generalization. Our insight is to add equivariance to both the visual object representation and policy architecture. We propose EquivAct which utilizes SIM(3)-equivariant network structures that guarantee generalization across all possible object translations, 3D rotations, and scales by construction. Training of EquivAct is done in two phases. We first pre-train a SIM(3)-equivariant visual representation on simulated scene point clouds. Then, we learn a SIM(3)-equivariant visuomotor policy on top of the pre-trained visual representation using a small amount of source task demonstrations. We demonstrate that after training, the learned policy directly transfers to objects that substantially differ in scale, position and orientation from the source demonstrations. In simulation, we evaluate our method in three manipulation tasks involving deformable and articulated objects thereby going beyond the typical rigid object manipulation tasks that prior works considered. We show that our method outperforms prior works that do not use equivariant architectures or do not use our contrastive pre-training procedure. We also show quantitative and qualitative experiments on three real robot tasks, where the robot watches twenty demonstrations of a tabletop task and transfers zero-shot to a mobile manipulation task in a much larger setup. Project website: https://equivact.github.io	cs.RO	None
3	MuSR: Testing the Limits of Chain-of-thought with Multistep Soft Reasoning	Zayne Sprague,Xi Ye,Kaj Bostrom,Swarat Chaudhuri,Greg Durrett	While large language models (LLMs) equipped with techniques like chain-of-thought prompting have demonstrated impressive capabilities, they still fall short in their ability to reason robustly in complex settings. However, evaluating LLM reasoning is challenging because system capabilities continue to grow while benchmark datasets for tasks like logical deduction have remained static. We introduce MuSR, a dataset for evaluating language models on multistep soft reasoning tasks specified in a natural language narrative. This dataset has two crucial features. First, it is created through a novel neurosymbolic synthetic-to-natural generation algorithm, enabling the construction of complex reasoning instances that challenge GPT-4 (e.g., murder mysteries roughly 1000 words in length) and which can be scaled further as more capable LLMs are released. Second, our dataset instances are free text narratives corresponding to real-world domains of reasoning; this makes it simultaneously much more challenging than other synthetically-crafted benchmarks while remaining realistic and tractable for human annotators to solve with high accuracy. We evaluate a range of LLMs and prompting techniques on this dataset and characterize the gaps that remain for techniques like chain-of-thought to perform robust reasoning.	cs.CL	None
4	AI Alignment and Social Choice: Fundamental Limitations and Policy Implications	Abhilash Mishra	Aligning AI agents to human intentions and values is a key bottleneck in building safe and deployable AI applications. But whose values should AI agents be aligned with? Reinforcement learning with human feedback (RLHF) has emerged as the key framework for AI alignment. RLHF uses feedback from human reinforcers to fine-tune outputs; all widely deployed large language models (LLMs) use RLHF to align their outputs to human values. It is critical to understand the limitations of RLHF and consider policy challenges arising from these limitations. In this paper, we investigate a specific challenge in building RLHF systems that respect democratic norms. Building on impossibility results in social choice theory, we show that, under fairly broad assumptions, there is no unique voting protocol to universally align AI systems using RLHF through democratic processes. Further, we show that aligning AI agents with the values of all individuals will always violate certain private ethical preferences of an individual user i.e., universal AI alignment using RLHF is impossible. We discuss policy implications for the governance of AI systems built using RLHF: first, the need for mandating transparent voting rules to hold model builders accountable. Second, the need for model builders to focus on developing AI agents that are narrowly aligned to specific user groups.	cs.AI	10 pages, no figures
5	From Posterior Sampling to Meaningful Diversity in Image Restoration	Noa Cohen,Hila Manor,Yuval Bahat,Tomer Michaeli	Image restoration problems are typically ill-posed in the sense that each degraded image can be restored in infinitely many valid ways. To accommodate this, many works generate a diverse set of outputs by attempting to randomly sample from the posterior distribution of natural images given the degraded input. Here we argue that this strategy is commonly of limited practical value because of the heavy tail of the posterior distribution. Consider for example inpainting a missing region of the sky in an image. Since there is a high probability that the missing region contains no object but clouds, any set of samples from the posterior would be entirely dominated by (practically identical) completions of sky. However, arguably, presenting users with only one clear sky completion, along with several alternative solutions such as airships, birds, and balloons, would better outline the set of possibilities. In this paper, we initiate the study of meaningfully diverse image restoration. We explore several post-processing approaches that can be combined with any diverse image restoration method to yield semantically meaningful diversity. Moreover, we propose a practical approach for allowing diffusion based image restoration methods to generate meaningfully diverse outputs, while incurring only negligent computational overhead. We conduct extensive user studies to analyze the proposed techniques, and find the strategy of reducing similarity between outputs to be significantly favorable over posterior sampling. Code and examples are available in https://noa-cohen.github.io/MeaningfulDiversityInIR	cs.CV	Code and examples are available in   https://noa-cohen.github.io/MeaningfulDiversityInIR
6	A Unified, Scalable Framework for Neural Population Decoding	Mehdi Azabou,Vinam Arora,Venkataramana Ganesh,Ximeng Mao,Santosh Nachimuthu,Michael J. Mendelson,Blake Richards,Matthew G. Perich,Guillaume Lajoie,Eva L. Dyer	Our ability to use deep learning approaches to decipher neural activity would likely benefit from greater scale, in terms of both model size and datasets. However, the integration of many neural recordings into one unified model is challenging, as each recording contains the activity of different neurons from different individual animals. In this paper, we introduce a training framework and architecture designed to model the population dynamics of neural activity across diverse, large-scale neural recordings. Our method first tokenizes individual spikes within the dataset to build an efficient representation of neural events that captures the fine temporal structure of neural activity. We then employ cross-attention and a PerceiverIO backbone to further construct a latent tokenization of neural population activities. Utilizing this architecture and training framework, we construct a large-scale multi-session model trained on large datasets from seven nonhuman primates, spanning over 158 different sessions of recording from over 27,373 neural units and over 100 hours of recordings. In a number of different tasks, we demonstrate that our pretrained model can be rapidly adapted to new, unseen sessions with unspecified neuron correspondence, enabling few-shot performance with minimal labels. This work presents a powerful new approach for building deep learning tools to analyze neural data and stakes out a clear path to training at scale.	cs.LG	Accepted at NeurIPS 2023
7	Woodpecker: Hallucination Correction for Multimodal Large Language Models	Shukang Yin,Chaoyou Fu,Sirui Zhao,Tong Xu,Hao Wang,Dianbo Sui,Yunhang Shen,Ke Li,Xing Sun,Enhong Chen	Hallucination is a big shadow hanging over the rapidly evolving Multimodal Large Language Models (MLLMs), referring to the phenomenon that the generated text is inconsistent with the image content. In order to mitigate hallucinations, existing studies mainly resort to an instruction-tuning manner that requires retraining the models with specific data. In this paper, we pave a different way, introducing a training-free method named Woodpecker. Like a woodpecker heals trees, it picks out and corrects hallucinations from the generated text. Concretely, Woodpecker consists of five stages: key concept extraction, question formulation, visual knowledge validation, visual claim generation, and hallucination correction. Implemented in a post-remedy manner, Woodpecker can easily serve different MLLMs, while being interpretable by accessing intermediate outputs of the five stages. We evaluate Woodpecker both quantitatively and qualitatively and show the huge potential of this new paradigm. On the POPE benchmark, our method obtains a 30.66%/24.33% improvement in accuracy over the baseline MiniGPT-4/mPLUG-Owl. The source code is released at https://github.com/BradyFU/Woodpecker.	cs.CV	16 pages, 7 figures. Code Website:   https://github.com/BradyFU/Woodpecker
8	Stanford-ORB: A Real-World 3D Object Inverse Rendering Benchmark	Zhengfei Kuang,Yunzhi Zhang,Hong-Xing Yu,Samir Agarwala,Shangzhe Wu,Jiajun Wu	We introduce Stanford-ORB, a new real-world 3D Object inverse Rendering Benchmark. Recent advances in inverse rendering have enabled a wide range of real-world applications in 3D content generation, moving rapidly from research and commercial use cases to consumer devices. While the results continue to improve, there is no real-world benchmark that can quantitatively assess and compare the performance of various inverse rendering methods. Existing real-world datasets typically only consist of the shape and multi-view images of objects, which are not sufficient for evaluating the quality of material recovery and object relighting. Methods capable of recovering material and lighting often resort to synthetic data for quantitative evaluation, which on the other hand does not guarantee generalization to complex real-world environments. We introduce a new dataset of real-world objects captured under a variety of natural scenes with ground-truth 3D scans, multi-view images, and environment lighting. Using this dataset, we establish the first comprehensive real-world evaluation benchmark for object inverse rendering tasks from in-the-wild scenes, and compare the performance of various existing methods.	cs.CV	NeurIPS 2023 Datasets and Benchmarks Track. The first two authors   contributed equally to this work. Project page:   https://stanfordorb.github.io/
9	The ballistic to diffusive crossover in a weakly-interacting Fermi gas	Jerome Lloyd,Tibor Rakovszky,Frank Pollmann,Curt von Keyserlingk	Charge and energy are expected to diffuse in interacting systems of fermions at finite temperatures, even in the absence of disorder, with the interactions inducing a crossover from the coherent and ballistic streaming of quasi-particles at early times, to incoherent diffusive behavior at late times. The relevant crossover timescales and the transport coefficients are both controlled by the strength of interactions. In this work we develop a numerical method to simulate such systems at high temperatures, applicable in a wide range of interaction strengths, by adapting Dissipation-assisted Operator Evolution (DAOE) to fermions. Our fermion DAOE, which approximates the exact dynamics by systematically discarding information from high $n$-point functions, is tailored to capture non-interacting dynamics exactly, thus providing a good starting point for the weakly interacting problem. Applying our method to a microscopic model of weakly interacting fermions, we numerically demonstrate that the crossover from ballistic to diffusive transport happens at a time $t_D\sim1/\Delta^{2}$ and that the diffusion constant similarly scales as $D \sim 1/\Delta^2$, where $\Delta$ is the interaction strength. We substantiate this scaling with a Fermi's golden rule calculation in the operator spreading picture, interpreting $t_D$ as the fermion-fermion scattering time and lifetime of the single-particle Green's function.	cond-mat.str-el	None
0	WebWISE: Web Interface Control and Sequential Exploration with Large Language Models	Heyi Tao,Sethuraman T V,Michal Shlapentokh-Rothman,Derek Hoiem	The paper investigates using a Large Language Model (LLM) to automatically perform web software tasks using click, scroll, and text input operations. Previous approaches, such as reinforcement learning (RL) or imitation learning, are inefficient to train and task-specific. Our method uses filtered Document Object Model (DOM) elements as observations and performs tasks step-by-step, sequentially generating small programs based on the current observations. We use in-context learning, either benefiting from a single manually provided example, or an automatically generated example based on a successful zero-shot trial. We evaluate the proposed method on the MiniWob++ benchmark. With only one in-context example, our WebWISE method achieves similar or better performance than other methods that require many demonstrations or trials.	cs.CL	None
1	Ramified and Unramified Motivic Multiple $t$-, $T$- and $S$-Values	Ce Xu,Jianqiang Zhao	In this paper we shall consider a few variants of the motivic multiple zeta values of level two by restricting the summation indices in the definition of multiple zeta values to some fixed parity patterns. These include Hoffman's multiple $t$-values, Kaneko and Tsumura's multiple $T$-values, and the multiple $S$-values studied previously by the authors. By applying Brown and Glanois's descent theory on the motivic versions of these values we shall derive some criterion for when these values are ramified and unramified. Assuming Grothendieck's period conjecture, our results partially confirms a conjecture of Kaneko and Tsumura about when multiple $T$-values can be expressed as a rational linear combination of multiple zeta values (i.e., unramified) if their depth is less than four. Similar results are obtained for motivic multiple $S$-values. Further, we are able to generalize a result of Charlton to more families of unramified multiple $t$-values with unit components (i.e. components equal to 1). We propose some more unsolved problems at the end of the paper.	math.NT	40 pages, comments welcome
2	Instruct and Extract: Instruction Tuning for On-Demand Information Extraction	Yizhu Jiao,Ming Zhong,Sha Li,Ruining Zhao,Siru Ouyang,Heng Ji,Jiawei Han	Large language models with instruction-following capabilities open the door to a wider group of users. However, when it comes to information extraction - a classic task in natural language processing - most task-specific systems cannot align well with long-tail ad hoc extraction use cases for non-expert users. To address this, we propose a novel paradigm, termed On-Demand Information Extraction, to fulfill the personalized demands of real-world users. Our task aims to follow the instructions to extract the desired content from the associated text and present it in a structured tabular format. The table headers can either be user-specified or inferred contextually by the model. To facilitate research in this emerging area, we present a benchmark named InstructIE, inclusive of both automatically generated training data, as well as the human-annotated test set. Building on InstructIE, we further develop an On-Demand Information Extractor, ODIE. Comprehensive evaluations on our benchmark reveal that ODIE substantially outperforms the existing open-source models of similar size. Our code and dataset are released on https://github.com/yzjiao/On-Demand-IE.	cs.CL	EMNLP 2023
3	Modeling of Fluctuations in Dynamical Optoelectronic Device Simulations within a Maxwell-Density Matrix Langevin Approach	Johannes Popp,Johannes Stowasser,Michael A. Schreiber,Lukas Seitner,Felix Hitzelhammer,Michael Haider,Gabriela Slavcheva,Christian Jirauschek	We present a full-wave Maxwell-density matrix simulation tool including c-number stochastic noise terms for the modeling of the spatiotemporal dynamics in active photonic devices, such as quantum cascade lasers (QCLs) and quantum dot (QD) structures. The coherent light-matter interaction in such devices plays an important role in the generation of frequency combs and other nonlinear and nonclassical optical phenomena. Since the emergence of nonlinear and nonclassical features is directly linked to the noise properties, detailed simulations of the noise characteristics are required for the development of low-noise quantum optoelectronic sources. Our semiclassical simulation framework is based on the Lindblad equation for the electron dynamics, coupled with Maxwell's equations for the optical propagation in the laser waveguide. Fluctuations arising from interactions of the optical field and quantum system with their reservoirs are treated within the quantum Langevin theory. Here, the fluctuations are included by adding stochastic c-number terms to the Maxwell-density matrix equations. The implementation in the mbsolve dynamic simulation framework is publicly available.	quant-ph	18 pages, 5 figures
4	Identifying interphase vs mitotic cell cycle phases using oxidative stress and a proximity-based null model	Michelle Kovarik,Tyler Allcroft,Per Sebastian Skardal	Detecting communities in large complex networks has found a wide range of applications in physical, biological, and social sciences by identifying mesoscopic groups based on the links between individual units. Moreover, community detection approaches have been generalized to various data analysis tasks by constructing networks whose links depend on individual units' measurements. However, identifying well separated subpopulations in data sets, e.g., multimodality, still presents challenges due to both the inherent spatial nature of the resulting networks and the generic emergence of communities in such networks and the similarity between network structures and distance-dependent null models. Here we introduce a new spatially informed null model for this task that takes into account spatial structure but does not explicitly depend on distances between measurements. We find that community detection using this null model successfully identifies subpopulations in multimodal data and accurately does not for unimodal data. We apply this new null model to the task of identifying interphase vs mitotic cell cycle phases in a group of Dictyostelium discoideum cells using measurements of oxidative stress, which have been shown to correlate strongly with cell cycle behaviors.	nlin.PS	None
5	What's Left? Concept Grounding with Logic-Enhanced Foundation Models	Joy Hsu,Jiayuan Mao,Joshua B. Tenenbaum,Jiajun Wu	"Recent works such as VisProg and ViperGPT have smartly composed foundation models for visual reasoning-using large language models (LLMs) to produce programs that can be executed by pre-trained vision-language models. However, they operate in limited domains, such as 2D images, not fully exploiting the generalization of language: abstract concepts like ""left"" can also be grounded in 3D, temporal, and action data, as in moving to your left. This limited generalization stems from these inference-only methods' inability to learn or adapt pre-trained models to a new domain. We propose the Logic-Enhanced Foundation Model (LEFT), a unified framework that learns to ground and reason with concepts across domains with a differentiable, domain-independent, first-order logic-based program executor. LEFT has an LLM interpreter that outputs a program represented in a general, logic-based reasoning language, which is shared across all domains and tasks. LEFT's executor then executes the program with trainable domain-specific grounding modules. We show that LEFT flexibly learns concepts in four domains: 2D images, 3D scenes, human motions, and robotic manipulation. It exhibits strong reasoning ability in a wide variety of tasks, including those that are complex and not seen during training, and can be easily applied to new domains."	cs.CV	NeurIPS 2023. First two authors contributed equally. Project page:   https://web.stanford.edu/~joycj/projects/left_neurips_2023
6	Visual Cropping Improves Zero-Shot Question Answering of Multimodal Large Language Models	Jiarui Zhang,Mahyar Khayatkhoei,Prateek Chhikara,Filip Ilievski	Multimodal Large Language Models (LLMs) have recently achieved promising zero-shot accuracy on visual question answering (VQA) -- a fundamental task affecting various downstream applications and domains. Given the great potential for the broad use of these models, it is important to investigate their limitations in dealing with different image and question properties. In this work, we investigate whether multimodal LLMs can perceive small details as well as large details in images. In particular, we show that their zero-shot accuracy in answering visual questions is very sensitive to the size of the visual subject of the question, declining up to $46\%$ with size. Furthermore, we show that this effect is causal by observing that human visual cropping can significantly mitigate their sensitivity to size. Inspired by the usefulness of human cropping, we then propose three automatic visual cropping methods as inference time mechanisms to improve the zero-shot performance of multimodal LLMs. We study their effectiveness on four popular VQA datasets, and a subset of the VQAv2 dataset tailored towards fine visual details. Our findings suggest that multimodal LLMs should be used with caution in detail-sensitive VQA applications, and that visual cropping is a promising direction to improve their zero-shot performance. Our code and data are publicly available.	cs.CV	11 pages, 4 figures, 4 tables
7	The Physics of (good) LDPC Codes I. Gauging and dualities	Tibor Rakovszky,Vedika Khemani	Low-depth parity check (LDPC) codes are a paradigm of error correction that allow for spatially non-local interactions between (qu)bits, while still enforcing that each (qu)bit interacts only with finitely many others. On expander graphs, they can give rise to ``good codes'' that combine a finite encoding rate with an optimal scaling of the code distance, which governs the code's robustness against noise. Such codes have garnered much recent attention due to two breakthrough developments: the construction of good quantum LDPC codes and good locally testable classical LDPC codes, using similar methods. Here we explore these developments from a physics lens, establishing connections between LDPC codes and ordered phases of matter defined for systems with non-local interactions and on non-Euclidean geometries. We generalize the physical notions of Kramers-Wannier (KW) dualities and gauge theories to this context, using the notion of chain complexes as an organizing principle. We discuss gauge theories based on generic classical LDPC codes and make a distinction between two classes, based on whether their excitations are point-like or extended. For the former, we describe KW dualities, analogous to the 1D Ising model and describe the role played by ``boundary conditions''. For the latter we generalize Wegner's duality to obtain generic quantum LDPC codes within the deconfined phase of a Z_2 gauge theory. We show that all known examples of good quantum LDPC codes are obtained by gauging locally testable classical codes. We also construct cluster Hamiltonians from arbitrary classical codes, related to the Higgs phase of the gauge theory, and formulate generalizations of the Kennedy-Tasaki duality transformation. We use the chain complex language to discuss edge modes and non-local order parameters for these models, initiating the study of SPT phases in non-Euclidean geometries.	quant-ph	None
8	Entanglement from superradiance and rotating quantum fluids of light	Adri√† Delhom,Killian Guerrero,Paula Calizaya,K√©vin Falque,Anthony J. Brady,Ivan Agullo,Maxime J. Jacquet	The amplification of radiation by superradiance is a universal phenomenon observed in numerous physical systems. We demonstrate that superradiant scattering generates entanglement for different input states, including coherent states, thereby revealing the inherently quantum nature of this phenomenon. To put these concepts to the test, we propose a novel approach to create horizonless ergoregions, which are nonetheless dynamically stable thanks to the dissipative dynamics of a polaritonic fluid of light. We numerically simulate the system to demonstrate the creation of a stable ergoregion, and experimentally realize a comparable configuration. Subsequently, we investigate rotational superradiance within this system, with a primary focus on entanglement generation and the possibilities for its enhancement using current techniques. Our methods permit the investigation of quantum emission by rotational superradiance by controlling the input state at will.	gr-qc	13 pages with 10 figures + 9 pages (references + appendices with an   extra figure and a table with numerical data)
9	Finetuning Offline World Models in the Real World	Yunhai Feng,Nicklas Hansen,Ziyan Xiong,Chandramouli Rajagopalan,Xiaolong Wang	Reinforcement Learning (RL) is notoriously data-inefficient, which makes training on a real robot difficult. While model-based RL algorithms (world models) improve data-efficiency to some extent, they still require hours or days of interaction to learn skills. Recently, offline RL has been proposed as a framework for training RL policies on pre-existing datasets without any online interaction. However, constraining an algorithm to a fixed dataset induces a state-action distribution shift between training and inference, and limits its applicability to new tasks. In this work, we seek to get the best of both worlds: we consider the problem of pretraining a world model with offline data collected on a real robot, and then finetuning the model on online data collected by planning with the learned model. To mitigate extrapolation errors during online interaction, we propose to regularize the planner at test-time by balancing estimated returns and (epistemic) model uncertainty. We evaluate our method on a variety of visuo-motor control tasks in simulation and on a real robot, and find that our method enables few-shot finetuning to seen and unseen tasks even when offline data is limited. Videos, code, and data are available at https://yunhaifeng.com/FOWM .	cs.LG	CoRL 2023 Oral; Project website: https://yunhaifeng.com/FOWM
0	What Algorithms can Transformers Learn? A Study in Length Generalization	Hattie Zhou,Arwen Bradley,Etai Littwin,Noam Razin,Omid Saremi,Josh Susskind,Samy Bengio,Preetum Nakkiran	"Large language models exhibit surprising emergent generalization properties, yet also struggle on many simple reasoning tasks such as arithmetic and parity. This raises the question of if and when Transformer models can learn the true algorithm for solving a task. We study the scope of Transformers' abilities in the specific setting of length generalization on algorithmic tasks. Here, we propose a unifying framework to understand when and how Transformers can exhibit strong length generalization on a given task. Specifically, we leverage RASP (Weiss et al., 2021) -- a programming language designed for the computational model of a Transformer -- and introduce the RASP-Generalization Conjecture: Transformers tend to length generalize on a task if the task can be solved by a short RASP program which works for all input lengths. This simple conjecture remarkably captures most known instances of length generalization on algorithmic tasks. Moreover, we leverage our insights to drastically improve generalization performance on traditionally hard tasks (such as parity and addition). On the theoretical side, we give a simple example where the ""min-degree-interpolator"" model of learning from Abbe et al. (2023) does not correctly predict Transformers' out-of-distribution behavior, but our conjecture does. Overall, our work provides a novel perspective on the mechanisms of compositional generalization and the algorithmic capabilities of Transformers."	cs.LG	Preprint
1	TimewarpVAE: Simultaneous Time-Warping and Representation Learning of Trajectories	Travers Rhodes,Daniel D. Lee	Human demonstrations of trajectories are an important source of training data for many machine learning problems. However, the difficulty of collecting human demonstration data for complex tasks makes learning efficient representations of those trajectories challenging. For many problems, such as for handwriting or for quasistatic dexterous manipulation, the exact timings of the trajectories should be factored from their spatial path characteristics. In this work, we propose TimewarpVAE, a fully differentiable manifold-learning algorithm that incorporates Dynamic Time Warping (DTW) to simultaneously learn both timing variations and latent factors of spatial variation. We show how the TimewarpVAE algorithm learns appropriate time alignments and meaningful representations of spatial variations in small handwriting and fork manipulation datasets. Our results have lower spatial reconstruction test error than baseline approaches and the learned low-dimensional representations can be used to efficiently generate semantically meaningful novel trajectories.	cs.LG	17 pages, 12 figures
2	Retrievals of Protoplanetary Disk Parameters using Thermochemical Models: I. Disk Gas Mass from Hydrogen Deuteride Spectroscopy	Young Min Seo,Karen Willacy,Geoffrey Bryden,Dariusz C. Lis,Paul F. Goldsmith,Klaus M. Pontoppidan,Wing-Fai Thi	We discuss statistical relationships between the mass of protoplanetary disks and the hydrogen deuteride (HD) line emission and the dust spectral energy distribution (SED) determined using 3000 ProDiMo disk models. The models have 15 free parameters describing disk physical properties, the central star, and the local radiation field. The sampling of physical parameters is done using a Monte Carlo approach to evaluate the probability density functions of observables as a function of physical parameters. We find that the HD fractional abundance is almost constant even though the UV flux varies by several orders of magnitude. Probing the statistical relation between the physical quantities and the HD flux, we find that low-mass (optically thin) disks display a tight correlation between the average disk gas temperature and HD line flux, while massive disks show no such correlation. We demonstrate that the central star luminosity, disk size, dust size distribution, and HD flux may be used to determine the disk gas mass to within a factor of three. We also find that the far-IR and sub-mm/mm SEDs and the HD flux may serve as strong constraints for determining the disk gas mass to within a factor of two. If the HD lines are fully spectrally resolved ($R\gtrsim 1.5\times10^6, \Delta v=0.2~\rm km\,s^{-1}$), the 56 $\mu$m and 112 $\mu$m HD line profiles alone may constrain the disk gas mass to within a factor of two.	astro-ph.SR	26 pages, 13 figures, ApJ Submitted, preprint
3	GW190521: a binary black hole merger inside an active galactic nucleus?	Sophia Morton,Stefano Rinaldi,Alejandro Torres-Orjuela,Andrea Derdzinski,Maria Paola Vaccaro,Walter Del Pozzo	GW190521, the most massive binary black hole merger confidently detected by the LIGO-Virgo-KAGRA collaboration, is the first gravitational-wave observation of an intermediate-mass black hole. The signal was followed approximately 34 days later by flare ZTF19abanrhr, detected in AGN J124942.3+344929 by the Zwicky Transient Facility at the 78\% spatial contour for GW190521s sky localization. Using the GWTC-2.1 data release, we find that the association between GW190521 and flare ZTF19abanrhr as its electromagnetic counterpart is preferred over a random coincidence of the two transients with a log Bayes factor of 8.6, corresponding to an odds ratio of $\sim$ 5400 to 1 for equal prior odds and $\sim$ 400 to 1 assuming an astrophysical prior odds of 1/13. Given the association, the multi-messenger signal allows for an estimation of the Hubble constant, finding $H_0 = 102^{+27}_{-25}\mathrm{\ km \ s^{-1} \ Mpc^{-1}}$ when solely analyzing GW190521 and $79.2^{+17.6}_{-9.6}\mathrm{\ km \ s^{-1} \ Mpc^{-1}}$ assuming prior information from the binary neutron star merger GW170817, both consistent with the existing literature.	gr-qc	10 pages, 5 figures
4	Femtosecond laser fabricated nitinol living hinges for millimeter-sized robots	Alexander Hedrick,Heiko Kabutz,Lawrence Smith,Robert MacCurdy,Kaushik Jayaram	Nitinol is a smart material that can be used as an actuator, a sensor, or a structural element, and has the potential to significantly enhance the capabilities of microrobots. Femtosecond laser technology can be used to process nitinol while avoiding heat-affected zones (HAZ), thus retaining superelastic properties. In this work, we manufacture living hinges of arbitrary cross-sections from nitinol using a femtosecond laser micromachining process. We first determined the laser cutting parameters, 4.1 Jcm^-2 fluence with 5 passes for 5 um ablation, by varying laser power level and number of passes. Next, we modeled the hinges using an analytical model as well as creating an Abaqus finite element method, and showed the accuracy of the models by comparing them to the torque produced by eight different hinges, four with a rectangular cross-section and four with an arc cross-section. Finally, we manufactured three prototype miniature devices to illustrate the usefulness of these nitinol hinges: a sample spherical 5-bar mechanism, a sarrus linkage, and a piezoelectric actuated robotic wing mechanism.	cs.RO	6 pages, 6 figures, submitted to IEEE RA-L
5	A Colorful and Robust Measure for FDFAs	Dana Fisman,Emmanuel Goldberg,Oded Zimerman	"We define a measure on families of DFAs (FDFAs) that we show to be robust in the sense that two FDFAs for the same language are guaranteed to agree on this measure. This measure tightly relates to the Wagner-Hierarchy (that defines the complexity of omega regular languages). Inspired by the recently introduced natural colors of infinite words, we define natural colors for finite words (prefixes of periods of infinite words). From this semantic definition we derive the Colorful FDFA a novel canonical model for $\omega$-regular languages that also assigns correct colors for finite and infinite words. From the colorful FDFA, for languages that can be recognized by deterministic B\""uchi or coB\""uchi automata, we generate a canonical DBA or DCA termed the Black $\&$ White Automaton, thus complementing the recent result on canonical good for games coB\""uchi automata for coB\""uchi languages."	cs.FL	None
6	Measuring tropical rainforest resilience under non-Gaussian disturbances	Vitus Benson,Jonathan F. Donges,Niklas Boers,Marina Hirota,Andreas Morr,Arie Staal,J√ºrgen Vollmer,Nico Wunderling	The Amazon rainforest is considered one of the Earth's tipping elements and may lose stability under ongoing climate change. Recently a decrease in tropical rainforest resilience has been identified globally from remotely sensed vegetation data. However, the underlying theory assumes a Gaussian distribution of forest disturbances, which is different from most observed forest stressors such as fires, deforestation, or windthrow. Those stressors often occur in power-law-like distributions and can be approximated by $\alpha$-stable L\'evy noise. Here, we show that classical critical slowing down indicators to measure changes in forest resilience are robust under such power-law disturbances. To assess the robustness of critical slowing down indicators, we simulate pulse-like perturbations in an adapted and conceptual model of a tropical rainforest. We find few missed early warnings and few false alarms are achievable simultaneously if the following steps are carried out carefully: First, the model must be known to resolve the timescales of the perturbation. Second, perturbations need to be filtered according to their absolute temporal autocorrelation. Third, critical slowing down has to be assessed using the non-parametric Kendall-$\tau$ slope. These prerequisites allow for an increase in the sensitivity of early warning signals. Hence, our findings imply improved reliability of the interpretation of empirically estimated rainforest resilience through critical slowing down indicators.	physics.ao-ph	None
7	ConvBKI: Real-Time Probabilistic Semantic Mapping Network with Quantifiable Uncertainty	Joey Wilson,Yuewei Fu,Joshua Friesen,Parker Ewen,Andrew Capodieci,Paramsothy Jayakumar,Kira Barton,Maani Ghaffari	In this paper, we develop a modular neural network for real-time semantic mapping in uncertain environments, which explicitly updates per-voxel probabilistic distributions within a neural network layer. Our approach combines the reliability of classical probabilistic algorithms with the performance and efficiency of modern neural networks. Although robotic perception is often divided between modern differentiable methods and classical explicit methods, a union of both is necessary for real-time and trustworthy performance. We introduce a novel Convolutional Bayesian Kernel Inference (ConvBKI) layer which incorporates semantic segmentation predictions online into a 3D map through a depthwise convolution layer by leveraging conjugate priors. We compare ConvBKI against state-of-the-art deep learning approaches and probabilistic algorithms for mapping to evaluate reliability and performance. We also create a Robot Operating System (ROS) package of ConvBKI and test it on real-world perceptually challenging off-road driving data.	cs.RO	arXiv admin note: text overlap with arXiv:2209.10663
8	Symmetry-breaking pathway towards the unpinned broken helix	E. Donoway,T. V. Trevisan,A. Liebman - Pel√°ez,R. P. Day,K. Yamakawa,Y. Sun,J. R. Soh,D. Prabhakaran,A. Boothroyd,R. M. Fernandes,J. G. Analytis,J. E. Moore,J. Orenstein,V. Sunko	One of the prime material candidates to host the axion insulator state is EuIn$_{2}$As$_{2}$. First-principles calculations predicted the emergence of this exotic topological phase based on the assumption of a collinear antiferromagnetic structure. However, neutron scattering measurements revealed a more intricate magnetic ground state, characterized by two coexisting magnetic wavevectors, reached by successive thermal phase transitions. The proposed high and low temperature phases were a spin helix and a state with interpenetrating helical and antiferromagnetic order, termed a broken helix, respectively. Despite its complexity, the broken helix still protects the axion state because the product of time-reversal and a rotational symmetry is preserved. Here we identify the magnetic structure associated with these two phases using a multimodal approach that combines symmetry-sensitive optical probes, scattering, and group theoretical analysis. We find that the higher temperature phase hosts a nodal structure rather than a helix, characterized by a variation of the magnetic moment amplitude from layer to layer, with the moment vanishing entirely in every third Eu layer. The lower temperature structure is similar to the broken helix, with one important difference: the relative orientation of the magnetic structure and the lattice is not fixed, resulting in an `unpinned broken helix'. As a result of the breaking of rotational symmetry, the axion phase is not generically protected. Nevertheless, we show that it can be restored if the magnetic structure is tuned with externally-applied uniaxial strain. Finally, we present a spin Hamiltonian that identifies the spin interactions needed to account for the complex magnetic order in EuIn$_{2}$As$_{2}$. Our work highlights the importance of the multimodal approach in determining the symmetry of complex order-parameters.	cond-mat.str-el	32 pages, 21 figures
9	Physically Explainable Deep Learning for Convective Initiation Nowcasting Using GOES-16 Satellite Observations	Da Fan,Steven J. Greybush,David John Gagne II,Eugene E. Clothiaux	Convection initiation (CI) nowcasting remains a challenging problem for both numerical weather prediction models and existing nowcasting algorithms. In this study, object-based probabilistic deep learning models are developed to predict CI based on multichannel infrared GOES-R satellite observations. The data come from patches surrounding potential CI events identified in Multi-Radar Multi-Sensor Doppler weather radar products over the Great Plains region from June and July 2020 and June 2021. An objective radar-based approach is used to identify these events. The deep learning models significantly outperform the classical logistic model at lead times up to 1 hour, especially on the false alarm ratio. Through case studies, the deep learning model exhibits the dependence on the characteristics of clouds and moisture at multiple levels. Model explanation further reveals the model's decision-making process with different baselines. The explanation results highlight the importance of moisture and cloud features at different levels depending on the choice of baseline. Our study demonstrates the advantage of using different baselines in further understanding model behavior and gaining scientific insights.	physics.ao-ph	None
0	Searching for sub-populations within the gamma-ray solar flares catalog: a graph-based clustering analysis	Jonathan Mauro,Gwenha√´l de Wasseige	Solar flares are highly energetic events that happen in the solar atmosphere. They are mostly observed as X-ray or gamma-ray bursts located on the Sun's surface. While they are known to be sites of particle acceleration, the acceleration process(es) responsible for the observed fluxes remain unsure. The diversity in shape and duration of the gamma-ray fluxes suggests the existence of distinct phases of hadronic acceleration. Moreover, different acceleration processes could explain the differences observed among flares. In this work we search for the evidence of sub-populations within the catalog of gamma-ray solar flares observed by Fermi-LAT. We aim at grouping flares with similar physical properties to be able to probe theoretical models for neutrino production within different classes of flares. We use measurements of the X-ray and gamma-ray fluxes, as well as CMEs and SEPs, to cluster the events using a graph-based algorithm. Furthermore, we investigate the most representative features that characterise the identified sub-populations to allow for qualitative analysis and model development.	astro-ph.SR	8 pages, Presented at the 38th International Cosmic Ray Conference   (ICRC2023)
1	Spatio-temporal reconstruction of drop impact dynamics by means of color-coded glare points and deep learning	Maximilian Dreisbach,Jochen Kriegseis,Alexander Stroh	The present work introduces a deep learning approach for the three-dimensional reconstruction of the spatio-temporal dynamics of the gas-liquid interface in two-phase flows on the basis of monocular images obtained via optical measurement techniques. The dynamics of liquid droplets impacting onto structured solid substrates are captured through high-speed imaging in an extended shadowgraphy setup with additional reflective glare points from lateral light sources that encode further three-dimensional information of the gas-liquid interface in the images. A neural network is learned for the physically correct reconstruction of the droplet dynamics on a labelled dataset generated by synthetic image rendering on the basis of gas-liquid interface shapes obtained from direct numerical simulation. The employment of synthetic image rendering allows for the efficient generation of training data and circumvents the introduction of errors resulting from the inherent discrepancy of the droplet shapes between experiment and simulation. The accurate reconstruction of the gas-liquid interface during droplet impingement on the basis of images obtained in the experiment demonstrates the practicality of the presented approach based on neural networks and synthetic training data generation. The introduction of glare points from lateral light sources in the experiments is shown to improve the reconstruction accuracy, which indicates that the neural network learns to leverage the additional three-dimensional information encoded in the images for a more accurate depth estimation. Furthermore, the physically reasonable reconstruction of unknown gas-liquid interface shapes indicates that the neural network learned a versatile model of the involved two-phase flow phenomena during droplet impingement.	physics.flu-dyn	None
2	Cosmological Perturbation Theory in Metric-Affine Gravity	Katsuki Aoki,Sebastian Bahamonde,Jorge Gigante Valcarcel,Mohammad Ali Gorji	We formulate cosmological perturbation theory around the spatially curved FLRW background in the context of metric-affine gauge theory of gravity which includes torsion and nonmetricity. Performing scalar-vector-tensor decomposition of the spatial perturbations, we find that the theory displays a rich perturbation spectrum with helicities 0, 1, 2 and 3, on top of the usual scalar, vector and tensor metric perturbations arising from Riemannian geometry. Accordingly, the theory provides a diverse phenomenology, e.g. the helicity-2 modes of the torsion and/or nonmetricity tensors source helicity-2 metric tensor perturbation at the linear level leading to the production of gravitational waves. As an immediate application, we study linear perturbation of the nonmetricity helicity-3 modes for a general parity-preserving action of metric-affine gravity which includes quadratic terms in curvature, torsion, and nonmetricity. We then find the conditions to avoid possible instabilities in the helicity-3 modes of the spin-3 field.	gr-qc	23+20 pages, 5 appendices
3	CVPR 2023 Text Guided Video Editing Competition	Jay Zhangjie Wu,Xiuyu Li,Difei Gao,Zhen Dong,Jinbin Bai,Aishani Singh,Xiaoyu Xiang,Youzeng Li,Zuwei Huang,Yuanxi Sun,Rui He,Feng Hu,Junhua Hu,Hai Huang,Hanyu Zhu,Xu Cheng,Jie Tang,Mike Zheng Shou,Kurt Keutzer,Forrest Iandola	Humans watch more than a billion hours of video per day. Most of this video was edited manually, which is a tedious process. However, AI-enabled video-generation and video-editing is on the rise. Building on text-to-image models like Stable Diffusion and Imagen, generative AI has improved dramatically on video tasks. But it's hard to evaluate progress in these video tasks because there is no standard benchmark. So, we propose a new dataset for text-guided video editing (TGVE), and we run a competition at CVPR to evaluate models on our TGVE dataset. In this paper we present a retrospective on the competition and describe the winning method. The competition dataset is available at https://sites.google.com/view/loveucvpr23/track4.	cs.CV	Project page: https://sites.google.com/view/loveucvpr23/track4
4	CDMFT+HFD : an extension of dynamical mean field theory for nonlocal interactions applied to the single band extended Hubbard model	Sarbajaya Kundu,David S√©n√©chal	We examine the phase diagram of the extended Hubbard model on a square lattice, for both attractive and repulsive nearest-neighbor interactions, using CDMFT+HFD, a combination of Cluster Dynamical Mean Field theory (CDMFT) and a Hartree-Fock mean-field decoupling of the inter-cluster extended interaction. For attractive non-local interactions, this model exhibits a region of phase separation near half-filling, in the vicinity of which we find pockets of d-wave superconductivity, decaying rapidly as a function of doping, with disconnected patches of extended s-wave order at smaller (higher) electron densities. On the other hand, when the extended interaction is repulsive, a Mott insulating state at half-filling is destabilized by hole doping, in the strong-coupling limit, in favor of d-wave superconductivity. At the particle-hole invariant chemical potential, we find a first-order phase transition from antiferromagnetism (AF) to d-wave superconductivity as a function of the attractive nearest-neighbor interaction, along with a deviation of the density from the half-filled limit. A repulsive extended interaction instead favors charge-density wave (CDW) order at half-filling.	cond-mat.str-el	13 pages, 14 figures
5	Implementation of microwave with arbitrary amplitude and phase for the DCLS	H. K. Li,H. L. Ding,Y. Li,J. F. Zhu,J. W. Han,X. W. Dai,J. Y. Yang,W. Q. Zhang	In many experiments, the simultaneous emission of multiple wavelengths of FEL (Free-Electron Laser) is significant. For the pulsed-mode FEL facility, we must accelerate multiple electron beams in one microwave pulse, and they may be in different amplitudes and phases in the acceleration field. Therefore, we implement a microwave excitation, whose amplitude and phase have arbitrary shapes in the LLRF (Low-Level Radiofrequency) system. We generate a microwave pulse with step-shaped amplitude and phase for dual beam operation in DCLS (Dalian Coherent Light Source). The microwave system of the primary accelerator has four pulsed LLRF devices, which output excitation to drive four solid-state amplifiers and then excite two 50 MW and two 80 MW klystrons, respectively. Preliminary experiments have shown that this step-shaped microwave can be used for the DCLS twin-bunch operation.	physics.acc-ph	Poster presented at LLRF Workshop 2023 (LLRF2023, arXiv: 2310.03199)
6	Probing extreme black-hole outflows on short timescales via high spectral-resolution X-ray imagers	Ciro Pinto,James F. Steiner,Arash Bodaghee,Priyanka Chakraborty,Malgosia Sobolewska,Dheeraj R. Pasham,Anna Ogorzalek,John Zuhone,Akos Bogdan,Mark Vogelsberger	We investigate outflows and the physics of super-Eddington versus sub-Eddington regimes in black hole systems. Our focus is on prospective science using next-generation high-resolution soft X-ray instruments. We highlight the properties of black hole ultraluminous X-ray source (ULX) systems in particular. Owing to scale invariance in accreting black holes, ULX accretion properties including their outflows, inform our understanding not only of the closely-related population of (similar-mass) X-ray binary systems, but also of tidal disruption events (TDEs) around supermassive black holes. A subsample of TDEs are likely to transcend super-Eddington to sub-Eddington regimes as they evolve, offering an important unifying analog to ULXs and sub-Eddington X-ray binaries. We demonstrate how next-generation soft X-ray observations with resolving power > 1000 and collecting area > 1000 cm^2 can simultaneously identify ultrafast and more typical wind components, distinguish between different wind mechanisms, and constrain changing wind properties over characteristic variability timescales.	astro-ph.HE	19 pages, 8 figures, submitted to ApJ
7	Photon-mediated long range coupling of two Andreev level qubits	L. Y. Cheung,R. Haller,A. Kononov,C. Ciaccia,J. H. Ungerer,T. Kanne,J. Nyg√•rd,P. Winkel,T. Reisinger,I. M. Pop,A. Baumgartner,C. Sch√∂nenberger	In a superconducting weak link, the supercurrent is carried by Andreev bound states (ABSs) formed by the phase-coherent reflection of electrons and their time-reversed partners. A single, highly transmissive ABS can serve as an ideal, compact two-level system, due to a potentially large energy difference to the next ABS. While the coherent manipulation of such Andreev levels qubits (ALQs) has been demonstrated, a long-range coupling between two ALQs, necessary for advanced qubit architectures, has not been achieved, yet. Here, we demonstrate a coherent remote coupling between two ALQs, mediated by a microwave photon in a novel superconducting microwave cavity coupler. The latter hosts two modes with different coupling rates to an external port. This allows us to perform fast readout of each qubit using the strongly coupled mode, while the weakly coupled mode is utilized to mediate the coupling between the qubits. When both qubits are tuned into resonance with the latter mode, we find excitation spectra with avoided-crossings, in very good agreement with the Tavis-Cummings model. Based on this model, we identify highly entangled two-qubit states for which the entanglement is mediated over a distance of six millimeters. This work establishes ALQs as compact and scalable solid-state qubits.	cond-mat.mes-hall	13 pages, 7 figures
8	Training models using forces computed by stochastic electronic structure methods	David M. Ceperley,Scott Jensen,Yubo Yang,Hongwei Niu,Carlo Pierleoni,Markus Holzmann	Quantum Monte Carlo (QMC) can play a very important role in generating accurate data needed for constructing potential energy surfaces. We argue that QMC has advantages in terms of a smaller systematic bias and an ability to cover phase space more completely. The stochastic noise can ease the training of the machine learning model. We discuss how stochastic errors affect the generation of effective models by analyzing the errors within a linear least squares procedure, finding that there is an advantage to having many relatively imprecise data points for constructing models. We then analyze the effect of noise on a model of many-body silicon finding that noise in some situations improves the resulting model. We then study the effect of QMC noise on two machine learning models of dense hydrogen used in a recent study of its phase diagram. The noise enable us to estimate the errors in the model. We conclude with a discussion of future research problems.	cond-mat.mtrl-sci	None
9	Explicit construction of a plane sextic model for genus-five Howe curves, I	Tomoki Moriya,Momonari Kudo	In the past several years, Howe curves have been studied actively in the field of algebraic curves over fields of positive characteristic. Here, a Howe curve is defined as the desingularization of the fiber product over a projective line of two hyperelliptic curves. In this paper, we construct an explicit plane sextic model for non-hyperelliptic Howe curves of genus five. We also determine singularities of our sextic model.	math.AG	Comments are welcome!
0	A New 2D Energy Balance Model For Simulating the Climates of Rapidly- and Slowly-Rotating Terrestrial Planets	Ramses M. Ramirez	Energy balance models (EBMs), alongside radiative-convective climate models (RCMs) and global climate models (GCMs), are useful tools for simulating planetary climates. Historically, planetary and exoplanetary EBMs have solely been 1D latitudinally-dependent models with no longitudinal dependence, until the study of Okuya et al., which focused on simulating synchronously-rotating planets. Following the work of Okuya et al., I have designed the first 2D EBM (PlaHab) that can simulate N2-CO2-H2O-H2 atmospheres of both rapidly-rotating and synchronously-rotating planets, including Mars, Earth, and exoplanets located within their circumstellar habitable zones. PlaHab includes physics for both water and CO2 condensation. Regional topography can be incorporated. Here, I have specifically applied PlaHab to investigate present Earth, early Mars, TRAPPIST-1e and Proxima Centauri b, representing examples of habitable (and potentially habitable) worlds in our solar system and beyond. I compare my EBM results against those of other 1D and 3D models, including those of the recent Trappist-1 Habitable Atmosphere (THAI) comparison project. Overall, EBM results are consistent with those of other 1D and 3D models although inconsistencies among all models continue to be related to the treatment of clouds and other known differences between EBMs and GCMs, including heat transport parameterizations. Although two-dimensional EBMs are a relatively new entry in the study of planetary/exoplanetary climates, their ease-of-use, speed, flexibility, wide applicability, and greater complexity (relative to 1D models), may indicate an ideal combination for the modeling of planetary and exoplanetary atmospheres alike.	astro-ph.EP	Accepted into The Planetary Science Journal (35 pages, 12 Figures, 4   Tables)
1	White-box Compiler Fuzzing Empowered by Large Language Models	Chenyuan Yang,Yinlin Deng,Runyu Lu,Jiayi Yao,Jiawei Liu,Reyhaneh Jabbarvand,Lingming Zhang	Compiler correctness is crucial, as miscompilation falsifying the program behaviors can lead to serious consequences. In the literature, fuzzing has been extensively studied to uncover compiler defects. However, compiler fuzzing remains challenging: Existing arts focus on black- and grey-box fuzzing, which generates tests without sufficient understanding of internal compiler behaviors. As such, they often fail to construct programs to exercise conditions of intricate optimizations. Meanwhile, traditional white-box techniques are computationally inapplicable to the giant codebase of compilers. Recent advances demonstrate that Large Language Models (LLMs) excel in code generation/understanding tasks and have achieved state-of-the-art performance in black-box fuzzing. Nonetheless, prompting LLMs with compiler source-code information remains a missing piece of research in compiler testing.   To this end, we propose WhiteFox, the first white-box compiler fuzzer using LLMs with source-code information to test compiler optimization. WhiteFox adopts a dual-model framework: (i) an analysis LLM examines the low-level optimization source code and produces requirements on the high-level test programs that can trigger the optimization; (ii) a generation LLM produces test programs based on the summarized requirements. Additionally, optimization-triggering tests are used as feedback to further enhance the test generation on the fly. Our evaluation on four popular compilers shows that WhiteFox can generate high-quality tests to exercise deep optimizations requiring intricate conditions, practicing up to 80 more optimizations than state-of-the-art fuzzers. To date, WhiteFox has found in total 96 bugs, with 80 confirmed as previously unknown and 51 already fixed. Beyond compiler testing, WhiteFox can also be adapted for white-box fuzzing of other complex, real-world software systems in general.	cs.SE	None
2	FabricCRDT: A Conflict-Free Replicated Datatypes Approach to Permissioned Blockchains	Pezhman Nasirifard,Ruben Mayer,Hans-Arno Jacobsen	With the increased adaption of blockchain technologies, permissioned blockchains such as Hyperledger Fabric provide a robust ecosystem for developing production-grade decentralized applications. However, the additional latency between executing and committing transactions, due to Fabric's three-phase transaction lifecycle of Execute-Order-Validate (EOV), is a potential scalability bottleneck. The added latency increases the probability of concurrent updates on the same keys by different transactions, leading to transaction failures caused by Fabric's concurrency control mechanism. The transaction failures increase the application development complexity and decrease Fabric's throughput. Conflict-free Replicated Datatypes (CRDTs) provide a solution for merging and resolving conflicts in the presence of concurrent updates. In this work, we introduce FabricCRDT, an approach for integrating CRDTs to Fabric. Our evaluations show that in general, FabricCRDT offers higher throughput of successful transactions than Fabric, while successfully committing and merging all conflicting transactions without any failures.	cs.DC	In Proceedings of the 20th International Middleware Conference   (Middleware '19). ACM 2019
3	Dissecting In-Context Learning of Translations in GPTs	Vikas Raunak,Hany Hassan Awadalla,Arul Menezes	Most of the recent work in leveraging Large Language Models (LLMs) such as GPT-3 for Machine Translation (MT) has focused on selecting the few-shot samples for prompting. In this work, we try to better understand the role of demonstration attributes for the in-context learning of translations through perturbations of high-quality, in-domain demonstrations. We find that asymmetric perturbation of the source-target mappings yield vastly different results. We show that the perturbation of the source side has surprisingly little impact, while target perturbation can drastically reduce translation quality, suggesting that it is the output text distribution that provides the most important learning signal during in-context learning of translations. We propose a method named Zero-Shot-Context to add this signal automatically in Zero-Shot prompting. We demonstrate that it improves upon the zero-shot translation performance of GPT-3, even making it competitive with few-shot prompted translations.	cs.CL	EMNLP Findings (+ Minor Updates over Camera-Ready)
4	Using CHIRON Spectroscopy to Test the Hypothesis of a Precessing Orbit for the WN4 star EZ CMa	Krister DG. Barclay,Sophie Rosu,Noel D. Richardson,Andr√©-Nicolas Chen√©,Nicole St-Louis,Richard Ignace,Anthony F. J. Moffat	The bright WN4 star EZ CMa exhibits a 3.77 day periodicity in photometry, spectroscopy, and polarimetry but the variations in the measurements are not strictly phase-locked, exhibiting changes in reference times, amplitudes, and the shape of the variability happening over times as short as a few weeks. Recently, 137 days of contiguous, variable photometry from BRITE-Constellation was interpreted as caused either by large-scale dense wind structures modulated by rotation, or by a fast-precessing binary having a slightly shorter 3.626 day orbital period and a fast apsidal motion rate of $1315^\circ\,\text{yr}^{-1}$. We aim at testing the latter hypothesis through analysis of spectroscopy and focus on the N\,{\sc v} $\lambda\,4945$ line. We derive an orbital solution for the system and reject the 3.626 day period to represent the variations in the radial velocities of EZ CMa. An orbital solution with an orbital period of 3.77 days was obtained but at the cost of an extremely high and thus improbable apsidal motion rate. Our best orbital solution yields a period of $3.751\pm0.001$\,days with no apsidal motion. We place our results in the context of other variability studies and system properties. While we cannot fully reject the precessing binary model, we find that the corotating interaction region (CIR) hypothesis is better supported by these and other data through qualitative models of CIRs.	astro-ph.SR	accepted to MNRAS
5	Vision-Language Pseudo-Labels for Single-Positive Multi-Label Learning	Xin Xing,Zhexiao Xiong,Abby Stylianou,Srikumar Sastry,Liyu Gong,Nathan Jacobs	This paper presents a novel approach to Single-Positive Multi-label Learning. In general multi-label learning, a model learns to predict multiple labels or categories for a single input image. This is in contrast with standard multi-class image classification, where the task is predicting a single label from many possible labels for an image. Single-Positive Multi-label Learning (SPML) specifically considers learning to predict multiple labels when there is only a single annotation per image in the training data. Multi-label learning is in many ways a more realistic task than single-label learning as real-world data often involves instances belonging to multiple categories simultaneously; however, most common computer vision datasets predominantly contain single labels due to the inherent complexity and cost of collecting multiple high quality annotations for each instance. We propose a novel approach called Vision-Language Pseudo-Labeling (VLPL), which uses a vision-language model to suggest strong positive and negative pseudo-labels, and outperforms the current SOTA methods by 5.5% on Pascal VOC, 18.4% on MS-COCO, 15.2% on NUS-WIDE, and 8.4% on CUB-Birds. Our code and data are available at https://github.com/mvrl/VLPL.	cs.CV	None
6	Geometry-Aware Video Quality Assessment for Dynamic Digital Human	Zicheng Zhang,Yingjie Zhou,Wei Sun,Xiongkuo Min,Guangtao Zhai	Dynamic Digital Humans (DDHs) are 3D digital models that are animated using predefined motions and are inevitably bothered by noise/shift during the generation process and compression distortion during the transmission process, which needs to be perceptually evaluated. Usually, DDHs are displayed as 2D rendered animation videos and it is natural to adapt video quality assessment (VQA) methods to DDH quality assessment (DDH-QA) tasks. However, the VQA methods are highly dependent on viewpoints and less sensitive to geometry-based distortions. Therefore, in this paper, we propose a novel no-reference (NR) geometry-aware video quality assessment method for DDH-QA challenge. Geometry characteristics are described by the statistical parameters estimated from the DDHs' geometry attribute distributions. Spatial and temporal features are acquired from the rendered videos. Finally, all kinds of features are integrated and regressed into quality values. Experimental results show that the proposed method achieves state-of-the-art performance on the DDH-QA database.	cs.CV	None
7	Minimum Connected Dominating Set and Backbone of a Random Graph	Yusupjan Habibulla,Hai-Jun Zhou	"We study the minimum dominating set problem as a representative combinatorial optimization challenge with a global topological constraint. The requirement that the backbone induced by the vertices of a dominating set should be a connected subgraph makes the problem rather nontrivial to investigate by statistical physics methods. Here we convert this global connectivity constraint into a set of local vertex constraints and build a spin glass model with only five coarse-grained vertex states. We derive a set of coarse-grained belief-propagation equations and obtain theoretical predictions on the relative sizes of minimum dominating sets for regular random and Erd\""os-R\'enyi random graph ensembles. We also implement an efficient message-passing algorithm to construct close-to-minimum connected dominating sets and backbone subgraphs for single random graph instances. Our theoretical strategy may also be inspiring for some other global topological constraints."	physics.data-an	27pages,18 figures
8	The Radiant Massive Magnetic Dipole	Jos√© Diaz Polanco,Jos√© Ayala,Maximiliano Ujevic	We present an exact, time-dependent solution for the Einstein field equations that models the coupling between an anisotropic fluid and a magnetic field in an axially symmetric space-time. By carefully selecting the metric components, we achieve a convenient separation of variables that enables us to solve Einstein's field equations and obtain a solution that evolves into the Gutsunaev-Manko massive magnetic dipole. The analysis of the thermodynamic quantities suggests that this solution may represent a pulse of radiation emitted by a massive object with magnetic properties as for example pulsars or neutron stars.	gr-qc	None
9	Graph Deep Learning for Time Series Forecasting	Andrea Cini,Ivan Marisca,Daniele Zambon,Cesare Alippi	Graph-based deep learning methods have become popular tools to process collections of correlated time series. Differently from traditional multivariate forecasting methods, neural graph-based predictors take advantage of pairwise relationships by conditioning forecasts on a (possibly dynamic) graph spanning the time series collection. The conditioning can take the form of an architectural inductive bias on the neural forecasting architecture, resulting in a family of deep learning models called spatiotemporal graph neural networks. Such relational inductive biases enable the training of global forecasting models on large time-series collections, while at the same time localizing predictions w.r.t. each element in the set (i.e., graph nodes) by accounting for local correlations among them (i.e., graph edges). Indeed, recent theoretical and practical advances in graph neural networks and deep learning for time series forecasting make the adoption of such processing frameworks appealing and timely. However, most of the studies in the literature focus on proposing variations of existing neural architectures by taking advantage of modern deep learning practices, while foundational and methodological aspects have not been subject to systematic investigation. To fill the gap, this paper aims to introduce a comprehensive methodological framework that formalizes the forecasting problem and provides design principles for graph-based predictive models and methods to assess their performance. At the same time, together with an overview of the field, we provide design guidelines, recommendations, and best practices, as well as an in-depth discussion of open challenges and future research directions.	cs.LG	None
0	The Conspiracy Money Machine: Uncovering Telegram's Conspiracy Channels and their Profit Model	Vincenzo Imperati,Massimo La Morgia,Alessandro Mei,Alberto Maria Mongardini,Francesco Sassi	"In recent years, major social media platforms have implemented increasingly strict moderation policies, resulting in bans and restrictions on conspiracy theory-related content. To circumvent these restrictions, conspiracy theorists are turning to alternatives, such as Telegram, where they can express and spread their views with fewer limitations. Telegram offers channels -- virtual rooms where only administrators can broadcast messages -- and a more permissive content policy. These features have created the perfect breeding ground for a complex ecosystem of conspiracy channels.   In this paper, we illuminate this ecosystem. First, we propose an approach to detect conspiracy channels. Then, we discover that conspiracy channels can be clustered into four distinct communities comprising over 17,000 channels. Finally, we uncover the ""Conspiracy Money Machine,"" revealing how most conspiracy channels actively seek to profit from their subscribers. We find conspiracy theorists leverage e-commerce platforms to sell questionable products or lucratively promote them through affiliate links. Moreover, we observe that conspiracy channels use donation and crowdfunding platforms to raise funds for their campaigns. We determine that this business involves hundreds of donors and generates a turnover of over $90 million."	cs.CY	None
1	Data-driven Traffic Simulation: A Comprehensive Review	Di Chen,Meixin Zhu,Hao Yang,Xuesong Wang,Yinhai Wang	Autonomous vehicles (AVs) have the potential to significantly revolutionize society by providing a secure and efficient mode of transportation. Recent years have witnessed notable advance-ments in autonomous driving perception and prediction, but the challenge of validating the performance of AVs remains largely unresolved. Data-driven microscopic traffic simulation has be-come an important tool for autonomous driving testing due to 1) availability of high-fidelity traffic data; 2) its advantages of ena-bling large-scale testing and scenario reproducibility; and 3) its potential in reactive and realistic traffic simulation. However, a comprehensive review of this topic is currently lacking. This pa-per aims to fill this gap by summarizing relevant studies. The primary objective of this paper is to review current research ef-forts and provide a futuristic perspective that will benefit future developments in the field. It introduces the general issues of data-driven traffic simulation and outlines key concepts and terms. After overviewing traffic simulation, various datasets and evalua-tion metrics commonly used are reviewed. The paper then offers a comprehensive evaluation of imitation learning, reinforcement learning, generative and deep learning methods, summarizing each and analyzing their advantages and disadvantages in detail. Moreover, it evaluates the state-of-the-art, existing challenges, and future research directions.	cs.LG	18 pages, 4 figures, 4 tables
2	Accented Speech Recognition With Accent-specific Codebooks	Darshan Prabhu,Preethi Jyothi,Sriram Ganapathy,Vinit Unni	Speech accents pose a significant challenge to state-of-the-art automatic speech recognition (ASR) systems. Degradation in performance across underrepresented accents is a severe deterrent to the inclusive adoption of ASR. In this work, we propose a novel accent adaptation approach for end-to-end ASR systems using cross-attention with a trainable set of codebooks. These learnable codebooks capture accent-specific information and are integrated within the ASR encoder layers. The model is trained on accented English speech, while the test data also contained accents which were not seen during training. On the Mozilla Common Voice multi-accented dataset, we show that our proposed approach yields significant performance gains not only on the seen English accents (up to $37\%$ relative improvement in word error rate) but also on the unseen accents (up to $5\%$ relative improvement in WER). Further, we illustrate benefits for a zero-shot transfer setup on the L2Artic dataset. We also compare the performance with other approaches based on accent adversarial training.	cs.CL	Accepted to EMNLP 2023 Main Conference (Long Paper)
3	An Intra-pulse feedforward algorithm for improving pulsed microwave stability	J. W. Han,H. L. Ding,J. F. Zhu,H. K. Li,X. W. Dai,J. Y. Yang,W. Q. Zhang	During the pulsed operation of the linear accelerator in DCLS (Dalian Coherent Light Source), we found a strong correlation between the klystron modulator's high voltage and the klystron output microwave, with noticeable jitter among adjacent microwaves. Therefore, we propose an intra-pulse feedforward algorithm and implement it in LLRF (Low-Level Radiofrequency) systems. This algorithm assumes that the transfer model of the microwave system is linear within a small range of work points and measures the transfer coefficient of the microwave between the LLRF and klystron. For each pulsed microwave of the klystron output, the LLRF system first calculates the vector deviation between the initial measurement within its pulse and the target. The deviation will be compensated in the LLRF excitation so that the jitter in the later part of the pulsed microwave is suppressed. Experiments have shown that this algorithm can effectively suppress the jitter among adjacent microwaves, e.g., improving the amplitude and phase stability (RMS) from 0.11%/0.2{\deg} to 0.1%/0.05{\deg}. This algorithm can also be applied to other accelerators operating in pulsed modes.	physics.acc-ph	Talk presented at LLRF Workshop 2023 (LLRF2023, arXiv: 2310.03199)
4	Long-Term Employment Effects of the Minimum Wage in Germany: New Data and Estimators	Marco Caliendo,Nico Pestel,Rebecca Olthaus	We study the long-term effects of the 2015 German minimum wage introduction and its subsequent increases on regional employment. Using data from two waves of the Structure of Earnings Survey allows us to estimate models that account for changes in the minimum wage bite over time. While the introduction mainly affected the labour market in East Germany, the raises are also increasingly affecting low-wage regions in West Germany, such that around one third of regions have changed their (binary) treatment status over time. We apply different specifications and extensions of the classic difference-in-differences approach as well as a set of new estimators that enables for unbiased effect estimation with a staggered treatment adoption and heterogeneous treatment effects. Our results indicate a small negative effect on dependent employment of 0.5 percent, no significant effect on employment subject to social security contributions, and a significant negative effect of about 2.4 percent on marginal employment until the first quarter of 2022. The extended specifications suggest additional effects of the minimum wage increases, as well as stronger negative effects on total dependent and marginal employment for those regions that were strongly affected by the minimum wage in 2015 and 2019.	econ.GN	None
5	Acceptance effect on the $N_t N_p-N_d^2$ ratio of light nuclei coalescence yields versus nucleon density fluctuations	Michael X. Zhang,An Gu	"We employ a coalescence model to form deuterons ($\rm d$), tritons (${\rm t}$) and helium-3 ($^3{\rm He}$) nuclei from a uniformly distributed volume of protons ({\rm p}) and neutrons ({\rm n}). %thermal nucleons We study the ratio $N_{\rm t} N_{\rm p}/N_{\rm d}^2$ of light nuclei yields as a function of the neutron number fluctuations. We investigate the effect of finite transverse momentum ($p_{\rm T}$) acceptance on the ratio, in particular, the ``extrapolation factor"" for the ratio as functions of the $p_{\rm T}$ spectral shape and the magnitude of neutron number fluctuations itself. The extrapolation factor is monotonic in $p_{\rm T}$ spectral ``temperature parameter"", as expected, and would not cause a non-monotonic beam energy dependence of the extrapolation. The extrapolation factor is found to vary with the neutron number fluctuation magnitude and the variations are relatively small for our studied $p_{\rm T}$ ranges. More realistic simulation will be a next step to quantitatively examine whether the observed non-monotonic extrapolation factor by STAR could be explained by coalescence. Our study provides a necessary benchmark for light nuclei ratios as a probe of nucleon fluctuations, an important observable in the search for the critical point of nuclear matter. os as a probe of nucleon fluctuations, an important observable in the search for the critical point of nuclear matter."	nucl-th	None
6	Mixture of Tokens: Efficient LLMs through Cross-Example Aggregation	Szymon Antoniak,Sebastian Jaszczur,Micha≈Ç Krutul,Maciej Pi√≥ro,Jakub Krajewski,Jan Ludziejewski,Tomasz Odrzyg√≥≈∫d≈∫,Marek Cygan	Despite the promise of Mixture of Experts (MoE) models in increasing parameter counts of Transformer models while maintaining training and inference costs, their application carries notable drawbacks. The key strategy of these models is to, for each processed token, activate at most a few experts - subsets of an extensive feed-forward layer. But this approach is not without its challenges. The operation of matching experts and tokens is discrete, which makes MoE models prone to issues like training instability and uneven expert utilization. Existing techniques designed to address these concerns, such as auxiliary losses or balance-aware matching, result either in lower model performance or are more difficult to train. In response to these issues, we propose Mixture of Tokens, a fully-differentiable model that retains the benefits of MoE architectures while avoiding the aforementioned difficulties. Rather than routing tokens to experts, this approach mixes tokens from different examples prior to feeding them to experts, enabling the model to learn from all token-expert combinations. Importantly, this mixing can be disabled to avoid mixing of different sequences during inference. Crucially, this method is fully compatible with both masked and causal Large Language Model training and inference.	cs.CL	None
7	LGR-MPC: A user-friendly software based on Legendre-Gauss-Radau pseudo spectral method for solving Model Predictive Control problems	Saeid Bayat,James T. Allison	Active components, such as actuators, constitute a fundamental aspect of engineering systems, affording the freedom to shape system behavior as desired. However, this capability necessitates energy consumption, primarily in the form of electricity. Thus, a trade-off emerges between energy usage and desired outcomes. While open-loop optimal control methods strive for efficiency, practical implementation is hampered by disturbances and model discrepancies, underscoring the need for closed-loop controllers. The Proportional- Integral-Derivative (PID) controller is widely favored in industry due to its simplicity, despite sub-optimal responses in many cases. To bridge this gap, Model Predictive Control (MPC) offers a solution, yet its complexity limits its broad applicability. This paper introduces user-friendly Python-based MPC software, enabling easy access to MPC. The effectiveness of this software is demonstrated through multiple examples, including those with a known analytical solution.	eess.SY	19 pages, 16 figures
8	NoteChat: A Dataset of Synthetic Doctor-Patient Conversations Conditioned on Clinical Notes	Junda Wang,Zonghai Yao,Zhichao Yang,Huixue Zhou,Rumeng Li,Xun Wang,Yucheng Xu,Hong Yu	The detailed clinical records drafted by doctors after each patient's visit are crucial for medical practitioners and researchers. Automating the creation of these notes with language models can reduce the workload of doctors. However, training such models can be difficult due to the limited public availability of conversations between patients and doctors. In this paper, we introduce NoteChat, a cooperative multi-agent framework leveraging Large Language Models (LLMs) for generating synthetic doctor-patient conversations conditioned on clinical notes. NoteChat consists of Planning, Roleplay, and Polish modules. We provide a comprehensive automatic and human evaluation of NoteChat, comparing it with state-of-the-art models, including OpenAI's ChatGPT and GPT-4. Results demonstrate that NoteChat facilitates high-quality synthetic doctor-patient conversations, underscoring the untapped potential of LLMs in healthcare. This work represents the first instance of multiple LLMs cooperating to complete a doctor-patient conversation conditioned on clinical notes, offering promising avenues for the intersection of AI and healthcare	cs.CL	None
9	Comparison of Unscented Kalman Filter Design for Agricultural Anaerobic Digestion Model	Simon Hellmann,Terrance Wilms,Stefan Streif,S√∂ren Weinrich	Dynamic operation of biological processes, such as anaerobic digestion (AD), requires reliable process monitoring to guarantee stable operating conditions at all times. Unscented Kalman filters (UKF) are an established tool for nonlinear state estimation, and there exist numerous variants of UKF implementations, treating state constraints, improvements of numerical performance and different noise scenarios. So far, however, a unified comparison of proposed methods emphasizing the algorithmic details is lacking. The present study thus examines multiple unconstrained and constrained UKF variants, addresses aspects crucial for direct implementation and applies them to a simplified AD model. The constrained UKF considering additive noise delivered the most accurate state estimations. The long run time of the underlying optimization could be vastly reduced through pre-calculated gradients and Hessian of the associated cost function, as well as by reformulation of the cost function as a quadratic program. However, unconstrained UKF variants showed lower run times and competitive estimation accuracy. This study provides useful advice to practitioners working with nonlinear Kalman filters by paying close attention to algorithmic details and modifications crucial for successful implementation.	eess.SY	Updated model equations in appendix. Updated paper title
0	"Non-coplanar gravitational lenses and the ""communication bridge"""	Viktor T. Toth	We investigate the propagation of light signals across multiple gravitational lenses. The lenses are assumed to be non-coplanar, far enough from one another for each lens to be treated independently as thin lenses in the limit of weak gravity. We analyze these scenarios using several different tools, including geometric optics, photon mapping, wave optics and ray tracing. Specifically, we use these tools to assess light amplification and image formation by a two-lens system. We then extend the ray tracing analysis to the case of multiple non-coplanar lenses, demonstrating the complexity of images that are projected even by relatively simple lens configurations. We introduce a simple simulation tool that can be used to analyze lensing by non-coplanar gravitational monopoles in the weak gravity limit, treating them as thin lenses.	astro-ph.IM	19 pages, 11 figures
1	Likelihood-Based Inference for Semi-Parametric Transformation Cure Models with Interval Censored Data	Suvra Pal,Sandip Barui	A simple yet effective way of modeling survival data with cure fraction is by considering Box-Cox transformation cure model (BCTM) that unifies mixture and promotion time cure models. In this article, we numerically study the statistical properties of the BCTM when applied to interval censored data. Time-to-events associated with susceptible subjects are modeled through proportional hazards structure that allows for non-homogeneity across subjects, where the baseline hazard function is estimated by distribution-free piecewise linear function with varied degrees of non-parametricity. Due to missing cured statuses for right censored subjects, maximum likelihood estimates of model parameters are obtained by developing an expectation-maximization (EM) algorithm. Under the EM framework, the conditional expectation of the complete data log-likelihood function is maximized by considering all parameters (including the Box-Cox transformation parameter $\alpha$) simultaneously, in contrast to conventional profile-likelihood technique of estimating $\alpha$. The robustness and accuracy of the model and estimation method are established through a detailed simulation study under various parameter settings, and an analysis of real-life data obtained from a smoking cessation study.	stat.ME	20 pages
2	Decoupled DETR: Spatially Disentangling Localization and Classification for Improved End-to-End Object Detection	Manyuan Zhang,Guanglu Song,Yu Liu,Hongsheng Li	The introduction of DETR represents a new paradigm for object detection. However, its decoder conducts classification and box localization using shared queries and cross-attention layers, leading to suboptimal results. We observe that different regions of interest in the visual feature map are suitable for performing query classification and box localization tasks, even for the same object. Salient regions provide vital information for classification, while the boundaries around them are more favorable for box regression. Unfortunately, such spatial misalignment between these two tasks greatly hinders DETR's training. Therefore, in this work, we focus on decoupling localization and classification tasks in DETR. To achieve this, we introduce a new design scheme called spatially decoupled DETR (SD-DETR), which includes a task-aware query generation module and a disentangled feature learning process. We elaborately design the task-aware query initialization process and divide the cross-attention block in the decoder to allow the task-aware queries to match different visual regions. Meanwhile, we also observe that the prediction misalignment problem for high classification confidence and precise localization exists, so we propose an alignment loss to further guide the spatially decoupled DETR training. Through extensive experiments, we demonstrate that our approach achieves a significant improvement in MSCOCO datasets compared to previous work. For instance, we improve the performance of Conditional DETR by 4.5 AP. By spatially disentangling the two tasks, our method overcomes the misalignment problem and greatly improves the performance of DETR for object detection.	cs.CV	accepted by ICCV2023
3	Bakry-√âmery and Ollivier Ricci Curvature of Cayley Graphs	David Cushing,Supanat Kamtue,Riikka Kangaslampi,Shiping Liu,Florentin M√ºnch,Norbert Peyerimhoff	In this article we study two discrete curvature notions, Bakry-\'Emery curvature and Ollivier Ricci curvature, on Cayley graphs. We introduce Right Angled Artin-Coxeter Hybrids (RAACHs) generalizing Right Angled Artin and Coxeter groups (RAAGs and RACGs) and derive the curvatures of Cayley graphs of certain RAACHs. Moreover, we show for general finitely presented groups $\Gamma = \langle S \, \mid\, R \rangle$ that addition of relators does not lead to a decrease the weighted curvatures of their Cayley graphs with adapted weighting schemes.	math.CO	None
4	Improving Robustness and Reliability in Medical Image Classification with Latent-Guided Diffusion and Nested-Ensembles	Xing Shen,Hengguan Huang,Brennan Nichyporuk,Tal Arbel	While deep learning models have achieved remarkable success across a range of medical image analysis tasks, deployment of these models in real clinical contexts requires that they be robust to variability in the acquired images. While many methods apply predefined transformations to augment the training data to enhance test-time robustness, these transformations may not ensure the model's robustness to the diverse variability seen in patient images. In this paper, we introduce a novel three-stage approach based on transformers coupled with conditional diffusion models, with the goal of improving model robustness to the kinds of imaging variability commonly encountered in practice without the need for pre-determined data augmentation strategies. To this end, multiple image encoders first learn hierarchical feature representations to build discriminative latent spaces. Next, a reverse diffusion process, guided by the latent code, acts on an informative prior and proposes prediction candidates in a generative manner. Finally, several prediction candidates are aggregated in a bi-level aggregation protocol to produce the final output. Through extensive experiments on medical imaging benchmark datasets, we show that our method improves upon state-of-the-art methods in terms of robustness and confidence calibration. Additionally, we introduce a strategy to quantify the prediction uncertainty at the instance level, increasing their trustworthiness to clinicians using them in clinical practice.	cs.LG	13 pages, 6 figures, 7 tables
5	Weighted Distance Nearest Neighbor Condensing	Lee-Ad Gottlieb,Timor Sharabi,Roi Weiss	The problem of nearest neighbor condensing has enjoyed a long history of study, both in its theoretical and practical aspects. In this paper, we introduce the problem of weighted distance nearest neighbor condensing, where one assigns weights to each point of the condensed set, and then new points are labeled based on their weighted distance nearest neighbor in the condensed set.   We study the theoretical properties of this new model, and show that it can produce dramatically better condensing than the standard nearest neighbor rule, yet is characterized by generalization bounds almost identical to the latter. We then suggest a condensing heuristic for our new problem. We demonstrate Bayes consistency for this heuristic, and also show promising empirical results.	cs.LG	None
6	Representation Learning with Large Language Models for Recommendation	Xubin Ren,Wei Wei,Lianghao Xia,Lixin Su,Suqi Cheng,Junfeng Wang,Dawei Yin,Chao Huang	Recommender systems have seen significant advancements with the influence of deep learning and graph neural networks, particularly in capturing complex user-item relationships. However, these graph-based recommenders heavily depend on ID-based data, potentially disregarding valuable textual information associated with users and items, resulting in less informative learned representations. Moreover, the utilization of implicit feedback data introduces potential noise and bias, posing challenges for the effectiveness of user preference learning. While the integration of large language models (LLMs) into traditional ID-based recommenders has gained attention, challenges such as scalability issues, limitations in text-only reliance, and prompt input constraints need to be addressed for effective implementation in practical recommender systems. To address these challenges, we propose a model-agnostic framework RLMRec that aims to enhance existing recommenders with LLM-empowered representation learning. It proposes a recommendation paradigm that integrates representation learning with LLMs to capture intricate semantic aspects of user behaviors and preferences. RLMRec incorporates auxiliary textual signals, develops a user/item profiling paradigm empowered by LLMs, and aligns the semantic space of LLMs with the representation space of collaborative relational signals through a cross-view alignment framework. This work further establish a theoretical foundation demonstrating that incorporating textual signals through mutual information maximization enhances the quality of representations. In our evaluation, we integrate RLMRec with state-of-the-art recommender models, while also analyzing its efficiency and robustness to noise data. Our implementation codes are available at https://github.com/HKUDS/RLMRec.	cs.IR	None
7	Language-driven Scene Synthesis using Multi-conditional Diffusion Model	An Vuong,Minh Nhat Vu,Toan Tien Nguyen,Baoru Huang,Dzung Nguyen,Thieu Vo,Anh Nguyen	Scene synthesis is a challenging problem with several industrial applications. Recently, substantial efforts have been directed to synthesize the scene using human motions, room layouts, or spatial graphs as the input. However, few studies have addressed this problem from multiple modalities, especially combining text prompts. In this paper, we propose a language-driven scene synthesis task, which is a new task that integrates text prompts, human motion, and existing objects for scene synthesis. Unlike other single-condition synthesis tasks, our problem involves multiple conditions and requires a strategy for processing and encoding them into a unified space. To address the challenge, we present a multi-conditional diffusion model, which differs from the implicit unification approach of other diffusion literature by explicitly predicting the guiding points for the original data distribution. We demonstrate that our approach is theoretically supportive. The intensive experiment results illustrate that our method outperforms state-of-the-art benchmarks and enables natural scene editing applications. The source code and dataset can be accessed at https://lang-scene-synth.github.io/.	cs.CV	Accepted to NeurIPS 2023
8	A two-component jet model for the optical plateau in the afterglow of GRB 191221B	Yi-Ming Zhu,Yun Wang,Hao Zhou,Vladimir Lipunov,David A. H. Buckley,Pavel Balanutsa,Zhi-Ping Jin,Da-Ming Wei	The long gamma-ray burst GRB 191221B has abundant observations in X-ray, optical and radio bands. In the literature, the observed optical light curve of GRB 191221B displays a plateau around 0.1-day, which is rather peculiar in gamma-ray bursts. Here we performed detailed analysis of the observational data from Swift/UVOT, VLT and LCO, obtained the light curve of the multi-band afterglow of GRB 191221B. By examining optical, ultraviolet, X-ray, and radio data for this event, we demonstrate that an on-axis two-component jet model can explain the observations. Our analysis suggests that the narrow component has an initial Lorentz factor of 400 and a jet opening half-angle of $1.4^{\circ}$, while the wide component has an initial Lorentz factor of 25 and a jet opening half-angle of $2.8^{\circ}$. The narrow jet dominates the early decay, whereas the wider jet causes the optical plateau and dominates late decay. According to this model, the reason for the absence of the X-ray plateau is due to the steeper spectral index of the wide component, resulting in a less significant flux contribution from the wide jet in the X-ray bands than in the optical bands. Moreover, we have explained the inconsistency in the decay indices of the UVOT and Rc-band data around 2000 seconds using reverse shock emission.	astro-ph.HE	10 pages, 7 figures, Accepted by the Monthly Notices of the Royal   Astronomical Society
9	Frictional weakening of a granular sheared layer due to viscous rolling revealed by Discrete Element Modeling	Alexandre Sac--Morane,Manolis Veveakis,Hadrien Rattez	Considering a 3D sheared granular layer modeled with discrete elements, it is well known the rolling resistance significantly influences the mechanical behavior. Even if the rolling resistance role has been deeply investigated as it is commonly used to represent the the roughness of the grains and the interparticle locking, the role of rolling viscous damping coefficient has been largely overlooked so far. This parameter is rarely used or only to dissipate the energy and to converge numerically. This paper revisits the physical role of those coefficients with a parametric study of the rolling friction and the rolling damping for a sheared layer at different shear speeds and different confinement pressures. It has been observed that the damping coefficient induces a frictional weakening. Hence, competition between the rolling resistance and the rolling damping occurs. Angular resistance aims to avoid grains rolling, decreasing the difference between the angular velocities of grains. Whereas, angular damping acts in the opposite, avoiding a change in the difference between the angular velocities of grains. In consequence, grains keep rolling and the sample strength decreases. This effect must be considered to not overestimate the frictional response of a granular layer.	physics.geo-ph	14 pages, 12 figures, 4 tables
0	A radial variable for de Sitter two-point functions	Manuel Loparco,Jiaxin Qiao,Zimo Sun	"We introduce a ""radial"" two-point invariant for quantum field theory in de Sitter (dS) analogous to the radial coordinate used in conformal field theory. We show that the two-point function of a free massive scalar in the Bunch-Davies vacuum has an exponentially convergent series expansion in this variable with positive coefficients only. Assuming a convergent K\""all\'en-Lehmann decomposition, this result is then generalized to the two-point function of any scalar operator non-perturbatively. A corollary of this result is that, starting from two-point functions on the sphere, an analytic continuation to an extended complex domain is admissible. dS two-point configurations live inside or on the boundary of this domain, and all the paths traced by Wick rotations between dS and the sphere or between dS and Euclidean Anti-de Sitter are also contained within this domain."	hep-th	27+19 pages, 8 figures
1	A Roadmap of Emerging Trends Discovery in Hydrology: A Topic Modeling Approach	Sila Ovgu Korkut,Oznur Oztunc Kaymak,Aytug Onan,Erman Ulker,Femin Yalcin	"In the new global era, determining trends can play an important role in guiding researchers, scientists, and agencies. The main faced challenge is to track the emerging topics among the stacked publications. Therefore, any study done to propose the trend topics in a field to foresee upcoming subjects is crucial. In the current study, the trend topics in the field of ""Hydrology"" have been attempted to evaluate. To do so, the model is composed of three key components: a gathering of data, preprocessing of the article's significant features, and determining trend topics. Various topic models including Latent Dirichlet Allocation (LDA), Non-negative Matrix Factorization (NMF), and Latent Semantic Analysis (LSA) have been implemented. Comparing the obtained results with respect to the $C_V$ coherence score, in 2022, the topics of ""Climate change"", ""River basin"", ""Water management"", ""Natural hazards/erosion"", and ""Hydrologic cycle"" have been obtained. According to a further analysis, it is shown that these topics keep their impact on the field in 2023, as well."	cs.CE	16 pages, 4 figures, 3 Tables. This work was supported by the Center   of Scientific Research Projects of the Izmir Katip Celebi University [Grant   Number: 2022-GAP-MUMF-0029]
2	Spin wave excitations in low dimensional systems with large magnetic anisotropy	F. Delgado,M. M. Otrokov,A. Arnau	The low energy excitation spectrum of a two-dimensional ferromagnetic material is dominated by single-magnon excitations that show a gapless parabolic dispersion relation with the spin wave vector. This occurs as long as magnetic anisotropy and anisotropic exchange are negligible compared to isotropic exchange. However, to maintain magnetic order at finite temperatures, it is necessary to have sizable anisotropy to open a gap in the spin wave excitation spectrum. We consider four real two-dimensional systems for which ferromagnetic order at finite temperature has been observed or predicted. Density functional theory calculations of the total energy differences for different spin configurations permit us to extract the relevant parameters and connect them with a spin Hamiltonian. The corresponding values of the Curie temperature are estimated using a simple model and found to be mostly determined by the value of the isotropic exchange. The exchange and anisotropy parameters are used in a toy model of finite-size periodic chains to study the low-energy excitation spectrum, including single-magnon and two-magnon excitations. At low energies we find that single-magnon excitations appear in the spectrum together with two-magnon excitations. These excitations present a gap that grows particularly for large values of the magnetic anisotropy or anisotropic exchange, relative to the isotropic exchange.	cond-mat.mes-hall	11 pages, 3 figures, 2 tables
3	This is not a Dataset: A Large Negation Benchmark to Challenge Large Language Models	Iker Garc√≠a-Ferrero,Bego√±a Altuna,Javier √Ålvez,Itziar Gonzalez-Dios,German Rigau	Although large language models (LLMs) have apparently acquired a certain level of grammatical knowledge and the ability to make generalizations, they fail to interpret negation, a crucial step in Natural Language Processing. We try to clarify the reasons for the sub-optimal performance of LLMs understanding negation. We introduce a large semi-automatically generated dataset of circa 400,000 descriptive sentences about commonsense knowledge that can be true or false in which negation is present in about 2/3 of the corpus in different forms. We have used our dataset with the largest available open LLMs in a zero-shot approach to grasp their generalization and inference capability and we have also fine-tuned some of the models to assess whether the understanding of negation can be trained. Our findings show that, while LLMs are proficient at classifying affirmative sentences, they struggle with negative sentences and lack a deep understanding of negation, often relying on superficial cues. Although fine-tuning the models on negative sentences improves their performance, the lack of generalization in handling negation is persistent, highlighting the ongoing challenges of LLMs regarding negation understanding and generalization. The dataset and code are publicly available.	cs.CL	Accepted in the The 2023 Conference on Empirical Methods in Natural   Language Processing (EMNLP 2023)
4	Combining Behaviors with the Successor Features Keyboard	Wilka Carvalho,Andre Saraiva,Angelos Filos,Andrew Kyle Lampinen,Loic Matthey,Richard L. Lewis,Honglak Lee,Satinder Singh,Danilo J. Rezende,Daniel Zoran	"The Option Keyboard (OK) was recently proposed as a method for transferring behavioral knowledge across tasks. OK transfers knowledge by adaptively combining subsets of known behaviors using Successor Features (SFs) and Generalized Policy Improvement (GPI). However, it relies on hand-designed state-features and task encodings which are cumbersome to design for every new environment. In this work, we propose the ""Successor Features Keyboard"" (SFK), which enables transfer with discovered state-features and task encodings. To enable discovery, we propose the ""Categorical Successor Feature Approximator"" (CSFA), a novel learning algorithm for estimating SFs while jointly discovering state-features and task encodings. With SFK and CSFA, we achieve the first demonstration of transfer with SFs in a challenging 3D environment where all the necessary representations are discovered. We first compare CSFA against other methods for approximating SFs and show that only CSFA discovers representations compatible with SF&GPI at this scale. We then compare SFK against transfer learning baselines and show that it transfers most quickly to long-horizon tasks."	cs.AI	NeurIPS 2023
5	Blip-Up Blip-Down Circular EPI (BUDA-cEPI) for Distortion-Free dMRI with Rapid Unrolled Deep Learning Reconstruction	Uten Yarach,Itthi Chatnuntawech,Congyu Liao,Surat Teerapittayanon,Siddharth Srinivasan Iyer,Tae Hyung Kim,Justin Haldar,Jaejin Cho,Berkin Bilgic,Yuxin Hu,Brian Hargreaves,Kawin Setsompop	"Purpose: We implemented the blip-up, blip-down circular echo planar imaging (BUDA-cEPI) sequence with readout and phase partial Fourier to reduced off-resonance effect and T2* blurring. BUDA-cEPI reconstruction with S-based low-rank modeling of local k-space neighborhoods (S-LORAKS) is shown to be effective at reconstructing the highly under-sampled BUDA-cEPI data, but it is computationally intensive. Thus, we developed an ML-based reconstruction technique termed ""BUDA-cEPI RUN-UP"" to enable fast reconstruction.   Methods: BUDA-cEPI RUN-UP - a model-based framework that incorporates off-resonance and eddy current effects was unrolled through an artificial neural network with only six gradient updates. The unrolled network alternates between data consistency (i.e., forward BUDA-cEPI and its adjoint) and regularization steps where U-Net plays a role as the regularizer. To handle the partial Fourier effect, the virtual coil concept was also incorporated into the reconstruction to effectively take advantage of the smooth phase prior, and trained to predict the ground-truth images obtained by BUDA-cEPI with S-LORAKS.   Results: BUDA-cEPI with S-LORAKS reconstruction enabled the management of off-resonance, partial Fourier, and residual aliasing artifacts. However, the reconstruction time is approximately 225 seconds per slice, which may not be practical in a clinical setting. In contrast, the proposed BUDA-cEPI RUN-UP yielded similar results to BUDA-cEPI with S-LORAKS, with less than a 5% normalized root mean square error detected, while the reconstruction time is approximately 3 seconds.   Conclusion: BUDA-cEPI RUN-UP was shown to reduce the reconstruction time by ~88x when compared to the state-of-the-art technique, while preserving imaging details as demonstrated through DTI application."	physics.med-ph	Number: Figures: 8 Tables: 3 References: 71
6	ABKD: Graph Neural Network Compression with Attention-Based Knowledge Distillation	Anshul Ahluwalia,Rohit Das,Payman Behnam,Alind Khare,Pan Li,Alexey Tumanov	Graph Neural Networks (GNNs) have proven to be quite versatile for a variety of applications, including recommendation systems, fake news detection, drug discovery, and even computer vision. Due to the expanding size of graph-structured data, GNN models have also increased in complexity, leading to substantial latency issues. This is primarily attributed to the irregular structure of graph data and its access pattern into memory. The natural solution to reduce latency is to compress large GNNs into small GNNs. One way to do this is via knowledge distillation (KD). However, most KD approaches for GNNs only consider the outputs of the last layers and do not consider the outputs of the intermediate layers of the GNNs; these layers may contain important inductive biases indicated by the graph structure. To address this shortcoming, we propose a novel KD approach to GNN compression that we call Attention-Based Knowledge Distillation (ABKD). ABKD is a KD approach that uses attention to identify important intermediate teacher-student layer pairs and focuses on aligning their outputs. ABKD enables higher compression of GNNs with a smaller accuracy dropoff compared to existing KD approaches. On average, we achieve a 1.79% increase in accuracy with a 32.3x compression ratio on OGBN-Mag, a large graph dataset, compared to state-of-the-art approaches.	cs.LG	None
7	A Behavioral Perspective on Models of Linear Dynamical Networks with Manifest Variables	Shengling Shi,Zhiyong Sun,Bart De Schutter	Networks of dynamical systems play an important role in various domains and have motivated many studies on control and analysis of linear dynamical networks. For linear network models considered in these studies, it is typically pre-determined what signal channels are inputs and what are outputs. These models do not capture the practical need to incorporate different experimental situations, where different selections of input and output channels are applied to the same network. Moreover, a unified view on different network models is lacking. This work makes an initial step towards addressing the above issues by taking a behavioral perspective, where input and output channels are not pre-determined. The focus of this work is on behavioral network models with only external variables. Novel dual graphical representations, called system graphs and signal graphs, are introduced for behavioral networks. Moreover, connections between behavioral network models and structural vector autoregressive models are established. Besides their connection in graphical representations, it is shown that the regularity of interconnections is an essential assumption when choosing a structural vector autoregressive model.	eess.SY	None
8	Mediator Interpretation and Faster Learning Algorithms for Linear Correlated Equilibria in General Extensive-Form Games	Brian Hu Zhang,Gabriele Farina,Tuomas Sandholm	"A recent paper by Farina & Pipis (2023) established the existence of uncoupled no-linear-swap regret dynamics with polynomial-time iterations in extensive-form games. The equilibrium points reached by these dynamics, known as linear correlated equilibria, are currently the tightest known relaxation of correlated equilibrium that can be learned in polynomial time in any finite extensive-form game. However, their properties remain vastly unexplored, and their computation is onerous. In this paper, we provide several contributions shedding light on the fundamental nature of linear-swap regret. First, we show a connection between linear deviations and a generalization of communication deviations in which the player can make queries to a ""mediator"" who replies with action recommendations, and, critically, the player is not constrained to match the timing of the game as would be the case for communication deviations. We coin this latter set the untimed communication (UTC) deviations. We show that the UTC deviations coincide precisely with the linear deviations, and therefore that any player minimizing UTC regret also minimizes linear-swap regret. We then leverage this connection to develop state-of-the-art no-regret algorithms for computing linear correlated equilibria, both in theory and in practice. In theory, our algorithms achieve polynomially better per-iteration runtimes; in practice, our algorithms represent the state of the art by several orders of magnitude."	cs.GT	None
9	Exploring Kondo effect by quantum energy teleportation	Kazuki Ikeda,Rajeev Singh,Robert-Jan Slager	We consider a quantum energy teleportation (QET) method to replicate the phase diagram of a one-dimensional $XXZ$ spin chain featuring a Kondo effect coupling. In this setup, the energy supplier and receiver are spatially separated from the point impurity and do not interact directly with it. Nonetheless, they may successfully generate phase diagrams that closely mirror those produced via exact diagonalization. This can be achieved using only local operations on their respective subsystems, supplemented by classical communication. This feat is made possible due to a critical connection between the energy obtained through the QET approach and the system's quantum entanglement entropy. To substantiate these findings, we initially demonstrate that the quantum entanglement entropy serves as the relevant order parameter for the system. Intriguingly, changes in the gap spacing of the entanglement spectra align with the locations of peaks in both entanglement entropy and energy, as determined by QET. We hypothesize that this theoretical framework could, for example, be validated experimentally using a one-dimensional chain of Rydberg atoms.	quant-ph	Comments and criticisms are welcome!
0	Modeling and Contribution of Flexible Heating Systems for Transmission Grid Congestion Management	David Kr√∂ger,Milijana Teodosic,Christian Rehtanz	The large-scale integration of flexible heating systems in the European electricity market leads to a substantial increase of transportation requirements and consecutively grid congestions in the continental transmission grid. Novel model formulations for the grid-aware operation of both individual small-scale heat pumps and large-scale power-to-heat (PtH) units located in district heating networks are presented. The functionality of the models and the contribution of flexible heating systems for transmission grid congestion management is evaluated by running simulations for the target year 2035 for the German transmission grid. The findings show a decrease in annual conventional redispatch volumes and renewable energy sources (RES) curtailment resulting in cost savings of approximately 6 % through the integration of flexible heating systems in the grid congestion management scheme. The analysis suggests that especially large-scale PtH units in combination with thermal energy storages can contribute significantly to the alleviation of grid congestion and foster RES integration.	eess.SY	None
1	Online Robust Mean Estimation	Daniel M. Kane,Ilias Diakonikolas,Hanshen Xiao,Sihan Liu	We study the problem of high-dimensional robust mean estimation in an online setting. Specifically, we consider a scenario where $n$ sensors are measuring some common, ongoing phenomenon. At each time step $t=1,2,\ldots,T$, the $i^{th}$ sensor reports its readings $x^{(i)}_t$ for that time step. The algorithm must then commit to its estimate $\mu_t$ for the true mean value of the process at time $t$. We assume that most of the sensors observe independent samples from some common distribution $X$, but an $\epsilon$-fraction of them may instead behave maliciously. The algorithm wishes to compute a good approximation $\mu$ to the true mean $\mu^\ast := \mathbf{E}[X]$. We note that if the algorithm is allowed to wait until time $T$ to report its estimate, this reduces to the well-studied problem of robust mean estimation. However, the requirement that our algorithm produces partial estimates as the data is coming in substantially complicates the situation.   We prove two main results about online robust mean estimation in this model. First, if the uncorrupted samples satisfy the standard condition of $(\epsilon,\delta)$-stability, we give an efficient online algorithm that outputs estimates $\mu_t$, $t \in [T],$ such that with high probability it holds that $\|\mu-\mu^\ast\|_2 = O(\delta \log(T))$, where $\mu = (\mu_t)_{t \in [T]}$. We note that this error bound is nearly competitive with the best offline algorithms, which would achieve $\ell_2$-error of $O(\delta)$. Our second main result shows that with additional assumptions on the input (most notably that $X$ is a product distribution) there are inefficient algorithms whose error does not depend on $T$ at all.	cs.LG	To appear in SODA2024
2	GO-FEAP: Global Optimal UAV Planner Using Frontier-Omission-Aware Exploration and Altitude-Stratified Planning	Weiye Zhang,Wenshuai Yu,Licong Zhuang,Xiaoyi Zhang,Zhi Zeng,Jiasong Zhu	Autonomous exploration is a fundamental problem for various applications of unmanned aerial vehicles(UAVs). Existing methods, however, are demonstrated to static local optima and two-dimensional exploration. To address these challenges, this paper introduces GO-FEAP (Global Optimal UAV Planner Using Frontier-Omission-Aware Exploration and Altitude-Stratified Planning), aiming to achieve efficient and complete three-dimensional exploration. Frontier-Omission-Aware Exploration module presented in this work takes into account multiple pivotal factors, encompassing frontier distance, nearby frontier count, frontier duration, and frontier categorization, for a comprehensive assessment of frontier importance. Furthermore, to tackle scenarios with substantial vertical variations, we introduce the Altitude-Stratified Planning strategy, which stratifies the three-dimensional space based on altitude, conducting global-local planning for each stratum. The objective of global planning is to identify the most optimal frontier for exploration, followed by viewpoint selection and local path optimization based on frontier type, ultimately generating dynamically feasible three-dimensional spatial exploration trajectories. We present extensive benchmark and real-world tests, in which our method completes the exploration tasks with unprecedented completeness compared to state-of-the-art approaches.	cs.RO	7 pages,29 figures
3	CDSD: Chinese Dysarthria Speech Database	Mengyi Sun,Ming Gao,Xinchen Kang,Shiru Wang,Jun Du,Dengfeng Yao,Su-Jing Wang	We present the Chinese Dysarthria Speech Database (CDSD) as a valuable resource for dysarthria research. This database comprises speech data from 24 participants with dysarthria. Among these participants, one recorded an additional 10 hours of speech data, while each recorded one hour, resulting in 34 hours of speech material. To accommodate participants with varying cognitive levels, our text pool primarily consists of content from the AISHELL-1 dataset and speeches by primary and secondary school students. When participants read these texts, they must use a mobile device or the ZOOM F8n multi-track field recorder to record their speeches. In this paper, we elucidate the data collection and annotation processes and present an approach for establishing a baseline for dysarthric speech recognition. Furthermore, we conducted a speaker-dependent dysarthric speech recognition experiment using an additional 10 hours of speech data from one of our participants. Our research findings indicate that, through extensive data-driven model training, fine-tuning limited quantities of specific individual data yields commendable results in speaker-dependent dysarthric speech recognition. However, we observe significant variations in recognition results among different dysarthric speakers. These insights provide valuable reference points for speaker-dependent dysarthric speech recognition.	cs.SD	9 pages, 3 figures
4	E-Sparse: Boosting the Large Language Model Inference through Entropy-based N:M Sparsity	Yun Li,Lin Niu,Xipeng Zhang,Kai Liu,Jianchen Zhu,Zhanhui Kang	Traditional pruning methods are known to be challenging to work in Large Language Models (LLMs) for Generative AI because of their unaffordable training process and large computational demands. For the first time, we introduce the information entropy of hidden state features into a pruning metric design, namely E-Sparse, to improve the accuracy of N:M sparsity on LLM. E-Sparse employs the information richness to leverage the channel importance, and further incorporates several novel techniques to put it into effect: (1) it introduces information entropy to enhance the significance of parameter weights and input feature norms as a novel pruning metric, and performs N:M sparsity without modifying the remaining weights. (2) it designs global naive shuffle and local block shuffle to quickly optimize the information distribution and adequately cope with the impact of N:M sparsity on LLMs' accuracy. E-Sparse is implemented as a Sparse-GEMM on FasterTransformer and runs on NVIDIA Ampere GPUs. Extensive experiments on the LLaMA family and OPT models show that E-Sparse can significantly speed up the model inference over the dense model (up to 1.53X) and obtain significant memory saving (up to 43.52%), with acceptable accuracy loss.	cs.LG	None
5	AO-Grasp: Articulated Object Grasp Generation	Carlota Par√©s Morlans,Claire Chen,Yijia Weng,Michelle Yi,Yuying Huang,Nick Heppert,Linqi Zhou,Leonidas Guibas,Jeannette Bohg	We introduce AO-Grasp, a grasp proposal method that generates stable and actionable 6 degree-of-freedom grasps for articulated objects. Our generated grasps enable robots to interact with articulated objects, such as opening and closing cabinets and appliances. Given a segmented partial point cloud of a single articulated object, AO-Grasp predicts the best grasp points on the object with a novel Actionable Grasp Point Predictor model and then finds corresponding grasp orientations for each point by leveraging a state-of-the-art rigid object grasping method. We train AO-Grasp on our new AO-Grasp Dataset, which contains 48K actionable parallel-jaw grasps on synthetic articulated objects. In simulation, AO-Grasp achieves higher grasp success rates than existing rigid object grasping and articulated object interaction baselines on both train and test categories. Additionally, we evaluate AO-Grasp on 120 realworld scenes of objects with varied geometries, articulation axes, and joint states, where AO-Grasp produces successful grasps on 67.5% of scenes, while the baseline only produces successful grasps on 33.3% of scenes.	cs.RO	Project website: https://stanford-iprl-lab.github.io/ao-grasp
6	Stellar surface information from the Ca II H&K lines I. Intensity profiles of the solar activity components	M. Cretignier,A. G. M. Pietrow,S. Aigrain	The detection of Earth-like planets with the radial-velocity method is currently limited by the presence of stellar activity signatures. On rotational timescales, spots and plages (or faculae) are known to introduce different RV signals, but their corrections require better activity proxies. The best-known chromospheric activity proxies in the visible are the Ca II H & K lines, but the physical quantities measured by their profiles need to be clarified. We first investigate resolved images of the Sun in order to better understand the spectrum of plages, spots, and the network using the Meudon spectroheliogram. We show that distinct line profiles are produced by plages, spots, and by the network component and we also derived the center-to-limb variations of the three profiles. Some care is required to disentangle their contributions due to their similarities. By combining disk-integrated spectra from the ISS high-resolution spectrograph with SDO direct images of the Sun, we managed to extract a high-resolution emission spectrum of the different components, which tend to confirm the spectra extracted from the Meudon spectroheliogram datacubes. Similar results were obtained with the HARPS-N Sun-as-a-star spectra. We concluded using a three-component model that the temporal variation of the popular S-index contains, on average for the 24th solar cycle: 70 +/- 12% of plage, 26 +/- 12% of network and 4 +/- 4% of spots. This preliminary investigation suggests that a detailed study of the Ca II H & K profiles may provide rich information about the filling factor and distribution of different types of active regions.	astro-ph.SR	20 pages, 17 figures
7	Tutorial on Congestion Control in Multi-Area Transmission Grids via Online Feedback Equilibrium Seeking	Giuseppe Belgioioso,Saverio Bolognani,Giulia Pejrani,Florian D√∂rfler	Online feedback optimization (OFO) is an emerging control methodology for real-time optimal steady-state control of complex dynamical systems. This tutorial focuses on the application of OFO for the autonomous operation of large-scale transmission grids, with a specific goal of minimizing renewable generation curtailment and losses while satisfying voltage and current limits. When this control methodology is applied to multi-area transmission grids, where each area independently manages its congestion while being dynamically interconnected with the rest of the grid, a non-cooperative game arises. In this context, OFO must be interpreted as an online feedback equilibrium seeking (FES) scheme. Our analysis incorporates technical tools from game theory and monotone operator theory to evaluate the stability and performance of multi-area grid operation. Through numerical simulations, we illustrate the key challenge of this non-cooperative setting: on the one hand, independent multi-area decisions are suboptimal compared to a centralized control scheme; on the other hand, some areas are heavily penalized by the centralized decision, which may discourage participation in the coordination mechanism.	math.OC	None
8	Nambu-Goldstone modes in a lattice Nambu-Jona-Lasinio model with multi flavor symmetries	Yukimi Goto,Tohru Koma	We study a lattice Nambu-Jona-Lasinio model with SU(2) and SU(3) flavor symmetries of staggered fermions in the Kogut-Susskind Hamiltonian formalism. This type of four-fermion interactions has been widely used for describing low-energy behaviors of strongly interacting quarks as an effective model. In the strong coupling regime for the interactions, we prove the following: (i) For the spatial dimension $\nu \ge 5$, the SU(3) model shows a long-range order at sufficiently low temperatures. (ii) In the case of the SU(2) symmetry, there appears a long-range order in the spatial dimension $\nu \ge 3$ at sufficiently low temperatures. (iii) These results hold in the ground states as well. (iv) In general, if a long-range order emerges in this type of models, then there exists a gapless excitation above an infinite-volume ground state. This is nothing but the Nambu-Goldstone mode associated with the spontaneous breakdown of the global rotational symmetry of flavors. (v) It is also established that the number of Nambu-Goldstone modes is equal to the number of broken symmetry generators.	math-ph	61 pages
9	Contrastive Learning-based Sentence Encoders Implicitly Weight Informative Words	Hiroto Kurita,Goro Kobayashi,Sho Yokoi,Kentaro Inui	The performance of sentence encoders can be significantly improved through the simple practice of fine-tuning using contrastive loss. A natural question arises: what characteristics do models acquire during contrastive learning? This paper theoretically and experimentally shows that contrastive-based sentence encoders implicitly weight words based on information-theoretic quantities; that is, more informative words receive greater weight, while others receive less. The theory states that, in the lower bound of the optimal value of the contrastive learning objective, the norm of word embedding reflects the information gain associated with the distribution of surrounding words. We also conduct comprehensive experiments using various models, multiple datasets, two methods to measure the implicit weighting of models (Integrated Gradients and SHAP), and two information-theoretic quantities (information gain and self-information). The results provide empirical evidence that contrastive fine-tuning emphasizes informative words.	cs.CL	16 pages, 6 figures, accepted to EMNLP 2023 Findings (short paper)
0	Mergers of double neutron stars with one high-spin component: brighter kilonovae and fallback accretion, weaker gravitational waves	S. Rosswog,P. Diener,F. Torsello,T. Tauris,N. Sarin	"Neutron star mergers where both stars have negligible spins are commonly considered as the most likely, ""standard"" case. But based on observed systems, we estimate that actually a non-negligible fraction of all double neutron star mergers ($\sim$ 5 %) may contain one millisecond component. We use the Lagrangian Numerical Relativity code SPHINCS_BSSN to simulate mergers where one star has no spin and the other has a dimensionless spin parameter of $\chi=0.5$. These mergers exhibit several distinct signatures compared to irrotational cases. Morphologically, they are similar to unequal mass mergers and they form in particular only one, very pronounced spiral arm. Compared to the non-spinning cases, they dynamically eject an order of magnitude more mass of unshocked material at the original low electron fraction of the neutron stars and therefore produce particularly bright, red kilonovae and brighter kilonova afterglows months after the merger. We also find that the spinning cases have significantly more fallback accretion, with implications for late-time X-ray flares and the duration of the associated gamma-ray burst. Overall, the spinning case collisions are substantially less violent and they emit smaller amounts of shock-generated semi-relativistic material and therefore produce less pronounced blue/UV kilonova precursor signals. Their post-merger gravitational wave signal is weaker and, during the simulated time, substantially smaller amounts of energy and angular momentum are emitted. Therefore the central remnant contains a larger angular momentum reservoir and could remain an ""active engine"" for a longer time."	astro-ph.HE	17 pages, 15 figures, submitted
1	Variational quantum simulation using non-Gaussian continuous-variable systems	Paolo Stornati,Antonio Acin,Ulysse Chabaud,Alexandre Dauphin,Valentina Parigi,Federico Centrone	This work introduces a novel approach to quantum simulation by leveraging continuous-variable systems within a photonic hardware-inspired framework. The primary focus is on simulating static properties of the ground state of Hamiltonians associated with infinite-dimensional systems, such as those arising in quantum field theory. We present a continuous-variable variational quantum eigensolver compatible with state-of-the-art photonic technology. We apply it to the study of static properties of the Bose--Hubbard model in 1+1 dimension and demonstrate its effectiveness and practicality, highlighting the potential of continuous-variable quantum simulations in addressing complex problems in quantum physics.	quant-ph	None
2	In-Context Learning Creates Task Vectors	Roee Hendel,Mor Geva,Amir Globerson	"In-context learning (ICL) in Large Language Models (LLMs) has emerged as a powerful new learning paradigm. However, its underlying mechanism is still not well understood. In particular, it is challenging to map it to the ""standard"" machine learning framework, where one uses a training set $S$ to find a best-fitting function $f(x)$ in some hypothesis class. Here we make progress on this problem by showing that the functions learned by ICL often have a very simple structure: they correspond to the transformer LLM whose only inputs are the query $x$ and a single ""task vector"" calculated from the training set. Thus, ICL can be seen as compressing $S$ into a single task vector $\boldsymbol{\theta}(S)$ and then using this task vector to modulate the transformer to produce the output. We support the above claim via comprehensive experiments across a range of models and tasks."	cs.CL	Accepted at Findings of EMNLP 2023
3	RePoseDM: Recurrent Pose Alignment and Gradient Guidance for Pose Guided Image Synthesis	Anant Khandelwal	Pose-guided person image synthesis task requires re-rendering a reference image, which should have a photorealistic appearance and flawless pose transfer. Since person images are highly structured, existing approaches require dense connections for complex deformations and occlusions because these are generally handled through multi-level warping and masking in latent space. But the feature maps generated by convolutional neural networks do not have equivariance, and hence even the multi-level warping does not have a perfect pose alignment. Inspired by the ability of the diffusion model to generate photorealistic images from the given conditional guidance, we propose recurrent pose alignment to provide pose-aligned texture features as conditional guidance. Moreover, we propose gradient guidance from pose interaction fields, which output the distance from the valid pose manifold given a target pose as input. This helps in learning plausible pose transfer trajectories that result in photorealism and undistorted texture details. Extensive results on two large-scale benchmarks and a user study demonstrate the ability of our proposed approach to generate photorealistic pose transfer under challenging scenarios. Additionally, we prove the efficiency of gradient guidance in pose-guided image generation on the HumanArt dataset with fine-tuned stable diffusion.	cs.CV	10 pages, 4 tables, 7 figures
4	Mitigate Domain Shift by Primary-Auxiliary Objectives Association for Generalizing Person ReID	Qilei Li,Shaogang Gong	While deep learning has significantly improved ReID model accuracy under the independent and identical distribution (IID) assumption, it has also become clear that such models degrade notably when applied to an unseen novel domain due to unpredictable/unknown domain shift. Contemporary domain generalization (DG) ReID models struggle in learning domain-invariant representation solely through training on an instance classification objective. We consider that a deep learning model is heavily influenced and therefore biased towards domain-specific characteristics, e.g., background clutter, scale and viewpoint variations, limiting the generalizability of the learned model, and hypothesize that the pedestrians are domain invariant owning they share the same structural characteristics. To enable the ReID model to be less domain-specific from these pure pedestrians, we introduce a method that guides model learning of the primary ReID instance classification objective by a concurrent auxiliary learning objective on weakly labeled pedestrian saliency detection. To solve the problem of conflicting optimization criteria in the model parameter space between the two learning objectives, we introduce a Primary-Auxiliary Objectives Association (PAOA) mechanism to calibrate the loss gradients of the auxiliary task towards the primary learning task gradients. Benefiting from the harmonious multitask learning design, our model can be extended with the recent test-time diagram to form the PAOA+, which performs on-the-fly optimization against the auxiliary objective in order to maximize the model's generative capacity in the test target domain. Experiments demonstrate the superiority of the proposed PAOA model.	cs.CV	Accepted to WACV2024
5	Beam Design and Signal Enhancement in RIS-Aided Multi-User Communication Systems: A Maximization-Minimization Approach	Rujing Xiong,Jialong Lu,Ke Yin,Tiebin Mi,Robert Caiming Qiu	Most beam design schemes in RIS-aided multi-user systems suffer from imbalanced signal power gains and computation complexity. This paper tackles the crucial beam design issue by focusing on received power optimization. Concretely, we leverage the passive characteristics of RIS, modeling the reflecting signals and articulating a comprehensive max-min optimization framework. To efficiently address the beamforming issue, we propose the Moreau-Yosida approximation (MA) algorithm, which pursues the optimal beamforming designs based on arbitrary utility functions in the user's received power. The comprehensive numerical simulations and prototype experiments substantiate the effectiveness of our proposed algorithm.	eess.SY	None
6	Characterizing Mechanisms for Factual Recall in Language Models	Qinan Yu,Jack Merullo,Ellie Pavlick	"Language Models (LMs) often must integrate facts they memorized in pretraining with new information that appears in a given context. These two sources can disagree, causing competition within the model, and it is unclear how an LM will resolve the conflict. On a dataset that queries for knowledge of world capitals, we investigate both distributional and mechanistic determinants of LM behavior in such situations. Specifically, we measure the proportion of the time an LM will use a counterfactual prefix (e.g., ""The capital of Poland is London"") to overwrite what it learned in pretraining (""Warsaw""). On Pythia and GPT2, the training frequency of both the query country (""Poland"") and the in-context city (""London"") highly affect the models' likelihood of using the counterfactual. We then use head attribution to identify individual attention heads that either promote the memorized answer or the in-context answer in the logits. By scaling up or down the value vector of these heads, we can control the likelihood of using the in-context answer on new data. This method can increase the rate of generating the in-context answer to 88\% of the time simply by scaling a single head at runtime. Our work contributes to a body of evidence showing that we can often localize model behaviors to specific components and provides a proof of concept for how future methods might control model behavior dynamically at runtime."	cs.CL	None
7	Towards a high-dimensional Dirac's theorem	Hyunwoo Lee	Dirac's theorem determines the sharp minimum degree threshold for graphs to contain perfect matchings and Hamiltonian cycles. There have been various attempts to generalize this theorem to hypergraphs with larger uniformity by considering hypergraph matchings and Hamiltonian cycles. In this paper, we consider another natural generalization of the perfect matchings, Steiner triple systems. As a Steiner triple system can be viewed as a partition of pairs of vertices, it is a natural high-dimensional analogue of a perfect matching in graphs. We prove that for sufficiently large integer $n$ with $n \equiv 1 \text{ or } 3 \pmod{6},$ any $n$-vertex $3$-uniform hypergraph $H$ with minimum codegree at least $\left(\frac{3 + \sqrt{57}}{12} + o(1) \right)n = (0.879... + o(1))n$ contains a Steiner triple system. In fact, we prove a stronger statement by considering transversal Steiner triple systems in a collection of hypergraphs. We conjecture that the number $\frac{3 + \sqrt{57}}{12}$ can be replaced with $\frac{3}{4}$ which would provide an asymptotically tight high-dimensional generalization of Dirac's theorem.	math.CO	None
8	Ultrafast Optical Modulation by Virtual Interband Transitions	Evgenii E. Narimanov	A new frontier in optics research has been opened by the recent developments in non-perturbative optical modulation in both time and space that creates temporal boundaries generating ``time-reflection'' and ``time-refraction'' of light in the medium. The resulting formation of a Photonic Time Crystal within the modulated optical material leads to a broad range new phenomena with a potential for practical applications, from non-resonant light amplification and tunable lasing, to the new regime of quantum light-matter interactions. However, the formation of the temporal boundary for light relies on optical modulation of the refractive index that is both strong and fast even on the time scale of a single optical cycle. Both of these two problems are extremely challenging even when addressed independently, leading to conflicting requirements for all existing methods of optical modulation. However, as we show in the present work, an alternative approach based on virtual interband transition excitation, solves this seemingly insurmountable problem. Being fundamentally dissipation-free, optical modulation by virtual excitation does not face the problem of heat accumulation and dissipation in the material, while the transient nature of the excited virtual population that modifies the material response only on the time scale of a single optical cycle, ensures that the resulting change in the refractive index is inherently ultrafast. Here we develop the theoretical description of the proposed modulation approach, and demonstrate that it can be readily implemented using already existing optical materials and technology.	physics.optics	6 pages, 4 figures
9	LiCROM: Linear-Subspace Continuous Reduced Order Modeling with Neural Fields	Yue Chang,Peter Yichen Chen,Zhecheng Wang,Maurizio M. Chiaramonte,Kevin Carlberg,Eitan Grinspun	Linear reduced-order modeling (ROM) simplifies complex simulations by approximating the behavior of a system using a simplified kinematic representation. Typically, ROM is trained on input simulations created with a specific spatial discretization, and then serves to accelerate simulations with the same discretization. This discretization-dependence is restrictive.   Becoming independent of a specific discretization would provide flexibility to mix and match mesh resolutions, connectivity, and type (tetrahedral, hexahedral) in training data; to accelerate simulations with novel discretizations unseen during training; and to accelerate adaptive simulations that temporally or parametrically change the discretization.   We present a flexible, discretization-independent approach to reduced-order modeling. Like traditional ROM, we represent the configuration as a linear combination of displacement fields. Unlike traditional ROM, our displacement fields are continuous maps from every point on the reference domain to a corresponding displacement vector; these maps are represented as implicit neural fields.   With linear continuous ROM (LiCROM), our training set can include multiple geometries undergoing multiple loading conditions, independent of their discretization. This opens the door to novel applications of reduced order modeling. We can now accelerate simulations that modify the geometry at runtime, for instance via cutting, hole punching, and even swapping the entire mesh. We can also accelerate simulations of geometries unseen during training. We demonstrate one-shot generalization, training on a single geometry and subsequently simulating various unseen geometries.	cs.GR	None
0	Gravitational production of sterile neutrinos	Fotis Koutroulis,Oleg Lebedev,Stefan Pokorski	We consider gravitational production of singlet fermions such as sterile neutrinos during and after inflation. The production efficiency due to classical gravity is suppressed by the fermion mass. Quantum gravitational effects, on the other hand, are expected to break conformal invariance of the fermion sector by the Planck scale-suppressed operators irrespective of the mass. We find that such operators are very efficient in fermion production immediately after inflation, generating a significant background of stable or long-lived feebly interacting particles. This applies, in particular, to sterile neutrinos which can constitute cold non-thermal dark matter for a wide range of masses, including the keV scale.	hep-ph	18 pages, 1 figure
1	Is Probing All You Need? Indicator Tasks as an Alternative to Probing Embedding Spaces	Tal Levy,Omer Goldman,Reut Tsarfaty	The ability to identify and control different kinds of linguistic information encoded in vector representations of words has many use cases, especially for explainability and bias removal. This is usually done via a set of simple classification tasks, termed probes, to evaluate the information encoded in the embedding space. However, the involvement of a trainable classifier leads to entanglement between the probe's results and the classifier's nature. As a result, contemporary works on probing include tasks that do not involve training of auxiliary models. In this work we introduce the term indicator tasks for non-trainable tasks which are used to query embedding spaces for the existence of certain properties, and claim that this kind of tasks may point to a direction opposite to probes, and that this contradiction complicates the decision on whether a property exists in an embedding space. We demonstrate our claims with two test cases, one dealing with gender debiasing and another with the erasure of morphological information from embedding spaces. We show that the application of a suitable indicator provides a more accurate picture of the information captured and removed compared to probes. We thus conclude that indicator tasks should be implemented and taken into consideration when eliciting information from embedded representations.	cs.CL	Findings of EMNLP 2023
2	Do Stochastic Parrots have Feelings Too? Improving Neural Detection of Synthetic Text via Emotion Recognition	Alan Cowap,Yvette Graham,Jennifer Foster	Recent developments in generative AI have shone a spotlight on high-performance synthetic text generation technologies. The now wide availability and ease of use of such models highlights the urgent need to provide equally powerful technologies capable of identifying synthetic text. With this in mind, we draw inspiration from psychological studies which suggest that people can be driven by emotion and encode emotion in the text they compose. We hypothesize that pretrained language models (PLMs) have an affective deficit because they lack such an emotional driver when generating text and consequently may generate synthetic text which has affective incoherence i.e. lacking the kind of emotional coherence present in human-authored text. We subsequently develop an emotionally aware detector by fine-tuning a PLM on emotion. Experiment results indicate that our emotionally-aware detector achieves improvements across a range of synthetic text generators, various sized models, datasets, and domains. Finally, we compare our emotionally-aware synthetic text detector to ChatGPT in the task of identification of its own output and show substantial gains, reinforcing the potential of emotion as a signal to identify synthetic text. Code, models, and datasets are available at https: //github.com/alanagiasi/emoPLMsynth	cs.CL	Accepted to Findings of EMNLP 2023 (long paper). Camera ready version
3	Neural Collapse in Multi-label Learning with Pick-all-label Loss	Pengyu Li,Yutong Wang,Xiao Li,Qing Qu	"We study deep neural networks for the multi-label classification (MLab) task through the lens of neural collapse (NC). Previous works have been restricted to the multi-class classification setting and discovered a prevalent NC phenomenon comprising of the following properties for the last-layer features: (i) the variability of features within every class collapses to zero, (ii) the set of feature means form an equi-angular tight frame (ETF), and (iii) the last layer classifiers collapse to the feature mean upon some scaling. We generalize the study to multi-label learning, and prove for the first time that a generalized NC phenomenon holds with the ""pick-all-label'' formulation. Under the natural analog of the unconstrained feature model (UFM), we establish that the only global classifier of the pick-all-label cross entropy loss display the same ETF geometry which further collapse to multiplicity-1 feature class means. Besides, we discover a combinatorial property in generalized NC which is unique for multi-label learning that we call ``tag-wise average'' property, where the feature class-means of samples with multiple labels are scaled average of the feature class-means of single label tags. Theoretically, we establish global optimality result for the pick-all-label cross-entropy risk for the UFM. Additionally, We also provide empirical evidence to support our investigation into training deep neural networks on multi-label datasets, resulting in improved training efficiency."	cs.LG	None
4	Enhancing Energy Efficiency for Reconfigurable Intelligent Surfaces with Practical Power Models	Zhiyi Li,Jida Zhang,Jieao Zhu,Shi Jin,Linglong Dai	Reconfigurable intelligent surfaces (RISs) are widely considered a promising technology for future wireless communication systems. As an important indicator of RIS-assisted communication systems in green wireless communications, energy efficiency (EE) has recently received intensive research interest as an optimization target. However, most previous works have ignored the different power consumption between ON and OFF states of the PIN diodes attached to each RIS element. This oversight results in extensive unnecessary power consumption and reduction of actual EE due to the inaccurate power model. To address this issue, in this paper, we first utilize a practical power model for a RIS-assisted multi-user multiple-input single-output (MU-MISO) communication system, which takes into account the difference in power dissipation caused by ON-OFF states of RIS's PIN diodes. Based on this model, we formulate a more accurate EE optimization problem. However, this problem is non-convex and has mixed-integer properties, which poses a challenge for optimization. To solve the problem, an effective alternating optimization (AO) algorithm framework is utilized to optimize the base station and RIS beamforming precoder separately. To obtain the essential RIS beamforming precoder, we develop two effective methods based on maximum gradient search and SDP relaxation respectively. Theoretical analysis shows the exponential complexity of the original problem has been reduced to polynomial complexity. Simulation results demonstrate that the proposed algorithm outperforms the existing ones, leading to a significant increase in EE across a diverse set of scenarios.	eess.SP	Reconfigurable intelligent surface is a promising 6G technology.   However, RIS power models are inaccurate. In this paper, we construct a   practical power model for RIS communication systems with an SDP-relaxation   algorithm, achieving optimal energy efficiency
5	YOLO-Angio: An Algorithm for Coronary Anatomy Segmentation	Tom Liu,Hui Lin,Aggelos K. Katsaggelos,Adrienne Kline	Coronary angiography remains the gold standard for diagnosis of coronary artery disease, the most common cause of death worldwide. While this procedure is performed more than 2 million times annually, there remain few methods for fast and accurate automated measurement of disease and localization of coronary anatomy. Here, we present our solution to the Automatic Region-based Coronary Artery Disease diagnostics using X-ray angiography images (ARCADE) challenge held at MICCAI 2023. For the artery segmentation task, our three-stage approach combines preprocessing and feature selection by classical computer vision to enhance vessel contrast, followed by an ensemble model based on YOLOv8 to propose possible vessel candidates by generating a vessel map. A final segmentation is based on a logic-based approach to reconstruct the coronary tree in a graph-based sorting method. Our entry to the ARCADE challenge placed 3rd overall. Using the official metric for evaluation, we achieved an F1 score of 0.422 and 0.4289 on the validation and hold-out sets respectively.	eess.IV	MICCAI Conference ARCADE Grand Challenge, YOLO, Computer Vision,
6	Correlation Debiasing for Unbiased Scene Graph Generation in Videos	Anant Khandelwal	Dynamic scene graph generation (SGG) from videos requires not only comprehensive understanding of objects across the scenes that are prone to temporal fluctuations but also a model the temporal motions and interactions with different objects. Moreover, the long-tailed distribution of visual relationships is the crucial bottleneck of most dynamic SGG methods, since most of them focus on capturing spatio-temporal context using complex architectures, which leads to the generation of biased scene graphs. To address these challenges, we propose FloCoDe: Flow-aware temporal consistency and Correlation Debiasing with uncertainty attenuation for unbiased dynamic scene graphs. FloCoDe employs feature warping using flow to detect temporally consistent objects across the frames. In addition, it uses correlation debiasing to learn the unbiased relation representation for long-tailed classes. Moreover, to attenuate the predictive uncertainties, it uses a mixture of sigmoidal cross-entropy loss and contrastive loss to incorporate label correlations to identify the commonly co-occurring relations and help debias the long-tailed ones. Extensive experimental evaluation shows a performance gain as high as 4.1% showing the superiority of generating more unbiased scene graphs.	cs.CV	11 pages, 5 tables, 4 figures
7	BianQue: Balancing the Questioning and Suggestion Ability of Health LLMs with Multi-turn Health Conversations Polished by ChatGPT	Yirong Chen,Zhenyu Wang,Xiaofen Xing,huimin zheng,Zhipei Xu,Kai Fang,Junhong Wang,Sihang Li,Jieling Wu,Qi Liu,Xiangmin Xu	Large language models (LLMs) have performed well in providing general and extensive health suggestions in single-turn conversations, exemplified by systems such as ChatGPT, ChatGLM, ChatDoctor, DoctorGLM, and etc. However, the limited information provided by users during single turn results in inadequate personalization and targeting of the generated suggestions, which requires users to independently select the useful part. It is mainly caused by the missing ability to engage in multi-turn questioning. In real-world medical consultations, doctors usually employ a series of iterative inquiries to comprehend the patient's condition thoroughly, enabling them to provide effective and personalized suggestions subsequently, which can be defined as chain of questioning (CoQ) for LLMs. To improve the CoQ of LLMs, we propose BianQue, a ChatGLM-based LLM finetuned with the self-constructed health conversation dataset BianQueCorpus that is consist of multiple turns of questioning and health suggestions polished by ChatGPT. Experimental results demonstrate that the proposed BianQue can simultaneously balance the capabilities of both questioning and health suggestions, which will help promote the research and application of LLMs in the field of proactive health.	cs.CL	None
8	New recursive construction for tree NLSM and SG amplitudes, and new understanding of enhanced Adler zero	Kang Zhou	"We propose a new bottom up method to construct tree amplitudes of non-linear sigma model (NLSM) and special Galileon theory (SG), based on assuming the universality of soft behaviors and the double copy structure. We extend the on-shell amplitudes to off-shell ones with two off-shell external legs, which allow the numbers of external legs to be odd. Then the $3$-point and $4$-point off-shell amplitudes can be bootstrapped, and the soft behaviors of $4$-point NLSM and SG amplitudes can be derived from them. The universality of soft behaviors allows us to invert the resulted soft theorems to construct higher-point off-shell amplitudes recursively, and express them in the formula of expansions to tree amplitudes of bi-adjoint scalar theory. We emphasize that the exact forms of universal soft behaviors are derived, rather than assumed as the input. Back to the on-shell limit, amplitudes with odd numbers of external legs vanish automatically, and the enhanced Adler zero emerge. From the bottom up perspective without the aid of a Lagrangian, the enhanced Adler zero are understood as that soft behaviors vanish faster than the degree expected from the naive power counting of soft momentum in the formula of expansions. Interestingly, such ""zero"" have explicit formulas and can be interpreted naturally. For tree amplitudes of Born-Infeld and Dirac-Born-Infeld theories, our method for construction does not make sense, but the enhanced Adler zero can be studied similarly."	hep-th	36 pages, 2 figures
9	Thermal Hall conductivity of electron-doped cuprates: Electrons and phonons	Marie-Eve Boulanger,Lu Chen,Vincent Oliviero,David Vignolles,Ga√´l Grissonnanche,Kejun Xu,Zhi-Xun Shen,Cyril Proust,Jordan Baglo,Louis Taillefer	It has recently become clear that phonons generate a sizable thermal Hall effect in cuprates, whether they are undoped, electron-doped or hole-doped (inside the pseudogap phase). At higher doping, where cuprates are reasonably good metals, mobile electrons also generate a thermal Hall effect, the thermal equivalent of the standard electrical Hall effect. Here we show that in the cleanest crystals of the electron-doped cuprate Nd$_{2-x}$Ce$_{x}$CuO$_{4}$, at high doping, the phonon and electron contributions to the thermal Hall conductivity $\kappa_{\rm {xy}}$ are of comparable magnitude, but of opposite sign. In samples of lower quality, phonons dominate $\kappa_{\rm {xy}}$, resulting in a negative $\kappa_{\rm {xy}}$ at all temperatures. The fact that the negative phononic $\kappa_{\rm {xy}}$ in the metallic state is similar in magnitude and temperature dependence to that found in the insulating state at lower doping rules out any mechanism based on skew scattering of phonons off charged impurities, since a local charge should be screened in the metallic regime. The phononic $\kappa_{\rm {xy}}$ is found to persist over the entire doping range where antiferromagnetic correlations are known to be significant, suggesting that such correlations may play a role in generating the phonon thermal Hall effect in electron-doped cuprates. If the same mechanism is also at play in hole-doped cuprates, the presence of a phononic $\kappa_{\rm {xy}}$ below (and only below) the critical doping $p^{\star}$ would be evidence that spin correlations are a property of the pseudogap phase.	cond-mat.str-el	None
0	Cross-feature Contrastive Loss for Decentralized Deep Learning on Heterogeneous Data	Sai Aparna Aketi,Kaushik Roy	The current state-of-the-art decentralized learning algorithms mostly assume the data distribution to be Independent and Identically Distributed (IID). However, in practical scenarios, the distributed datasets can have significantly heterogeneous data distributions across the agents. In this work, we present a novel approach for decentralized learning on heterogeneous data, where data-free knowledge distillation through contrastive loss on cross-features is utilized to improve performance. Cross-features for a pair of neighboring agents are the features (i.e., last hidden layer activations) obtained from the data of an agent with respect to the model parameters of the other agent. We demonstrate the effectiveness of the proposed technique through an exhaustive set of experiments on various Computer Vision datasets (CIFAR-10, CIFAR-100, Fashion MNIST, and ImageNet), model architectures, and network topologies. Our experiments show that the proposed method achieves superior performance (0.2-4% improvement in test accuracy) compared to other existing techniques for decentralized learning on heterogeneous data.	cs.LG	12 pages, 7 figures, 11 tables. arXiv admin note: text overlap with   arXiv:2305.04792
1	Indoor Geometry Generator (IGG) Manual	Laetitia Mottet	The Indoor Geometry Generator (IGG) is able to generate automatically simplified indoor geometry and its associated unstructured mesh for Computational Fluid Dynamics (CFD) simulations purposes given very simple user inputs. A large number of indoor features are supported by IGG such as (non-exhaustive list): shelves, tills, tables, chairs, seats... Smaller features such as laptops, computer towers and screens can also be included. In addition, doors/windows as well as ventilation inlet and outlet can be taken into account. Finally, the adding of simplified shape of humans standing, sitting or lying are also supported by IGG. IGG allows the user to generate without much effort indoor geometries such that shop, train, bus, plane, school, open spaces..., while being fully consistent with CFD requirements. The geometry and the mesh are outputted in GMSH format supported by both Fluidity and IC-FERST open-source finite-element CFD software.	physics.flu-dyn	None
2	State Sequences Prediction via Fourier Transform for Representation Learning	Mingxuan Ye,Yufei Kuang,Jie Wang,Rui Yang,Wengang Zhou,Houqiang Li,Feng Wu	While deep reinforcement learning (RL) has been demonstrated effective in solving complex control tasks, sample efficiency remains a key challenge due to the large amounts of data required for remarkable performance. Existing research explores the application of representation learning for data-efficient RL, e.g., learning predictive representations by predicting long-term future states. However, many existing methods do not fully exploit the structural information inherent in sequential state signals, which can potentially improve the quality of long-term decision-making but is difficult to discern in the time domain. To tackle this problem, we propose State Sequences Prediction via Fourier Transform (SPF), a novel method that exploits the frequency domain of state sequences to extract the underlying patterns in time series data for learning expressive representations efficiently. Specifically, we theoretically analyze the existence of structural information in state sequences, which is closely related to policy performance and signal regularity, and then propose to predict the Fourier transform of infinite-step future state sequences to extract such information. One of the appealing features of SPF is that it is simple to implement while not requiring storage of infinite-step future states as prediction targets. Experiments demonstrate that the proposed method outperforms several state-of-the-art algorithms in terms of both sample efficiency and performance.	cs.LG	None
3	AdaptiX -- A Transitional XR Framework for Development and Evaluation of Shared Control Applications in Assistive Robotics	Max Pascher,Felix Ferdinand Goldau,Kirill Kronhardt,Udo Frese,Jens Gerken	With the ongoing efforts to empower people with mobility impairments and the increase in technological acceptance by the general public, assistive technologies, such as collaborative robotic arms, are gaining popularity. Yet, their widespread success is limited by usability issues, specifically the disparity between user input and software control along the autonomy continuum. To address this, shared control concepts provide opportunities to combine the targeted increase of user autonomy with a certain level of computer assistance. This paper presents the free and open-source AdaptiX XR framework for developing and evaluating shared control applications in a high-resolution simulation environment. The initial framework consists of a simulated robotic arm with an example scenario in Virtual Reality (VR), multiple standard control interfaces, and a specialized recording/replay system. AdaptiX can easily be extended for specific research needs, allowing Human-Robot Interaction (HRI) researchers to rapidly design and test novel interaction methods, intervention strategies, and multi-modal feedback techniques, without requiring an actual physical robotic arm during the early phases of ideation, prototyping, and evaluation. Also, a Robot Operating System (ROS) integration enables the controlling of a real robotic arm in a PhysicalTwin approach without any simulation-reality gap. Here, we review the capabilities and limitations of AdaptiX in detail and present three bodies of research based on the framework. AdaptiX can be accessed at https://adaptix.robot-research.de.	cs.HC	Accepted submission at The 16th ACM SIGCHI Symposium on Engineering   Interactive Computing Systems (EICS'24)
4	Adapted Thermodynamical Model for the Prediction of Adsorption in Nanoporous Materials	F. Stavarache,A. Luna-Triguero,S. Calero,J. M. Vicent-Luna	In this paper, we introduce a novel, adapted approach for computing gas adsorption properties in porous materials. We analyze the Dubinin-Polanyi's adsorption model and investigate various frameworks to estimate its required essential components. Those are linked to physicochemical properties of the adsorbates, such as the vapor saturation pressure and density in the adsorbed state. To conduct this analysis, we obtain adsorption isotherms for several metal-organic frameworks, encompassing a range of pore sizes, shapes, and chemical compositions. We then apply and evaluate multiple combinations of models for saturation pressure and density.   After the evaluation of the method, we propose a working thermodynamic model for computing adsorption isotherms, which entails using the critical isochore as an approximation of the saturation pressure above the critical point and applying Hauer's method with a universal thermal expansion coefficient for density in the adsorbed state. This framework is applicable not only to simulated isotherms but also to experimental data from the literature for various molecules and structures, demonstrating robust predictive capabilities and high transferability. Our method showcases superior performance in terms of accuracy, generalizability, and simplicity compared to existing methods currently in use. For the first time, a method starting from a single adsorption curve and based on physically interpretable parameters can predict adsorption properties across a wide range of operating conditions.	cond-mat.mtrl-sci	None
5	Efficiently generating inverse-Wishart matrices and their Cholesky factors	Seth D. Axen	This paper presents a new algorithm for generating random inverse-Wishart matrices that directly generates the Cholesky factor of the matrix without computing the factorization. Whenever parameterized in terms of a precision matrix $\Omega=\Sigma^{-1}$, or its Cholesky factor, instead of a covariance matrix $\Sigma$, the new algorithm is more efficient than the current standard algorithm.	stat.CO	9 pages
6	Attitude Takeover Control for Noncooperative Space Targets Based on Gaussian Processes with Online Model Learning	Yuhan Liu,Pengyu Wang,Chang-Hun Lee,Roland T√≥th	One major challenge for autonomous attitude takeover control for on-orbit servicing of spacecraft is that an accurate dynamic motion model of the combined vehicles is highly nonlinear, complex and often costly to identify online, which makes traditional model-based control impractical for this task. To address this issue, a recursive online sparse Gaussian Process (GP)-based learning strategy for attitude takeover control of noncooperative targets with maneuverability is proposed, where the unknown dynamics are online compensated based on the learnt GP model in a semi-feedforward manner. The method enables the continuous use of on-orbit data to successively improve the learnt model during online operation and has reduced computational load compared to standard GP regression. Next to the GP-based feedforward, a feedback controller is proposed that varies its gains based on the predicted model confidence, ensuring robustness of the overall scheme. Moreover, rigorous theoretical proofs of Lyapunov stability and boundedness guarantees of the proposed method-driven closed-loop system are provided in the probabilistic sense. A simulation study based on a high-fidelity simulator is used to show the effectiveness of the proposed strategy and demonstrate its high performance.	eess.SY	17 pages, 14 figures. Submitted to in IEEE Transactions on Aerospace   and Electronic Systems
7	Long time behavior of a porous medium model with degenerate hysteresis	Chiara Gavioli,Pavel Krejƒç√≠	Hysteresis in the pressure-saturation relation in unsaturated porous media, which is due to surface tension on the liquid-gas interface, exhibits strong degeneracy in the resulting mass balance equation. As an extension of previous existence and uniqueness results, we prove that under physically admissible initial conditions and without mass exchange with the exterior, the unique global solution of the fluid diffusion problem exists and asymptotically converges as time tends to infinity to a possibly non-homogeneous mass distribution and an a priori unknown constant pressure.	math.AP	16 pages. arXiv admin note: text overlap with arXiv:2303.17451
8	Another approach to build Lyapunov functions for the first order methods in the quadratic case	Daniil Merkulov,Ivan Oseledets	Lyapunov functions play a fundamental role in analyzing the stability and convergence properties of optimization methods. In this paper, we propose a novel and straightforward approach for constructing Lyapunov functions for first-order methods applied to quadratic functions. Our approach involves bringing the iteration matrix to an upper triangular form using Schur decomposition, then examining the value of the last coordinate of the state vector. This value is multiplied by a magnitude smaller than one at each iteration. Consequently, this value should decrease at each iteration, provided that the method converges. We rigorously prove the suitability of this Lyapunov function for all first-order methods and derive the necessary conditions for the proposed function to decrease monotonically. Experiments conducted with general convex functions are also presented, alongside a study on the limitations of the proposed approach.   Remarkably, the newly discovered Lyapunov function is straightforward and does not explicitly depend on the exact method formulation or function characteristics like strong convexity or smoothness constants. In essence, a single expression serves as a Lyapunov function for several methods, including Heavy Ball, Nesterov Accelerated Gradient, and Triple Momentum, among others. To the best of our knowledge, this approach has not been previously reported in the literature.	math.OC	None
9	Prospects for probing the interaction between dark energy and dark matter using gravitational-wave dark sirens with neutron star tidal deformation	Tian-Nuo Li,Shang-Jie Jin,Hai-Li Li,Jing-Fei Zhang,Xin Zhang	Gravitational wave (GW) standard siren observations provide a rather useful tool to explore the evolution of the universe. In this work, we wish to investigate whether the dark sirens with neutron star (NS) deformation from third-generation (3G) GW detectors could help probe the interaction between dark energy and dark matter. We simulate the GW dark sirens of four detection strategies based on the three-year observation and consider four phenomenological interacting dark energy models to perform cosmological analysis. We find that GW dark sirens could provide tight constraints on $\Omega_{\rm m}$ and $H_0$ in the four IDE models, but perform not well in constraining the dimensionless coupling parameter $\beta$ with the interaction proportional to the energy density of cold dark matter. Nevertheless, the parameter degeneracy orientations of CMB and GW are almost orthogonal, and thus the combination of them could effectively break cosmological parameter degeneracies, with the constraint errors of $\beta$ being 0.00068-0.018. In addition, we choose three typical equation of states (EoSs) of NS, i.e., SLy, MPA1, and MS1, to investigate the effect of NS's EoS in cosmological analysis. The stiffer EoS could give tighter constraints than the softer EoS. Nonetheless, the combination of CMB and GW dark sirens (using different EoSs of NS) shows basically the same constraint results of cosmological parameters. We conclude that the dark sirens from 3G GW detectors would play a crucial role in helping probe the interaction between dark energy and dark matter, and the CMB+GW results are basically not affected by the EoS of NS.	astro-ph.CO	12 pages, 9 figures
0	Regression analysis of multiplicative hazards model with time-dependent coefficient for sparse longitudinal covariates	Zhuowei Sun,Hongyuan Cao	We study the multiplicative hazards model with intermittently observed longitudinal covariates and time-varying coefficients. For such models, the existing {\it ad hoc} approach, such as the last value carried forward, is biased. We propose a kernel weighting approach to get an unbiased estimation of the non-parametric coefficient function and establish asymptotic normality for any fixed time point. Furthermore, we construct the simultaneous confidence band to examine the overall magnitude of the variation. Simulation studies support our theoretical predictions and show favorable performance of the proposed method. A data set from cerebral infarction is used to illustrate our methodology.	stat.ME	None
1	Data-Driven Modeling and Analysis of Transmission Error in Harmonic Drive Systems: Nonlinear Dynamics, Error Modeling, and Compensation Techniques	Ju Wu,Philippe Louis Schuchert,Alireza Karimi	Harmonic drive systems (HDS) are high-precision robotic transmissions featuring compact size and high gear ratios. However, issues like kinematic transmission errors hamper their precision performance. This article focuses on data-driven modeling and analysis of an HDS to improve kinematic error compensation. The background introduces HDS mechanics, nonlinear attributes, and modeling approaches from literature. The HDS dynamics are derived using Lagrange equations. Experiments under aggressive conditions provide training data exhibiting deterministic patterns. Various linear and nonlinear models have been developed. The best-performing model, based on a nonlinear neural network, achieves over 98\% accuracy for one-step predictions on both the training and validation data sets. A phenomenological model separates the kinematic error into a periodic pure part and flexible part. Apart from implementation of estimated transmission error injection compensation, novel compensation mechanisms policies for the kinematic error are analyzed and proposed, including nonlinear model predictive control and frequency loop-shaping. The feedback loop is analyzed to select the controller for vibration mitigation. Main contributions include the nonlinear dynamics derivation, data-driven nonlinear modeling of flexible kinematic errors, repeatable experiment design, and proposed novel compensation mechanism and policies. Future work involves using physics-informed neural networks, sensitivity analysis, full life-cycle monitoring, and extracting physical laws directly from data.	cs.RO	None
2	KirchhoffNet: A Circuit Bridging Message Passing and Continuous-Depth Models	Zhengqi Gao,Fan-Keng Sun,Duane S. Boning	In this paper, we exploit a fundamental principle of analog electronic circuitry, Kirchhoff's current law, to introduce a unique class of neural network models that we refer to as KirchhoffNet. KirchhoffNet establishes close connections with message passing neural networks and continuous-depth networks. We demonstrate that even in the absence of any traditional layers (such as convolution, pooling, or linear layers), KirchhoffNet attains 98.86% test accuracy on the MNIST dataset, comparable with state of the art (SOTA) results. What makes KirchhoffNet more intriguing is its potential in the realm of hardware. Contemporary deep neural networks are conventionally deployed on GPUs. In contrast, KirchhoffNet can be physically realized by an analog electronic circuit. Moreover, we justify that irrespective of the number of parameters within a KirchhoffNet, its forward calculation can always be completed within 1/f seconds, with f representing the hardware's clock frequency. This characteristic introduces a promising technology for implementing ultra-large-scale neural networks.	cs.LG	4 pages, 3 figures
3	A strategy to compute convective timescales of the Indian monsoon with the WRF model	Lucy G. Recchia,Valerio Lucarini	The Indian monsoon brings around 80% of the annual rainfall over the summer months June--September to the Indian subcontinent. The timing of the monsoon onset and the associated rainfall has a large impact on agriculture, thus impacting the livelihoods of over one billion people. To improve forecasting the monsoon on sub-seasonal timescales, global climate models are in continual development. One of the key issues is the representation of convection, which is typically parametrised. Different convection schemes offer varying degrees of performance, depending on the model and scenario. Here, we propose a method to compute a convective timescale, which could be used as a metric for comparison across different models and convection schemes. The method involves the determination of a vertical convective flux between the lower and upper troposphere through moisture budget analysis, and then relating this to the total column moisture content. The method is applied to a WRF model simulation of the 2016 Indian monsoon, giving convective timescales that are reduced by a factor of 2 when the onset of the monsoon occurs. The convective timescale can also be used as an indicator of monsoon transitions from pre-onset to full phase of the monsoon, and to assess changes in monsoon phases under future climate scenarios.	physics.ao-ph	21 pages, 9 Figures plus 10 Supplementary Figures
4	The distribution, kinematics and luminosities of extreme helium stars as probes of their origin and evolution	A. Philip Monai,P. Martin,C. S. Jeffery	Hydrogen deficient stars include the cool R CrB variable (RCBs) and hydrogen-deficient carbon (HdCs) giants through extreme helium stars (EHes) to the very hot helium-rich subdwarfs (He-sdO and O(He) stars) and white dwarfs. With surfaces rich in helium, nitrogen and carbon, their origins have been identified with the merger of two white dwarfs. Using Gaia to focus on the EHes, we aim to identify progenitor populations and test the evolution models. Gaia DR3 measurements and ground-based radial velocities have been used to compute Galactic orbits using galpy. Each orbit has been classified by population; EHe stars are found in all of the thin disk, thick disk, halo and bulge, as are RCB, HdC and He-sdO stars. Spectral energy distributions were constructed for all EHes, to provide angular diameters, and hence radii and luminosities. The EHes fall into two luminosity groups divided at L ~ 2500 solar L. This supports theory for the origin of EHes, and is the strongest confirmation so far in terms of luminosity. The lower luminosity EHes correspond well with the post-merger evolution of a double helium white dwarf binary. Likewise, the higher luminosity EHes match the post-merger evolution of a carbon/oxygen plus helium white dwarf binary. In terms of parent populations, current models predict that double white dwarf mergers should occur in all Galactic populations, but favour mergers arising from recent star formation (i.e. thin disk), whereas the statistics favour an older epoch (i.e. thick disk).	astro-ph.SR	Accepted for publication in MNRAS 24/10/23, 14 pages + 6 pages   supplementary material, 13 figures
5	Deformation classes of invertible field theories and the Freed--Hopkins conjecture	Daniel Grady	"We prove a conjecture of Freed and Hopkins, which relates deformation classes of reflection positive, invertible, $d$-dimensional extended field theories with fixed symmetry type to a certain generalized cohomology of a Thom spectrum. Along the way, we establish several results, including the construction of a smooth variant of the Brown--Comenetz dual of the sphere spectrum and a calculation of the ""deformation type"" of the extended geometric bordism category."	math.AT	47 pages
6	Using Causality-Aware Graph Neural Networks to Predict Temporal Centralities in Dynamic Graphs	Franziska Heeg,Ingo Scholtes	Node centralities play a pivotal role in network science, social network analysis, and recommender systems. In temporal data, static path-based centralities like closeness or betweenness can give misleading results about the true importance of nodes in a temporal graph. To address this issue, temporal generalizations of betweenness and closeness have been defined that are based on the shortest time-respecting paths between pairs of nodes. However, a major issue of those generalizations is that the calculation of such paths is computationally expensive. Addressing this issue, we study the application of De Bruijn Graph Neural Networks (DBGNN), a causality-aware graph neural network architecture, to predict temporal path-based centralities in time series data. We experimentally evaluate our approach in 13 temporal graphs from biological and social systems and show that it considerably improves the prediction of both betweenness and closeness centrality compared to a static Graph Convolutional Neural Network.	cs.LG	None
7	Metric Clustering and MST with Strong and Weak Distance Oracles	MohammadHossein Bateni,Prathamesh Dharangutte,Rajesh Jayaram,Chen Wang	We study optimization problems in a metric space $(\mathcal{X},d)$ where we can compute distances in two ways: via a ''strong'' oracle that returns exact distances $d(x,y)$, and a ''weak'' oracle that returns distances $\tilde{d}(x,y)$ which may be arbitrarily corrupted with some probability. This model captures the increasingly common trade-off between employing both an expensive similarity model (e.g. a large-scale embedding model), and a less accurate but cheaper model. Hence, the goal is to make as few queries to the strong oracle as possible. We consider both so-called ''point queries'', where the strong oracle is queried on a set of points $S \subset \mathcal{X} $ and returns $d(x,y)$ for all $x,y \in S$, and ''edge queries'' where it is queried for individual distances $d(x,y)$.   Our main contributions are optimal algorithms and lower bounds for clustering and Minimum Spanning Tree (MST) in this model. For $k$-centers, $k$-median, and $k$-means, we give constant factor approximation algorithms with only $\tilde{O}(k)$ strong oracle point queries, and prove that $\Omega(k)$ queries are required for any bounded approximation. For edge queries, our upper and lower bounds are both $\tilde{\Theta}(k^2)$. Surprisingly, for the MST problem we give a $O(\sqrt{\log n})$ approximation algorithm using no strong oracle queries at all, and a matching $\Omega(\sqrt{\log n})$ lower bound. We empirically evaluate our algorithms, and show that their quality is comparable to that of the baseline algorithms that are given all true distances, but while querying the strong oracle on only a small fraction ($<1\%$) of points.	cs.DS	None
8	Social Learning of General Rules	Enrique Urbano Arellano,Xinyang Wang	Why do agents adopt a particular general behavioral rule among a collection of possible alternatives? To address this question, we introduce a dynamic social learning framework, where agents rely on general rules of thumb and imitate the behavioral rules of successful peers. We find the social learning outcome can be characterized independent of the initial rule distribution. When one dominant general rule consistently yields superior problem-specific outcomes, social learning almost surely leads all agents to adopt this dominant rule; otherwise, provided the population is sufficiently large, the better rule for the more frequent problem becomes the consensus rule with arbitrarily high probability. As a result, the behavioral rule selected by the social learning process need not maximize social welfare. We complement our theoretical analysis with an application to the market sentiment selection in a stochastic production market.	econ.TH	47 pages, 1 figures
9	Identification of low energy neutral and charged cosmic ray events in large wide field observatorie	L Apolin√°rio,P. Assis,P. Brogueira,R. Concei√ß√£o,P. J. Costa,G. La Mura,M. Pimenta,B. Tom√©	The lower energy thresholds of large wide-field gamma-ray observatories are often determined by their capability to deal with the very low-energy cosmic ray background. In fact, in observatories with areas of tens or hundreds of thousands of square meters, the number of background events generated by the superposition of random, very low energy cosmic rays is huge and may exceed by far the possible signal events. In this article, we argue that a trigger strategy based on pattern recognition of the shower front can significantly reject the background, keeping a good efficiency and a good angular accuracy (few square degrees) for gamma rays with energies as low as tens of GeV. In this way, alerts can be followed or emitted within time lapses of the order of the second, enabling wide-field gamma-ray observatories to better contribute to global multi-messenger networks of astrophysical observatories.	astro-ph.HE	9 pages, 14 figures
0	Topology-aware Debiased Self-supervised Graph Learning for Recommendation	Lei Han,Hui Yan,Zhicheng Qiao	In recommendation, graph-based Collaborative Filtering (CF) methods mitigate the data sparsity by introducing Graph Contrastive Learning (GCL). However, the random negative sampling strategy in these GCL-based CF models neglects the semantic structure of users (items), which not only introduces false negatives (negatives that are similar to anchor user (item)) but also ignores the potential positive samples. To tackle the above issues, we propose Topology-aware Debiased Self-supervised Graph Learning (TDSGL) for recommendation, which constructs contrastive pairs according to the semantic similarity between users (items). Specifically, since the original user-item interaction data commendably reflects the purchasing intent of users and certain characteristics of items, we calculate the semantic similarity between users (items) on interaction data. Then, given a user (item), we construct its negative pairs by selecting users (items) which embed different semantic structures to ensure the semantic difference between the given user (item) and its negatives. Moreover, for a user (item), we design a feature extraction module that converts other semantically similar users (items) into an auxiliary positive sample to acquire a more informative representation. Experimental results show that the proposed model outperforms the state-of-the-art models significantly on three public datasets. Our model implementation codes are available at https://github.com/malajikuai/TDSGL.	cs.IR	6 pages,8 figures
1	Xeno Amino Acids: A look into biochemistry as we don't know it	Sean M. Brown,Christopher Mayer-Bacon,Stephen Freeland	Would another origin of life resemble Earth's biochemistry? Here, we review amino acids at three levels: 1) could other chemical classes serve as building blocks for structure and catalysis? Amino acids are both readily available to, and a plausible chemical attractor for, life as we don't know it. 2) If amino acids are used, would we expect the same, L-alpha structural subclass used by life? It is not clear why life favors L-enantiomers, despite numerous ideas. It seems clearer why life on Earth uses the shortest possible (alpha) amino acid backbone, and why each carries only one side chain. Assertions that other backbones are physicochemically impossible have relaxed into evidence that suggest L-{\alpha}-amino acids are preferable. 3) Would we expect a similar set of side chains to those within the genetic code? Many plausible alternatives exist, along with evidence for both evolutionary advantage and physicochemical constraint. As focus shifts from amino acids as a chemical class to specific side chains used by post-LUCA life, the probable role of physicochemical constraint diminishes relative to that of biological evolution. Exciting opportunities now present themselves for laboratory work and computing to explore how changing the amino acid alphabet alters the universe of protein folds. Amino acids remain important and tractable targets for astrobiology. Near-term milestones include: a) systemically generalizing evidence about amino acids as attractors within chemical evolution; b) extending characterization of other backbones relative to biological proteins; c) merging computing and laboratory explorations of structures/functions unlocked by xeno peptides.	q-bio.BM	To be submitted to Life (ISSN 2075-1729), 26 pages (without   references), 8 figures, 1 table, 1 box
2	Noise-tailored Constructions for Spin Wigner Function Kernels	Michael Hanks,Soovin Lee,M. S. Kim	The effective use of noisy intermediate-scale quantum devices requires error mitigation to improve the accuracy of sampled measurement distributions. The more accurately the effects of noise on these distributions can be modeled, the more closely error mitigation will be able to approach theoretical bounds. The characterisation of noisy quantum channels and the inference of their effects on general observables are challenging problems, but in many cases a change in representation can greatly simplify the analysis. Here, we investigate spin Wigner functions for multi-qudit systems. We generalise previous kernel constructions, capturing the effects of several probabilistic unitary noise models in few parameters.	quant-ph	None
3	Control of McKean--Vlasov SDEs with Contagion Through Killing at a State-Dependent Intensity	Ben Hambly,Philipp Jettkant	We consider a novel McKean--Vlasov control problem with contagion through killing of particles and common noise. Each particle is killed at an exponential rate according to an intensity process that increases whenever the particle is located in a specific region. The removal of a particle pushes others towards the removal region, which can trigger cascades that see particles exiting the system in rapid succession. We study the control of such a system by a central agent who intends to preserve particles at minimal cost. Our theoretical contribution is twofold. Firstly, we rigorously justify the McKean--Vlasov control problem as the limit of a corresponding controlled finite particle system. Our proof is based on a controlled martingale problem and tightness arguments. Secondly, we connect our framework with models in which particles are killed once they hit the boundary of the removal region. We show that these models appear in the limit as the exponential rate tends to infinity. As a corollary, we obtain new existence results for McKean--Vlasov SDEs with singular interaction through hitting times which extend those in the established literature. We conclude the paper with numerical investigations of our model applied to government control of systemic risk in financial systems.	math.PR	None
4	Improving Event Time Prediction by Learning to Partition the Event Time Space	Jimmy Hickey,Ricardo Henao,Daniel Wojdyla,Michael Pencina,Matthew M. Engelhard	Recently developed survival analysis methods improve upon existing approaches by predicting the probability of event occurrence in each of a number pre-specified (discrete) time intervals. By avoiding placing strong parametric assumptions on the event density, this approach tends to improve prediction performance, particularly when data are plentiful. However, in clinical settings with limited available data, it is often preferable to judiciously partition the event time space into a limited number of intervals well suited to the prediction task at hand. In this work, we develop a method to learn from data a set of cut points defining such a partition. We show that in two simulated datasets, we are able to recover intervals that match the underlying generative model. We then demonstrate improved prediction performance on three real-world observational datasets, including a large, newly harmonized stroke risk prediction dataset. Finally, we argue that our approach facilitates clinical decision-making by suggesting time intervals that are most appropriate for each task, in the sense that they facilitate more accurate risk prediction.	stat.ML	16 pages, 5 figures, 2 tables
5	Using Artificial French Data to Understand the Emergence of Gender Bias in Transformer Language Models	Lina Conti,Guillaume Wisniewski	Numerous studies have demonstrated the ability of neural language models to learn various linguistic properties without direct supervision. This work takes an initial step towards exploring the less researched topic of how neural models discover linguistic properties of words, such as gender, as well as the rules governing their usage. We propose to use an artificial corpus generated by a PCFG based on French to precisely control the gender distribution in the training data and determine under which conditions a model correctly captures gender information or, on the contrary, appears gender-biased.	cs.CL	Accepted at EMNLP'23
6	Self-Guard: Empower the LLM to Safeguard Itself	Zezhong Wang,Fangkai Yang,Lu Wang,Pu Zhao,Hongru Wang,Liang Chen,Qingwei Lin,Kam-Fai Wong	The jailbreak attack can bypass the safety measures of a Large Language Model (LLM), generating harmful content. This misuse of LLM has led to negative societal consequences. Currently, there are two main approaches to address jailbreak attacks: safety training and safeguards. Safety training focuses on further training LLM to enhance its safety. On the other hand, safeguards involve implementing external models or filters to prevent harmful outputs. However, safety training has constraints in its ability to adapt to new attack types and often leads to a drop in model performance. Safeguards have proven to be of limited help. To tackle these issues, we propose a novel approach called Self-Guard, which combines the strengths of both safety methods. Self-Guard includes two stages. In the first stage, we enhance the model's ability to assess harmful content, and in the second stage, we instruct the model to consistently perform harmful content detection on its own responses. The experiment has demonstrated that Self-Guard is robust against jailbreak attacks. In the bad case analysis, we find that LLM occasionally provides harmless responses to harmful queries. Additionally, we evaluated the general capabilities of the LLM before and after safety training, providing evidence that Self-Guard does not result in the LLM's performance degradation. In sensitivity tests, Self-Guard not only avoids inducing over-sensitivity in LLM but also can even mitigate this issue.	cs.CL	None
7	Posterior Estimation for Dynamic PET imaging using Conditional Variational Inference	Xiaofeng Liu,Thibault Marin,Tiss Amal,Jonghye Woo,Georges El Fakhri,Jinsong Ouyang	This work aims efficiently estimating the posterior distribution of kinetic parameters for dynamic positron emission tomography (PET) imaging given a measurement of time of activity curve. Considering the inherent information loss from parametric imaging to measurement space with the forward kinetic model, the inverse mapping is ambiguous. The conventional (but expensive) solution can be the Markov Chain Monte Carlo (MCMC) sampling, which is known to produce unbiased asymptotical estimation. We propose a deep-learning-based framework for efficient posterior estimation. Specifically, we counteract the information loss in the forward process by introducing latent variables. Then, we use a conditional variational autoencoder (CVAE) and optimize its evidence lower bound. The well-trained decoder is able to infer the posterior with a given measurement and the sampled latent variables following a simple multivariate Gaussian distribution. We validate our CVAE-based method using unbiased MCMC as the reference for low-dimensional data (a single brain region) with the simplified reference tissue model.	physics.med-ph	Published on IEEE NSS&MIC
8	A Resilient Framework for 5G-Edge-Connected UAVs based on Switching Edge-MPC and Onboard-PID Control	Gerasimos Damigos,Achilleas Santi Seisa,Sumeet Gajanan Satpute,Tore Lindgren,George Nikolakopoulos	In recent years, the need for resources for handling processes with high computational complexity for mobile robots is becoming increasingly urgent. More specifically, robots need to autonomously operate in a robust and continuous manner, while keeping high performance, a need that led to the utilization of edge computing to offload many computationally demanding and time-critical robotic procedures. However, safe mechanisms should be implemented to handle situations when it is not possible to use the offloaded procedures, such as if the communication is challenged or the edge cluster is not available. To this end, this article presents a switching strategy for safety, redundancy, and optimized behavior through an edge computing-based Model Predictive Controller (MPC) and a low-level onboard-PID controller for edge-connected Unmanned Aerial Vehicles (UAVs). The switching strategy is based on the communication Key Performance Indicators (KPIs) over 5G to decide whether the UAV should be controlled by the edge-based or have a safe fallback based on the onboard controller.	cs.RO	8 pages, 9 figures, isie2023
9	On Responsible Machine Learning Datasets with Fairness, Privacy, and Regulatory Norms	Surbhi Mittal,Kartik Thakral,Richa Singh,Mayank Vatsa,Tamar Glaser,Cristian Canton Ferrer,Tal Hassner	"Artificial Intelligence (AI) has made its way into various scientific fields, providing astonishing improvements over existing algorithms for a wide variety of tasks. In recent years, there have been severe concerns over the trustworthiness of AI technologies. The scientific community has focused on the development of trustworthy AI algorithms. However, machine and deep learning algorithms, popular in the AI community today, depend heavily on the data used during their development. These learning algorithms identify patterns in the data, learning the behavioral objective. Any flaws in the data have the potential to translate directly into algorithms. In this study, we discuss the importance of Responsible Machine Learning Datasets and propose a framework to evaluate the datasets through a responsible rubric. While existing work focuses on the post-hoc evaluation of algorithms for their trustworthiness, we provide a framework that considers the data component separately to understand its role in the algorithm. We discuss responsible datasets through the lens of fairness, privacy, and regulatory compliance and provide recommendations for constructing future datasets. After surveying over 100 datasets, we use 60 datasets for analysis and demonstrate that none of these datasets is immune to issues of fairness, privacy preservation, and regulatory compliance. We provide modifications to the ``datasheets for datasets"" with important additions for improved dataset documentation. With governments around the world regularizing data protection laws, the method for the creation of datasets in the scientific community requires revision. We believe this study is timely and relevant in today's era of AI."	cs.LG	None
0	Deciphering Radio Emission from Solar Coronal Mass Ejections using High-fidelity Spectropolarimetric Radio Imaging	Devojyoti Kansabanik	Coronal mass ejections (CMEs) are large-scale expulsions of plasma and magnetic fields from the Sun into the heliosphere and are the most important driver of space weather. The geo-effectiveness of a CME is primarily determined by its magnetic field strength and topology. Measurement of CME magnetic fields, both in the corona and heliosphere, is essential for improving space weather forecasting. Observations at radio wavelengths can provide several remote measurement tools for estimating both strength and topology of the CME magnetic fields. Among them, gyrosynchrotron (GS) emission produced by mildly-relativistic electrons trapped in CME magnetic fields is one of the promising methods to estimate magnetic field strength of CMEs at lower and middle coronal heights. However, GS emissions from some parts of the CME are much fainter than the quiet Sun emission and require high dynamic range (DR) imaging for their detection. This thesis presents a state-of-the-art calibration and imaging algorithm capable of routinely producing high DR spectropolarimetric snapshot solar radio images using data from a new technology radio telescope, the Murchison Widefield Array. This allows us to detect much fainter GS emissions from CME plasma at much higher coronal heights. For the first time, robust circular polarization measurements have been jointly used with total intensity measurements to constrain the GS model parameters, which has significantly improved the robustness of the estimated GS model parameters. A piece of observational evidence is also found that routinely used homogeneous and isotropic GS models may not always be sufficient to model the observations. In the future, with upcoming sensitive telescopes and physics-based forward models, it should be possible to relax some of these assumptions and make this method more robust for estimating CME plasma parameters at coronal heights.	astro-ph.SR	297 pages, 100 figures, 9 tables. Submitted at Tata Institute of   Fundamental Research, Mumbai, India, Ph.D Thesis
1	Optimal Spatial-Temporal Triangulation for Bearing-Only Cooperative Motion Estimation	C. L. Zheng,Y. Z. Mi,H. Q. Guo,H. B. Chen,Z. Y. Lin,S. Y. Zhao	Vision-based cooperative motion estimation is an important problem for many multi-robot systems such as cooperative aerial target pursuit. This problem can be formulated as bearing-only cooperative motion estimation, where the visual measurement is modeled as a bearing vector pointing from the camera to the target. The conventional approaches for bearing-only cooperative estimation are mainly based on the framework distributed Kalman filtering (DKF). In this paper, we propose a new optimal bearing-only cooperative estimation algorithm, named spatial-temporal triangulation, based on the method of distributed recursive least squares, which provides a more flexible framework for designing distributed estimators than DKF. The design of the algorithm fully incorporates all the available information and the specific triangulation geometric constraint. As a result, the algorithm has superior estimation performance than the state-of-the-art DKF algorithms in terms of both accuracy and convergence speed as verified by numerical simulation. We rigorously prove the exponential convergence of the proposed algorithm. Moreover, to verify the effectiveness of the proposed algorithm under practical challenging conditions, we develop a vision-based cooperative aerial target pursuit system, which is the first of such fully autonomous systems so far to the best of our knowledge.	cs.RO	None
2	Pre-training Music Classification Models via Music Source Separation	Christos Garoufis,Athanasia Zlatintsi,Petros Maragos	In this paper, we study whether music source separation can be used as a pre-training strategy for music representation learning, targeted at music classification tasks. To this end, we first pre-train U-Net networks under various music source separation objectives, such as the isolation of vocal or instrumental sources from a musical piece; afterwards, we attach a convolutional tail network to the pre-trained U-Net and jointly finetune the whole network. The features learned by the separation network are also propagated to the tail network through skip connections. Experimental results in two widely used and publicly available datasets indicate that pre-training the U-Nets with a music source separation objective can improve performance compared to both training the whole network from scratch and using the tail network as a standalone in two music classification tasks: music auto-tagging, when vocal separation is used, and music genre classification for the case of multi-source separation.	eess.AS	5 pages (4+references), 3 figures. ICASSP-24 submission
3	Decay Estimates of High Dimensional Adjoint Radon Transforms	Ruipeng Shen	In this paper we prove an optimal $L^2-L^{2d}$ decay estimate of the adjoint Radon transform of compactly supported data in $d$-dimensional space via a geometric method. A similar problem in dimension $3$ has be considered in the author's previous work. This work deals with all higher dimensional case $d\geq 4$. As an application we give the decay of Strichartz norms of $5$-dimensional non-radiative free waves. The general idea is similar to the lower dimensional case but we introduce a new method to prove the corresponding geometric inequality because the old method becomes too complicated in higher dimensions.	math.AP	21 pages, 1 figure
4	Grid Frequency Forecasting in University Campuses using Convolutional LSTM	Aneesh Sathe,Wen Ren Yang	The modern power grid is facing increasing complexities, primarily stemming from the integration of renewable energy sources and evolving consumption patterns. This paper introduces an innovative methodology that harnesses Convolutional Neural Networks (CNN) and Long Short-Term Memory (LSTM) networks to establish robust time series forecasting models for grid frequency. These models effectively capture the spatiotemporal intricacies inherent in grid frequency data, significantly enhancing prediction accuracy and bolstering power grid reliability. The research explores the potential and development of individualized Convolutional LSTM (ConvLSTM) models for buildings within a university campus, enabling them to be independently trained and evaluated for each building. Individual ConvLSTM models are trained on power consumption data for each campus building and forecast the grid frequency based on historical trends. The results convincingly demonstrate the superiority of the proposed models over traditional forecasting techniques, as evidenced by performance metrics such as Mean Square Error (MSE), Mean Absolute Error (MAE), and Mean Absolute Percentage Error (MAPE). Additionally, an Ensemble Model is formulated to aggregate insights from the building-specific models, delivering comprehensive forecasts for the entire campus. This approach ensures the privacy and security of power consumption data specific to each building.	cs.LG	9 pages, 20 figures
5	Characterizing dynamical phase transitions in a spinor Bose-Einstein condensate via quantum and semiclassical analyses	Zhen-Xia Niu,Qian Wang	Phase transitions in nonequilibrium dynamics of many body quantum systems,the so-called dynamical phases transition (DPTs), play an important role for understanding various dynamical phenomena observed in different branches of physics.In general, there have two types of DPTs, the first one refers to the phase transition that is characterized by distinct evolution behaviors of a physical observable, while the second one is marked by the nonanalyticities in the rate function of the initial state survival probability. Here, we focus on such DPTs from both quantum and semiclassical perspectives in a spinor Bose-Einstein condensate (BEC), an ideal platform to investigate nonequilibrium dynamics.By using the sudden quench process, we demonstrate that the system exhibits both types of DPTs as the control parameter quenches through the critical one, referring to as the critical quench. We show analytically how to determine the critical quenches by means of the semiclassical approach and carry out a detailed examination on both semiclassical and quantum signatures of two types of DPTs. Moreover, we further reveal that the occurrence of DPTs is closely connected to the separatrix in the underlying classical system. Our findings provide more insights into the properties of DPTs and verify the usefulness of semiclassical analysis for understanding DPTs in quantum systems with well-defined semiclassical limit.	cond-mat.quant-gas	22 pages, 14 figures
6	Spatial-Temporal Hypergraph Neural Network for Traffic Forecasting	Chengzhi Yao,Zhi Li,Junbo Wang	Traffic forecasting, which benefits from mobile Internet development and position technologies, plays a critical role in Intelligent Transportation Systems. It helps to implement rich and varied transportation applications and bring convenient transportation services to people based on collected traffic data. Most existing methods usually leverage graph-based deep learning networks to model the complex road network for traffic forecasting shallowly. Despite their effectiveness, these methods are generally limited in fully capturing high-order spatial dependencies caused by road network topology and high-order temporal dependencies caused by traffic dynamics. To tackle the above issues, we focus on the essence of traffic system and propose STHODE: Spatio-Temporal Hypergraph Neural Ordinary Differential Equation Network, which combines road network topology and traffic dynamics to capture high-order spatio-temporal dependencies in traffic data. Technically, STHODE consists of a spatial module and a temporal module. On the one hand, we construct a spatial hypergraph and leverage an adaptive MixHop hypergraph ODE network to capture high-order spatial dependencies. On the other hand, we utilize a temporal hypergraph and employ a hyperedge evolving ODE network to capture high-order temporal dependencies. Finally, we aggregate the outputs of stacked STHODE layers to mutually enhance the prediction performance. Extensive experiments conducted on four real-world traffic datasets demonstrate the superior performance of our proposed model compared to various baselines.	cs.LG	None
7	On sublinear elliptic systems on bounded and thin unbounded domains	Jean C. Cortissoz	We show the existence of a positive solution to certain weakly coupled elliptic systems of sublinear growth and homogenous Dirichlet boundary conditions. Our result generalizes known results in the case of sublinear systems of two weakly coupled equations, as, for instance Lane-Emden systems and not only applies to bounded but to thin unbounded domains (that is, unbounded domains contained in a region bounded by two parallel hyperplanes).	math.AP	Criticisms are quite welcome
8	Uniform bound of the entanglement for the ground state of the one-dimensional quantum Ising model with non-homogeneous transverse field	Massimo Campanino	We consider the ground state of the one-dimensional quantum Ising model with transverse field $h_x$ in one dimension depending on the site $x \in \mathbb Z$ in a finite volume $\Lambda_{m}:=\{-m,-m+1,\ldots,m+L\}\ $. We make suitable assumptions on the regions where the field is small and prove that if the field is sufficiently large on the complementary set, then the entanglement of the interval $\Lambda_{0}:=\left\{ 0,..,L\right\} $ relative to its complement $\Lambda_{m}\backslash\Lambda_{0}$ is bounded uniformly in $m$ and $L$. The result applies in particular to periodic transverse fields. The bound is established by means of a suitable cluster expansion.	math-ph	13 pages
9	Scenario analysis of livestock-related PM2.5 pollution based on heteroskedastic geostatistical modelling	Jacopo Rodeschini,Alessandro Fass√≤,Alessandro Fusta Moro,Francesco Finazzi	The air in the Lombardy region, Italy, is one of the most polluted in Europe because of limited air circulation and high emissions levels. There is a large scientific consensus that the agricultural sector has a major impact on air quality. In Lombardy, livestock activities are widely acknowledged to be responsible for approximately 97% of regional ammonia emissions due to the high density of livestock. The main objective of our study is to quantify the relationship between ammonia emissions and PM2.5 concentrations in the Lombardy region and evaluate PM2.5 changes due to the reduction of ammonia emissions through scenario analysis. In particular, the study refers to the years between 2016 and 2020 inclusive. The information contained in the data is exploited using a spatiotemporal model capable of handling spatial and temporal correlation, as well as missing data. In this study, we propose a heteroskedastic extension of the Hidden Dynamic Geostatistical Model (HDGM) which is a two-level hierarchical model suitable for complex environmental processes. Scenario analysis will be carried out on high-resolution maps of the Lombardy region showing the changes in PM2.5 across the area. As a result, it is shown that a 26% reduction in NH3 emissions in the wintertime could reduce the PM2.5 average by 2.09 mg/m3 while a 50% reduction could reduce the PM2.5 average by 4.02 mg/m3 which corresponds to a reduction close to 5% and 10% respectively. Finally, results are detailed by province and land type.	stat.AP	None
0	A Diffusion Weighted Graph Framework for New Intent Discovery	Wenkai Shi,Wenbin An,Feng Tian,Qinghua Zheng,QianYing Wang,Ping Chen	New Intent Discovery (NID) aims to recognize both new and known intents from unlabeled data with the aid of limited labeled data containing only known intents. Without considering structure relationships between samples, previous methods generate noisy supervisory signals which cannot strike a balance between quantity and quality, hindering the formation of new intent clusters and effective transfer of the pre-training knowledge. To mitigate this limitation, we propose a novel Diffusion Weighted Graph Framework (DWGF) to capture both semantic similarities and structure relationships inherent in data, enabling more sufficient and reliable supervisory signals. Specifically, for each sample, we diffuse neighborhood relationships along semantic paths guided by the nearest neighbors for multiple hops to characterize its local structure discriminately. Then, we sample its positive keys and weigh them based on semantic similarities and local structures for contrastive learning. During inference, we further propose Graph Smoothing Filter (GSF) to explicitly utilize the structure relationships to filter high-frequency noise embodied in semantically ambiguous samples on the cluster boundary. Extensive experiments show that our method outperforms state-of-the-art models on all evaluation metrics across multiple benchmark datasets. Code and data are available at https://github.com/yibai-shi/DWGF.	cs.CL	EMNLP 2023 Main
1	Designing superselectivity in linker-mediated multivalent nanoparticle adsorption	Xiuyang Xia,Ran Ni	Using a statistical mechanical model and numerical simulations, we provide the design principle for the bridging energy ($\xi$) and linker density ($\rho$) dependent superselectivity in linker-mediated multivalent nanoparticle adsorption. When the bridges are insufficient, the formation of multiple bridges leads to both $\xi$- and $\rho$-dependent superselectivity. Whereas, when the bridges are excessive, the system becomes insensitive to bridging energy due to entropy-induced self-saturation and shows a superselective desorption with respect to the linker density. Counterintuitively, lower linker density or stronger bridging energy enhances the superselectivity. These findings not only help understand relevant biological processes but also open up opportunities for applications in biosensing, drug delivery, and programmable self-assembly.	cond-mat.soft	SI can be found at   https://www.dropbox.com/scl/fi/68dmarx6v1cxvwqya49tp/SI.pdf?rlkey=97ualee7hrauhopvdbgirn8i9&dl=0
2	The positional probability and true host star identification of TESS exoplanet candidates	Andreas Hadjigeorghiou,David J. Armstrong	We present a method for deriving a probabilistic estimate of the true source of a detected TESS transiting event. Our method relies on comparing the observed photometric centroid offset for the target star with models of the offset that would occur if the event was either on the target or any of the Gaia identified nearby sources. The comparison is done probabilistically, allowing us to incorporate the uncertainties of the observed and modelled offsets in our result. The method was developed for TESS Full Frame Image lightcurves produced from the SPOC pipeline, but could be easily adapted to lightcurves from other sources. We applied the method on 3226 TESS Objects of Interest (TOIs), with a released lightcurve from SPOC. The method correctly identified 96.5% of 655 known exoplanet hosts as the most likely source of the eclipse. For 142 confirmed Nearby Eclipsing Binaries (NEBs) and Nearby Planet Candidates (NPCs), a nearby source was found to be the most likely in 96.5% of the cases. For 40 NEBs and NPCs where the true source is known, it was correctly designated as the most likely in 38 of those. Finally, for 2365 active planet candidates, the method suggests that 2072 are most likely on-target and 293 on a nearby source. The method forms a part of an in-development vetting and validation pipeline, called RAVEN, and is released as a standalone tool.	astro-ph.EP	Accepted for publication in MNRAS
3	High-energy Neutrino Emission Associated with GWs from Binary Black Hole Mergers in AGN Accretion Discs	Zi-Hang Zhou,Kai Wang	The search for multi-messenger signals of binary black hole (BBH) mergers is crucial to understanding the merger process of BBH and the relative astrophysical environment. Considering BBH mergers occurring in the active galactic nuclei (AGN) accretion disks, we focus on the accompanying high-energy neutrino production from the interaction between the jet launched by the post-merger remnant BH and disk materials. Particles can be accelerated by the shocks generated from the jet-disk interaction and subsequently interact with the disk gas and radiations to produce high-energy neutrinos through hadronic processes. We demonstrate that the identification of the high-energy neutrino signal from BBH merger in AGN disks is feasible. In addition, the joint BBH gravitational wave (GW) and neutrino detection rate is derived, which can be used to constrain the BBH merger rate and the accretion rate of the remnant BH based on the future associated detections of GWs and neutrinos.	astro-ph.HE	8 pages, 4 figures, 1 table, Submitted to ApJ Letters
4	A Comparative Study of Variational Autoencoders, Normalizing Flows, and Score-based Diffusion Models for Electrical Impedance Tomography	Huihui Wang,Guixian Xu,Qingping Zhou	Electrical Impedance Tomography (EIT) is a widely employed imaging technique in industrial inspection, geophysical prospecting, and medical imaging. However, the inherent nonlinearity and ill-posedness of EIT image reconstruction present challenges for classical regularization techniques, such as the critical selection of regularization terms and the lack of prior knowledge. Deep generative models (DGMs) have been shown to play a crucial role in learning implicit regularizers and prior knowledge. This study aims to investigate the potential of three DGMs-variational autoencoder networks, normalizing flow, and score-based diffusion model-to learn implicit regularizers in learning-based EIT imaging. We first introduce background information on EIT imaging and its inverse problem formulation. Next, we propose three algorithms for performing EIT inverse problems based on corresponding DGMs. Finally, we present numerical and visual experiments, which reveal that (1) no single method consistently outperforms the others across all settings, and (2) when reconstructing an object with 2 anomalies using a well-trained model based on a training dataset containing 4 anomalies, the conditional normalizing flow model (CNF) exhibits the best generalization in low-level noise, while the conditional score-based diffusion model (CSD*) demonstrates the best generalization in high-level noise settings. We hope our preliminary efforts will encourage other researchers to assess their DGMs in EIT and other nonlinear inverse problems.	eess.IV	None
5	Localization of Small Leakages in Water Distribution Networks using Concept Drift Explanation Methods	Valerie Vaquet,Fabian Hinder,Kathrin Lammers,Jonas Vaquet,Barbara Hammer	Facing climate change the already limited availability of drinking water will decrease in the future rendering drinking water an increasingly scarce resource. Considerable amounts of it are lost through leakages in water transportation and distribution networks. Leakage detection and localization are challenging problems due to the complex interactions and changing demands in water distribution networks. Especially small leakages are hard to pinpoint yet their localization is vital to avoid water loss over long periods of time. While there exist different approaches to solving the tasks of leakage detection and localization, they are relying on various information about the system, e.g. real-time demand measurements and the precise network topology, which is an unrealistic assumption in many real-world scenarios. In contrast, this work attempts leakage localization using pressure measurements only. For this purpose, first, leakages in the water distribution network are modeled employing Bayesian networks, and the system dynamics are analyzed. We then show how the problem is connected to and can be considered through the lens of concept drift. In particular, we argue that model-based explanations of concept drift are a promising tool for localizing leakages given limited information about the network. The methodology is experimentally evaluated using realistic benchmark scenarios.	cs.LG	None
6	Unnatural language processing: How do language models handle machine-generated prompts?	Corentin Kervadec,Francesca Franzon,Marco Baroni	Language model prompt optimization research has shown that semantically and grammatically well-formed manually crafted prompts are routinely outperformed by automatically generated token sequences with no apparent meaning or syntactic structure, including sequences of vectors from a model's embedding space. We use machine-generated prompts to probe how models respond to input that is not composed of natural language expressions. We study the behavior of models of different sizes in multiple semantic tasks in response to both continuous and discrete machine-generated prompts, and compare it to the behavior in response to human-generated natural-language prompts. Even when producing a similar output, machine-generated and human prompts trigger different response patterns through the network processing pathways, including different perplexities, different attention and output entropy distributions, and different unit activation profiles. We provide preliminary insight into the nature of the units activated by different prompt types, suggesting that only natural language prompts recruit a genuinely linguistic circuit.	cs.CL	Findings of EMNLP 2023 Camera-Ready
7	Automatic Aorta Segmentation with Heavily Augmented, High-Resolution 3-D ResUNet: Contribution to the SEG.A Challenge	Marek Wodzinski,Henning M√ºller	Automatic aorta segmentation from 3-D medical volumes is an important yet difficult task. Several factors make the problem challenging, e.g. the possibility of aortic dissection or the difficulty with segmenting and annotating the small branches. This work presents a contribution by the MedGIFT team to the SEG.A challenge organized during the MICCAI 2023 conference. We propose a fully automated algorithm based on deep encoder-decoder architecture. The main assumption behind our work is that data preprocessing and augmentation are much more important than the deep architecture, especially in low data regimes. Therefore, the solution is based on a variant of traditional convolutional U-Net. The proposed solution achieved a Dice score above 0.9 for all testing cases with the highest stability among all participants. The method scored 1st, 4th, and 3rd in terms of the clinical evaluation, quantitative results, and volumetric meshing quality, respectively. We freely release the source code, pretrained model, and provide access to the algorithm on the Grand-Challenge platform.	cs.CV	MICCAI 2023 - SEG.A Challenge Contribution
8	A new set of Gibbs measures for the SOS model on a Cayley tree	Muzaffar M. Rahmatullaev,Bunyod U. Abraev	The phase transition phenomenon is one of the central problems of statistical mechanics. It occurs when the model possesses multiple Gibbs measures. In this paper, we consider a three-state SOS (solid-on-solid) model on a Cayley tree. We reduce description of Gibbs measures to solving of a non-linear functional equation, which each solution of the equation corresponds to a Gibbs measure. We give some sufficiency conditions on the existence of multiple Gibbs measures for the model. We give a review of some known (translation-invariant, periodic, non-periodic) Gibbs measures of the model and compare them with our new measures. We show that the Gibbs measures found in the paper differ from the known Gibbs measures, i.e, we show that these measures are new.	math-ph	None
9	Rosetta Stone at KSAA-RD Shared Task: A Hop From Language Modeling To Word--Definition Alignment	Ahmed ElBakry,Mohamed Gabr,Muhammad ElNokrashy,Badr AlKhamissi	"A Reverse Dictionary is a tool enabling users to discover a word based on its provided definition, meaning, or description. Such a technique proves valuable in various scenarios, aiding language learners who possess a description of a word without its identity, and benefiting writers seeking precise terminology. These scenarios often encapsulate what is referred to as the ""Tip-of-the-Tongue"" (TOT) phenomena. In this work, we present our winning solution for the Arabic Reverse Dictionary shared task. This task focuses on deriving a vector representation of an Arabic word from its accompanying description. The shared task encompasses two distinct subtasks: the first involves an Arabic definition as input, while the second employs an English definition. For the first subtask, our approach relies on an ensemble of finetuned Arabic BERT-based models, predicting the word embedding for a given definition. The final representation is obtained through averaging the output embeddings from each model within the ensemble. In contrast, the most effective solution for the second subtask involves translating the English test definitions into Arabic and applying them to the finetuned models originally trained for the first subtask. This straightforward method achieves the highest score across both subtasks."	cs.CL	ArabicNLP 2023
0	Symplectic determinant laws and invariant theory	Mohamed Moakher,Julian Quast	We introduce the notion of $\textit{symplectic determinant laws}$ by analogy with Chenevier's definition of determinant laws. Symplectic determinant laws are a way to define pseudorepresentations for symplectic representations of algebras with involution over arbitrary $\mathbb{Z}[\frac{1}{2}]$-algebras. We prove that this notion satisfies the properties expected from a good theory of pseudorepresentations, and we compare it to Lafforgue's $\text{Sp}_{2d}$-pseudocharacters. In the process, we compute generators of the invariant algebras $A[M_d^m]^{G}$ and $A[G^m]^G$ over an arbitrary commutative ring $A$ when $G \in \{\text{Sp}_d, \mathrm O_d, \text{GSp}_d, \text{GO}_d\}$, generalizing results of Zubkov.	math.NT	None
1	Generative Language Models Exhibit Social Identity Biases	Tiancheng Hu,Yara Kyrychenko,Steve Rathje,Nigel Collier,Sander van der Linden,Jon Roozenbeek	"The surge in popularity of large language models has given rise to concerns about biases that these models could learn from humans. In this study, we investigate whether ingroup solidarity and outgroup hostility, fundamental social biases known from social science, are present in 51 large language models. We find that almost all foundational language models and some instruction fine-tuned models exhibit clear ingroup-positive and outgroup-negative biases when prompted to complete sentences (e.g., ""We are...""). A comparison of LLM-generated sentences with human-written sentences on the internet reveals that these models exhibit similar level, if not greater, levels of bias than human text. To investigate where these biases stem from, we experimentally varied the amount of ingroup-positive or outgroup-negative sentences the model was exposed to during fine-tuning in the context of the United States Democrat-Republican divide. Doing so resulted in the models exhibiting a marked increase in ingroup solidarity and an even greater increase in outgroup hostility. Furthermore, removing either ingroup-positive or outgroup-negative sentences (or both) from the fine-tuning data leads to a significant reduction in both ingroup solidarity and outgroup hostility, suggesting that biases can be reduced by removing biased training data. Our findings suggest that modern language models exhibit fundamental social identity biases and that such biases can be mitigated by curating training data. Our results have practical implications for creating less biased large-language models and further underscore the need for more research into user interactions with LLMs to prevent potential bias reinforcement in humans."	cs.CL	supplementary material, data, and code see   https://osf.io/9ht32/?view_only=f0ab4b23325f4c31ad3e12a7353b55f5
2	Discriminator Guidance for Autoregressive Diffusion Models	Filip Ekstr√∂m Kelvinius,Fredrik Lindsten	We introduce discriminator guidance in the setting of Autoregressive Diffusion Models. The use of a discriminator to guide a diffusion process has previously been used for continuous diffusion models, and in this work we derive ways of using a discriminator together with a pretrained generative model in the discrete case. First, we show that using an optimal discriminator will correct the pretrained model and enable exact sampling from the underlying data distribution. Second, to account for the realistic scenario of using a sub-optimal discriminator, we derive a sequential Monte Carlo algorithm which iteratively takes the predictions from the discrimiator into account during the generation process. We test these approaches on the task of generating molecular graphs and show how the discriminator improves the generative performance over using only the pretrained model.	cs.LG	None
3	Nonlinear dimensionality reduction then and now: AIMs for dissipative PDEs in the ML era	Eleni D. Koronaki,Nikolaos Evangelou,Cristina P. Martin-Linares,Edriss S. Titi,Ioannis G. Kevrekidis	This study presents a collection of purely data-driven workflows for constructing reduced-order models (ROMs) for distributed dynamical systems. The ROMs we focus on, are data-assisted models inspired by, and templated upon, the theory of Approximate Inertial Manifolds (AIMs); the particular motivation is the so-called post-processing Galerkin method of Garcia-Archilla, Novo and Titi. Its applicability can be extended: the need for accurate truncated Galerkin projections and for deriving closed-formed corrections can be circumvented using machine learning tools. When the right latent variables are not a priori known, we illustrate how autoencoders as well as Diffusion Maps (a manifold learning scheme) can be used to discover good sets of latent variables and test their explainability. The proposed methodology can express the ROMs in terms of (a) theoretical (Fourier coefficients), (b) linear data-driven (POD modes) and/or (c) nonlinear data-driven (Diffusion Maps) coordinates. Both Black-Box and (theoretically-informed and data-corrected) Gray-Box models are described; the necessity for the latter arises when truncated Galerkin projections are so inaccurate as to not be amenable to post-processing. We use the Chafee-Infante reaction-diffusion and the Kuramoto-Sivashinsky dissipative partial differential equations to illustrate and successfully test the overall framework.	math.DS	27 pages, 22 figures
4	Good Better Best: Self-Motivated Imitation Learning for noisy Demonstrations	Ye Yuan,Xin Li,Yong Heng,Leiji Zhang,MingZhong Wang	Imitation Learning (IL) aims to discover a policy by minimizing the discrepancy between the agent's behavior and expert demonstrations. However, IL is susceptible to limitations imposed by noisy demonstrations from non-expert behaviors, presenting a significant challenge due to the lack of supplementary information to assess their expertise. In this paper, we introduce Self-Motivated Imitation LEarning (SMILE), a method capable of progressively filtering out demonstrations collected by policies deemed inferior to the current policy, eliminating the need for additional information. We utilize the forward and reverse processes of Diffusion Models to emulate the shift in demonstration expertise from low to high and vice versa, thereby extracting the noise information that diffuses expertise. Then, the noise information is leveraged to predict the diffusion steps between the current policy and demonstrators, which we theoretically demonstrate its equivalence to their expertise gap. We further explain in detail how the predicted diffusion steps are applied to filter out noisy demonstrations in a self-motivated manner and provide its theoretical grounds. Through empirical evaluations on MuJoCo tasks, we demonstrate that our method is proficient in learning the expert policy amidst noisy demonstrations, and effectively filters out demonstrations with expertise inferior to the current policy.	cs.LG	None
5	Low- and high-redshift H II starburst galaxies obey different luminosity-velocity dispersion relations	Shulei Cao,Bharat Ratra	To determine whether or not H II starburst galaxies (H IIG) are standardizable candles, we study the correlation between the H$\beta$ luminosity ($L$) and the velocity dispersion ($\sigma$) of the ionized gas from H IIG measurements by simultaneously constraining the $L-\sigma$ relation parameters and the cosmological model parameters. We investigate six flat and nonflat relativistic dark energy cosmological models, spatially flat and nonflat, and with cosmological constant or dynamical dark energy. We find that low-redshift and high-redshift H IIG data subsets are standardizable but obey different $L-\sigma$ relations. Current H IIG data are too sparse and too non-uniformly distributed in redshift to allow for a determination of whether what we have found is just a consequence of H IIG evolution. Until this issue is better understood, H IIG data cosmological constraints must be treated with caution.	astro-ph.CO	15 pages, 4 figures, submitted to Physical Review D
6	Monte Carlo study on low-temperature phase diagrams of the $J_1$-$J_2$ classical $XY$ kagome antiferromagnet	Fumiya Kakizawa,Takahiro Misawa,Hiroshi Shinaoka	Frustrated magnets with degenerate ground states exhibit exotic ground states and rich phase structures when perturbations and/or thermal fluctuations lift the degeneracy. In two-dimensional models with short-range interactions, continuous symmetries cannot spontaneously break at finite temperatures, leading to the suppression of conventional magnetic long-range ordering (LRO). In this paper, we numerically study the classical $J_1$-$J_2$ $XY$ antiferromagnet on the kagome lattice as a prototype model of such frustrated magnets, where $J_2$ denotes the next-nearest-neighbor exchange interaction. We map out the $J_2$-$T$ phase diagram of this model employing extensive classical Monte Carlo (MC) simulations. The obtained phase diagram features Berezinskii-Kosterlitz-Thouless (BKT) transitions of $q=0$, $\sqrt{3}\times\sqrt{3}$ magnetic orders, and octupole orders, in addition to finite-temperature phase transitions of both ferrochiral and antiferrochiral long-range orders. Additionally, we find a non-trivial first-order transition for antiferromagnetic $J_2/J_1 < 0$. The origin of this transition is discussed in the context of non-local loop structures present in local $120^\circ$ spin structures.	cond-mat.stat-mech	None
7	Cutoff for the Glauber-Exclusion process in the full high-temperature regime: an information percolation approach	Hong-Quan Tran	The Glauber-Exclusion process is a superposition of a Glauber dynamics and the Symmetric Simple Exclusion Process (SSEP) on the lattice. The model was shown to admit a reaction-diffusion equation as the hydrodynamic limit. In this article, we define a notion of temperature regimes via the reaction function in the equation and prove cutoff in the full high-temperature regime for the attractive model in dimensions $1$ and $2$ with periodic boundary condition. Our results show that the equation in the hydrodynamic limit reflects the mixing behavior of the large but finite system. Besides, cutoff is proved under the lack of reversibility and an explicit formula for the invariant measure. We also provide the spectral gap and prove pre-cutoff in all dimensions. Our proof involves a new interpretation of attractiveness, the information percolation framework introduced by Lubetzky and Sly, anti-concentration of simple random walk on the lattice, and a coupling inspired by excursion theory. We hope that this approach can find new applications in the future.	math.PR	68 + 3 pages, 5 figures, comments welcome!
8	One-variable fragments of first-order logics	Petr Cintula,George Metcalfe,Naomi Tokuda	"The one-variable fragment of a first-order logic may be viewed as an ""S5-like"" modal logic, where the universal and existential quantifiers are replaced by box and diamond modalities, respectively. Axiomatizations of these modal logics have been obtained for special cases -- notably, the modal counterparts S5 and MIPC of the one-variable fragments of first-order classical logic and intuitionistic logic -- but a general approach, extending beyond first-order intermediate logics, has been lacking. To this end, a sufficient criterion is given in this paper for the one-variable fragment of a semantically-defined first-order logic -- spanning families of intermediate, substructural, many-valued, and modal logics -- to admit a natural axiomatization. More precisely, such an axiomatization is obtained for the one-variable fragment of any first-order logic based on a variety of algebraic structures with a lattice reduct that has the superamalgamation property, building on a generalized version of a functional representation theorem for monadic Heyting algebras due to Bezhanishvili and Harding. An alternative proof-theoretic strategy for obtaining such axiomatization results is also developed for first-order substructural logics that have a cut-free sequent calculus and admit a certain interpolation property."	math.LO	arXiv admin note: text overlap with arXiv:2209.08566
9	Unstable independence from the categorical point of view	Mark Kamsma,Jiri Rosick√Ω	We give a category-theoretic construction of simple and NSOP$_1$-like independence relations in locally finitely presentable categories, and in the more general locally finitely multipresentable categories. We do so by identifying properties of a class of monomorphisms $\mathcal{M}$ such that the pullback squares consisting of morphisms in $\mathcal{M}$ form the desired independence relation. This generalizes the category-theoretic construction of stable independence relations using effective unions or cellular squares by M. Lieberman, S. Vasey and the second author to the unstable setting.	math.CT	32 pages
0	Optimal Strategies for Round-Trip Pairs Trading Under Geometric Brownian Motions	Emily Crawford Das,Jingzhi Tie,Qing Zhang	This paper is concerned with an optimal strategy for simultaneously trading a pair of stocks. The idea of pairs trading is to monitor their price movements and compare their relative strength over time. A pairs trade is triggered by the divergence of their prices and consists of a pair of positions to short the strong stock and to long the weak one. Such a strategy bets on the reversal of their price strengths. A round-trip trading strategy refers to opening and closing such a pair of security positions. Typical pairs-trading models usually assume a difference of the stock prices satisfies a mean-reversion equation. However, we consider the optimal pairs-trading problem by allowing the stock prices to follow general geometric Brownian motions. The objective is to trade the pairs over time to maximize an overall return with a fixed commission cost for each transaction. Initially, we allow the initial pairs position to be either long or flat. We then consider the problem when the initial pairs position may be long, flat, or short. In each case, the optimal policy is characterized by threshold curves obtained by solving the associated HJB equations.	math.OC	47 pages, 5 figures
1	A High-Performance and Low-Complexity 5G LDPC Decoder: Algorithm and Implementation	Yuqing Ren,Hassan Harb,Yifei Shen,Alexios Balatsoukas-Stimming,Andreas Burg	5G New Radio (NR) has stringent demands on both performance and complexity for the design of low-density parity-check (LDPC) decoding algorithms and corresponding VLSI implementations. Furthermore, decoders must fully support the wide range of all 5G NR blocklengths and code rates, which is a significant challenge. In this paper, we present a high-performance and low-complexity LDPC decoder, tailor-made to fulfill the 5G requirements. First, to close the gap between belief propagation (BP) decoding and its approximations in hardware, we propose an extension of adjusted min-sum decoding, called generalized adjusted min-sum (GA-MS) decoding. This decoding algorithm flexibly truncates the incoming messages at the check node level and carefully approximates the non-linear functions of BP decoding to balance the error-rate and hardware complexity. Numerical results demonstrate that the proposed fixed-point GAMS has only a minor gap of 0.1 dB compared to floating-point BP under various scenarios of 5G standard specifications. Secondly, we present a fully reconfigurable 5G NR LDPC decoder implementation based on GA-MS decoding. Given that memory occupies a substantial portion of the decoder area, we adopt multiple data compression and approximation techniques to reduce 42.2% of the memory overhead. The corresponding 28nm FD-SOI ASIC decoder has a core area of 1.823 mm2 and operates at 895 MHz. It is compatible with all 5G NR LDPC codes and achieves a peak throughput of 24.42 Gbps and a maximum area efficiency of 13.40 Gbps/mm2 at 4 decoding iterations.	cs.IT	14 pages, 14 figures
2	Direct Access for Conjunctive Queries with Negation	Florent Capelli,Oliver Irwin	Given a conjunctive query $Q$ and a database $\mathbf{D}$, a direct access to the answers of $Q$ over $\mathbf{D}$ is the operation of returning, given an index $j$, the $j^{\mathsf{th}}$ answer for some order on its answers. While this problem is $\#\mathsf{P}$-hard in general with respect to combined complexity, many conjunctive queries have an underlying structure that allows for a direct access to their answers for some lexicographical ordering that takes polylogarithmic time in the size of the database after a polynomial time precomputation. Previous work has precisely characterised the tractable classes and given fine-grained lower bounds on the precomputation time needed depending on the structure of the query.   In this paper, we generalise these tractability results to the case of signed conjunctive queries, that is, conjunctive queries that may contain negative atoms. Our technique is based on a class of circuits that can represent relational data. We first show that this class supports tractable direct access after a polynomial time preprocessing. We then give bounds on the size of the circuit needed to represent the answer set of signed conjunctive queries depending on their structure. Both results combined together allow us to prove the tractability of direct access for a large class of conjunctive queries. On the one hand, we recover the known tractable classes from the literature in the case of positive conjunctive queries. On the other hand, we generalise and unify known tractability results about negative conjunctive queries -- that is, queries having only negated atoms. In particular, we show that the class of $\beta$-acyclic negative conjunctive queries and the class of bounded nest set width negative conjunctive queries admit tractable direct access.	cs.DB	None
3	DALE: Generative Data Augmentation for Low-Resource Legal NLP	Sreyan Ghosh,Chandra Kiran Evuru,Sonal Kumar,S Ramaneswaran,S Sakshi,Utkarsh Tyagi,Dinesh Manocha	We present DALE, a novel and effective generative Data Augmentation framework for low-resource LEgal NLP. DALE addresses the challenges existing frameworks pose in generating effective data augmentations of legal documents - legal language, with its specialized vocabulary and complex semantics, morphology, and syntax, does not benefit from data augmentations that merely rephrase the source sentence. To address this, DALE, built on an Encoder-Decoder Language Model, is pre-trained on a novel unsupervised text denoising objective based on selective masking - our masking strategy exploits the domain-specific language characteristics of templatized legal documents to mask collocated spans of text. Denoising these spans helps DALE acquire knowledge about legal concepts, principles, and language usage. Consequently, it develops the ability to generate coherent and diverse augmentations with novel contexts. Finally, DALE performs conditional generation to generate synthetic augmentations for low-resource Legal NLP tasks. We demonstrate the effectiveness of DALE on 13 datasets spanning 6 tasks and 4 low-resource settings. DALE outperforms all our baselines, including LLMs, qualitatively and quantitatively, with improvements of 1%-50%.	cs.CL	Accepted to EMNLP 2023 Main Conference. Code:   https://github.com/Sreyan88/DALE
4	A general nonuniqueness result for Yamabe-type problems for conformally variational Riemannian invariants	Jo√£o Henrique Andrade,Jeffrey S. Case,Paolo Piccione,Juncheng Wei	Given a conformally variational scalar Riemannian invariant $I$, we identify a sufficient condition for a closed Riemannian manifold to admit finite regular coverings with many nonhomothetic conformal rescalings with $I$ constant. We also identify a sufficient condition for the universal cover to admit infinitely many geometrically distinct periodic conformal rescalings with $I$ constant. Using these conditions, we improve known nonuniqueness results for the $Q$-curvatures of orders two, four, and six, and establish nonuniqueness results for higher-order $Q$-curvatures and renormalized volume coefficients.	math.DG	16 pages
5	Testing for equivalence of pre-trends in Difference-in-Differences estimation	Holger Dette,Martin Schumann	The plausibility of the ``parallel trends assumption'' in Difference-in-Differences estimation is usually assessed by a test of the null hypothesis that the difference between the average outcomes of both groups is constant over time before the treatment. However, failure to reject the null hypothesis does not imply the absence of differences in time trends between both groups. We provide equivalence tests that allow researchers to find evidence in favor of the parallel trends assumption and thus increase the credibility of their treatment effect estimates. While we motivate our tests in the standard two-way fixed effects model, we discuss simple extensions to settings in which treatment adoption is staggered over time.	econ.EM	None
6	Temperature profiles of galactic dark matter halos	Andr√©s Ace√±a,Juan Barranco,Argelia Bernal,Ericson L√≥pez	We present the temperature profiles of galactic dark matter halos by considering that dark matter can be treated as a classical ideal gas, as an ideal Fermi gas, or as an ideal Bose gas. The only free parameter in the matter model is the mass of the dark matter particle. We obtain the temperature profiles by using the rotational velocity profile proposed by Persic, Salucci, and Stel (1996) and assuming that the dark matter halo is a self-gravitating stand-alone structure. From the temperature profiles, we conclude that the classical ideal gas and the ideal Fermi gas are not viable explanations for dark matter, while the ideal Bose gas is if the mass of the particle is low enough. If we take into account the relationship presented by Donato et al. (2009) and Gentile et al. (2009) between central density and core radius then we conclude that the central temperature of dark matter in all galaxies is the same. Also, the dark matter halo is in a state of Bose-Einstein condensation, or at least the central region is. By using fittings of observational data, we can put an upper bound on the dark matter particle mass in the order of $13\,eV/c^2$.	astro-ph.GA	8 pages, 4 figures
7	Numerical Derivative-based Flexible Integration Algorithm for Power Electronic Systems Simulation Considering Nonlinear Components	Han Xu,Bochen Shi,Zhujun Yu,Jialin Zheng,Zhengming Zhao	Simulation is an efficient tool in the design and control of power electronic systems. However, quick and accurate simulation of them is still challenging, especially when the system contains a large number of switches and state variables. Conventional general-purpose integration algorithms assume nonlinearity within systems but face inefficiency in handling the piecewise characteristics of power electronic switches. While some specialized algorithms can adapt to the piecewise characteristics, most of these methods require systems to be piecewise linear. In this article, a numerical derivative-based flexible integration algorithm is proposed. This algorithm can adapt to the piecewise characteristic caused by switches and have no difficulty when nonlinear non-switching components are present in the circuit. This algorithm consists of a recursive numerical scheme that obtains high-order time derivatives of nonlinear components and a decoupling strategy that further increases computational efficiency. The proposed method is applied to solve a motor derive system and a large-scale power conversion system (PCS) to verify its accuracy and efficiency by comparing experimental waveforms and simulated results given by commercial software. Our proposed method demonstrates several-fold acceleration compared to multiple commonly used algorithms in Simulink.	eess.SY	10 pages, 8 figures
8	Improving generalization in large language models by learning prefix subspaces	Louis Falissard,Vincent Guigue,Laure Soulier	"This article focuses on large language models (LLMs) fine-tuning in the scarce data regime (also known as the ""few-shot"" learning setting). We propose a method to increase the generalization capabilities of LLMs based on neural network subspaces. This optimization method, recently introduced in computer vision, aims to improve model generalization by identifying wider local optima through the joint optimization of an entire simplex of models in parameter space. Its adaptation to massive, pretrained transformers, however, poses some challenges. First, their considerable number of parameters makes it difficult to train several models jointly, and second, their deterministic parameter initialization schemes make them unfit for the subspace method as originally proposed. We show in this paper that ""Parameter Efficient Fine-Tuning"" (PEFT) methods, however, are perfectly compatible with this original approach, and propose to learn entire simplex of continuous prefixes. We test our method on a variant of the GLUE benchmark adapted to the few-shot learning setting, and show that both our contributions jointly lead to a gain in average performances compared to sota methods. The implementation can be found at the following link: https://github.com/Liloulou/prefix_subspace"	cs.LG	None
9	Three dimensional quotient singularity and 4d $\mathcal{N}=1$ AdS-CFT correspondence	Yuanyuan Fang,Jing Feng,Dan Xie	We systematically study the AdS/CFT correspondence induced by D3 branes probing three dimensional Gorenstein quotient singularity $\mathbb{C}^3/G$. The field theory is given by the McKay quiver, which has a vanishing NSVZ beta function assuming that all the chiral fields have the $U(1)_R$ charge $\frac{2}{3}$. Various physical quantities such as quiver Hilbert series, superconformal index, central charges, etc are computed, which match exactly with those computed using the singularity. We also study the relevant deformation of those theories and find the dual geometry, therefore generate many new interesting AdS/CFT pairs. The quiver gauge theory defined using finite subgroups of $SO(3)$ group has some interesting features, for example, its Seiberg duality behavior is quite interesting.	hep-th	43 pages, 15 tables, and 13 figures
0	A statistical significance testing approach for measuring term burstiness with applications to domain-specific terminology extraction	Samuel Sarria Hurtado,Todd Mullen,Taku Onodera,Paul Sheridan	"Domain-specific terminology extraction is an important task in text analysis. A term in a corpus is said to be ""bursty"" when its occurrences are concentrated in few out of many documents. Being content rich, bursty terms are highly suited for subject matter characterization, and serve as natural candidates for identifying with technical terminology. Multiple measures of term burstiness have been proposed in the literature. However, the statistical significance testing paradigm has remained underexplored in text analysis, including in relation to term burstiness. To test these waters, we propose as our main contribution a multinomial language model-based exact test of statistical significance for term burstiness. Due to its prohibitive computational cost, we advance a heuristic formula designed to serve as a proxy for test P-values. As a complementary theoretical contribution, we derive a previously unreported relationship connecting the inverse document frequency and inverse collection frequency (two foundational quantities in text analysis) under the multinomial language model. The relation is used in the evaluation of our heuristic. Using the GENIA Term corpus benchmark, we compare our approach against established methods, demonstrating our heuristic's potential in identifying domain-specific technical terms. We hope this demonstration of statistical significance testing in text analysis serves as a springboard for future research."	cs.IR	23 pages, 1 figure, 6 tables
1	Verification of Multi-Agent Properties in Electronic Voting: A Case Study	Damian Kurpiewski,Wojciech Jamroga,≈Åukasz Ma≈õko,≈Åukasz Mikulski,Witold Pazderski,Wojciech Penczek,Teofil Sidoruk	Formal verification of multi-agent systems is hard, both theoretically and in practice. In particular, studies that use a single verification technique typically show limited efficiency, and allow to verify only toy examples. Here, we propose some new techniques and combine them with several recently developed ones to see what progress can be achieved for a real-life scenario. Namely, we use fixpoint approximation, domination-based strategy search, partial order reduction, and parallelization to verify heterogeneous scalable models of the Selene e-voting protocol. The experimental results show that the combination allows to verify requirements for much more sophisticated models than previously.	cs.MA	None
2	SequenceMatch: Revisiting the design of weak-strong augmentations for Semi-supervised learning	Khanh-Binh Nguyen	Semi-supervised learning (SSL) has become popular in recent years because it allows the training of a model using a large amount of unlabeled data. However, one issue that many SSL methods face is the confirmation bias, which occurs when the model is overfitted to the small labeled training dataset and produces overconfident, incorrect predictions. To address this issue, we propose SequenceMatch, an efficient SSL method that utilizes multiple data augmentations. The key element of SequenceMatch is the inclusion of a medium augmentation for unlabeled data. By taking advantage of different augmentations and the consistency constraints between each pair of augmented examples, SequenceMatch helps reduce the divergence between the prediction distribution of the model for weakly and strongly augmented examples. In addition, SequenceMatch defines two different consistency constraints for high and low-confidence predictions. As a result, SequenceMatch is more data-efficient than ReMixMatch, and more time-efficient than both ReMixMatch ($\times4$) and CoMatch ($\times2$) while having higher accuracy. Despite its simplicity, SequenceMatch consistently outperforms prior methods on standard benchmarks, such as CIFAR-10/100, SVHN, and STL-10. It also surpasses prior state-of-the-art methods by a large margin on large-scale datasets such as ImageNet, with a 38.46\% error rate. Code is available at https://github.com/beandkay/SequenceMatch.	cs.CV	Accepted to WACV 2024
3	Amortised Inference in Neural Networks for Small-Scale Probabilistic Meta-Learning	Matthew Ashman,Tommy Rochussen,Adrian Weller	The global inducing point variational approximation for BNNs is based on using a set of inducing inputs to construct a series of conditional distributions that accurately approximate the conditionals of the true posterior distribution. Our key insight is that these inducing inputs can be replaced by the actual data, such that the variational distribution consists of a set of approximate likelihoods for each datapoint. This structure lends itself to amortised inference, in which the parameters of each approximate likelihood are obtained by passing each datapoint through a meta-model known as the inference network. By training this inference network across related datasets, we can meta-learn Bayesian inference over task-specific BNNs.	stat.ML	None
4	Violent mass ejection by the progenitors of the brightest planetary nebulae: supernova progenitors	Noam Soker	I examine the morphologies of the brightest planetary nebulae (PNe) in the Milky Way Galaxy and conclude that violent binary interaction processes eject the main nebulae of the brightest PNe. The typical morphologies of the brightest PNe are multipolar, namely have been shaped by two or more major jet-launching episodes at varying directions, and possess small to medium departures from pure point-symmetry. The departure from pure point-symmetry is generally not large. This suggests that triple-star interaction is not behind the mass ejection process, but rather a violent binary interaction. By violent interaction I refer to two or more energetic jet-launching episodes within a relatively short time (much shorter than the PN formation time). In particular, I suggest that the timescales of some interactions are shorter than the dynamical timescale of the asymptotic giant branch (AGB) progenitor. I discuss some possibilities, including a rapid onset of the common envelope evolution (CEE) and the merger of the companion with the AGB core at the termination of the CEE. I suggest that the most likely companions to experience such interactions are white dwarfs (WDs). Some of these might actually be progenitors of type Ia supernovae (SNe Ia), as I suggest for SNR G1.9+0.3, the youngest SN Ia in the Galaxy. I speculate here on a positive correlation (but not one-to-one correspondence) between the brightest PNe and cases of CEE that end with WD-core merger, including progenitors of some SNe Ia.	astro-ph.HE	Will be submitted in one week to the Proceedings of IAU Symposium   384: Planetary Nebulae: a Universal Toolbox in the Era of Precision   Astrophysics. Eds: O. De Marco, A. Zijlstra, R. Szczerba
5	Local Chern Marker for Periodic Systems	Nicolas Ba√π,Antimo Marrazzo	Topological invariants are global properties of the ground-state wave function, typically defined as winding numbers in reciprocal space. Over the years, a number of topological markers in real space have been introduced, allowing to map topological order in heterogeneous crystalline and disordered systems. Notably, even if these formulations can be expressed in terms of lattice-periodic quantities, they can actually be deployed in open boundary conditions only, as in practice they require computing the position operator $\mathbf{r}$ which is ill-defined in periodic boundary conditions. Here we derive a local Chern marker for infinite two-dimensional systems with periodic boundary conditions in the large supercell limit, where the electronic structure is sampled with one single point in reciprocal space. We validate our approach with tight-binding numerical simulations on the Haldane model, including trivial/topological superlattices made of pristine and disordered Chern insulators. The strategy introduced here is very general and could be applied to other topological invariants and geometrical quantities in any dimension.	cond-mat.mes-hall	6 pages, 3 figures + supplementary material (3 pages)
6	Convective characteristics of Fe I lines across the solar disc	M. Ellwarth,B. Ehmann,S. Sch√§fer,A. Reiners	Solar convection is visible as a net blueshift of absorption lines, which becomes apparent when observing quiet Sun granulation. This blueshift exhibits variations from the disc centre to the solar limb due to differing projection angles onto the solar atmosphere. Our goal is to investigate convective Doppler velocities based on observations from the disc centre to the solar limb. Consequently, we aim to improve our understanding of atmospheric hydrodynamics and contribute to the improvement of solar and stellar atmospheric models. We used resolved quiet-Sun spectra to investigate the convective velocity shifts of more than 1000\,\ion{Fe}{I} lines across multiple centre-to-limb positions on the solar disc. We determined the Doppler velocities with respect to the line depth. Additionally, we calculated the formation temperature and investigated its correlation with Doppler velocities. The general behaviour of convective line shifts shows a decreasing blueshift as the lines become deeper for all observing positions from the centre to limb. For spectra obtained at the solar limb, even deeper lines exhibit redshifts. We observe a velocity trend for the different observation angles, with a less pronounced convective blueshift towards the solar limb. Convective velocities show a wavelength dependence for each observing angle when analysing on the basis of line depths. We observe a decreasing convective blueshift as the formation temperatures of the lines decrease. The velocity change over temperature ranges proceeds slower towards the solar limb. When investigating Doppler velocities with respect to formation temperature, the disc centre does not exhibit the strongest blueshift.	astro-ph.SR	None
7	Make LLM a Testing Expert: Bringing Human-like Interaction to Mobile GUI Testing via Functionality-aware Decisions	Zhe Liu,Chunyang Chen,Junjie Wang,Mengzhuo Chen,Boyu Wu,Xing Che,Dandan Wang,Qing Wang	Automated Graphical User Interface (GUI) testing plays a crucial role in ensuring app quality, especially as mobile applications have become an integral part of our daily lives. Despite the growing popularity of learning-based techniques in automated GUI testing due to their ability to generate human-like interactions, they still suffer from several limitations, such as low testing coverage, inadequate generalization capabilities, and heavy reliance on training data. Inspired by the success of Large Language Models (LLMs) like ChatGPT in natural language understanding and question answering, we formulate the mobile GUI testing problem as a Q&A task. We propose GPTDroid, asking LLM to chat with the mobile apps by passing the GUI page information to LLM to elicit testing scripts, and executing them to keep passing the app feedback to LLM, iterating the whole process. Within this framework, we have also introduced a functionality-aware memory prompting mechanism that equips the LLM with the ability to retain testing knowledge of the whole process and conduct long-term, functionality-based reasoning to guide exploration. We evaluate it on 93 apps from Google Play and demonstrate that it outperforms the best baseline by 32% in activity coverage, and detects 31% more bugs at a faster rate. Moreover, GPTDroid identify 53 new bugs on Google Play, of which 35 have been confirmed and fixed.	cs.SE	Accepted by IEEE/ACM International Conference on Software Engineering   2024 (ICSE 2024). arXiv admin note: substantial text overlap with   arXiv:2305.09434
8	3D Masked Autoencoders for Enhanced Privacy in MRI Scans	Lennart Alexander Van der Goten,Kevin Smith	MRI scans provide valuable medical information, however they also contain sensitive and personally identifiable information (PII) that needs to be protected. Whereas MRI metadata is easily sanitized, MRI image data is a privacy risk because it contains information to render highly-realistic 3D visualizations of a patient's head, enabling malicious actors to possibly identify the subject by cross-referencing a database. Data anonymization and de-identification is concerned with ensuring the privacy and confidentiality of individuals' personal information. Traditional MRI de-identification methods remove privacy-sensitive parts (e.g. eyes, nose etc.) from a given scan. This comes at the expense of introducing a domain shift that can throw off downstream analyses. Recently, a GAN-based approach was proposed to de-identify a patient's scan by remodeling it (e.g. changing the face) rather than by removing parts. In this work, we propose CP-MAE, a model that de-identifies the face using masked autoencoders and that outperforms all previous approaches in terms of downstream task performance as well as de-identification. With our method we are able to synthesize scans of resolution up to $256^3$ (previously 128 cubic) which constitutes an eight-fold increase in the number of voxels. Using our construction we were able to design a system that exhibits a highly robust training stage, making it easy to fit the network on novel data.	cs.CV	None
9	MindLLM: Pre-training Lightweight Large Language Model from Scratch, Evaluations and Domain Applications	Yizhe Yang,Huashan Sun,Jiawei Li,Runheng Liu,Yinghao Li,Yuhang Liu,Heyan Huang,Yang Gao	Large Language Models (LLMs) have demonstrated remarkable performance across various natural language tasks, marking significant strides towards general artificial intelligence. While general artificial intelligence is leveraged by developing increasingly large-scale models, there could be another branch to develop lightweight custom models that better serve certain domains, taking into account the high cost of training and deploying LLMs and the scarcity of resources. In this paper, we present MindLLM, a novel series of bilingual lightweight large language models, trained from scratch, alleviating such burdens by offering models with 1.3 billion and 3 billion parameters. A thorough account of experiences accrued during large model development is given, covering every step of the process, including data construction, model architecture, evaluation, and applications. Such insights are hopefully valuable for fellow academics and developers. MindLLM consistently matches or surpasses the performance of other open-source larger models on some public benchmarks. We also introduce an innovative instruction tuning framework tailored for smaller models to enhance their capabilities efficiently. Moreover, we explore the application of MindLLM in specific vertical domains such as law and finance, underscoring the agility and adaptability of our lightweight models.	cs.CL	Working in progress
0	navlie: A Python Package for State Estimation on Lie Groups	Charles Champagne Cossette,Mitchell Cohen,Vassili Korotkine,Arturo del Castillo Bernal,Mohammed Ayman Shalaby,James Richard Forbes	The ability to rapidly test a variety of algorithms for an arbitrary state estimation task is valuable in the prototyping phase of navigation systems. Lie group theory is now mainstream in the robotics community, and hence estimation prototyping tools should allow state definitions that belong to manifolds. A new package, called navlie, provides a framework that allows a user to model a large class of problems by implementing a set of classes complying with a generic interface. Once accomplished, navlie provides a variety of on-manifold estimation algorithms that can run directly on these classes. The package also provides a built-in library of common models, as well as many useful utilities. The open-source project can be found at https://github.com/decargroup/navlie.	cs.RO	6 pages, 8 figures, presented at the 2023 IEEE/RSJ International   Conference on Intelligent Robots and Systems (IROS)
1	BLESS: Benchmarking Large Language Models on Sentence Simplification	Tannon Kew,Alison Chi,Laura V√°squez-Rodr√≠guez,Sweta Agrawal,Dennis Aumiller,Fernando Alva-Manchego,Matthew Shardlow	We present BLESS, a comprehensive performance benchmark of the most recent state-of-the-art large language models (LLMs) on the task of text simplification (TS). We examine how well off-the-shelf LLMs can solve this challenging task, assessing a total of 44 models, differing in size, architecture, pre-training methods, and accessibility, on three test sets from different domains (Wikipedia, news, and medical) under a few-shot setting. Our analysis considers a suite of automatic metrics as well as a large-scale quantitative investigation into the types of common edit operations performed by the different models. Furthermore, we perform a manual qualitative analysis on a subset of model outputs to better gauge the quality of the generated simplifications. Our evaluation indicates that the best LLMs, despite not being trained on TS, perform comparably with state-of-the-art TS baselines. Additionally, we find that certain LLMs demonstrate a greater range and diversity of edit operations. Our performance benchmark will be available as a resource for the development of future TS methods and evaluation metrics.	cs.CL	This paper has been accepted to EMNLP 2023 as a main long paper. 9   pages, 7 figures
2	Causal Understanding of Why Users Share Hate Speech on Social Media	Dominique Geissler,Abdurahman Maarouf,Stefan Feuerriegel	Hate speech on social media threatens the mental and physical well-being of individuals and is further responsible for real-world violence. An important driver behind the spread of hate speech and thus why hateful posts can go viral are reshares, yet little is known about why users reshare hate speech. In this paper, we present a comprehensive, causal analysis of the user attributes that make users reshare hate speech. However, causal inference from observational social media data is challenging, because such data likely suffer from selection bias, and there is further confounding due to differences in the vulnerability of users to hate speech. We develop a novel, three-step causal framework: (1) We debias the observational social media data by applying inverse propensity scoring. (2) We use the debiased propensity scores to model the latent vulnerability of users to hate speech as a latent embedding. (3) We model the causal effects of user attributes on users' probability of sharing hate speech, while controlling for the latent vulnerability of users to hate speech. Compared to existing baselines, a particular strength of our framework is that it models causal effects that are non-linear, yet still explainable. We find that users with fewer followers, fewer friends, and fewer posts share more hate speech. Younger accounts, in return, share less hate speech. Overall, understanding the factors that drive users to share hate speech is crucial for detecting individuals at risk of engaging in harmful behavior and for designing effective mitigation strategies.	cs.SI	None
3	Stable gravastar with large surface redshift in Einstein's gravity with two scalar fields	Shin'ichi Nojiri,G. G. L. Nashed	We propose a class of models, in which stable gravastar with large surface redshift becomes a solution. In recent decades, gravastars have become a plausible substitute for black holes. Researchers have explored stable gravastar models in various alternative gravity theories, in addition to the conventional framework of general relativity. In this paper, we present a stellar model within the framework of Einstein's gravity with two scalar fields, in accordance with the conjecture proposed by Mazur and Mottola [Proc. Nat. Acad. Sci. \textbf{101} (2004), 9545-9550]. In the model, the two scalar fields become non-dynamical by imposing constraints in order to avoid ghosts. The gravastar comprises two distinct regions, namely: (a) the interior region and (b) the exterior region. We assume the interior region consists of the de Sitter spacetime, and the exterior region is the Schwarzschild one. The two regions are connected with each other by the shell region. On the shell, we assume that the metric is given by a polynomial function of the radial coordinate $r$. The function has six constants. These constants are fixed by the smooth junction conditions, i.e., the interior region with the interior layer of the shell and the exterior region with the exterior layer of the shell.   From these boundary conditions, we are able to write the coefficients of the scalar fields in terms of the interior radius and exterior radius. To clarify the philosophy of this study, we also give two examples of spacetimes that asymptote as the de Sitter spacetime for small $r$ and as the Schwarzschild spacetime for large $r$. Exploration is focused on the physical attribute of the shell region, specifically, its proper length.	gr-qc	18 pages, 8 Figures
4	Control problems on infinite horizon subject to time-dependent pure state constraints	Vincenzo Basco	In the last decades, control problems with infinite horizons and discount factors have become increasingly central not only for economics but also for applications in artificial intelligence and machine learning. The strong links between reinforcement learning and control theory have led to major efforts towards the development of algorithms to learn how to solve constrained control problems. In particular, discount plays a role in addressing the challenges that come with models that have unbounded disturbances. Although algorithms have been extensively explored, few results take into account time-dependent state constraints, which are imposed in most real-world control applications. For this purpose, here we investigate feasibility and sufficient conditions for Lipschitz regularity of the value function for a class of discounted infinite horizon optimal control problems subject to time-dependent constraints. We focus on problems with data that allow nonautonomous dynamics, and Lagrangian and state constraints that can be unbounded with possibly nonsmooth boundaries.	math.OC	None
5	Development and Application of a Detection System for a Novel Class of Gravitational-Wave Transients	Soichiro Kuwahara,Kipp Cannon	We have applied the system to the data of the LIGO/Virgo/KAGRA O3 science run, and report a null result. The ad hoc waveform model is motivated by the conjectured emission of gravitational waves from a curvature source moving at super-luminal speed, and while there is no plausible natural or artificial source of such waves, we nevertheless use the null result to infer a tongue-in-cheek upper bound on the number density of near-Earth transits of spacecraft travelling at warp speed. The upper bound is parameterized in terms of the trajectory's impact parameter, the vehicle's engine power, and speed. These quantities can be connected to statements made in science fiction allowing us to translate the upper bound into a bound on the number density of specific types of spacecraft from, for example, Star Trek or Star Wars. Although most suitable for entertainment purposes, these constraints might find use being folded into a Bayesian inference type estimate on the number of extra-terrestrial civilizations in the galaxy. Finally, on a more practical note, we serendipitously discovered that the ad hoc waveform model is an excellent match for a class of glitches in the gravitational-wave antenna data, and should be useful in the future for glitch mitigation in searches for astrophysical gravitational waves.	gr-qc	None
6	Dynamical and finite-size effects on the signal of first-order phase transition	Lijia Jiang,Fei Gao,Yu-xin Liu	We study the dynamical behaviors of the criterion identifying the first-order phase transition in the matter generated by the relativistic heavy-ion collisions, by explicitly involving the dynamical effects based on the Fokker-Plank framework. The perspectives we taken into account range from phase transition scenarios, initial temperatures, volume effect, relaxation rates, and evolution trajectories. Our numerical calculations show that the dynamical signal of the first-order phase transition can be reserved in certain conditions. Besides the delaying effects due to a finite relaxation time, a larger initial temperature, a smaller volume, a larger relaxation rate, or bending of the trajectory will lead to reduction of the signal. Our discussions on the criterion offer valuable reference information for the experimental detection of the first-order phase transition signal.	nucl-th	9 pages, 7 figures
7	Local-ECM: An empirical cubature hyper-reduction method adapted to local reduced order models	Jose Raul Bravo Martinez,Sebastian Ares de Parga Regalado,Joaquin Alberto Hernandez Ortega,Riccardo Rossi Bernecoli	We present the Local Empirical Cubature Method (Local-ECM), a novel algorithm tailored for creating efficient integration rules, particularly addressing clusters of intrinsically distinct functions, as observed in local reduced-order models. Local-ECM seeks to enhance existing empirical cubature methodologies by harnessing the locality of the functions to yield the sparsest outcome, while incurring virtually no implementation overheads. Our approach straightforwardly poses a local cubature optimization problem for the first time, out of which we also propose alternative Linear Programming (LP) strategies for its resolution. Through examination across three academic examples, we demonstrate the capability of our method to identify the sparsest cubature rules for a given tolerance, outperforming alternate methods outlined, including the LP and other global strategies. We have made our code freely available through the GitHub repository at https://github.com/Rbravo555/localECM	math-ph	None
8	Unpaired MRI Super Resolution with Self-Supervised Contrastive Learning	Hao Li,Quanwei Liu,Jianan Liu,Xiling Liu,Yanni Dong,Tao Huang,Zhihan Lv	High-resolution (HR) magnetic resonance imaging (MRI) is crucial for enhancing diagnostic accuracy in clinical settings. Nonetheless, the inherent limitation of MRI resolution restricts its widespread applicability. Deep learning-based image super-resolution (SR) methods exhibit promise in improving MRI resolution without additional cost. However, these methods frequently require a substantial number of HR MRI images for training, which can be challenging to acquire. In this paper, we propose an unpaired MRI SR approach that employs self-supervised contrastive learning to enhance SR performance with limited training data. Our approach leverages both authentic HR images and synthetically generated SR images to construct positive and negative sample pairs, thus facilitating the learning of discriminative features. Empirical results presented in this study underscore significant enhancements in the peak signal-to-noise ratio and structural similarity index, even when a paucity of HR images is available. These findings accentuate the potential of our approach in addressing the challenge of limited training data, thereby contributing to the advancement of high-resolution MRI in clinical applications.	eess.IV	None
9	Robust Learning via Conditional Prevalence Adjustment	Minh Nguyen,Alan Q. Wang,Heejong Kim,Mert R. Sabuncu	Healthcare data often come from multiple sites in which the correlations between confounding variables can vary widely. If deep learning models exploit these unstable correlations, they might fail catastrophically in unseen sites. Although many methods have been proposed to tackle unstable correlations, each has its limitations. For example, adversarial training forces models to completely ignore unstable correlations, but doing so may lead to poor predictive performance. Other methods (e.g. Invariant risk minimization [4]) try to learn domain-invariant representations that rely only on stable associations by assuming a causal data-generating process (input X causes class label Y ). Thus, they may be ineffective for anti-causal tasks (Y causes X), which are common in computer vision. We propose a method called CoPA (Conditional Prevalence-Adjustment) for anti-causal tasks. CoPA assumes that (1) generation mechanism is stable, i.e. label Y and confounding variable(s) Z generate X, and (2) the unstable conditional prevalence in each site E fully accounts for the unstable correlations between X and Y . Our crucial observation is that confounding variables are routinely recorded in healthcare settings and the prevalence can be readily estimated, for example, from a set of (Y, Z) samples (no need for corresponding samples of X). CoPA can work even if there is a single training site, a scenario which is often overlooked by existing methods. Our experiments on synthetic and real data show CoPA beating competitive baselines.	cs.LG	Accepted at WACV
0	Debiasing, calibrating, and improving Semi-supervised Learning performance via simple Ensemble Projector	Khanh-Binh Nguyen	Recent studies on semi-supervised learning (SSL) have achieved great success. Despite their promising performance, current state-of-the-art methods tend toward increasingly complex designs at the cost of introducing more network components and additional training procedures. In this paper, we propose a simple method named Ensemble Projectors Aided for Semi-supervised Learning (EPASS), which focuses mainly on improving the learned embeddings to boost the performance of the existing contrastive joint-training semi-supervised learning frameworks. Unlike standard methods, where the learned embeddings from one projector are stored in memory banks to be used with contrastive learning, EPASS stores the ensemble embeddings from multiple projectors in memory banks. As a result, EPASS improves generalization, strengthens feature representation, and boosts performance. For instance, EPASS improves strong baselines for semi-supervised learning by 39.47\%/31.39\%/24.70\% top-1 error rate, while using only 100k/1\%/10\% of labeled data for SimMatch, and achieves 40.24\%/32.64\%/25.90\% top-1 error rate for CoMatch on the ImageNet dataset. These improvements are consistent across methods, network architectures, and datasets, proving the general effectiveness of the proposed methods. Code is available at https://github.com/beandkay/EPASS.	cs.CV	Accepted to WACV 2024
1	Nonequilibrium thermodynamics perspectives for the monotonicity of the renormalization group flow	Ki-Seok Kim,Shinsei Ryu	"We investigate the monotonicity of the renormalization group (RG) flow from the perspectives of nonequilibrium thermodynamics. Applying the Martin-Siggia-Rose formalism to the Wilsonian RG transformation, we incorporate the RG flow equations manifestly in an effective action, where all coupling functions are dynamically promoted. As a result, we obtain an emergent holographic dual effective field theory, where an extra dimension appears from the Wilsonian RG transformation. We observe that Becchi-Rouet-Stora-Tyutin (BRST)-type transformations play an important role in the bulk effective action, which give rise to novel Ward identities for correlation functions between the renormalized coupling fields. As generalized fluctuation-dissipation theorems in the semiclassical nonequilibrium dynamics can be understood from the Ward identities of such BRST symmetries, we find essentially the same principle for the RG flow in the holographic dual effective field theory. Furthermore, we discuss how these ``nonequilibrium work identities"" can be related to the monotonicity of the RG flow, for example, the $c-theorem$. In particular, we introduce an entropy functional for the dynamical coupling field and show that the production rate of the total entropy functional is always positive, indicating the irreversibility of the RG flow."	hep-th	None
2	Agent-based models of social behaviour and communication in evacuations: A systematic review	Anne Templeton,Hui Xie,Steve Gwynne,Aoife Hunt,Pete Thompson,Gerta K√∂ster	Most modern agent-based evacuation models involve interactions between evacuees. However, the assumed reasons for interactions and portrayal of them may be overly simple. Research from social psychology suggests that people interact and communicate with one another when evacuating and evacuee response is impacted by the way information is communicated. Thus, we conducted a systematic review of agent-based evacuation models to identify 1) how social interactions and communication approaches between agents are simulated, and 2) what key variables related to evacuation are addressed in these models. We searched Web of Science and ScienceDirect to identify articles that simulated information exchange between agents during evacuations, and social behaviour during evacuations. From the final 70 included articles, we categorised eight types of social interaction that increased in social complexity from collision avoidance to social influence based on strength of social connections with other agents. In the 17 models which simulated communication, we categorised four ways that agents communicate information: spatially through information trails or radii around agents, via social networks and via external communication. Finally, the variables either manipulated or measured in the models were categorised into the following groups: environmental condition, personal attributes of the agents, procedure, and source of information. We discuss promising directions for agent-based evacuation models to capture the effects of communication and group dynamics on evacuee behaviour. Moreover, we demonstrate how communication and group dynamics may impact the variables commonly used in agent-based evacuation models.	cs.MA	Pre-print submitted to Safety Science special issue following the   2023 Pedestrian and Evacuation Dynamics conference
3	Improved action for contact effective field theory	Lorenzo Contessi,Martin Sch√§fer,Ubirajara van Kolck	We present an improved action for renormalizable effective field theories (EFTs) of systems near the two-body unitarity limit. The ordering of EFT interactions is constrained, but not entirely fixed, by the renormalization group. The remaining freedom can be used to improve the theory's convergence, to simplify its applications, and to connect it to phenomenological models. We exemplify the method on a contact theory applied to systems of up to five $^4$He atoms. We solve the EFT at LO including a subleading interaction that accounts for part of the two-body effective range. We show that the effects of such fake range can be compensated in perturbation theory at NLO, as long as the fake range is smaller or comparable to the experimental effective range. These results open the possibility of using similar improved actions for other many-body systems.	physics.atm-clus	15 pages, 8 figures
4	2D excitation information by MPS method on infinite helixes	Xing-Yu Zhang,Runze Chi,Yang Liu,Lei Wang	Understanding the excitation spectrum in two-dimensional quantum many-body systems has long been a challenging task. We present an approach by introducing an excitation ansatz based on an infinite matrix product state (MPS) on a helix structure. With the canonical form of MPS states, we can accurately extract key properties such as energy, degeneracy, spectrum weight, and scaling behavior of low-energy excited states simultaneously. To validate the effectiveness of this method, we begin by applying it to the critical point of the transverse-field Ising model. The extracted scaling exponent of the energy gap closely aligns with the conformal bootstrap results. Subsequently, we apply this approach to the $J_1$-$J_2$ Heisenberg model on a square lattice. We discover that the degeneracy of lowest-energy excitations serves as a reliable metric for distinguishing different phases. The phase boundary identified by our method is consistent with some of the previous findings. The present method provides a promising avenue for studying the excitation spectrum of two-dimensional quantum many-body systems.	cond-mat.str-el	None
5	Learning From Free-Text Human Feedback -- Collect New Datasets Or Extend Existing Ones?	Dominic Petrak,Nafise Sadat Moosavi,Ye Tian,Nikolai Rozanov,Iryna Gurevych	Learning from free-text human feedback is essential for dialog systems, but annotated data is scarce and usually covers only a small fraction of error types known in conversational AI. Instead of collecting and annotating new datasets from scratch, recent advances in synthetic dialog generation could be used to augment existing dialog datasets with the necessary annotations. However, to assess the feasibility of such an effort, it is important to know the types and frequency of free-text human feedback included in these datasets. In this work, we investigate this question for a variety of commonly used dialog datasets, including MultiWoZ, SGD, BABI, PersonaChat, Wizards-of-Wikipedia, and the human-bot split of the Self-Feeding Chatbot. Using our observations, we derive new taxonomies for the annotation of free-text human feedback in dialogs and investigate the impact of including such data in response generation for three SOTA language generation models, including GPT-2, LLAMA, and Flan-T5. Our findings provide new insights into the composition of the datasets examined, including error types, user response types, and the relations between them.	cs.CL	Accepted to be presented at EMNLP 2023
6	Do Differences in Values Influence Disagreements in Online Discussions?	Michiel van der Meer,Piek Vossen,Catholijn M. Jonker,Pradeep K. Murukannaiah	Disagreements are common in online discussions. Disagreement may foster collaboration and improve the quality of a discussion under some conditions. Although there exist methods for recognizing disagreement, a deeper understanding of factors that influence disagreement is lacking in the literature. We investigate a hypothesis that differences in personal values are indicative of disagreement in online discussions. We show how state-of-the-art models can be used for estimating values in online discussions and how the estimated values can be aggregated into value profiles. We evaluate the estimated value profiles based on human-annotated agreement labels. We find that the dissimilarity of value profiles correlates with disagreement in specific cases. We also find that including value information in agreement prediction improves performance.	cs.CL	Accepted as main paper at EMNLP 2023
7	A necessary and sufficient condition for the existence of chaotic dynamics in an overlapping generations model	Tomohiro Uchiyama	In this paper, we study economic dynamics in a standard overlapping generations model without production. In particular, using numerical methods, we obtain a necessary and sufficient condition for the existence of a topological chaos. This is a new application of a recent result characterising the existence of a topological chaos for a unimodal interval map by Deng, Khan, Mitra (2022).	econ.GN	None
8	Efficient CPU-Optimized Parameter Estimation for Modeling Fish Schooling Behavior in Large Particle Systems	S. Arabeei,S. Subbey	The schooling behavior of fish can be studied through simulations involving a large number of interacting particles. In such systems, each individual particle is guided by behavior rules, which include aggregation towards a centroid, collision avoidance, and direction alignment. The movement vector of each particle may be expressed as a linear combination of behaviors, with unknown parameters that define a trade-off among several behavioral constraints. A fitness function for collective schooling behavior encompasses all individual particle parameters.   For a large number of interacting particles in a complex environment, heuristic methods, such as evolutionary algorithms, are used to optimize the fitness function, ensuring that the resulting decision rule preserves collective behavior. However, these algorithms exhibit slow convergence, making them inefficient in terms of CPU time cost.   This paper proposes a CPU-efficient iterative (Cluster, Partition, Refine -- CPR) algorithm for estimating decision rule parameters for a large number of interacting particles. In the first step, we employ the K-Means (unsupervised learning) algorithm to cluster candidate solutions. Then, we partition the search space using Voronoi tessellation over the defined clusters. We assess the quality of each cluster based on the fitness function, with the centroid of their Voronoi cells representing the clusters. Subsequently, we refine the search space by introducing new cells into a number of identified well-fitting Voronoi cells. This process is repeated until convergence.   A comparison of the performance of the CPR algorithm with a standard Genetic Algorithm reveals that the former converges faster than the latter. We also demonstrate that the application of the CPR algorithm results in a schooling behavior consistent with empirical observations.	q-bio.PE	10pages
9	Integrating Language Models into Direct Speech Translation: An Inference-Time Solution to Control Gender Inflection	Dennis Fucci,Marco Gaido,Sara Papi,Mauro Cettolo,Matteo Negri,Luisa Bentivogli	When translating words referring to the speaker, speech translation (ST) systems should not resort to default masculine generics nor rely on potentially misleading vocal traits. Rather, they should assign gender according to the speakers' preference. The existing solutions to do so, though effective, are hardly feasible in practice as they involve dedicated model re-training on gender-labeled ST data. To overcome these limitations, we propose the first inference-time solution to control speaker-related gender inflections in ST. Our approach partially replaces the (biased) internal language model (LM) implicitly learned by the ST decoder with gender-specific external LMs. Experiments on en->es/fr/it show that our solution outperforms the base models and the best training-time mitigation strategy by up to 31.0 and 1.6 points in gender accuracy, respectively, for feminine forms. The gains are even larger (up to 32.0 and 3.4) in the challenging condition where speakers' vocal traits conflict with their gender.	cs.CL	Accepted at EMNLP 2023
0	Gradient-Based Eigenvalue Optimization for Electromagnetic Cavities with Built-in Mode Matching	Anna Ziegler,Robert Hahn,Victoria Isensee,Anh Duc Nguyen,Sebastian Sch√∂ps	Shape optimization with respect to eigenvalues of a cavity plays an important role in the design of new resonators or in the optimization of existing ones. In our paper, we propose a gradient-based optimization scheme, which we enhance with closed-form shape derivatives of the system matrices. Based on these, we can compute accurate derivatives of eigenvalues, eigenmodes and the cost function with respect to the geometry, which significantly reduces the computational effort of the optimizer. We demonstrate our work by applying it to the 9-cell TESLA cavity, for which we tune the design parameters of the computational model to match the design criteria for devices in realistic use cases. Since eigenvalues may cross during the shape optimization of a cavity, we propose a new algorithm based on an eigenvalue matching procedure, to ensure the optimization of the desired mode in order to also enable successful matching along large shape variations.	cs.CE	None
1	On the complement to a real caustic germ of type $E_6$	Vyacheslav D. Sedykh	We prove that the complement to the caustic of a stable Lagrangian map germ of type $E_6^\pm$ has seven connected components, six of which are contractible and one is homotopy equivalent to a circle. The inverse image of the noncontractible component under this map has three connected components. The restriction of the map to one of them is a two-sheeted covering; the restriction to each of the other two is a diffeomorphism. The table of adjacency indexes of type $E_6^\pm$ monosingularity to multisingularities of a generic Lagrangian map is given.	math.AG	59 pages, 21 figures
2	Large Language Models are Temporal and Causal Reasoners for Video Question Answering	Dohwan Ko,Ji Soo Lee,Wooyoung Kang,Byungseok Roh,Hyunwoo J. Kim	Large Language Models (LLMs) have shown remarkable performances on a wide range of natural language understanding and generation tasks. We observe that the LLMs provide effective priors in exploiting $\textit{linguistic shortcuts}$ for temporal and causal reasoning in Video Question Answering (VideoQA). However, such priors often cause suboptimal results on VideoQA by leading the model to over-rely on questions, $\textit{i.e.}$, $\textit{linguistic bias}$, while ignoring visual content. This is also known as `ungrounded guesses' or `hallucinations'. To address this problem while leveraging LLMs' prior on VideoQA, we propose a novel framework, Flipped-VQA, encouraging the model to predict all the combinations of $\langle$V, Q, A$\rangle$ triplet by flipping the source pair and the target label to understand their complex relationships, $\textit{i.e.}$, predict A, Q, and V given a VQ, VA, and QA pairs, respectively. In this paper, we develop LLaMA-VQA by applying Flipped-VQA to LLaMA, and it outperforms both LLMs-based and non-LLMs-based models on five challenging VideoQA benchmarks. Furthermore, our Flipped-VQA is a general framework that is applicable to various LLMs (OPT and GPT-J) and consistently improves their performances. We empirically demonstrate that Flipped-VQA not only enhances the exploitation of linguistic shortcuts but also mitigates the linguistic bias, which causes incorrect answers over-relying on the question. Code is available at https://github.com/mlvlab/Flipped-VQA.	cs.CV	Accepted paper at EMNLP 2023 Main
3	Failures Pave the Way: Enhancing Large Language Models through Tuning-free Rule Accumulation	Zeyuan Yang,Peng Li,Yang Liu	Large Language Models (LLMs) have showcased impressive performance. However, due to their inability to capture relationships among samples, these frozen LLMs inevitably keep repeating similar mistakes. In this work, we propose our Tuning-free Rule Accumulation (TRAN) framework, which guides LLMs in improving their performance by learning from previous mistakes. Considering data arrives sequentially, LLMs gradually accumulate rules from incorrect cases, forming a rule collection. These rules are then utilized by the LLMs to avoid making similar mistakes when processing subsequent inputs. Moreover, the rules remain independent of the primary prompts, seamlessly complementing prompt design strategies. Experimentally, we show that TRAN improves over recent baselines by a large margin.	cs.CL	This paper is accepted by the EMNLP 2023 Main Conference
4	Correlation Functions and Stochastic Feynman Rules for Self-Interacting Scalar Fields	Moongul Byun	It is well known that perturbative solutions of the Langevin equation can be used to calculate correlation functions in stochastic quantum mechanics (SQM). However, this work is challenging due to the absence of generalized rules. In this paper, we address this difficulty by studying correlation functions up to certain orders for self-interacting scalar fields. Through the perturbative approach, we establish stochastic Feynman rules applicable to both finite and large fictitious times. Within this process, we introduce a fictitious-time ordering diagram, which serves as a keystone for finding all possible fictitious-time orderings and directly writing down an exact contribution for a given stochastic diagram with its fixed fictitious-time ordering.	hep-th	None
5	RAPL: A Relation-Aware Prototype Learning Approach for Few-Shot Document-Level Relation Extraction	Shiao Meng,Xuming Hu,Aiwei Liu,Shu'ang Li,Fukun Ma,Yawen Yang,Lijie Wen	How to identify semantic relations among entities in a document when only a few labeled documents are available? Few-shot document-level relation extraction (FSDLRE) is crucial for addressing the pervasive data scarcity problem in real-world scenarios. Metric-based meta-learning is an effective framework widely adopted for FSDLRE, which constructs class prototypes for classification. However, existing works often struggle to obtain class prototypes with accurate relational semantics: 1) To build prototype for a target relation type, they aggregate the representations of all entity pairs holding that relation, while these entity pairs may also hold other relations, thus disturbing the prototype. 2) They use a set of generic NOTA (none-of-the-above) prototypes across all tasks, neglecting that the NOTA semantics differs in tasks with different target relation types. In this paper, we propose a relation-aware prototype learning method for FSDLRE to strengthen the relational semantics of prototype representations. By judiciously leveraging the relation descriptions and realistic NOTA instances as guidance, our method effectively refines the relation prototypes and generates task-specific NOTA prototypes. Extensive experiments demonstrate that our method outperforms state-of-the-art approaches by average 2.61% $F_1$ across various settings of two FSDLRE benchmarks.	cs.CL	Accepted to EMNLP 2023
6	Improving Diffusion Models for ECG Imputation with an Augmented Template Prior	Alexander Jenkins,Zehua Chen,Fu Siong Ng,Danilo Mandic	Pulsative signals such as the electrocardiogram (ECG) are extensively collected as part of routine clinical care. However, noisy and poor-quality recordings, leading to missing values, are a major issue for signals collected using mobile health systems, decreasing the signal quality and affecting the automated downstream tasks. Recent studies have explored imputation of missing values for ECG with probabilistic time-series models. Nevertheless, in comparison with the deterministic models, their performance is still limited, as the variations across subjects and heart-beat relationships are not explicitly considered in the training objective. In this work, to improve the ECG imputation and forecasting accuracy with probabilistic models, we present an template-guided denoising diffusion probabilistic model, PulseDiff, which is conditioned an informative prior for a range of health conditions. Specifically, 1) we first extract a subject-level pulsative template from the observation as an informative prior of missing values, which captures the personal characteristics; 2) we then add beat-level stochastic shift terms on the template for prior augmentation, which considers the beat-level variance of positioning and amplitude; 3) we finally design a confidence score to consider the health condition of subject, which ensures our prior is provided in a safe way. Experiments with the PTBXL dataset reveal PulseDiff improves the performance of two strong DDPMs baseline models, CSDI and SSSD$^{S4}$, verifying our method guides the generation of DDPMs while managing the uncertainty. When combining with SSSD$^{S4}$, our PulseDiff method outperforms the leading deterministic model for short-interval missing data and is comparable for long-interval data loss.	cs.LG	None
7	The Hyperdimensional Transform: a Holographic Representation of Functions	Pieter Dewulf,Michiel Stock,Bernard De Baets	Integral transforms are invaluable mathematical tools to map functions into spaces where they are easier to characterize. We introduce the hyperdimensional transform as a new kind of integral transform. It converts square-integrable functions into noise-robust, holographic, high-dimensional representations called hyperdimensional vectors. The central idea is to approximate a function by a linear combination of random functions. We formally introduce a set of stochastic, orthogonal basis functions and define the hyperdimensional transform and its inverse. We discuss general transform-related properties such as its uniqueness, approximation properties of the inverse transform, and the representation of integrals and derivatives. The hyperdimensional transform offers a powerful, flexible framework that connects closely with other integral transforms, such as the Fourier, Laplace, and fuzzy transforms. Moreover, it provides theoretical foundations and new insights for the field of hyperdimensional computing, a computing paradigm that is rapidly gaining attention for efficient and explainable machine learning algorithms, with potential applications in statistical modelling and machine learning. In addition, we provide straightforward and easily understandable code, which can function as a tutorial and allows for the reproduction of the demonstrated examples, from computing the transform to solving differential equations.	cs.LG	None
8	Interpretable Medical Image Classification using Prototype Learning and Privileged Information	Luisa Gallee,Meinrad Beer,Michael Goetz	Interpretability is often an essential requirement in medical imaging. Advanced deep learning methods are required to address this need for explainability and high performance. In this work, we investigate whether additional information available during the training process can be used to create an understandable and powerful model. We propose an innovative solution called Proto-Caps that leverages the benefits of capsule networks, prototype learning and the use of privileged information. Evaluating the proposed solution on the LIDC-IDRI dataset shows that it combines increased interpretability with above state-of-the-art prediction performance. Compared to the explainable baseline model, our method achieves more than 6 % higher accuracy in predicting both malignancy (93.0 %) and mean characteristic features of lung nodules. Simultaneously, the model provides case-based reasoning with prototype representations that allow visual validation of radiologist-defined attributes.	cs.CV	MICCAI 2023 Medical Image Computing and Computer Assisted   Intervention
9	Non-Equilibrium Pathways for Excitation of Bulk and Surface Phonons through Anharmonic Coupling	C. Brand,V. Tinnemann,A. Hanisch-Blicharski,M. Tajik,J. D. Fortmann,A. Ka√üen,F. Thiemann,M. Horn-von Hoegen	Upon impulsive optical excitation of solid-state materials, the non-equilibrium flow of energy from the excited electronic system to the lattice degrees of freedom typically happens in a few picoseconds. Here we identified the surface of thin Bi films grown on Si(001) as an additional subsystem which is excited much slower on a 100 ps timescale that is caused by decoupling due to mismatched phonon dispersions relations of bulk and surface. Anharmonic coupling among the phonon systems provides pathways for excitations which exhibits a 1/T-dependence causing a speed-up of surface excitation at higher temperatures. A quantitative justification is provided by phonon Umklapp processes from lattice thermal conductivity of the Bi bulk. Three-temperature model simulations reveal a pronounced non-equilibrium situation up to nanoseconds: initially, the surface is colder than the bulk, that situation is then inverted during cooling and the surface feeds energy back into the bulk phonon system.	cond-mat.mes-hall	None
0	A counterexample to parabolic dichotomies in holomorphic iteration	Leandro Arosio,Filippo Bracci,Herv/'e Gaussier	We give an example of a parabolic holomorphic self-map $f$ of the unit ball $\mathbb B^2\subset \mathbb C^2$ whose canonical Kobayashi hyperbolic semi-model is given by an elliptic automorphism of the disc $\mathbb D\subset \mathbb C$, which can be chosen to be different from the identity. As a consequence, in contrast to the one dimensional case, this provides a first example of a holomorphic self-map of the unit ball which has points with zero hyperbolic step and points with nonzero hyperbolic step, solving an open question and showing that parabolic dynamics in the ball $\\mathbb B^2$ is radically different from parabolic dynamics in the disc. The example is obtained via a geometric method, embedding the ball $\mathbb B^2$ as a domain $\Omega$ in the bidisc $\\mathbb D\times \mathbb{H}$ that is forward invariant and absorbing for the map $(z,w)\mapsto (e^{i\theta}z,w+1)$, where $\mathbb H\subset \mathbb C$ denotes the right half-plane. We also show that a complete Kobayashi hyperbolic domain $\Omega$ with such properties cannot be Gromov hyperbolic w.r.t. the Kobayashi distance (hence, it cannot be biholomorphic to $\\mathbb B^2$) if an additional quantitative geometric condition is satisfied.	math.CV	None
1	Semantic-preserving image coding based on Conditional Diffusion models	Francesco Pezone,Osman Musa,Giuseppe Caire,Sergio Barbarossa	Semantic communication, rather than on a bit-by-bit recovery of the transmitted messages, focuses on the meaning and the goal of the communication itself. In this paper, we propose a novel semantic image coding scheme that preserves the semantic content of an image, while ensuring a good trade-off between coding rate and image quality. The proposed Semantic-Preserving Image Coding based on Conditional Diffusion Models (SPIC) transmitter encodes a Semantic Segmentation Map (SSM) and a low-resolution version of the image to be transmitted. The receiver then reconstructs a high-resolution image using a Denoising Diffusion Probabilistic Models (DDPM) doubly conditioned to the SSM and the low-resolution image. As shown by the numerical examples, compared to state-of-the-art (SOTA) approaches, the proposed SPIC exhibits a better balance between the conventional rate-distortion trade-off and the preservation of semantically-relevant features.	cs.IT	Submitted at ICASSP 2024
2	Nanoscale transient polarization gratings	Laura Foglia,Bj√∂rn Wehinger,Giovanni Perosa,Riccardo Mincigrucci,Enrico Allaria,Francesco Armillotta,Alexander Brynes,Riccardo Cucini,Dario De Angelis,Giovanni De Ninno,W. Dieter Engel,Danny Fainozzi,Luca Giannessi,Nupur N. Khatu,Simone Laterza,Ettore Paltanin,Jacopo Stefano Pelli-Cresi,Giuseppe Penco,Denny Puntel,Primo≈æ Rebernik Ribiƒç,Filippo Sottocorona,Mauro Trov√≤,Clemens von Korff Schmising,Kelvin Yao,Claudio Masciovecchio,Stefano Bonetti,Filippo Bencivenga	We present the generation of transient polarization gratings at the nanoscale, achieved using a tailored accelerator configuration of the FERMI free electron laser. We demonstrate the capabilities of such a transient polarization grating by comparing its induced dynamics with the ones triggered by a more conventional intensity grating on a thin film ferrimagnetic alloy. While the signal of the intensity grating is dominated by the thermoelastic response of the system, such a contribution is suppressed in the case of the polarization grating. This exposes helicity-dependent magnetization dynamics that have so-far remained hidden under the large thermally driven response. We anticipate nanoscale transient polarization gratings to become useful for the study of any physical, chemical and biological systems possessing chiral symmetry.	cond-mat.mtrl-sci	None
3	Supernova Ejecta with Crystalline Silicate Dust in the Supernova Remnant MSH 15-52	Hyun-Jeong Kim,Bon-Chul Koo,Takashi Onaka	IRAS 15099-5856 in the young supernova remnant (SNR) MSH 15-52 is the first and only SNR-associated object with crystalline silicate dust detected so far, although its nature and the origin of the crystalline silicate are still unclear. In this paper, we present high-resolution mid-infrared (MIR) imaging observations of the bright central compact source IRS1 of IRAS 15099-5856 to study the spatial distributions of gas and dust and the analysis of its Spitzer MIR spectrum to explore the origin of IRS1. The MIR images obtained with the T-ReCS attached on the Gemini South telescope show a complicated, inhomogeneous morphology of IRS1 with bright clumps and diffuse emission in [Ne II] 12.81 $\mu$m and Qa 18.30 $\mu$m, which confirms that IRS1 is an extended source externally heated by the nearby O star Muzzio 10, a candidate for the binary companion of the progenitor star. The Spitzer MIR spectrum reveals several ionic emission lines including a strong [Ne II] 12.81 $\mu$m line, but no hydrogen line is detected. We model the spectrum using the photoionization code CLOUDY with varying elemental composition. The elemental abundance of IRS1 derived from the model is close to that of SN ejecta with depleted hydrogen and enhanced metals, particularly neon, argon, and iron. Our results imply that IRS1 originates from the SN ejecta and suggest the possibility of the formation of crystalline silicate in newly-formed SN dust.	astro-ph.GA	17 pages, 10 figures, submitted to ApJ
4	Euclid preparation. TBD. Forecast impact of super-sample covariance on 3x2pt analysis with Euclid	Euclid Collaboration,D. Sciotti,S. Gouyou Beauchamps,V. F. Cardone,S. Camera,I. Tutusaus,F. Lacasa,A. Barreira,A. Gorce,M. Aubert,P. Baratta,R. E. Upham,M. Bonici,C. Carbone,S. Casas,S. Iliƒá,M. Martinelli,Z. Sakr,A. Schneider,R. Maoli,R. Scaramella,S. Escoffier,W. Gillard,N. Aghanim,A. Amara,S. Andreon,N. Auricchio,M. Baldi,S. Bardelli,D. Bonino,E. Branchini,M. Brescia,J. Brinchmann,V. Capobianco,J. Carretero,F. J. Castander,M. Castellano,S. Cavuoti,A. Cimatti,R. Cledassou,G. Congedo,C. J. Conselice,L. Conversi,Y. Copin,L. Corcione,F. Courbin,H. M. Courtois,M. Cropper,A. Da Silva,H. Degaudenzi,J. Dinis,F. Dubath,X. Dupac,S. Dusini,M. Farina,S. Farrens,P. Fosalba,M. Frailis,E. Franceschi,M. Fumana,S. Galeotta,B. Garilli,B. Gillis,C. Giocoli,A. Grazian,F. Grupp,L. Guzzo,S. V. H. Haugan,W. Holmes,I. Hook,F. Hormuth,A. Hornstrup,P. Hudelot,K. Jahnke,B. Joachimi,E. Keih√§nen,S. Kermiche,A. Kiessling,M. Kunz,H. Kurki-Suonio,P. B. Lilje,V. Lindholm,I. Lloro,D. Maino,O. Mansutti,O. Marggraf,K. Markovic,N. Martinet,F. Marulli,R. Massey,S. Maurogordato,E. Medinaceli,S. Mei,Y. Mellier,M. Meneghetti,G. Meylan,M. Moresco,L. Moscardini,E. Munari,S. -M. Niemi,C. Padilla,S. Paltani,F. Pasian,K. Pedersen,V. Pettorino,S. Pires,G. Polenta,M. Poncet,L. A. Popa,F. Raison,R. Rebolo,A. Renzi,J. Rhodes,G. Riccio,E. Romelli,M. Roncarelli,R. Saglia,D. Sapone,B. Sartoris,M. Schirmer,P. Schneider,A. Secroun,G. Seidel,S. Serrano,C. Sirignano,G. Sirri,L. Stanco,J. -L. Starck,P. Tallada-Cresp√≠,A. N. Taylor,I. Tereno,R. Toledo-Moreo,F. Torradeflot,E. A. Valentijn,L. Valenziano,T. Vassallo,A. Veropalumbo,Y. Wang,J. Weller,A. Zacchei,G. Zamorani,J. Zoubian,E. Zucca,A. Biviano,A. Boucaud,E. Bozzo,C. Colodro-Conde,D. Di Ferdinando,R. Farinelli,J. Graci√°-Carpio,N. Mauri,C. Neissner,V. Scottez,M. Tenti,Y. Akrami,V. Allevato,C. Baccigalupi,M. Ballardini,F. Bernardeau,A. Blanchard,S. Borgani,A. S. Borlaff,C. Burigana,R. Cabanac,A. Cappi,C. S. Carvalho,G. Castignani,T. Castro,G. Ca\ {n}as-Herrera,K. C. Chambers,A. R. Cooray,J. Coupon,A. D√≠az-S√°nchez,S. Davini,G. De Lucia,G. Desprez,S. Di Domizio,J. A. Escartin Vigo,I. Ferrero,F. Finelli,L. Gabarra,K. Ganga,J. Garcia-Bellido,E. Gaztanaga,F. Giacomini,G. Gozaliasl,H. Hildebrandt,J. Jacobson,J. J. E. Kajava,V. Kansal,C. C. Kirkpatrick,L. Legrand,A. Loureiro,J. Macias-Perez,M. Magliocchetti,G. Mainetti,C. J. A. P. Martins,S. Matthew,L. Maurin,R. B. Metcalf,M. Migliaccio,P. Monaco,G. Morgante,S. Nadathur,A. A. Nucita,M. P√∂ntinen,L. Patrizii,V. Popa,C. Porciani,D. Potter,A. Pourtsidou,A. G. S√°nchez,E. Sefusatti,M. Sereno,P. Simon,A. Spurio Mancini,J. Stadel,J. Steinwagner,R. Teyssier,S. Toft,M. Tucci,C. Valieri,J. Valiviita,M. Viel	Deviations from Gaussianity in the distribution of the fields probed by large-scale structure surveys generate additional terms in the data covariance matrix, increasing the uncertainties in the measurement of the cosmological parameters. Super-sample covariance (SSC) is among the largest of these non-Gaussian contributions, with the potential to significantly degrade constraints on some of the parameters of the cosmological model under study -- especially for weak lensing cosmic shear. We compute and validate the impact of SSC on the forecast uncertainties on the cosmological parameters for the Euclid photometric survey, obtained with a Fisher matrix analysis, both considering the Gaussian covariance alone and adding the SSC term -- computed through the public code PySSC. The photometric probes are considered in isolation and combined in the `3$\times$2pt' analysis. We find the SSC impact to be non-negligible -- halving the Figure of Merit of the dark energy parameters ($w_0$, $w_a$) in the 3$\times$2pt case and substantially increasing the uncertainties on $\Omega_{{\rm m},0}, w_0$, and $\sigma_8$ for cosmic shear; photometric galaxy clustering, on the other hand, is less affected due to the lower probe response. The relative impact of SSC does not show significant changes under variations of the redshift binning scheme, while it is smaller for weak lensing when marginalising over the multiplicative shear bias nuisance parameters, which also leads to poorer constraints on the cosmological parameters. Finally, we explore how the use of prior information on the shear and galaxy bias changes the SSC impact. Improving shear bias priors does not have a significant impact, while galaxy bias must be calibrated to sub-percent level to increase the Figure of Merit by the large amount needed to achieve the value when SSC is not included.	astro-ph.CO	22 pages, 13 figures
5	A multiparametric Murnaghan-Nakayama rule for Macdonald polynomials	Naihuan Jing,Ning Liu	We introduce a new family of operators as multi-parameter deformation of the one-row Macdonald polynomials. The matrix coefficients of these operators acting on the space of symmetric functions with rational coefficients in two parameters $q,t$ (denoted by $\Lambda[q,t]$) are computed by assigning some values to skew Macdonald polynomials in $\lambda$-ring notation. The new rule is utilized to provide new iterative formulas and also recover various existing formulas in a unified manner. Specifically the following applications are discussed: (i) A $(q,t)$-Murnaghan-Nakayama rule for Macdonald functions is given as a generalization of the $q$-Murnaghan-Nakayama rule; (ii) An iterative formula for the $(q,t)$-Green polynomial is deduced; (iii) A simple proof of the Murnaghan-Nakayama rule for the Hecke algebra and the Hecke-Clifford algebra is offered; (iv) A combinatorial inversion of the Pieri rule for Hall-Littlewood functions is derived with the help of the vertex operator realization of the Hall-Littlewood functions; (v) Two iterative formulae for the $(q,t)$-Kostka polynomials $K_{\lambda\mu}(q,t)$ are obtained from the dual version of our multiparametric Murnaghan-Nakayama rule, one of which yields an explicit formula for arbitrary $\lambda$ and $\mu$ in terms of the generalized $(q, t)$-binomial coefficient introduced independently by Lassalle and Okounkov.	math.CO	32 pp, 2 figures
6	Vacuum solutions of Einstein equations that depend on one coordinate	S. Parnovsky	In the famous textbook written by Landau and Lifshitz all the vacuum metrics of the general theory of relativity are derived, which depend on one coordinate in the absence of a cosmological constant. Unfortunately, when considering these solutions, the authors missed some of the possible solutions discussed in this article. An exact solution is demonstrated, which is absent in the book by Landau and Lifshitz. It describes space-time with a gravitational wave of zero frequency. It is shown that there are no other solutions of this type than listed above and Minkowski's metrics. The list of vacuum metrics that depend on one coordinate is not complete without the solution provided in this paper.	gr-qc	2 pages
7	Phenotype selection due to mutational robustness	Macoto Kikuchi	The mutation-selection mechanism of Darwinian evolution gives rise not only to the adaptation to environmental conditions but also to the enhancement of the robustness against mutation. Suppose more than one phenotypes share the same fitness value. The robustness distribution should differ for different phenotypes. Thus, we expect that some phenotype is favored in evolution and some is hardly selected as a consequence of the selection bias for mutational robustness. In this paper, we investigated this selection bias on phenotypes for a model of gene regulatory networks (GRNs) by numerical simulations. The model we used exhibits three types of response to the change of input signal; monostable, toggle switch, and one-way switch. We regarded these three response types as three phenotypes. We constructed the randomly generated set of GRNs using the multicanonical Monte Carlo method and compared it to the outcomes of evolutionary simulations. The results suggest that the one-way switches were strongly suppressed in evolution because a majority of the one-way switches were not mutationally robust.	q-bio.PE	8 pages, 7 figures
8	On the minimal model of kinetic cooperativity. The case of glucokinase	Leonid Christophorov	"The minimal 3-state scheme of kinetic cooperativity of monomeric enzymes is subjected to detailed analysis. The rigorous criteria of positive cooperativity and its sigmoidal version are established in terms of the system parameters (rate constants). It is shown that the cooperativity extent is especially sensitive to the rates and direction of the exchange between conformational states of the free enzyme. However, no necessity of the ""kinetic resonance"" (or, moreover, its generality claimed recently) for enhancing cooperativity is revealed. Overall, while the minimal 3-state model serves well for qualitative understanding the origin of kinetic cooperativity, it is hardly suitable for quantitative describing reactions of real enzymes, as it is shown with the case of glucokinase."	physics.bio-ph	19 pages, 5 figures
9	Towards Assume-Guarantee Verification of Strategic Ability	≈Åukasz Mikulski,Wojciech Jamroga,Damian Kurpiewski	Formal verification of strategic abilities is a hard problem. We propose to use the methodology of assume-guarantee reasoning in order to facilitate model checking of alternating-time temporal logic with imperfect information and imperfect recall.	cs.LO	None
0	Query-adaptive DETR for Crowded Pedestrian Detection	Feng Gao,Jiaxu Leng,Ji Gan,Xinbo Gao	DEtection TRansformer (DETR) and its variants (DETRs) have been successfully applied to crowded pedestrian detection, which achieved promising performance. However, we find that, in different degrees of crowded scenes, the number of DETRs' queries must be adjusted manually, otherwise, the performance would degrade to varying degrees. In this paper, we first analyze the two current query generation methods and summarize four guidelines for designing the adaptive query generation method. Then, we propose Rank-based Adaptive Query Generation (RAQG) to alleviate the problem. Specifically, we design a rank prediction head that can predict the rank of the lowest confidence positive training sample produced by the encoder. Based on the predicted rank, we design an adaptive selection method that can adaptively select coarse detection results produced by the encoder to generate queries. Moreover, to train the rank prediction head better, we propose Soft Gradient L1 Loss. The gradient of Soft Gradient L1 Loss is continuous, which can describe the relationship between the loss value and the updated value of model parameters granularly. Our method is simple and effective, which can be plugged into any DETRs to make it query-adaptive in theory. The experimental results on Crowdhuman dataset and Citypersons dataset show that our method can adaptively generate queries for DETRs and achieve competitive results. Especially, our method achieves state-of-the-art 39.4% MR on Crowdhuman dataset.	cs.CV	10 pages, 6 figures
1	Variator: Accelerating Pre-trained Models with Plug-and-Play Compression Modules	Chaojun Xiao,Yuqi Luo,Wenbin Zhang,Pengle Zhang,Xu Han,Yankai Lin,Zhengyan Zhang,Ruobing Xie,Zhiyuan Liu,Maosong Sun,Jie Zhou	Pre-trained language models (PLMs) have achieved remarkable results on NLP tasks but at the expense of huge parameter sizes and the consequent computational costs. In this paper, we propose Variator, a parameter-efficient acceleration method that enhances computational efficiency through plug-and-play compression plugins. Compression plugins are designed to reduce the sequence length via compressing multiple hidden vectors into one and trained with original PLMs frozen. Different from traditional model acceleration methods, which compress PLMs to smaller sizes, Variator offers two distinct advantages: (1) In real-world applications, the plug-and-play nature of our compression plugins enables dynamic selection of different compression plugins with varying acceleration ratios based on the current workload. (2) The compression plugin comprises a few compact neural network layers with minimal parameters, significantly saving storage and memory overhead, particularly in scenarios with a growing number of tasks. We validate the effectiveness of Variator on seven datasets. Experimental results show that Variator can save 53% computational costs using only 0.9% additional parameters with a performance drop of less than 2%. Moreover, when the model scales to billions of parameters, Variator matches the strong performance of uncompressed PLMs.	cs.CL	Accepted by Findings of EMNLP
2	Data Processing Engine (DPE): Data Analysis Tool for Particle Tracking and Mixed Radiation Field Characterization with Pixel Detectors Timepix	Marek Lukas,Granja Carlos,Jakubek Jan,Ingerle Jan,Turecek Daniel,Vuolo Marco,Oancea Cristina	"Hybrid semiconductor pixelated detectors from the Timepix family are advanced detectors for online particle tracking, offering energy measurement and precise time stamping capabilities for particles of various types and energies. This inherent capability makes them highly suitable for various applications, including imaging, medical fields such as radiotherapy and particle therapy, space-based applications aboard satellites and the International Space Station, and industrial applications. The data generated by these detectors is complex, necessitating the development and deployment of various analytical techniques to extract essential information. For this purpose, and to aid the Timepix user community, it was designed and developed the ""Data Processing Engine"" (DPE) as an advanced tool for data processing designed explicitly for Timepix detectors. The functionality of the DPE is structured into three distinct processing levels: i) Pre-processing: This phase involves clusterization and the application of necessary calibrations and corrections. ii) Processing: This stage includes particle classification, employing machine learning algorithms, and the recognition of radiation fields. iii) Post-processing: Involves various analyses, such as directional analysis, coincidence analysis, frame analysis, Compton directional analysis, and the generation of physics products, are performed. The core of the DPE is supported by an extensive experimental database containing calibrations and referential radiation fields of typical environments, including protons, ions, electrons, gamma rays and X-rays, as well as thermal and fast neutrons. To enhance accessibility, the DPE is implemented into various user interface platforms such as a command-line tool, an application programming interface, and as a graphical user interface in the form of a web portal."	physics.med-ph	9 pages, proceedings IWORID
3	Re-Temp: Relation-Aware Temporal Representation Learning for Temporal Knowledge Graph Completion	Kunze Wang,Soyeon Caren Han,Josiah Poon	Temporal Knowledge Graph Completion (TKGC) under the extrapolation setting aims to predict the missing entity from a fact in the future, posing a challenge that aligns more closely with real-world prediction problems. Existing research mostly encodes entities and relations using sequential graph neural networks applied to recent snapshots. However, these approaches tend to overlook the ability to skip irrelevant snapshots according to entity-related relations in the query and disregard the importance of explicit temporal information. To address this, we propose our model, Re-Temp (Relation-Aware Temporal Representation Learning), which leverages explicit temporal embedding as input and incorporates skip information flow after each timestamp to skip unnecessary information for prediction. Additionally, we introduce a two-phase forward propagation method to prevent information leakage. Through the evaluation on six TKGC (extrapolation) datasets, we demonstrate that our model outperforms all eight recent state-of-the-art models by a significant margin.	cs.CL	Findings of EMNLP 2023
4	An interpolation between Special Linear and General Algebraic cobordism $\text{MSL}$ and $\text{MGL}$	Ahina Nandy	We prove an interpolation between special linear algebraic cobordism $\text{MSL}$ and algebraic cobordism $\text{MGL}$ in stable motivic homotopy category over any Noetherian base scheme of finite Krull dimension. It generalizes a classical relation between special unitary and complex cobordism $\text{MSU}$ and $\text{MU}$ in classical stable homotopy theory.	math.AT	Comments welcome
5	Ensemble of Task-Specific Language Models for Brain Encoding	Sanjai Kumaran,Arvindh Arun,Jerrin John	Language models have been shown to be rich enough to encode fMRI activations of certain Regions of Interest in our Brains. Previous works have explored transfer learning from representations learned for popular natural language processing tasks for predicting brain responses. In our work, we improve the performance of such encoders by creating an ensemble model out of 10 popular Language Models (2 syntactic and 8 semantic). We beat the current baselines by 10% on average across all ROIs through our ensembling methods.	cs.CL	None
6	A Phase-Field Discrete Element Method to study chemo-mechanical coupling in granular materials	Alexandre Sac--Morane,Manolis Veveakis,Hadrien Rattez	This paper presents an extension of the discrete element method using a phase-field formulation to incorporate grain shape and its evolution. The introduction of a phase variable enables an effective representation of grain geometry and facilitates the application of physical laws, such as chemo-mechanical couplings, for modeling shape changes. These physical laws are solved numerically using the finite element method coupled in a staggered scheme to the discrete element model. The efficacy of the proposed Phase-Field Discrete Element Model (PFDEM) is demonstrated through its ability to accurately capture the real grain shape in a material subjected to dissolution only and compute the stress evolution. It is then applied to model the phenomenon of pressure solution involving dissolution and precipitation in granular materials at the microscale and enables to reproduce the creep response observed experimentally. This framework contributes to the enhanced understanding and simulation of complex behaviors in granular materials and sedimentary rocks for many geological processes like diagenesis or earthquake nucleation.	cond-mat.mtrl-sci	68 pages, 37 figures, 5 tables
7	Visible Lagrangians for Hitchin systems and pillowcase covers	Johannes Horn,Johannes Schwab	We study complex Lagrangians in Hitchin systems that factor through a proper subvariety of the Hitchin base non-trivially intersecting the regular locus. This gives a general framework for several examples in the literature. We compute the fiber-wise Fourier-Mukai transform of flat line bundles on visible Lagrangians. This proposes a construction of mirror dual branes to visible Lagrangians. Finally, we study a new example of visible Lagrangians in detail. Such visible Lagrangian exists whenever the underlying Riemann surface is a pillowcase cover. The proposed mirror dual brane turns out to be closely related to Hausel's toy model.	math.AG	24 pages, 5 figure, Comments are welcome!
8	A Review of $Œº\to eee$, $Œº\to eŒ≥$ and $ŒºN\to eN$ Conversion	Ann-Kathrin Perrevoort	The observation of lepton flavour violation (LFV) in interactions involving charged leptons would be an unambiguous sign of physics beyond the Standard Model of particle physics. Given that muons can be produced at high intensities, searches for LFV with muons are particularly sensitive.   In a global initiative, ongoing and upcoming experiments are aiming to discover physics beyond the Standard Model in the three golden muon LFV channels: $\mu\to e\gamma$, $\mu\to eee$ and $\mu$-to-$e$ conversion on nuclei. With innovative detector concepts and new muon beam lines, these experiments will be able to investigate muon LFV in the coming years with sensitivities improved by up to four orders of magnitude compared to past searches.   The current status of muon LFV searches is discussed and the ongoing MEG II and DeeMe experiments as well as the upcoming Mu2e, COMET and Mu3e experiments are presented.	hep-ex	14 pages, 12 figures, proceedings of the 21st Conference on Flavor   Physics and CP Violation (FPCP 2023)
9	GNeSF: Generalizable Neural Semantic Fields	Hanlin Chen,Chen Li,Mengqi Guo,Zhiwen Yan,Gim Hee Lee	3D scene segmentation based on neural implicit representation has emerged recently with the advantage of training only on 2D supervision. However, existing approaches still requires expensive per-scene optimization that prohibits generalization to novel scenes during inference. To circumvent this problem, we introduce a generalizable 3D segmentation framework based on implicit representation. Specifically, our framework takes in multi-view image features and semantic maps as the inputs instead of only spatial information to avoid overfitting to scene-specific geometric and semantic information. We propose a novel soft voting mechanism to aggregate the 2D semantic information from different views for each 3D point. In addition to the image features, view difference information is also encoded in our framework to predict the voting scores. Intuitively, this allows the semantic information from nearby views to contribute more compared to distant ones. Furthermore, a visibility module is also designed to detect and filter out detrimental information from occluded views. Due to the generalizability of our proposed method, we can synthesize semantic maps or conduct 3D semantic segmentation for novel scenes with solely 2D semantic supervision. Experimental results show that our approach achieves comparable performance with scene-specific approaches. More importantly, our approach can even outperform existing strong supervision-based approaches with only 2D annotations. Our source code is available at: https://github.com/HLinChen/GNeSF.	cs.CV	NeurPIS 2023
0	Causal Representation Learning Made Identifiable by Grouping of Observational Variables	Hiroshi Morioka,Aapo Hyv√§rinen	A topic of great current interest is Causal Representation Learning (CRL), whose goal is to learn a causal model for hidden features in a data-driven manner. Unfortunately, CRL is severely ill-posed since it is a combination of the two notoriously ill-posed problems of representation learning and causal discovery. Yet, finding practical identifiability conditions that guarantee a unique solution is crucial for its practical applicability. Most approaches so far have been based on assumptions on the latent causal mechanisms, such as temporal causality, or existence of supervision or interventions; these can be too restrictive in actual applications. Here, we show identifiability based on novel, weak constraints, which requires no temporal structure, intervention, nor weak supervision. The approach is based assuming the observational mixing exhibits a suitable grouping of the observational variables. We also propose a novel self-supervised estimation framework consistent with the model, prove its statistical consistency, and experimentally show its superior CRL performances compared to the state-of-the-art baselines. We further demonstrate its robustness against latent confounders and causal cycles.	stat.ML	None
1	Solving large flexible job shop scheduling instances by generating a diverse set of scheduling policies with deep reinforcement learning	Imanol Echeverria,Maialen Murua,Roberto Santana	The Flexible Job Shop Scheduling Problem (FJSSP) has been extensively studied in the literature, and multiple approaches have been proposed within the heuristic, exact, and metaheuristic methods. However, the industry's demand to be able to respond in real-time to disruptive events has generated the necessity to be able to generate new schedules within a few seconds. Among these methods, under this constraint, only dispatching rules (DRs) are capable of generating schedules, even though their quality can be improved. To improve the results, recent methods have been proposed for modeling the FJSSP as a Markov Decision Process (MDP) and employing reinforcement learning to create a policy that generates an optimal solution assigning operations to machines. Nonetheless, there is still room for improvement, particularly in the larger FJSSP instances which are common in real-world scenarios. Therefore, the objective of this paper is to propose a method capable of robustly solving large instances of the FJSSP. To achieve this, we propose a novel way of modeling the FJSSP as an MDP using graph neural networks. We also present two methods to make inference more robust: generating a diverse set of scheduling policies that can be parallelized and limiting them using DRs. We have tested our approach on synthetically generated instances and various public benchmarks and found that our approach outperforms dispatching rules and achieves better results than three other recent deep reinforcement learning methods on larger FJSSP instances.	cs.AI	None
2	Learning-based Scheduling for Information Accuracy and Freshness in Wireless Networks	Hitesh Gudwani	We consider a system of multiple sources, a single communication channel, and a single monitoring station. Each source measures a time-varying quantity with varying levels of accuracy and one of them sends its update to the monitoring station via the channel. The probability of success of each attempted communication is a function of the source scheduled for transmitting its update. Both the probability of correct measurement and the probability of successful transmission of all the sources are unknown to the scheduler. The metric of interest is the reward received by the system which depends on the accuracy of the last update received by the destination and the Age-of-Information (AoI) of the system. We model our scheduling problem as a variant of the multi-arm bandit problem with sources as different arms. We compare the performance of all $4$ standard bandit policies, namely, ETC, $\epsilon$-greedy, UCB, and TS suitably adjusted to our system model via simulations. In addition, we provide analytical guarantees of $2$ of these policies, ETC, and $\epsilon$-greedy. Finally, we characterize the lower bound on the cumulative regret achievable by any policy.	cs.AI	21 pages, 5 figures
3	Enhancing Biomedical Lay Summarisation with External Knowledge Graphs	Tomas Goldsack,Zhihao Zhang,Chen Tang,Carolina Scarton,Chenghua Lin	Previous approaches for automatic lay summarisation are exclusively reliant on the source article that, given it is written for a technical audience (e.g., researchers), is unlikely to explicitly define all technical concepts or state all of the background information that is relevant for a lay audience. We address this issue by augmenting eLife, an existing biomedical lay summarisation dataset, with article-specific knowledge graphs, each containing detailed information on relevant biomedical concepts. Using both automatic and human evaluations, we systematically investigate the effectiveness of three different approaches for incorporating knowledge graphs within lay summarisation models, with each method targeting a distinct area of the encoder-decoder model architecture. Our results confirm that integrating graph-based domain knowledge can significantly benefit lay summarisation by substantially increasing the readability of generated text and improving the explanation of technical concepts.	cs.CL	Accepted to the EMNLP 2023 main conference
4	Compatible Relative Lefschetz Fibrations On Admissible Relative Stein Pairs	Yasemin Yildirim,M. Firat Arikan	For more than two decades it has been known that any compact Stein surface (of real dimension four) admits a compatible Lefschetz fibration over a two-disk. More recently, Giroux and Pardon have generalized this result by giving a complex geometric proof for the existence of compatible Lefschetz fibrations on Stein domains of any even dimension. As a preparatory step in proving the former, Akbulut and Ozbagci have shown that there exist infinitely many pairwise non-equivalent Lefschetz fibrations on the four-ball by using a result of Lyon constructing fibrations on the complements of (p,q)-torus links in the three-sphere. In this paper, we first extend this result to obtain compatible Lefschetz fibrations on the six-ball whose pages are (p, q, 2)-Brieskorn varieties, and then construct a compatible 'relative' Lefschetz fibrations on any Stein domain (of dimension six) which admit a certain ('admissible') 'relative Stein pair' structure. In particular, we provide a purely topological proof for the existence of Lefschetz fibrations on specific 6-dimensional Stein domains.	math.GT	20 pages, 10 figures
5	DACOOP-A: Decentralized Adaptive Cooperative Pursuit via Attention	Zheng Zhang,Dengyu Zhan,Qingrui Zhang,Wei Pan,Tianjiang Hu	Integrating rule-based policies into reinforcement learning promises to improve data efficiency and generalization in cooperative pursuit problems. However, most implementations do not properly distinguish the influence of neighboring robots in observation embedding or inter-robot interaction rules, leading to information loss and inefficient cooperation. This paper proposes a cooperative pursuit algorithm named Decentralized Adaptive COOperative Pursuit via Attention (DACOOP-A) by empowering reinforcement learning with artificial potential field and attention mechanisms. An attention-based framework is developed to emphasize important neighbors by concurrently integrating the learned attention scores into observation embedding and inter-robot interaction rules. A KL divergence regularization is introduced to alleviate the resultant learning stability issue. Improvements in data efficiency and generalization are demonstrated through numerical simulations. Extensive quantitative analysis and ablation studies are performed to illustrate the advantages of the proposed modules. Real-world experiments are performed to justify the feasibility of deploying DACOOP-A in physical systems.	cs.RO	8 Pages; This manuscript has been accepted by IEEE Robotics and   Automation Letters
6	Correlation functions for open strings and chaos	Vladan Djukiƒá,Mihailo ƒåubroviƒá	We study the holographic interpretation of the bulk instability, i.e. the bulk Lyapunov exponent in the motion of open classical bosonic strings in AdS black hole/brane backgrounds. In the vicinity of homogeneous and isotropic horizons the bulk Lyapunov exponent saturates the MSS chaos bound but in fact has nothing to do with chaos as our string configurations live in an integrable sector. In the D1-D5-p black string background, the bulk Lyapunov exponent is deformed away from the MSS value both by the rotation (the infrared deformation) and the existence of an asympotically flat region (the ultraviolet deformation). The dynamics is still integrable and again has nothing to do with chaos (either in gravity or in field theory). Instead, the bulk Lyapunov scale exactly captures the values of the quasinormal mode frequencies. Therefore, the meaning of the bulk chaos is that it determines the thermal decay rate due to the coupling to the heat bath, i.e. the horizon.	hep-th	29 pages, 3 figures
7	Lie minimal Weingarten surfaces	Joseph Cho,Masaya Hara,Denis Polly,Tomohiro Tada	We consider Lie minimal surfaces, the critical points of the simplest Lie sphere invariant energy, in Riemannian space forms. These surfaces can be characterized via their Euler-Lagrange equations, which take the form of differential equations of the principal curvatures. Surfaces with constant mean curvature that satisfy these equations turn out to be rotational in their space form. We generalize in flat ambient space: here surfaces where the principal curvatures satisfy an affine relationship as well as elliptic linear Weingarten surfaces are rotational as well.	math.DG	11 pages
8	COPF: Continual Learning Human Preference through Optimal Policy Fitting	Han Zhang,Lin Gui,Yuanzhao Zhai,Hui Wang,Yu Lei,Ruifeng Xu	The technique of Reinforcement Learning from Human Feedback (RLHF) is a commonly employed method to improve pre-trained Language Models (LM), enhancing their ability to conform to human preferences. Nevertheless, the current RLHF-based LMs necessitate full retraining each time novel queries or feedback are introduced, which becomes a challenging task because human preferences can vary between different domains or tasks. Retraining LMs poses practical difficulties in many real-world situations due to the significant time and computational resources required, along with concerns related to data privacy. To address this limitation, we propose a new method called Continual Optimal Policy Fitting (COPF), in which we estimate a series of optimal policies using the Monte Carlo method, and then continually fit the policy sequence with the function regularization. COPF involves a single learning phase and doesn't necessitate complex reinforcement learning. Importantly, it shares the capability with RLHF to learn from unlabeled data, making it flexible for continual preference learning. Our experimental results show that COPF outperforms strong Continuous learning (CL) baselines when it comes to consistently aligning with human preferences on different tasks and domains.	cs.LG	None
9	Towards Automated Recipe Genre Classification using Semi-Supervised Learning	Nazmus Sakib,G. M. Shahariar,Md. Mohsinul Kabir,Md. Kamrul Hasan,Hasan Mahmud	"Sharing cooking recipes is a great way to exchange culinary ideas and provide instructions for food preparation. However, categorizing raw recipes found online into appropriate food genres can be challenging due to a lack of adequate labeled data. In this study, we present a dataset named the ``Assorted, Archetypal, and Annotated Two Million Extended (3A2M+) Cooking Recipe Dataset"" that contains two million culinary recipes labeled in respective categories with extended named entities extracted from recipe descriptions. This collection of data includes various features such as title, NER, directions, and extended NER, as well as nine different labels representing genres including bakery, drinks, non-veg, vegetables, fast food, cereals, meals, sides, and fusions. The proposed pipeline named 3A2M+ extends the size of the Named Entity Recognition (NER) list to address missing named entities like heat, time or process from the recipe directions using two NER extraction tools. 3A2M+ dataset provides a comprehensive solution to the various challenging recipe-related tasks, including classification, named entity recognition, and recipe generation. Furthermore, we have demonstrated traditional machine learning, deep learning and pre-trained language models to classify the recipes into their corresponding genre and achieved an overall accuracy of 98.6\%. Our investigation indicates that the title feature played a more significant role in classifying the genre."	cs.CL	None
0	$L^2$-estimates for the Dirac-Dolbeault operator and Bergman kernel asymptotics on some classes of non-compact complex manifolds	Ming-Yuan Chang	For high power $k$, the $L^2$-estimates for the Dirac-Dolbeault operator with coefficient $L^k\otimes E$ can be obtained from the Bochner-Kodaira-Nakano identity if $L$ has positive curvature. In this article, we generalize the classical method to obtain $L^2$-estimates for mixed curvature case, and give a bound to the extra error term. Modifying the $L^2$-estimates and existence theorems for $\bar{\partial}$-operator, we can get a local spectral gap of the Kodaira Laplacian $\Box$ and thus a full asymptotic expansion for Bergman kernel.	math.CV	None
1	Creating a silver standard for patent simplification	Silvia Casola,Alberto Lavelli,Horacio Saggion	Patents are legal documents that aim at protecting inventions on the one hand and at making technical knowledge circulate on the other. Their complex style -- a mix of legal, technical, and extremely vague language -- makes their content hard to access for humans and machines and poses substantial challenges to the information retrieval community. This paper proposes an approach to automatically simplify patent text through rephrasing. Since no in-domain parallel simplification data exist, we propose a method to automatically generate a large-scale silver standard for patent sentences. To obtain candidates, we use a general-domain paraphrasing system; however, the process is error-prone and difficult to control. Thus, we pair it with proper filters and construct a cleaner corpus that can successfully be used to train a simplification system. Human evaluation of the synthetic silver corpus shows that it is considered grammatical, adequate, and contains simple sentences.	cs.CL	This paper has been published at SIGIR 2023
2	Nighttime Thermal Infrared Image Colorization with Feedback-based Object Appearance Learning	Fu-Ya Luo,Shu-Lin Liu,Yi-Jun Cao,Kai-Fu Yang,Chang-Yong Xie,Yong Liu,Yong-Jie Li	Stable imaging in adverse environments (e.g., total darkness) makes thermal infrared (TIR) cameras a prevalent option for night scene perception. However, the low contrast and lack of chromaticity of TIR images are detrimental to human interpretation and subsequent deployment of RGB-based vision algorithms. Therefore, it makes sense to colorize the nighttime TIR images by translating them into the corresponding daytime color images (NTIR2DC). Despite the impressive progress made in the NTIR2DC task, how to improve the translation performance of small object classes is under-explored. To address this problem, we propose a generative adversarial network incorporating feedback-based object appearance learning (FoalGAN). Specifically, an occlusion-aware mixup module and corresponding appearance consistency loss are proposed to reduce the context dependence of object translation. As a representative example of small objects in nighttime street scenes, we illustrate how to enhance the realism of traffic light by designing a traffic light appearance loss. To further improve the appearance learning of small objects, we devise a dual feedback learning strategy to selectively adjust the learning frequency of different samples. In addition, we provide pixel-level annotation for a subset of the Brno dataset, which can facilitate the research of NTIR image understanding under multiple weather conditions. Extensive experiments illustrate that the proposed FoalGAN is not only effective for appearance learning of small objects, but also outperforms other image translation methods in terms of semantic preservation and edge consistency for the NTIR2DC task.	cs.CV	14 pages, 14 figures. arXiv admin note: text overlap with   arXiv:2208.02960
3	Reducing residential emissions: carbon pricing vs. subsidizing retrofits	Alkis Blanz,Beatriz Gaitan	In this paper, we compare different mitigation policies when housing investments are irreversible. We use a general equilibrium model with non-homothetic preferences and an elaborate setup of the residential housing and energy production sector. In the first-best transition, the energy demand plays only a secondary role. However, this changes when optimal carbon taxes are not available. While providing subsidies for retrofits results in the lowest direct costs for households, it ultimately leads to the highest aggregate costs and proves to be an ineffective way to decarbonize the economy. In the second-best context, a phased-in carbon price outperforms the subsidy-based transition.	econ.GN	None
4	Assume-Guarantee Verification of Strategic Ability	≈Åukasz Mikulski,Wojciech Jamroga,Damian Kurpiewski	Model checking of strategic abilities is a notoriously hard problem, even more so in the realistic case of agents with imperfect information. Assume-guarantee reasoning can be of great help here, providing a way to decompose the complex problem into a small set of exponentially easier subproblems. In this paper, we propose two schemes for assume-guarantee verification of alternating-time temporal logic with imperfect information. We prove the soundness of both schemes, and discuss their completeness. We illustrate the method by examples based on known benchmarks, and show experimental results that demonstrate the practical benefits of the approach.	cs.MA	None
5	Improving Biomedical Abstractive Summarisation with Knowledge Aggregation from Citation Papers	Chen Tang,Shun Wang,Tomas Goldsack,Chenghua Lin	Abstracts derived from biomedical literature possess distinct domain-specific characteristics, including specialised writing styles and biomedical terminologies, which necessitate a deep understanding of the related literature. As a result, existing language models struggle to generate technical summaries that are on par with those produced by biomedical experts, given the absence of domain-specific background knowledge. This paper aims to enhance the performance of language models in biomedical abstractive summarisation by aggregating knowledge from external papers cited within the source article. We propose a novel attention-based citation aggregation model that integrates domain-specific knowledge from citation papers, allowing neural networks to generate summaries by leveraging both the paper content and relevant knowledge from citation papers. Furthermore, we construct and release a large-scale biomedical summarisation dataset that serves as a foundation for our research. Extensive experiments demonstrate that our model outperforms state-of-the-art approaches and achieves substantial improvements in abstractive biomedical text summarisation.	cs.CL	Accepted by EMNLP 2023
6	Prevalence and prevention of large language model use in crowd work	Veniamin Veselovsky,Manoel Horta Ribeiro,Philip Cozzolino,Andrew Gordon,David Rothschild,Robert West	We show that the use of large language models (LLMs) is prevalent among crowd workers, and that targeted mitigation strategies can significantly reduce, but not eliminate, LLM use. On a text summarization task where workers were not directed in any way regarding their LLM use, the estimated prevalence of LLM use was around 30%, but was reduced by about half by asking workers to not use LLMs and by raising the cost of using them, e.g., by disabling copy-pasting. Secondary analyses give further insight into LLM use and its prevention: LLM use yields high-quality but homogeneous responses, which may harm research concerned with human (rather than model) behavior and degrade future models trained with crowdsourced data. At the same time, preventing LLM use may be at odds with obtaining high-quality responses; e.g., when requesting workers not to use LLMs, summaries contained fewer keywords carrying essential information. Our estimates will likely change as LLMs increase in popularity or capabilities, and as norms around their usage change. Yet, understanding the co-evolution of LLM-based tools and users is key to maintaining the validity of research done using crowdsourcing, and we provide a critical baseline before widespread adoption ensues.	cs.CL	VV and MHR equal contribution. 14 pages, 1 figure, 1 table
7	Singlet fission spin dynamics from molecular structure: a modular computational pipeline	Dominic Jones,Thomas MacDonald,Timothy W. Schmidt,Dane R. McCamey	Singlet fission, which has applications in areas ranging form solar energy to quantum information, relies critically on transitions within a multi-spin manifold. These transitions are driven by fluctuations in the spin-spin exchange interaction, which have been linked to changes in nuclear geometry or exciton migration. Whilst simple calculations have supported this mechanism, to date little effort has been made to model realistic fluctuations which are informed by the actual structure and properties of physical materials. In this paper, we develop a modular computational pipeline for calculating singlet fission spin dynamics by way of electronic structural calculations, molecular dynamics, and numerical models of spin dynamics. The outputs of this pipeline aid in the interpretation of measured spin dynamics and allow us to place constraints on geometric fluctuations which are consistent with these observations.	physics.chem-ph	23 pages (including SI), 7 Figures
8	Quantumness near a Schwarzschild black hole	S. Haddadi,M. A. Yurischev,M. Y. Abd-Rabbou,M. Azizi,M. R. Pourkarimi,M. Ghominejad	The merging of quantum information science with the relativity theory presents novel opportunities for understanding the enigmas surrounding the transmission of information in relation to black holes. For this purpose, we study the quantumness near a Schwarzschild black hole in a practical model under decoherence. The scenario we consider in this paper is that a stationary particle in the flat region interacts with its surroundings while another particle experiences free fall in the vicinity of a Schwarzschild black hole's event horizon. We explore the impacts of Hawking radiation and decoherence on the system under investigation and find that these effects can limit the survival of quantum characteristics, but cannot destroy them completely. Hence, the results of this study possess the potential to yield valuable insights into the comprehension of the quantum properties of a real system operating within a curved space-time framework.	gr-qc	13 pages, 9 figures. All comments are welcome
9	IceCube -- Neutrinos in Deep Ice The Top 3 Solutions from the Public Kaggle Competition	Habib Bukhari,Dipam Chakraborty,Philipp Eller,Takuya Ito,Maxim V. Shugaev,Rasmus √òrs√∏e	"During the public Kaggle competition ""IceCube -- Neutrinos in Deep Ice"", thousands of reconstruction algorithms were created and submitted, aiming to estimate the direction of neutrino events recorded by the IceCube detector. Here we describe in detail the three ultimate best, award-winning solutions. The data handling, architecture, and training process of each of these machine learning models is laid out, followed up by an in-depth comparison of the performance on the kaggle datatset. We show that on cascade events in IceCube above 10 TeV, the best kaggle solution is able to achieve an angular resolution of better than 5 degrees, and for tracks correspondingly better than 0.5 degrees. These performance measures compare favourably to the current state-of-the-art in the field."	astro-ph.HE	None
0	The Tully-Fisher relation and the Bosma effect	Francesco Sylos Labini,Giordano De Marzo,Matteo Straccamore,S√©bastien Comer√≥n	We show that the rotation curves of 16 nearby disc galaxies in the THINGS sample and the Milky Way can be described by the NFW halo model and by the Bosma effect at approximately the same level of accuracy. The latter effect suggests that the behavior of the rotation curve at large radii is determined by the rescaled gas component and thus that dark matter and gas distributions are tightly correlated. By focusing on galaxies with exponential decay in their gas surface density, we can normalize their rotation curves to match the exponential thin disc model at large enough radii. This normalization assumes that the galaxy mass is estimated consistently within this model, assuming a thin disc structure. We show that this rescaling allows us to derive a new version of the Tully-Fisher (TF) relation, the Bosma TF relation that nicely fit the data. In the framework of this model, the connection between the Bosma Tully-Fisher (TF) relation and the baryonic TF relation can be established by considering an additional empirical relation between the baryonic mass and the total mass of the disc, as measured in the data.	astro-ph.GA	21 pages, 12 figures. Monthly Notices of the Royal Astronomical   Society, in the press
1	How Much Context Does My Attention-Based ASR System Need?	Robert Flynn,Anton Ragni	For the task of speech recognition, the use of more than 30 seconds of acoustic context during training is uncommon, and under-investigated in literature. In this work, we examine the effect of scaling the sequence length used to train/evaluate (dense-attention based) acoustic and language models on speech recognition performance. For these experiments a dataset of roughly 100,000 pseudo-labelled Spotify podcasts is used, with context lengths of 5 seconds to 1 hour being explored. Zero-shot evaluations on long-format datasets Earnings-22 and Tedlium demonstrate a benefit from training with around 80 seconds of acoustic context, showing up to a 14.9% relative improvement from a limited context baseline. Furthermore, we perform a system combination with long-context transformer language models via beam search for a fully long-context ASR system, with results that are competitive with the current state-of-the-art.	cs.CL	None
2	Quality flags for GSP-Phot Gaia DR3 astrophysical parameters with machine learning: Effective temperatures case study	Aleksandra S. Avdeeva,Dana A. Kovaleva,Oleg Yu. Malkov,Gang Zhao	Gaia Data Release 3 (DR3) includes extensive information on the astrophysical properties of stars, such as effective temperature, surface gravity, metallicity, and luminosity, for over 470 million objects. However, as Gaia's stellar parameters in GSP-Phot module are derived through model-dependent methods and indirect measurements, it can lead to additional systematic errors in the derived parameters. Here we compare GSP-Phot effective temperature estimates with two high-resolution and high signal-to-noise spectroscopic catalogues, specifically, APOGEE DR17 and GALAH DR3 to assess Gaia's temperatures reliability. We develop an approach to distinguish good-quality Gaia DR3 effective temperatures using machine-learning methods such as XGBoost, CatBoost and LightGBM. The models create quality flags, which can help one to distinguish good-quality GSP-Phot effective temperatures. We test our models on three independent datasets, including PASTEL, a compilation of spectroscopically derived stellar parameters from different high-resolution studies. The results of the test suggest that with these models it is possible to filter effective temperatures as accurate as 250~K with $\sim 90$ per cent precision even in complex regions, such as the Galactic plane. Consequently, the models developed herein offer a valuable quality assessment tool for GSP-Phot effective temperatures in Gaia DR3. The dataset with flags for all GSP-Phot effective temperature estimates is publicly available as well as the models themselves.	astro-ph.SR	On the revision in MNRAS
3	Leveraging Vision-Centric Multi-Modal Expertise for 3D Object Detection	Linyan Huang,Zhiqi Li,Chonghao Sima,Wenhai Wang,Jingdong Wang,Yu Qiao,Hongyang Li	Current research is primarily dedicated to advancing the accuracy of camera-only 3D object detectors (apprentice) through the knowledge transferred from LiDAR- or multi-modal-based counterparts (expert). However, the presence of the domain gap between LiDAR and camera features, coupled with the inherent incompatibility in temporal fusion, significantly hinders the effectiveness of distillation-based enhancements for apprentices. Motivated by the success of uni-modal distillation, an apprentice-friendly expert model would predominantly rely on camera features, while still achieving comparable performance to multi-modal models. To this end, we introduce VCD, a framework to improve the camera-only apprentice model, including an apprentice-friendly multi-modal expert and temporal-fusion-friendly distillation supervision. The multi-modal expert VCD-E adopts an identical structure as that of the camera-only apprentice in order to alleviate the feature disparity, and leverages LiDAR input as a depth prior to reconstruct the 3D scene, achieving the performance on par with other heterogeneous multi-modal experts. Additionally, a fine-grained trajectory-based distillation module is introduced with the purpose of individually rectifying the motion misalignment for each object in the scene. With those improvements, our camera-only apprentice VCD-A sets new state-of-the-art on nuScenes with a score of 63.1% NDS.	cs.CV	Accepted by NeurIPS 2023
4	Robust Methods for Multiscale Coarse Approximations of Diffusion Models in Perforated Domains	Miranda Boutilier,Konstantin Brenner,Victorita Dolean	For the Poisson equation posed in a domain containing a large number of polygonal perforations, we propose a low-dimensional coarse approximation space based on a coarse polygonal partitioning of the domain. Similarly to other multiscale numerical methods, this coarse space is spanned by locally discrete harmonic basis functions. Along the subdomain boundaries, the basis functions are piecewise polynomial. The main contribution of this article is an error estimate regarding the H1-projection over the coarse space which depends only on the regularity of the solution over the edges of the coarse partitioning. For a specific edge refinement procedure, the error analysis establishes superconvergence of the method even if the true solution has a low general regularity. Combined with domain decomposition (DD) methods, the coarse space leads to an efficient two-level iterative linear solver which reaches the fine-scale finite element error in few iterations. It also bodes well as a preconditioner for Krylov methods and provides scalability with respect to the number of subdomains. Numerical experiments showcase the increased precision of the coarse approximation as well as the efficiency and scalability of the coarse space as a component of a DD algorithm.	math.NA	32 pages, 14 figures, submitted to Journal of Computational Physics
5	Rotational Response Induced by Electric Toroidal Dipole	Akimitsu Kirikoshi,Satoru Hayami	A ferroaxial ordering, which appears without mirror symmetry parallel to an electric axial moment, is described by a ferroic alignment of the electric toroidal (ET) dipole rather than the conventional electric and magnetic dipoles. Although its emergence requires neither spatial inversion nor time-reversal symmetry breakings, unconventional transverse responses between the conjugate physical quantities have been proposed, which are qualitatively different from those in multiferroic systems without both spatial inversion and time-reversal symmetries. We theoretically investigate a general relationship between ferroaxial ordering and its characteristic response tensor. We show that various rotational responses corresponding to an antisymmetric tensor component are related to the ferroaxial ordering based on symmetry analysis. Among them, we propose that second-order nonlinear magnetostriction, where the strain is induced by a second-order magnetic field, is one of the experimental setups to identify the ferroaxial ordering. We show its temperature and magnetic-field-angle dependence by analyzing a fundamental $d$-orbital model under the tetragonal symmetry.	cond-mat.str-el	5 pages, 4 figures, 2 tables
6	Expression Syntax Information Bottleneck for Math Word Problems	Jing Xiong,Chengming Li,Min Yang,Xiping Hu,Bin Hu	Math Word Problems (MWP) aims to automatically solve mathematical questions given in texts. Previous studies tend to design complex models to capture additional information in the original text so as to enable the model to gain more comprehensive features. In this paper, we turn our attention in the opposite direction, and work on how to discard redundant features containing spurious correlations for MWP. To this end, we design an Expression Syntax Information Bottleneck method for MWP (called ESIB) based on variational information bottleneck, which extracts essential features of expression syntax tree while filtering latent-specific redundancy containing syntax-irrelevant features. The key idea of ESIB is to encourage multiple models to predict the same expression syntax tree for different problem representations of the same problem by mutual learning so as to capture consistent information of expression syntax tree and discard latent-specific redundancy. To improve the generalization ability of the model and generate more diverse expressions, we design a self-distillation loss to encourage the model to rely more on the expression syntax information in the latent space. Experimental results on two large-scale benchmarks show that our model not only achieves state-of-the-art results but also generates more diverse solutions. The code is available.	cs.CL	This paper has been accepted by SIGIR 2022. The code can be found at   https://github.com/menik1126/math_ESIB
7	FOLEY-VAE: Generaci√≥n de efectos de audio para cine con inteligencia artificial	Mateo C√°mara,Jos√© Luis Blanco	In this research, we present an interface based on Variational Autoencoders trained with a wide range of natural sounds for the innovative creation of Foley effects. The model can transfer new sound features to prerecorded audio or microphone-captured speech in real time. In addition, it allows interactive modification of latent variables, facilitating precise and customized artistic adjustments. Taking as a starting point our previous study on Variational Autoencoders presented at this same congress last year, we analyzed an existing implementation: RAVE [1]. This model has been specifically trained for audio effects production. Various audio effects have been successfully generated, ranging from electromagnetic, science fiction, and water sounds, among others published with this work. This innovative approach has been the basis for the artistic creation of the first Spanish short film with sound effects assisted by artificial intelligence. This milestone illustrates palpably the transformative potential of this technology in the film industry, opening the door to new possibilities for sound creation and the improvement of artistic quality in film productions.	eess.AS	9 pages, in Spanish, Tecniac\'ustica
8	Interactive Generalized Additive Model and Its Applications in Electric Load Forecasting	Linxiao Yang,Rui Ren,Xinyue Gu,Liang Sun	Electric load forecasting is an indispensable component of electric power system planning and management. Inaccurate load forecasting may lead to the threat of outages or a waste of energy. Accurate electric load forecasting is challenging when there is limited data or even no data, such as load forecasting in holiday, or under extreme weather conditions. As high-stakes decision-making usually follows after load forecasting, model interpretability is crucial for the adoption of forecasting models. In this paper, we propose an interactive GAM which is not only interpretable but also can incorporate specific domain knowledge in electric power industry for improved performance. This boosting-based GAM leverages piecewise linear functions and can be learned through our efficient algorithm. In both public benchmark and electricity datasets, our interactive GAM outperforms current state-of-the-art methods and demonstrates good generalization ability in the cases of extreme weather events. We launched a user-friendly web-based tool based on interactive GAM and already incorporated it into our eForecaster product, a unified AI platform for electricity forecasting.	cs.LG	None
9	Enhancing Traffic Prediction with Learnable Filter Module	Yuanshao Zhu,Yongchao Ye,Xiangyu Zhao,James J. Q. Yu	Modeling future traffic conditions often relies heavily on complex spatial-temporal neural networks to capture spatial and temporal correlations, which can overlook the inherent noise in the data. This noise, often manifesting as unexpected short-term peaks or drops in traffic observation, is typically caused by traffic accidents or inherent sensor vibration. In practice, such noise can be challenging to model due to its stochastic nature and can lead to overfitting risks if a neural network is designed to learn this behavior. To address this issue, we propose a learnable filter module to filter out noise in traffic data adaptively. This module leverages the Fourier transform to convert the data to the frequency domain, where noise is filtered based on its pattern. The denoised data is then recovered to the time domain using the inverse Fourier transform. Our approach focuses on enhancing the quality of the input data for traffic prediction models, which is a critical yet often overlooked aspect in the field. We demonstrate that the proposed module is lightweight, easy to integrate with existing models, and can significantly improve traffic prediction performance. Furthermore, we validate our approach with extensive experimental results on real-world datasets, showing that it effectively mitigates noise and enhances prediction accuracy.	cs.LG	None
0	X-ray polarization from parsec-scale components of active galactic nuclei: observational prospects	J. Podgorn√Ω,F. Marin,M. Dovƒçiak	We present a broad analysis of X-ray polarimetric observational prospects for radio-quiet active galactic nuclei (AGN), focusing on the role of parsec-scale components. We provide a revision of self-consistent type-1 and type-2 generic AGN radiative transfer models that were obtained with a Monte Carlo code STOKES, evaluating the effects of absorption and scattering. Our model consists of a central disc-corona emission obtained with the KYNSTOKES code in the lamp-post geometry, an equatorial wedge-shaped dusty torus and two symmetric conical polar outflows. We argue that the information on the mutual orientation, shape, relative size and composition of such components, usually obtained from spectroscopy or polarimetry in other wavelengths, is essential for the X-ray polarization analysis of the obscured type-2 AGNs. We provide general detectability prospects for AGNs with 2-8 keV polarimeters on board of the currently flying IXPE satellite and the forthcoming eXTP mission. Finally, we assess the role of contemporary X-ray polarimetry in our understandings of the unified AGN model after the first year and a half of IXPE operation.	astro-ph.HE	20 pages, 31 figures, accepted for publication in MNRAS
1	Ending the prompt phase in photospheric models of gamma-ray bursts	Filip Alamaa,Fr√©d√©ric Daigne,Robert Mochkovitch	The early steep decay, a rapid decrease in X-ray flux as a function of time following the prompt emission, is a robust feature seen in almost all gamma-ray bursts with early enough X-ray observations. This peculiar phenomenon has often been explained as emission from high latitudes of the last flashing shell. However, in photospheric models of gamma-ray bursts, the timescale of high-latitude emission is generally short compared to the duration of the steep decay phase, and hence an alternative explanation is needed. In this paper, we show that the early steep decay can directly result from the final activity of the dying central engine. We find that the corresponding photospheric emission can reproduce both the temporal and spectral evolution observed. This requires a late-time behaviour that should be common to all GRB central engines, and we estimate the necessary evolution of the kinetic power and the Lorentz factor. If this interpretation is correct, observation of the early steep decay can grant us insights into the last stages of central activity, and provide new constraints on the late evolution of the Lorentz factor and photospheric radius.	astro-ph.HE	7 pages, 3 figures. Submitted to A&A
2	On Adaptive confidence Ellipsoids for sparse high dimensional linear models	Xiaoyang Xie	In high-dimensional linear models the problem of constructing adaptive confidence sets for the full parameter is known to be generally impossible. We propose re-weighted loss functions under which constructing fully adaptive confidence sets for the parameter is shown to be possible. We give necessary and sufficient conditions on the weights for adaptive confidence sets to exist, and exhibit a concrete rate-optimal procedure in the feasible regime.	math.ST	None
3	Confounder Balancing in Adversarial Domain Adaptation for Pre-Trained Large Models Fine-Tuning	Shuoran Jiang,Qingcai Chen,Yang Xiang,Youcheng Pan,Xiangping Wu	The excellent generalization, contextual learning, and emergence abilities in the pre-trained large models (PLMs) handle specific tasks without direct training data, making them the better foundation models in the adversarial domain adaptation (ADA) methods to transfer knowledge learned from the source domain to target domains. However, existing ADA methods fail to account for the confounder properly, which is the root cause of the source data distribution that differs from the target domains. This study proposes an adversarial domain adaptation with confounder balancing for PLMs fine-tuning (ADA-CBF). The ADA-CBF includes a PLM as the foundation model for a feature extractor, a domain classifier and a confounder classifier, and they are jointly trained with an adversarial loss. This loss is designed to improve the domain-invariant representation learning by diluting the discrimination in the domain classifier. At the same time, the adversarial loss also balances the confounder distribution among source and unmeasured domains in training. Compared to existing ADA methods, ADA-CBF can correctly identify confounders in domain-invariant features, thereby eliminating the confounder biases in the extracted features from PLMs. The confounder classifier in ADA-CBF is designed as a plug-and-play and can be applied in the confounder measurable, unmeasurable, or partially measurable environments. Empirical results on natural language processing and computer vision downstream tasks show that ADA-CBF outperforms the newest GPT-4, LLaMA2, ViT and ADA methods.	cs.LG	None
4	Testing the Limits: Unusual Text Inputs Generation for Mobile App Crash Detection with Large Language Model	Zhe Liu,Chunyang Chen,Junjie Wang,Mengzhuo Chen,Boyu Wu,Xing Che,Dandan Wang,Qing Wang	Mobile applications have become a ubiquitous part of our daily life, providing users with access to various services and utilities. Text input, as an important interaction channel between users and applications, plays an important role in core functionality such as search queries, authentication, messaging, etc. However, certain special text (e.g., -18 for Font Size) can cause the app to crash, and generating diversified unusual inputs for fully testing the app is highly demanded. Nevertheless, this is also challenging due to the combination of explosion dilemma, high context sensitivity, and complex constraint relations. This paper proposes InputBlaster which leverages the LLM to automatically generate unusual text inputs for mobile app crash detection. It formulates the unusual inputs generation problem as a task of producing a set of test generators, each of which can yield a batch of unusual text inputs under the same mutation rule. In detail, InputBlaster leverages LLM to produce the test generators together with the mutation rules serving as the reasoning chain, and utilizes the in-context learning schema to demonstrate the LLM with examples for boosting the performance. InputBlaster is evaluated on 36 text input widgets with cash bugs involving 31 popular Android apps, and results show that it achieves 78% bug detection rate, with 136% higher than the best baseline. Besides, we integrate it with the automated GUI testing tool and detect 37 unseen crashes in real-world apps from Google Play.	cs.SE	Accepted by IEEE/ACM International Conference on Software Engineering   2024 (ICSE 2024)
5	Momentum Gradient-based Untargeted Attack on Hypergraph Neural Networks	Yang Chen,Stjepan Picek,Zhonglin Ye,Zhaoyang Wang,Haixing Zhao	Hypergraph Neural Networks (HGNNs) have been successfully applied in various hypergraph-related tasks due to their excellent higher-order representation capabilities. Recent works have shown that deep learning models are vulnerable to adversarial attacks. Most studies on graph adversarial attacks have focused on Graph Neural Networks (GNNs), and the study of adversarial attacks on HGNNs remains largely unexplored. In this paper, we try to reduce this gap. We design a new HGNNs attack model for the untargeted attack, namely MGHGA, which focuses on modifying node features. We consider the process of HGNNs training and use a surrogate model to implement the attack before hypergraph modeling. Specifically, MGHGA consists of two parts: feature selection and feature modification. We use a momentum gradient mechanism to choose the attack node features in the feature selection module. In the feature modification module, we use two feature generation approaches (direct modification and sign gradient) to enable MGHGA to be employed on discrete and continuous datasets. We conduct extensive experiments on five benchmark datasets to validate the attack performance of MGHGA in the node and the visual object classification tasks. The results show that MGHGA improves performance by an average of 2% compared to the than the baselines.	cs.LG	None
6	Breaking of brightness consistency in optical flow with a lightweight CNN network	Yicheng Lin,Shuo Wang,Yunlong Jiang,Bin Han	Sparse optical flow is widely used in various computer vision tasks, however assuming brightness consistency limits its performance in High Dynamic Range (HDR) environments. In this work, a lightweight network is used to extract illumination robust convolutional features and corners with strong invariance. Modifying the typical brightness consistency of the optical flow method to the convolutional feature consistency yields the light-robust hybrid optical flow method. The proposed network runs at 190 FPS on a commercial CPU because it uses only four convolutional layers to extract feature maps and score maps simultaneously. Since the shallow network is difficult to train directly, a deep network is designed to compute the reliability map that helps it. An end-to-end unsupervised training mode is used for both networks. To validate the proposed method, we compare corner repeatability and matching performance with origin optical flow under dynamic illumination. In addition, a more accurate visual inertial system is constructed by replacing the optical flow method in VINS-Mono. In a public HDR dataset, it reduces translation errors by 93\%. The code is publicly available at https://github.com/linyicheng1/LET-NET.	cs.CV	7 pages,7 figures
7	A Survey on Detection of LLMs-Generated Content	Xianjun Yang,Liangming Pan,Xuandong Zhao,Haifeng Chen,Linda Petzold,William Yang Wang,Wei Cheng	The burgeoning capabilities of advanced large language models (LLMs) such as ChatGPT have led to an increase in synthetic content generation with implications across a variety of sectors, including media, cybersecurity, public discourse, and education. As such, the ability to detect LLMs-generated content has become of paramount importance. We aim to provide a detailed overview of existing detection strategies and benchmarks, scrutinizing their differences and identifying key challenges and prospects in the field, advocating for more adaptable and robust models to enhance detection accuracy. We also posit the necessity for a multi-faceted approach to defend against various attacks to counter the rapidly advancing capabilities of LLMs. To the best of our knowledge, this work is the first comprehensive survey on the detection in the era of LLMs. We hope it will provide a broad understanding of the current landscape of LLMs-generated content detection, offering a guiding reference for researchers and practitioners striving to uphold the integrity of digital information in an era increasingly dominated by synthetic content. The relevant papers are summarized and will be consistently updated at https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git.	cs.CL	We will keep updating at   https://github.com/Xianjun-Yang/Awesome_papers_on_LLMs_detection.git
8	Deceptive Fairness Attacks on Graphs via Meta Learning	Jian Kang,Yinglong Xia,Ross Maciejewski,Jiebo Luo,Hanghang Tong	We study deceptive fairness attacks on graphs to answer the following question: How can we achieve poisoning attacks on a graph learning model to exacerbate the bias deceptively? We answer this question via a bi-level optimization problem and propose a meta learning-based framework named FATE. FATE is broadly applicable with respect to various fairness definitions and graph learning models, as well as arbitrary choices of manipulation operations. We further instantiate FATE to attack statistical parity and individual fairness on graph neural networks. We conduct extensive experimental evaluations on real-world datasets in the task of semi-supervised node classification. The experimental results demonstrate that FATE could amplify the bias of graph neural networks with or without fairness consideration while maintaining the utility on the downstream task. We hope this paper provides insights into the adversarial robustness of fair graph learning and can shed light on designing robust and fair graph learning in future studies.	cs.LG	23 pages, 11 tables
9	Probing nuclear physics with supernova gravitational waves and machine learning	Ayan Mitra,Daniil Orel,Y. Sultan Abylkairov,Bekdaulet Shukirgaliyev,Ernazar Abdikamalov	Core-collapse supernovae are sources of powerful gravitational waves (GWs). We assess the possibility of extracting information about the equation of state (EOS) of high density matter from the GW signal. We use the bounce and early post-bounce signals of rapidly rotating supernovae. A large set of GW signals is generated using general relativistic hydrodynamics simulations for various EOS models. The uncertainty in the electron capture rate is parametrized by generating signals for six different models. To classify EOSs based on the GW data, we train a convolutional neural network (CNN) model. Even with the uncertainty in the electron capture rates, we find that the CNN models can classify the EOSs with an average accuracy of about 87 percent for a set of four distinct EOS models.	astro-ph.HE	Submitted to MNRAS
0	Dynamic Convolutional Neural Networks as Efficient Pre-trained Audio Models	Florian Schmid,Khaled Koutini,Gerhard Widmer	The introduction of large-scale audio datasets, such as AudioSet, paved the way for Transformers to conquer the audio domain and replace CNNs as the state-of-the-art neural network architecture for many tasks. Audio Spectrogram Transformers are excellent at exploiting large datasets, creating powerful pre-trained models that surpass CNNs when fine-tuned on downstream tasks. However, current popular Audio Spectrogram Transformers are demanding in terms of computational complexity compared to CNNs. Recently, we have shown that, by employing Transformer-to-CNN Knowledge Distillation, efficient CNNs can catch up with and even outperform Transformers on large datasets. In this work, we extend this line of research and increase the capacity of efficient CNNs by introducing dynamic CNN blocks, constructed of dynamic non-linearities, dynamic convolutions and attention mechanisms. We show that these dynamic CNNs outperform traditional efficient CNNs, in terms of the performance-complexity trade-off and parameter efficiency, at the task of audio tagging on the large-scale AudioSet. Our experiments further indicate that the introduced dynamic CNNs achieve better performance on downstream tasks and scale up well, attaining Transformer performance and even outperforming them on AudioSet and several downstream tasks.	cs.SD	Submitted to IEEE/ACM Transactions on Audio, Speech, and Language   Processing. Source Code available at:   https://github.com/fschmid56/EfficientAT
1	Simple numerical X-ray polarization models of reflecting axially symmetric structures around accreting compact objects	J. Podgorn√Ω,M. Dovƒçiak,F. Marin	We present a series of numerical models suitable for X-ray polarimetry of accreting systems. Firstly, we provide a spectropolarimetric routine that integrates reflection from inner optically thick walls of a geometrical torus of arbitrary size viewed under general inclination. In the studied example, the equatorial torus surrounding an accreting compact object is illuminated by a central isotropic source of X-ray power-law emission, representing a hot corona. Nearly neutral reprocessing inside the walls is precomputed by Monte Carlo code STOKES that incorporates both line and continuum processes, including multiple scatterings and absorption. Applying a conversion script to the torus reflection output, we created tabular dependencies for a new XSPEC model, called xsstokes. In this version, xsstokes enables efficient X-ray polarimetric fitting of the torus parameters, observer's inclination and primary emission properties, interpolating for arbitrary state of primary polarization. We provide comparisons of the results to a more sophisticated Monte Carlo simulation. Since the polarization interpolation routine works for any axially symmetric reflecting structure, we provide another version of xsstokes that is suitable for approximating nearly neutral reflection from a distant optically thick disc of small geometrical thickness. The second version uses the same precomputed Monte Carlo reprocessing, but assumes local illumination averaged for a range of high incident angles, representing a toy model of a diffuse, vertically extended hot inner accretion flow. Assessing both model variants, we conclude that the resulting polarization can be tens of % and perpendicularly/parallelly oriented towards the axis, if the reflecting medium is rather vertically/equatorially distributed.	astro-ph.HE	12 pages, 11 figures
2	Mean Teacher DETR with Masked Feature Alignment: A Robust Domain Adaptive Detection Transformer Framework	Weixi Weng,Chun Yuan	Unsupervised domain adaptation object detection(UDAOD) research on Detection Transformer(DETR) mainly focuses on feature alignment and existing methods can be divided into two kinds, each of which has its unresolved issues. One-stage feature alignment methods can easily lead to performance fluctuation and training stagnation. Two-stage feature alignment method based on mean teacher comprises a pretraining stage followed by a self-training stage, each facing problems in obtaining reliable pretrained model and achieving consistent performance gains. Methods mentioned above have not yet explore how to utilize the third related domain such as target-like domain to assist adaptation. To address these issues, we propose a two-stage framework named MTM, i.e. Mean Teacher-DETR with Masked Feature Alignment. In the pretraining stage, we utilize labeled target-like images produced by image style transfer to avoid performance fluctuation. In the self-training stage, we leverage unlabeled target images by pseudo labels based on mean teacher and propose a module called Object Queries Knowledge Transfer(OQKT) to ensure consistent performance gains of the student model. Most importantly, we propose masked feature alignment methods including Masked Domain Query-based Feature Alignment(MDQFA) and Masked Token-wise Feature Alignment(MTWFA) to alleviate domain shift in a more robust way, which not only prevent training stagnation and lead to a robust pretrained model in the pretraining stage, but also enhance the model's target performance in the self-training stage. Experiments on three challenging scenarios and a theoretical analysis verify the effectiveness of MTM.	cs.CV	None
3	Linear-in-Complexity Computational Strategies for Modeling and Dosimetry at TeraHertz	Viviana Giunzioni,Giuseppe Ciacco,Cl√©ment Henry,Adrien Merlini,Francesco P. Andriulli	This work presents a fast direct solver strategy allowing full-wave modeling and dosimetry at terahertz (THz) frequencies. The novel scheme leverages a preconditioned combined field integral equation together with a regularizer for its elliptic spectrum to enable its compression into a non-hierarchical skeleton, invertible in quasi-linear complexity. Numerical results will show the effectiveness of the new scheme in a realistic skin modeling scenario.	math.NA	None
4	Guaranteed Coverage Prediction Intervals with Gaussian Process Regression	Harris Papadopoulos	Gaussian Process Regression (GPR) is a popular regression method, which unlike most Machine Learning techniques, provides estimates of uncertainty for its predictions. These uncertainty estimates however, are based on the assumption that the model is well-specified, an assumption that is violated in most practical applications, since the required knowledge is rarely available. As a result, the produced uncertainty estimates can become very misleading; for example the prediction intervals (PIs) produced for the 95\% confidence level may cover much less than 95\% of the true labels. To address this issue, this paper introduces an extension of GPR based on a Machine Learning framework called, Conformal Prediction (CP). This extension guarantees the production of PIs with the required coverage even when the model is completely misspecified. The proposed approach combines the advantages of GPR with the valid coverage guarantee of CP, while the performed experimental results demonstrate its superiority over existing methods.	cs.LG	12 pages. This work has been submitted to IEEE Transactions on   Pattern Analysis and Machine Intelligence for possible publication. Copyright   may be transferred without notice, after which this version may no longer be   accessible
5	CoAnnotating: Uncertainty-Guided Work Allocation between Human and Large Language Models for Data Annotation	Minzhi Li,Taiwei Shi,Caleb Ziems,Min-Yen Kan,Nancy F. Chen,Zhengyuan Liu,Diyi Yang	Annotated data plays a critical role in Natural Language Processing (NLP) in training models and evaluating their performance. Given recent developments in Large Language Models (LLMs), models such as ChatGPT demonstrate zero-shot capability on many text-annotation tasks, comparable with or even exceeding human annotators. Such LLMs can serve as alternatives for manual annotation, due to lower costs and higher scalability. However, limited work has leveraged LLMs as complementary annotators, nor explored how annotation work is best allocated among humans and LLMs to achieve both quality and cost objectives. We propose CoAnnotating, a novel paradigm for Human-LLM co-annotation of unstructured texts at scale. Under this framework, we utilize uncertainty to estimate LLMs' annotation capability. Our empirical study shows CoAnnotating to be an effective means to allocate work from results on different datasets, with up to 21% performance improvement over random baseline. For code implementation, see https://github.com/SALT-NLP/CoAnnotating.	cs.CL	None
6	Career Path Prediction using Resume Representation Learning and Skill-based Matching	Jens-Joris Decorte,Jeroen Van Hautte,Johannes Deleu,Chris Develder,Thomas Demeester	The impact of person-job fit on job satisfaction and performance is widely acknowledged, which highlights the importance of providing workers with next steps at the right time in their career. This task of predicting the next step in a career is known as career path prediction, and has diverse applications such as turnover prevention and internal job mobility. Existing methods to career path prediction rely on large amounts of private career history data to model the interactions between job titles and companies. We propose leveraging the unexplored textual descriptions that are part of work experience sections in resumes. We introduce a structured dataset of 2,164 anonymized career histories, annotated with ESCO occupation labels. Based on this dataset, we present a novel representation learning approach, CareerBERT, specifically designed for work history data. We develop a skill-based model and a text-based model for career path prediction, which achieve 35.24% and 39.61% recall@10 respectively on our dataset. Finally, we show that both approaches are complementary as a hybrid approach achieves the strongest result with 43.01% recall@10.	cs.CL	Accepted to the 3nd Workshop on Recommender Systems for Human   Resources (RecSys in HR 2023) as part of RecSys 2023
7	Exploitation des propri{√©}t{√©}s de saturation synaptique pour obtenir un neurone {√†} fr{√©}quence sp{√©}cifique	Guillaume Marthe,Claire Goursaud	Energy consumption remains the main limiting factors in many promising IoT applications. In particular, micro-controllers consume far too much power. In order to overcome this problem, new circuit designs have been proposed and the use of spiking neurons and analog computing has emerged as it allows a very significant consumption reduction. However, working in the analog domain brings difficulty to handle the sequential processing of incoming signals as is needed in many use cases.In this paper, we propose to use a bio-inspired phenomenon called Interacting Synapses to produce a time filter. We propose a model of synapses that makes the neuron fire for a specific range of delays between two incoming spikes, but not react when this Inter-Spike Timing is not in that range. We study the parameters of the model to understand how to adapt the Inter-Spike Timing. The originality of the paper is to propose a new way, in the analog domain, to deal with temporal sequences.	eess.SP	in French language
8	Linear magneto-conductivity as a DC probe of time-reversal symmetry breaking	Veronika Sunko,Chunxiao Liu,Marc Vila,Ilyoun Na,Yuchen Tang,Vladyslav Kozii,Sin√©ad M. Griffin,Joel E. Moore,Joseph Orenstein	"Several optical experiments have shown that in magnetic materials the principal axes of response tensors can rotate in a magnetic field. Here we offer a microscopic explanation of this effect, and propose a closely related DC transport phenomenon -- an off-diagonal \emph{symmetric} conductivity linear in a magnetic field, which we refer to as linear magneto-conductivity (LMC). Although LMC has the same functional dependence on magnetic field as the Hall effect, its origin is fundamentally different: LMC requires time-reversal symmetry to be broken even before a magnetic field is applied, and is therefore a sensitive probe of magnetism. We demonstrate LMC in three different ways: via a tight-binding toy model, density functional theory calculations on MnPSe$_3$, and a semiclassical calculation. The third approach additionally identifies two distinct mechanisms yielding LMC: momentum-dependent band magnetization and Berry curvature. Finally, we propose an experimental geometry suitable for detecting LMC, and demonstrate its applicability using Landauer-B\""{u}ttiker simulations. Our results emphasize the importance of measuring the full conductivity tensor in magnetic materials, and introduce LMC as a new transport probe of symmetry."	cond-mat.mes-hall	6+8 pages, 4+3 figures
9	Compressive quantum waveform estimation	Alex Tritt,Joshua Morris,Christopher C. Bounds,Hamish A. M. Taylor,James Saunderson,L. D. Turner	Applying quantum sensors to sample entire signals (quantum waveform estimation) promises to revolutionize the sensing of small signals, such as the monitoring of electrical pulses generated by neurons for medical research. However, intensive use of quantum resources (e.g., long sensing times and/or many destructive measurements) make current implementations impractical for real-world use. In this Letter, we experimentally demonstrate quantum waveform estimation of a synthesized neural-like signal, taking many fewer cold-atom measurements than would naively be necessary.	quant-ph	6 pages + 3 pages of Supplemental Material, 3 figures + 1   supplemental figure
0	On-chip topological transport of optical frequency combs in silicon-based valley photonic crystals	Zhen Jiang,Hongwei Wang,Yuechen Yang,Yang Shen,Bo Ji,Yanghe Chen,Yong Zhang,Lu Sun,Zheng Wang,Chun Jiang,Yikai Su,Guangqiang He	The generation and control of optical frequency combs in integrated photonic systems enables complex, high-controllable, and large-scale devices. In parallel, harnessing topological physics in multipartite systems has allowed them with compelling features such as robustness against fabrication imperfections. Here we experimentally demonstrate on-chip topological transport for optical frequency combs at telecommunication wavelengths, both in classical and nonclassical domains. We access both the quantum frequency combs and dissipative Kerr soliton combs with a micro-resonator. The quantum frequency comb, that is, a coherent superposition of multiple frequency modes, is proven to be a frequency-entangled qudit state. We also show that dissipative Kerr soliton combs are highly coherent and mode-locked due to the collective coherence or self-organization of solitons. Moreover, the valley kink states allow both quantum frequency combs and dissipative Kerr soliton combs with robustness against sharp bends. Our topologically protected optical frequency combs could enable the inherent robustness in integrated complex photonic systems.	physics.optics	20 pages,12 figures
1	Orders and partitions of integers induced by arithmetic functions	Mario Ziller	We pursue the question how integers can be ordered or partitioned according to their divisibility properties. Based on pseudometrics on $\mathbb{Z}$, we investigate induced preorders, associated equivalence relations, and quotient sets. The focus is on metrics or pseudometrics on $\mathbb{D}_n$, the set of divisors of a given modulus $n\in\mathbb{N}$, that can be extended to pseudometrics on $\mathbb{Z}$.   Arithmetic functions can be used to generate such pseudometrics. We discuss several subsets of additive and multiplicative arithmetic functions and various combinations of their function values leading to binary metric functions that represent different divisibility properties of integers.   We conclude this paper with numerous examples and review the most important results. As an additional result, we derive a necessary condition for the truth of the odd k-perfect number conjecture.	math.NT	50 pages, 3 diagrams
2	Push-Pull Based Distributed Primal-Dual Algorithm for Coupled Constrained Convex Optimization in Multi-Agent Networks	Kai Gong,Liwei Zhang	This paper focuses on a distributed coupled constrained convex optimization problem over directed unbalanced and time-varying multi-agent networks, where the global objective function is the sum of all agents' private local objective functions, and decisions of all agents are subject to coupled equality and inequality constraints and a compact convex subset. In the multi-agent networks, each agent exchanges information with other neighboring agents. Finally, all agents reach a consensus on decisions, meanwhile achieving the goal of minimizing the global objective function under the given constraint conditions. For the purpose of protecting the information privacy of each agent, we first establish the saddle point problem of the constrained convex optimization problem considered in this article, then based on the push-pull method, develop a distributed primal-dual algorithm to solve the dual problem. Under Slater's condition, we will show that the sequence of points generated by the proposed algorithm converges to a saddle point of the Lagrange function. Moreover, we analyze the iteration complexity of the algorithm.	math.OC	None
3	GUPNet++: Geometry Uncertainty Propagation Network for Monocular 3D Object Detection	Yan Lu,Xinzhu Ma,Lei Yang,Tianzhu Zhang,Yating Liu,Qi Chu,Tong He,Yonghui Li,Wanli Ouyang	Geometry plays a significant role in monocular 3D object detection. It can be used to estimate object depth by using the perspective projection between object's physical size and 2D projection in the image plane, which can introduce mathematical priors into deep models. However, this projection process also introduces error amplification, where the error of the estimated height is amplified and reflected into the projected depth. It leads to unreliable depth inferences and also impairs training stability. To tackle this problem, we propose a novel Geometry Uncertainty Propagation Network (GUPNet++) by modeling geometry projection in a probabilistic manner. This ensures depth predictions are well-bounded and associated with a reasonable uncertainty. The significance of introducing such geometric uncertainty is two-fold: (1). It models the uncertainty propagation relationship of the geometry projection during training, improving the stability and efficiency of the end-to-end model learning. (2). It can be derived to a highly reliable confidence to indicate the quality of the 3D detection result, enabling more reliable detection inference. Experiments show that the proposed approach not only obtains (state-of-the-art) SOTA performance in image-based monocular 3D detection but also demonstrates superiority in efficacy with a simplified framework.	cs.CV	18 pages, 9 figures
4	New application of the mass-dependent analysis for renormalization group equation to extended Higgs models	Shinya Kanemura,Yushi Mura	We discuss at the first time ultraviolet behaviors of effective coupling constants using renormalization group equations with mass dependent beta functions in extended Higgs models, in which the scalar coupling constants may blow up at a scale much below the Planck scale. It is important to precisely evaluate such a scale as the upper bound where the models can hold. We find that by the natural treatment of the threshold in our method the upper bound in extended Higgs models can be much higher than that obtained by using the mass independent beta function, especially when such an upper bound is relatively low.	hep-ph	6 pages, 3 figures
5	Exact solutions for radiative transfer with partial frequency redistribution	H√©l√®ne Frisch	The construction of exact solutions for radiative transfer in a plane-parallel medium has been addressed by Hemsch and Ferziger in 1972 for a partial frequency redistribution model of the formation of spectral lines consisting in a linear combination of frequency coherent and fully incoherent scattering. The method of solution is based on an eigenfunction expansion of the radiation field, leading to two singular integral equations with a Cauchy-type kernel, that have to be solved one after the other. We reconsider this problem, using as starting point the integral formulation of the radiative transfer equation, where the terms involving the coupling between the two scattering mechanisms are clearly displayed, as well as the primary source of photons. With an inverse Laplace transform, we recover the singular integral equations previously established and, with Hilbert transforms as in the previous work, recast them as boundary value problems in the complex plane. Their solutions are presented in detail for an infinite and a semi-infinite medium. The coupling terms are carefully analyzed and consistency with either the coherent or the incoherent limit is systematically checked. We recover the important results of the previous work that an exact solution exists for an infinite medium, whereas for a semi-infinite medium, which requires the introduction of half-space auxiliary functions, the solution is given by a Fredholm integral equation to be solved numerically. The solutions of the singular integral equations are used to construct explicit expressions of the radiation field inside the medium and, for a semi-infinite medium, also those of the emerging field.	astro-ph.SR	52 pages, 6 figures, submitted to the Journal of Quantitative   Spectroscopy and Radiative transfer (JQSRT) on October 20th 2023
6	Spanning trees in $\mathbb{Z}$-covers of a finite graph and Mahler measures	Riccardo Pengo,Daniel Valli√®res	Using the special value at $u=1$ of Artin-Ihara $L$-functions, we associate to every $\mathbb{Z}$-cover of a finite graph a polynomial which we call the \emph{Ihara polynomial}. We show that the number of spanning trees for the finite intermediate graphs of such a cover can be expressed in terms of the Pierce-Lehmer sequence associated to a factor of the Ihara polynomial. This allows us to express the asymptotic growth of the number of spanning trees in terms of the Mahler measure of this polynomial. Specializing to the situation where the base graph is a bouquet or the dumbbell graph gives us back previous results in the literature for circulant and $I$-graphs (including the generalized Petersen graphs). We also express the $p$-adic valuation of the number of spanning trees of the finite intermediate graphs in terms of the $p$-adic Mahler measure of the Ihara polynomial. When applied to a particular $\mathbb{Z}$-cover, our result gives us back Lengyel's calculation of the $p$-adic valuations of Fibonacci numbers.	math.NT	Comments are very welcome!
7	A lower bound for the genus of a knot using the Links-Gould invariant	Ben-Michael Kohli,Guillaume Tahar	The Links-Gould invariant of links $LG^{2,1}$ is a two-variable generalization of the Alexander-Conway polynomial. Using representation theory of $U_{q}\mathfrak{gl}(2 \vert 1)$, we prove that the degree of the Links-Gould polynomial provides a lower bound on the Seifert genus of any knot, therefore improving the bound known as the Seifert inequality in the case of the Alexander invariant.	math.GT	26 pages
8	Atoms and associated spectral properties for positive operators on L^p	Jean-Fran√ßois Delmas,Kacem Lefki,Pierre-Andr√© Zitt	Inspired by Schwartz, Jang-Lewis and Victory, who study in particular generalizations of triangularizations of matrices to operators, we shall give for positive operators on Lebesgue spaces equivalent definitions of atoms (maximal irreducible sets). We also characterize positive power compact operators having a unique non-zero atom which appears as a natural generalization of irreducible operators and are also considered in epidemiological models. Using the different characterizations of atoms, we also provide a short proof for the representation of the ascent of a positive power compact operator as the maximal length in the graph of critical atoms.	math.SP	None
9	Super-resolved rainfall prediction with physics-aware deep learning	S. Moran,B. Demir,F. Serva,B. Le Saux	Rainfall prediction at the kilometre-scale up to a few hours in the future is key for planning and safety. But it is challenging given the complex influence of climate change on cloud processes and the limited skill of weather models at this scale. Following the set-up proposed by the \emph{weather4cast} challenge of NeurIPS, we build a two-step deep-learning solution for predicting rainfall occurrence at ground radar high spatial resolution starting from coarser resolution weather satellite images. Our approach is designed to predict future satellite images with a physics-aware ConvLSTM network, which is then converted into precipitation maps through a U-Net. We find that our two-step pipeline outperforms the baseline model and we quantify the benefits of including physical information. We find that local-scale rainfall predictions with good accuracy starting from satellite radiances can be obtained for up to 4 hours in the future.	physics.ao-ph	Accepted at Big Data from Space 2023 (BiDS); 4 pages, 3 figures
0	Multiplicity of solutions for semilinear subelliptic Dirichlet problem	Hua Chen,Hong-Ge Chen,Jin-Ning Li,Xin Liao	"In this paper, we study the semilinear subelliptic equation \[ \left\{   \begin{array}{cc}   -\triangle_{X} u=f(x,u)+g(x,u) & \mbox{in}~\Omega, \\[2mm]   u=0\hfill & \mbox{on}~\partial\Omega,   \end{array}   \right. \] where $\triangle_{X}=-\sum_{i=1}^{m}X_{i}^{*}X_{i}$ is the self-adjoint H\""{o}rmander operator associated with vector fields $X=(X_{1},X_{2},\ldots,X_{m})$ satisfying the H\""{o}rmander condition, $f(x,u)\in C(\overline{\Omega}\times \mathbb{R})$, $g(x,u)$ is a Carath\'{e}odory function on $\Omega\times \mathbb{R}$, and $\Omega$ is an open bounded domain in $\mathbb{R}^n$ with smooth boundary. Combining the perturbation from symmetry method with the approaches involving eigenvalue estimate and Morse index in estimating the min-max values, we obtain two kinds of existence results for multiple weak solutions to the problem above. Furthermore, we discuss the difference between the eigenvalue estimate approach and the Morse index approach in degenerate situations. Compared with the classical elliptic cases, both approaches here have their own strengths in the degenerate cases. This new phenomenon implies the results in general degenerate cases would be quite different from the situations in classical elliptic cases."	math.AP	39 pages
1	Machine Translation for Nko: Tools, Corpora and Baseline Results	Moussa Koulako Bala Doumbouya,Baba Mamadi Dian√©,Solo Farabado Ciss√©,Djibrila Dian√©,Abdoulaye Sow,S√©r√© Moussa Doumbouya,Daouda Bangoura,Fod√© Moriba Bayo,Ibrahima Sory 2. Cond√©,Kalo Mory Dian√©,Chris Piech,Christopher Manning	Currently, there is no usable machine translation system for Nko, a language spoken by tens of millions of people across multiple West African countries, which holds significant cultural and educational value. To address this issue, we present a set of tools, resources, and baseline results aimed towards the development of usable machine translation systems for Nko and other languages that do not currently have sufficiently large parallel text corpora available. (1) Friallel: A novel collaborative parallel text curation software that incorporates quality control through copyedit-based workflows. (2) Expansion of the FLoRes-200 and NLLB-Seed corpora with 2,009 and 6,193 high-quality Nko translations in parallel with 204 and 40 other languages. (3) nicolingua-0005: A collection of trilingual and bilingual corpora with 130,850 parallel segments and monolingual corpora containing over 3 million Nko words. (4) Baseline bilingual and multilingual neural machine translation results with the best model scoring 30.83 English-Nko chrF++ on FLoRes-devtest.	cs.CL	None
2	The strong Lefschetz property for quadratic reverse lexicographic ideals	Filip Jonsson Kling	Consider ideals $I$ of the form \[ I=(x_1^2,\dots, x_n^2)+\mathrm{RLex}(x_ix_j) \] where $\mathrm{RLex}(x_ix_j)$ is the ideal generated by all the square-free monomials which are greater than or equal to $x_ix_j$ in the reverse lexicographic order. We will determine some interesting properties regarding the shape of the Hilbert series of $I$. Using a theorem of Lindsey, this allows for a short proof that the algebras defined by $I$ has the strong Lefschetz property when the underlying field is of characteristic zero. Building on recent work by Phuong and Tran, this result is then extended to fields of sufficiently high positive characteristic. As a consequence, this shows that for any possible number of minimal generators for an artinian quadratic ideal, there exists such an ideal minimally generated by that many monomials and defining an algebra with the strong Lefschetz property.	math.AC	11 pages, 1 figure
3	Using Slisemap to interpret physical data	Lauri Sepp√§l√§inen,Anton Bj√∂rklund,Vitus Besel,Kai Puolam√§ki	Manifold visualisation techniques are commonly used to visualise high-dimensional datasets in physical sciences. In this paper we apply a recently introduced manifold visualisation method, called Slise, on datasets from physics and chemistry. Slisemap combines manifold visualisation with explainable artificial intelligence. Explainable artificial intelligence is used to investigate the decision processes of black box machine learning models and complex simulators. With Slisemap we find an embedding such that data items with similar local explanations are grouped together. Hence, Slisemap gives us an overview of the different behaviours of a black box model. This makes Slisemap into a supervised manifold visualisation method, where the patterns in the embedding reflect a target property. In this paper we show how Slisemap can be used and evaluated on physical data and that Slisemap is helpful in finding meaningful information on classification and regression models trained on these datasets.	cs.LG	17 pages, 5 + 1 figures, 1 table. The datasets and source code used   in the paper are available at https://www.edahelsinki.fi/papers/slisemap_phys
4	Exploring the Impact of Ejecta Velocity Profile on Kilonova Evolution: Diversity of the Kilonova Lightcurves	Donggeun Tak,Z. Lucas Uhm,James H. Gillanders	A kilonova is a short-lived explosive event in the universe, resulting from the merger of two compact objects. Despite its importance as a primary source of heavy elements through r-process nucleosynthesis, its nature is not well understood, due to its rarity. In this work, we introduce a model that determines the density of a radially-stratified relativistic ejecta. We apply the model to kilonova ejecta and explore several hypothesized velocity profiles as a function of the merger's ejection time. These velocity profiles result in diverse density profiles of the ejecta, for which we conduct radiative transfer simulations using TARDIS with the solar r-process composition. Consequently, we investigate the impact of the ejecta velocity profile on the resulting lightcurve and spectral evolution through the line transitions of heavy elements. The change in the rate at which these elements accumulate in the line-forming region leaves its imprint on the kilonova lightcurve at specific wavelengths, causing the lightcurves to decay at different rates. Furthermore, in several profiles, plateau-like behaviors (slow and/or flat decline) are also observed. In conclusion, this work proposes potential scenarios of the kilonova evolution due to the ejecta velocity profile.	astro-ph.HE	9 pages, 5 figures, ApJ accepted
5	tagE: Enabling an Embodied Agent to Understand Human Instructions	Chayan Sarkar,Avik Mitra,Pradip Pramanick,Tapas Nayak	Natural language serves as the primary mode of communication when an intelligent agent with a physical presence engages with human beings. While a plethora of research focuses on natural language understanding (NLU), encompassing endeavors such as sentiment analysis, intent prediction, question answering, and summarization, the scope of NLU directed at situations necessitating tangible actions by an embodied agent remains limited. The inherent ambiguity and incompleteness inherent in natural language present challenges for intelligent agents striving to decipher human intention. To tackle this predicament head-on, we introduce a novel system known as task and argument grounding for Embodied agents (tagE). At its core, our system employs an inventive neural network model designed to extract a series of tasks from complex task instructions expressed in natural language. Our proposed model adopts an encoder-decoder framework enriched with nested decoding to effectively extract tasks and their corresponding arguments from these intricate instructions. These extracted tasks are then mapped (or grounded) to the robot's established collection of skills, while the arguments find grounding in objects present within the environment. To facilitate the training and evaluation of our system, we have curated a dataset featuring complex instructions. The results of our experiments underscore the prowess of our approach, as it outperforms robust baseline models.	cs.RO	Accepted in EMNLP Findings 2023
6	Radiative correction on moduli stabilization in modular flavor symmetric models	Tatsuo Kobayashi,Kaito Nasu,Riku Sakuma,Yusuke Yamada	We study the radiative corrections to the stabilization of the complex structure modulus $\tau$ in modular flavor symmetric models. We discuss the possibility of obtaining the vacuum expectation value of $\tau$ in the vicinity of the fixed point where residual symmetries remain unbroken. As concrete examples, we analyze the 1-loop Coleman-Weinberg potential in the $A_4$ modular flavor models. We show that the 1-loop correction may lead to the slight deviation from the tree level result, which may realize a phenomenologically preferred value of the complex structure modulus $\tau$ particularly when the number of species contributing to the 1-loop correction is large enough.	hep-ph	26 pages, 12 figures
7	Tilted circumbinary planetary systems as efficient progenitors of free-floating planets	Cheng Chen,Rebecca G. Martin,Stephen H. Lubow,C. J. Nixon	The dominant mechanism for generating free-floating planets has so far remained elusive. One suggested mechanism is that planets are ejected from planetary systems due to planet-planet interactions. However, instability around a single star requires a very compactly spaced planetary system. We find that around binary star systems instability can occur even with widely separated planets that are on tilted orbits relative to the binary orbit due to combined effects of planet-binary and planet-planet interactions, especially if the binary is on an eccentric orbit. We investigate the orbital stability of planetary systems with various planet masses and architectures. We find that the stability of the system depends upon the mass of the highest mass planet. The order of the planets in the system does not significantly affect stability but, generally, the most massive planet remains stable and the lower mass planets are ejected. The minimum planet mass required to trigger the instability is about that of Neptune for a circular orbit binary and a super-Earth of about $10$ Earth masses for highly eccentric binaries. Hence, we suggest that planet formation around misaligned binaries can be an efficient formation mechanism for free-floating planets. While most observed free-floating planets are giant planets, we predict that there should be more low-mass free floating planets that are as yet unobserved than higher mass planets.	astro-ph.EP	10 pages, 2 figures
8	MUSER: A Multi-View Similar Case Retrieval Dataset	Qingquan Li,Yiran Hu,Feng Yao,Chaojun Xiao,Zhiyuan Liu,Maosong Sun,Weixing Shen	Similar case retrieval (SCR) is a representative legal AI application that plays a pivotal role in promoting judicial fairness. However, existing SCR datasets only focus on the fact description section when judging the similarity between cases, ignoring other valuable sections (e.g., the court's opinion) that can provide insightful reasoning process behind. Furthermore, the case similarities are typically measured solely by the textual semantics of the fact descriptions, which may fail to capture the full complexity of legal cases from the perspective of legal knowledge. In this work, we present MUSER, a similar case retrieval dataset based on multi-view similarity measurement and comprehensive legal element with sentence-level legal element annotations. Specifically, we select three perspectives (legal fact, dispute focus, and law statutory) and build a comprehensive and structured label schema of legal elements for each of them, to enable accurate and knowledgeable evaluation of case similarities. The constructed dataset originates from Chinese civil cases and contains 100 query cases and 4,024 candidate cases. We implement several text classification algorithms for legal element prediction and various retrieval methods for retrieving similar cases on MUSER. The experimental results indicate that incorporating legal elements can benefit the performance of SCR models, but further efforts are still required to address the remaining challenges posed by MUSER. The source code and dataset are released at https://github.com/THUlawtech/MUSER.	cs.CL	Accepted by CIKM 2023 Resource Track
9	Grasp Multiple Objects with One Hand	Yuyang Li,Bo Liu,Yiran Geng,Puhao Li,Yaodong Yang,Yixin Zhu,Tengyu Liu,Siyuan Huang	The human hand's complex kinematics allow for simultaneous grasping and manipulation of multiple objects, essential for tasks like object transfer and in-hand manipulation. Despite its importance, robotic multi-object grasping remains underexplored and presents challenges in kinematics, dynamics, and object configurations. This paper introduces MultiGrasp, a two-stage method for multi-object grasping on a tabletop with a multi-finger dexterous hand. It involves (i) generating pre-grasp proposals and (ii) executing the grasp and lifting the objects. Experimental results primarily focus on dual-object grasping and report a 44.13% success rate, showcasing adaptability to unseen object configurations and imprecise grasps. The framework also demonstrates the capability to grasp more than two objects, albeit at a reduced inference speed.	cs.RO	None
0	Decentralized Proximal Method of Multipliers for Convex Optimization with Coupled Constraints	Kai Gong,Liwei Zhang	In this paper, a decentralized proximal method of multipliers (DPMM) is proposed to solve constrained convex optimization problems over multi-agent networks, where the local objective of each agent is a general closed convex function, and the constraints are coupled equalities and inequalities. This algorithm strategically integrates the dual decomposition method and the proximal point algorithm. One advantage of DPMM is that subproblems can be solved inexactly and in parallel by agents at each iteration, which relaxes the restriction of requiring exact solutions to subproblems in many distributed constrained optimization algorithms. We show that the first-order optimality residual of the proposed algorithm decays to $0$ at a rate of $o(1/k)$ under general convexity. Furthermore, if a structural assumption for the considered optimization problem is satisfied, the sequence generated by DPMM converges linearly to an optimal solution. In numerical simulations, we compare DPMM with several existing algorithms using two examples to demonstrate its effectiveness.	math.OC	None
1	Motion of Test Particles in Spacetimes with Torsion and Nonmetricity	Danianos Iosifidis,Friedrich W. Hehl	We derive the equations of motion of a test particle with intrinsic hypermomentum in spacetimes with both torsion $S$ and nonmetricity $Q$ (along with curvature $R$). Accordingly, $S$ and $Q$ can be measured by tracing out the trajectory followed by a hypermomentum-charged test particle in such a non-Riemannian background. The test particle is approximated by means of a Dirac $\delta$-function. Thus we find a tangible way to observe and measure the effects of torsion and nonmetricity. Our results are consistent with earlier ones derived by Obukhov and Puetzfeld (2014) by means of a different method. We apply our insight and evaluate how far-reaching the so-called `geometrical trinity of gravity' really is.	gr-qc	8 pages, no figures
2	Retrieval-based Knowledge Transfer: An Effective Approach for Extreme Large Language Model Compression	Jiduan Liu,Jiahao Liu,Qifan Wang,Jingang Wang,Xunliang Cai,Dongyan Zhao,Ran Lucien Wang,Rui Yan	Large-scale pre-trained language models (LLMs) have demonstrated exceptional performance in various natural language processing (NLP) tasks. However, the massive size of these models poses huge challenges for their deployment in real-world applications. While numerous model compression techniques have been proposed, most of them are not well-suited for achieving extreme model compression when there is a significant gap in model scale. In this paper, we introduce a novel compression paradigm called Retrieval-based Knowledge Transfer (RetriKT), which effectively transfers the knowledge of LLMs to extremely small-scale models (e.g., 1%). In particular, our approach extracts knowledge from LLMs to construct a knowledge store, from which the small-scale model can retrieve relevant information and leverage it for effective inference. To improve the quality of the model, soft prompt tuning and Proximal Policy Optimization (PPO) reinforcement learning techniques are employed. Extensive experiments are conducted on low-resource tasks from SuperGLUE and GLUE benchmarks. The results demonstrate that the proposed approach significantly enhances the performance of small-scale models by leveraging the knowledge from LLMs.	cs.CL	EMNLP 2023 Findings
3	RecipeMeta: Metapath-enhanced Recipe Recommendation on Heterogeneous Recipe Network	Jialiang Shi,Takahiro Komamizu,Keisuke Doman,Haruya Kyutoku,Ichiro Ide	Recipe is a set of instructions that describes how to make food. It can help people from the preparation of ingredients, food cooking process, etc. to prepare the food, and increasingly in demand on the Web. To help users find the vast amount of recipes on the Web, we address the task of recipe recommendation. Due to multiple data types and relationships in a recipe, we can treat it as a heterogeneous network to describe its information more accurately. To effectively utilize the heterogeneous network, metapath was proposed to describe the higher-level semantic information between two entities by defining a compound path from peer entities. Therefore, we propose a metapath-enhanced recipe recommendation framework, RecipeMeta, that combines GNN (Graph Neural Network)-based representation learning and specific metapath-based information in a recipe to predict User-Recipe pairs for recommendation. Through extensive experiments, we demonstrate that the proposed model, RecipeMeta, outperforms state-of-the-art methods for recipe recommendation.	cs.MM	None
4	Honeybee-like collective decision making in a kilobot swarm	David March,Julia M√∫gica,Ezequiel E. Ferrero,M. Carmen Miguel	Drawing inspiration from honeybee swarms' nest-site selection process, we assess the ability of a kilobot robot swarm to replicate this captivating example of collective decision-making. Honeybees locate the optimal site for their new nest by aggregating information about potential locations and exchanging it through their waggle-dance. The complexity and elegance of solving this problem relies on two key abilities of scout honeybees: self-discovery and imitation, symbolizing independence and interdependence, respectively. We employ a mathematical model to represent this nest-site selection problem and program our kilobots to follow its rules. Our experiments demonstrate that the kilobot swarm can collectively reach consensus decisions in a decentralized manner, akin to honeybees. However, the strength of this consensus depends not only on the interplay between independence and interdependence but also on critical factors such as swarm density and the motion of kilobots. These factors enable the formation of a percolated communication network, through which each robot can receive information beyond its immediate vicinity. By shedding light on this crucial layer of complexity --the crowding and mobility conditions during the decision-making--, we emphasize the significance of factors typically overlooked but essential to living systems and life itself.	cond-mat.dis-nn	19 pages, 8 figures, 6 appendix figures, 3 supplementary figures
5	Facial Data Minimization: Shallow Model as Your Privacy Filter	Yuwen Pu,Jiahao Chen,Jiayu Pan,Hao li,Diqun Yan,Xuhong Zhang,Shouling Ji	Face recognition service has been used in many fields and brings much convenience to people. However, once the user's facial data is transmitted to a service provider, the user will lose control of his/her private data. In recent years, there exist various security and privacy issues due to the leakage of facial data. Although many privacy-preserving methods have been proposed, they usually fail when they are not accessible to adversaries' strategies or auxiliary data. Hence, in this paper, by fully considering two cases of uploading facial images and facial features, which are very typical in face recognition service systems, we proposed a data privacy minimization transformation (PMT) method. This method can process the original facial data based on the shallow model of authorized services to obtain the obfuscated data. The obfuscated data can not only maintain satisfactory performance on authorized models and restrict the performance on other unauthorized models but also prevent original privacy data from leaking by AI methods and human visual theft. Additionally, since a service provider may execute preprocessing operations on the received data, we also propose an enhanced perturbation method to improve the robustness of PMT. Besides, to authorize one facial image to multiple service models simultaneously, a multiple restriction mechanism is proposed to improve the scalability of PMT. Finally, we conduct extensive experiments and evaluate the effectiveness of the proposed PMT in defending against face reconstruction, data abuse, and face attribute estimation attacks. These experimental results demonstrate that PMT performs well in preventing facial data abuse and privacy leakage while maintaining face recognition accuracy.	cs.CR	14 pages, 11 figures
6	Feynman's inverse problem	Adrian Kirkeby	We analyse an inverse problem for water waves posed by Richard Feynman in the BBC documentary Fun to Imagine. The problem can be modelled as an inverse Cauchy problem for gravity-capillary waves on a bounded domain. We do a detailed analysis of the Cauchy problem and give a uniqueness proof for the inverse problem. This results, somewhat surprisingly, in a positive answer to Feynman's question. In addition, we derive stability estimates for the inverse problem both for continuous and discrete measurements, propose a simple inversion method and conduct numerical experiments to verify our results.	math.AP	None
7	ScanDL: A Diffusion Model for Generating Synthetic Scanpaths on Texts	Lena S. Bolliger,David R. Reich,Patrick Haller,Deborah N. Jakobi,Paul Prasse,Lena A. J√§ger	Eye movements in reading play a crucial role in psycholinguistic research studying the cognitive mechanisms underlying human language processing. More recently, the tight coupling between eye movements and cognition has also been leveraged for language-related machine learning tasks such as the interpretability, enhancement, and pre-training of language models, as well as the inference of reader- and text-specific properties. However, scarcity of eye movement data and its unavailability at application time poses a major challenge for this line of research. Initially, this problem was tackled by resorting to cognitive models for synthesizing eye movement data. However, for the sole purpose of generating human-like scanpaths, purely data-driven machine-learning-based methods have proven to be more suitable. Following recent advances in adapting diffusion processes to discrete data, we propose ScanDL, a novel discrete sequence-to-sequence diffusion model that generates synthetic scanpaths on texts. By leveraging pre-trained word representations and jointly embedding both the stimulus text and the fixation sequence, our model captures multi-modal interactions between the two inputs. We evaluate ScanDL within- and across-dataset and demonstrate that it significantly outperforms state-of-the-art scanpath generation methods. Finally, we provide an extensive psycholinguistic analysis that underlines the model's ability to exhibit human-like reading behavior. Our implementation is made available at https://github.com/DiLi-Lab/ScanDL.	cs.CL	EMNLP 2023
8	Detecting Intentional AIS Shutdown in Open Sea Maritime Surveillance Using Self-Supervised Deep Learning	Pierre Bernab√©,Arnaud Gotlieb,Bruno Legeard,Dusica Marijan,Frank Olaf Sem-Jacobsen,Helge Spieker	In maritime traffic surveillance, detecting illegal activities, such as illegal fishing or transshipment of illicit products is a crucial task of the coastal administration. In the open sea, one has to rely on Automatic Identification System (AIS) message transmitted by on-board transponders, which are captured by surveillance satellites. However, insincere vessels often intentionally shut down their AIS transponders to hide illegal activities. In the open sea, it is very challenging to differentiate intentional AIS shutdowns from missing reception due to protocol limitations, bad weather conditions or restricting satellite positions. This paper presents a novel approach for the detection of abnormal AIS missing reception based on self-supervised deep learning techniques and transformer models. Using historical data, the trained model predicts if a message should be received in the upcoming minute or not. Afterwards, the model reports on detected anomalies by comparing the prediction with what actually happens. Our method can process AIS messages in real-time, in particular, more than 500 Millions AIS messages per month, corresponding to the trajectories of more than 60 000 ships. The method is evaluated on 1-year of real-world data coming from four Norwegian surveillance satellites. Using related research results, we validated our method by rediscovering already detected intentional AIS shutdowns.	cs.LG	IEEE Transactions on Intelligent Transportation Systems
9	Multimodal Representations for Teacher-Guided Compositional Visual Reasoning	Wafa Aissa,Marin Ferecatu,Michel Crucianu	Neural Module Networks (NMN) are a compelling method for visual question answering, enabling the translation of a question into a program consisting of a series of reasoning sub-tasks that are sequentially executed on the image to produce an answer. NMNs provide enhanced explainability compared to integrated models, allowing for a better understanding of the underlying reasoning process. To improve the effectiveness of NMNs we propose to exploit features obtained by a large-scale cross-modal encoder. Also, the current training approach of NMNs relies on the propagation of module outputs to subsequent modules, leading to the accumulation of prediction errors and the generation of false answers. To mitigate this, we introduce an NMN learning strategy involving scheduled teacher guidance. Initially, the model is fully guided by the ground-truth intermediate outputs, but gradually transitions to an autonomous behavior as training progresses. This reduces error accumulation, thus improving training efficiency and final performance.We demonstrate that by incorporating cross-modal features and employing more effective training techniques for NMN, we achieve a favorable balance between performance and transparency in the reasoning process.	cs.CL	None
0	Accelerating Split Federated Learning over Wireless Communication Networks	Ce Xu,Jinxuan Li,Yuan Liu,Yushi Ling,Miaowen Wen	The development of artificial intelligence (AI) provides opportunities for the promotion of deep neural network (DNN)-based applications. However, the large amount of parameters and computational complexity of DNN makes it difficult to deploy it on edge devices which are resource-constrained. An efficient method to address this challenge is model partition/splitting, in which DNN is divided into two parts which are deployed on device and server respectively for co-training or co-inference. In this paper, we consider a split federated learning (SFL) framework that combines the parallel model training mechanism of federated learning (FL) and the model splitting structure of split learning (SL). We consider a practical scenario of heterogeneous devices with individual split points of DNN. We formulate a joint problem of split point selection and bandwidth allocation to minimize the system latency. By using alternating optimization, we decompose the problem into two sub-problems and solve them optimally. Experiment results demonstrate the superiority of our work in latency reduction and accuracy improvement.	cs.LG	None
1	SecV: Secure Code Partitioning via Multi-Language Secure Values	Peterson Yuhala,Pascal Felber,Hugo Guiroux,Jean-Pierre Lozi,Alain Tchana,Valerio Schiavoni,Ga√´l Thomas	Trusted execution environments like Intel SGX provide \emph{enclaves}, which offer strong security guarantees for applications. Running entire applications inside enclaves is possible, but this approach leads to a large trusted computing base (TCB). As such, various tools have been developed to partition programs written in languages such as C or Java into \emph{trusted} and \emph{untrusted} parts, which are run in and out of enclaves respectively. However, those tools depend on language-specific taint-analysis and partitioning techniques. They cannot be reused for other languages and there is thus a need for tools that transcend this language barrier.   We address this challenge by proposing a multi-language technique to specify sensitive code or data, as well as a multi-language tool to analyse and partition the resulting programs for trusted execution environments like Intel SGX. We leverage GraalVM's Truffle framework, which provides a language-agnostic abstract syntax tree (AST) representation for programs, to provide special AST nodes called \emph{secure nodes} that encapsulate sensitive program information. Secure nodes can easily be embedded into the ASTs of a wide range of languages via Truffle's \emph{polyglot API}. Our technique includes a multi-language dynamic taint tracking tool to analyse and partition applications based on our generic secure nodes. Our extensive evaluation with micro- and macro-benchmarks shows that we can use our technique for two languages (Javascript and \python), and that partitioned programs can obtain up to $14.5\%$ performance improvement as compared to unpartitioned versions.	cs.CR	12 pages
2	Deep ReLU neural networks overcome the curse of dimensionality in the numerical approximation of semilinear partial integro-differential equations	Ariel Neufeld,Tuan Anh Nguyen,Sizhou Wu	We prove that deep neural networks with ReLU activation function are capable of approximating solutions of semilinear partial integro-differential equations in the case of gradient-independent and Lipschitz-continuous nonlinearities, while the required number of parameters in the neural networks grows at most polynomially in both the dimension $ d\in\mathbb{N} $ and the reciprocal of the prescribed accuracy $ \epsilon $.	math.NA	arXiv admin note: text overlap with arXiv:2205.14398 by other authors
3	Identifiable Latent Polynomial Causal Models Through the Lens of Change	Yuhang Liu,Zhen Zhang,Dong Gong,Mingming Gong,Biwei Huang,Anton van den Hengel,Kun Zhang,Javen Qinfeng Shi	Causal representation learning aims to unveil latent high-level causal representations from observed low-level data. One of its primary tasks is to provide reliable assurance of identifying these latent causal models, known as identifiability. A recent breakthrough explores identifiability by leveraging the change of causal influences among latent causal variables across multiple environments \citep{liu2022identifying}. However, this progress rests on the assumption that the causal relationships among latent causal variables adhere strictly to linear Gaussian models. In this paper, we extend the scope of latent causal models to involve nonlinear causal relationships, represented by polynomial models, and general noise distributions conforming to the exponential family. Additionally, we investigate the necessity of imposing changes on all causal parameters and present partial identifiability results when part of them remains unchanged. Further, we propose a novel empirical estimation method, grounded in our theoretical finding, that enables learning consistent latent causal representations. Our experimental results, obtained from both synthetic and real-world data, validate our theoretical contributions concerning identifiability and consistency.	cs.LG	None
4	CONTRASTE: Supervised Contrastive Pre-training With Aspect-based Prompts For Aspect Sentiment Triplet Extraction	Rajdeep Mukherjee,Nithish Kannen,Saurabh Kumar Pandey,Pawan Goyal	Existing works on Aspect Sentiment Triplet Extraction (ASTE) explicitly focus on developing more efficient fine-tuning techniques for the task. Instead, our motivation is to come up with a generic approach that can improve the downstream performances of multiple ABSA tasks simultaneously. Towards this, we present CONTRASTE, a novel pre-training strategy using CONTRastive learning to enhance the ASTE performance. While we primarily focus on ASTE, we also demonstrate the advantage of our proposed technique on other ABSA tasks such as ACOS, TASD, and AESC. Given a sentence and its associated (aspect, opinion, sentiment) triplets, first, we design aspect-based prompts with corresponding sentiments masked. We then (pre)train an encoder-decoder model by applying contrastive learning on the decoder-generated aspect-aware sentiment representations of the masked terms. For fine-tuning the model weights thus obtained, we then propose a novel multi-task approach where the base encoder-decoder model is combined with two complementary modules, a tagging-based Opinion Term Detector, and a regression-based Triplet Count Estimator. Exhaustive experiments on four benchmark datasets and a detailed ablation study establish the importance of each of our proposed components as we achieve new state-of-the-art ASTE results.	cs.CL	Accepted as a Long Paper at EMNLP 2023 (Findings); 16 pages; Codes:   https://github.com/nitkannen/CONTRASTE/
5	A Near-Quadratic Sample Complexity Reduction for Agnostic Learning via Quantum Algorithms	Daniel Z. Zanger	Using quantum algorithms, we obtain, for accuracy $\epsilon,0<\epsilon<1/4$ and confidence $1-\delta,0<\delta <1,$ a new sample complexity upper bound of $O((\mbox{log}(\frac{1}{\delta}))/\epsilon)$ as $\epsilon,\delta\rightarrow 0$ (up to a polylogarithmic factor in $\epsilon^{-1}$) for a general agnostic learning model, provided the hypothesis class is of finite cardinality. This greatly improves upon a corresponding sample complexity of asymptotic order $\Theta((\mbox{log}(\frac{1}{\delta}))/\epsilon^{2})$ known in the literature to be attainable by means of classical (non-quantum) algorithms for an agnostic learning problem also with hypothesis set of finite cardinality (see, for example, Arunachalam and de Wolf (2018) and the classical statistical learning theory references cited there). Thus, for general agnostic learning, the quantum speedup in the rate of learning that we achieve is quadratic in $\epsilon^{-1}$ (up to a polylogarithmic factor).	quant-ph	None
6	POE: Process of Elimination for Multiple Choice Reasoning	Chenkai Ma,Xinya Du	Language models (LMs) are capable of conducting in-context learning for multiple choice reasoning tasks, but the options in these tasks are treated equally. As humans often first eliminate wrong options before picking the final correct answer, we argue a similar two-step strategy can make LMs better at these tasks. To this end, we present the Process of Elimination (POE), a two-step scoring method. In the first step, POE scores each option, and eliminates seemingly wrong options. In the second step, POE masks these wrong options, and makes the final prediction from the remaining options. Zero-shot experiments on 8 reasoning tasks illustrate the effectiveness of POE, and a following analysis finds our method to be especially performant on logical reasoning tasks. We further analyze the effect of masks, and show that POE applies to few-shot settings and large language models (LLMs) like ChatGPT.	cs.CL	Accepted as a short paper at EMNLP 2023
7	Natural Language Processing for Drug Discovery Knowledge Graphs: promises and pitfalls	J. Charles G. Jeynes,Tim James,Matthew Corney	Building and analysing knowledge graphs (KGs) to aid drug discovery is a topical area of research. A salient feature of KGs is their ability to combine many heterogeneous data sources in a format that facilitates discovering connections. The utility of KGs has been exemplified in areas such as drug repurposing, with insights made through manual exploration and modelling of the data. In this article, we discuss promises and pitfalls of using natural language processing (NLP) to mine unstructured text typically from scientific literature as a data source for KGs. This draws on our experience of initially parsing structured data sources such as ChEMBL as the basis for data within a KG, and then enriching or expanding upon them using NLP. The fundamental promise of NLP for KGs is the automated extraction of data from millions of documents a task practically impossible to do via human curation alone. However, there are many potential pitfalls in NLP-KG pipelines such as incorrect named entity recognition and ontology linking all of which could ultimately lead to erroneous inferences and conclusions.	cs.CL	17 pages, 7 figures
8	Visually Grounded Continual Language Learning with Selective Specialization	Kyra Ahrens,Lennart Bengtson,Jae Hee Lee,Stefan Wermter	A desirable trait of an artificial agent acting in the visual world is to continually learn a sequence of language-informed tasks while striking a balance between sufficiently specializing in each task and building a generalized knowledge for transfer. Selective specialization, i.e., a careful selection of model components to specialize in each task, is a strategy to provide control over this trade-off. However, the design of selection strategies requires insights on the role of each model component in learning rather specialized or generalizable representations, which poses a gap in current research. Thus, our aim with this work is to provide an extensive analysis of selection strategies for visually grounded continual language learning. Due to the lack of suitable benchmarks for this purpose, we introduce two novel diagnostic datasets that provide enough control and flexibility for a thorough model analysis. We assess various heuristics for module specialization strategies as well as quantifiable measures for two different types of model architectures. Finally, we design conceptually simple approaches based on our analysis that outperform common continual learning baselines. Our results demonstrate the need for further efforts towards better aligning continual learning algorithms with the learning behaviors of individual model parts.	cs.CL	Accepted to EMNLP 2023 Findings
9	MuLMS: A Multi-Layer Annotated Text Corpus for Information Extraction in the Materials Science Domain	Timo Pierre Schrader,Matteo Finco,Stefan Gr√ºnewald,Felix Hildebrand,Annemarie Friedrich	Keeping track of all relevant recent publications and experimental results for a research area is a challenging task. Prior work has demonstrated the efficacy of information extraction models in various scientific areas. Recently, several datasets have been released for the yet understudied materials science domain. However, these datasets focus on sub-problems such as parsing synthesis procedures or on sub-domains, e.g., solid oxide fuel cells. In this resource paper, we present MuLMS, a new dataset of 50 open-access articles, spanning seven sub-domains of materials science. The corpus has been annotated by domain experts with several layers ranging from named entities over relations to frame structures. We present competitive neural models for all tasks and demonstrate that multi-task training with existing related resources leads to benefits.	cs.CL	"17 pages, 2 figures, 28 tables, to be published in ""Proceedings of   the second Workshop on Information Extraction from Scientific Publications"""
0	I$^2$MD: 3D Action Representation Learning with Inter- and Intra-modal Mutual Distillation	Yunyao Mao,Jiajun Deng,Wengang Zhou,Zhenbo Lu,Wanli Ouyang,Houqiang Li	Recent progresses on self-supervised 3D human action representation learning are largely attributed to contrastive learning. However, in conventional contrastive frameworks, the rich complementarity between different skeleton modalities remains under-explored. Moreover, optimized with distinguishing self-augmented samples, models struggle with numerous similar positive instances in the case of limited action categories. In this work, we tackle the aforementioned problems by introducing a general Inter- and Intra-modal Mutual Distillation (I$^2$MD) framework. In I$^2$MD, we first re-formulate the cross-modal interaction as a Cross-modal Mutual Distillation (CMD) process. Different from existing distillation solutions that transfer the knowledge of a pre-trained and fixed teacher to the student, in CMD, the knowledge is continuously updated and bidirectionally distilled between modalities during pre-training. To alleviate the interference of similar samples and exploit their underlying contexts, we further design the Intra-modal Mutual Distillation (IMD) strategy, In IMD, the Dynamic Neighbors Aggregation (DNA) mechanism is first introduced, where an additional cluster-level discrimination branch is instantiated in each modality. It adaptively aggregates highly-correlated neighboring features, forming local cluster-level contrasting. Mutual distillation is then performed between the two branches for cross-level knowledge exchange. Extensive experiments on three datasets show that our approach sets a series of new records.	cs.CV	submitted to IJCV. arXiv admin note: substantial text overlap with   arXiv:2208.12448
1	Reconfigurable Intelligent Surface-Based Receive Generalized Spatial Modulation Design	Xinghao Guo,Hanjiang Hong,Yin Xu,Yi-yan Wu,Dazhi He,Wenjun Zhang	In this paper, the receive generalized spatial modulation (RGSM) scheme with reconfigurable intelligent surfaces (RIS) assistance is proposed. The RIS group controllers change the reflected phases of the RIS elements to achieve the selection of receive antennas and phase shift keying (PSK) modulation, and the amplitudes of the received symbols are adjusted by changing the activation states of the elements to achieve amplitude phase shift keying (APSK) modulation. Compared with the existing RIS-aided receive generalized space shift keying (RIS-RGSSK) scheme, the proposed scheme realizes that the selected antennas respectively receive different modulation symbols, and only adds the process to control the modulated phases and the activation states of elements. The proposed scheme has better bit error rate (BER) performance than the RIS-RGSSK scheme at the same rate. In addition, the results show that for low modulation orders, the proposed scheme will perform better with PSK, while for high modulation order, APSK is better. The proposed scheme is a promising scheme for future wireless communication to achieve high-efficiency.	cs.IT	6 pages, conference
2	Cartan subgroups in connected locally compact groups	Arunava Mandal,Riddhi Shah	"We define Cartan subgroups in connected locally compact groups, which extends the classical notion of Cartan subgroups in Lie groups. We prove their existence and justify our choice of the definition which differs from the one given by Chevalley on general groups. Apart from proving some properties of Cartan subgroups, we show that the Cartan subgroups of the quotient groups are precisely the images of Cartan subgroups of the ambient group. We establish the so-called `Levi' decomposition of Cartan subgroups which extends W\""ustner's decomposition theorem and our earlier results about the same proven for Lie groups. We also show that the centraliser of any maximal torus of the radical is connected and its Cartan subgroups are also the Cartan subgroup of the ambient group; moreover, every Cartan subgroup arises this way. We prove that Cartan subalgebras defined by Hofmann and Morris in pro-Lie algebras are the same as those corresponding to Cartan subgroups in case of pro-Lie algebras of connected locally compact groups, and that they are nilpotent. We characterise density of the image of a power map in the group in terms of its surjectivity on all Cartan subgroups, and show that weak exponentiality of the group is equivalent to the condition that all its Cartan subgroups are connected."	math.GR	33 pages
3	Label-free Imaging of Catalytic H2O2 Decomposition on Single Colloidal Pt Nanoparticles using Nanofluidic Scattering Microscopy	Bj√∂rn Altenburger,Carl Andersson,Sune Levin,Fredrik Westerlund,Joachim Fritzsche,Christoph Langhammer	Single particle catalysis aims at determining factors that dictate nanoparticle activity and selectivity. Existing methods often use fluorescent model reactions at low reactant concentrations, operate at low pressures, or rely on plasmonic enhancement effects. Hence, methods to measure single nanoparticle activity at technically relevant conditions, and without fluorescence or other enhancement mechanisms, are still lacking. Here, we introduce nanofluidic scattering microscopy to fill this gap. By detecting minuscule refractive index changes in a liquid flushed through a nanochannel, we demonstrate that local H2O2 concentration changes in water can be accurately measured. Applying this principle, we analyze the H2O2 concentration profiles adjacent to single colloidal Pt nanoparticles during catalytic H2O2 decomposition into O2 and H2O and derive the particles individual turnover frequencies from the growth rate of O2 gas bubbles formed in their respective nanochannel during reaction.	physics.chem-ph	None
4	Uniform ergodicity and the one-sided ergodic Hilbert transform	Guy Cohen,Michael Lin	Let $T$ be a bounded linear operator on a Banach space $X$ satisfying $\|T^n\|/n \to 0$. We prove that $T$ is uniformly ergodic if and only if the one-sided ergodic Hilbert transform $H_Tx:= \lim_{n\to\infty} \sum_{k=1}^n k^{-1}T^k x$ converges for every $x \in \overline{(I-T)X}$. When $T$ is power-bounded (or more generally $(C,\alpha)$ bounded for some $0< \alpha <1$), then $T$ is uniformly ergodic if and only if the domain of $H_T$ equals $(I-T)X$. We then study rotational uniform ergodicity -- uniform ergodicity of every $\lambda T$ with $|\lambda|=1$, and connect it to convergence of the rotated one-sided ergodic Hilbert transform, $H_{\lambda T}x$.   In the Appendix we prove that positive isometries with finite-dimensional fixed space on infinite-dimensional Banach lattices are never uniformly ergodic. In particular, the Koopman operators of ergodic, even non-invertible, probability preserving transformations on standard spaces are never uniformly ergodic.	math.DS	17 pages
5	Modeling and Design of the Communication Sensing and Control Coupled Closed-Loop Industrial System	Zeyang Meng,Dingyou Ma,Shengfeng Wang,Zhiqing Wei,Zhiyong Feng	With the advent of 5G era, factories are transitioning towards wireless networks to break free from the limitations of wired networks. In 5G-enabled factories, unmanned automatic devices such as automated guided vehicles and robotic arms complete production tasks cooperatively through the periodic control loops. In such loops, the sensing data is generated by sensors, and transmitted to the control center through uplink wireless communications. The corresponding control commands are generated and sent back to the devices through downlink wireless communications. Since wireless communications, sensing and control are tightly coupled, there are big challenges on the modeling and design of such closed-loop systems. In particular, existing theoretical tools of these functionalities have different modelings and underlying assumptions, which make it difficult for them to collaborate with each other. Therefore, in this paper, an analytical closed-loop model is proposed, where the performances and resources of communication, sensing and control are deeply related. To achieve the optimal control performance, a co-design of communication resource allocation and control method is proposed, inspired by the model predictive control algorithm. Numerical results are provided to demonstrate the relationships between the resources and control performances.	cs.PF	6 pages, 3 figures, received by GlobeCom 2023
6	Quantum geometry encoded to pair potentials	Akito Daido,Taisei Kitamura,Youichi Yanase	Bloch wave functions of electrons have properties called quantum geometry, which has recently attracted much attention as the origin of intriguing physical phenomena. In this paper, we introduce the notion of the quantum-geometric pair potentials (QGPP) based on the generalized band representation and thereby clarify how the quantum geometry of electrons is transferred to the Cooper pairs they form. QGPP quantifies the deviation of multiband superconductors from an assembly of single-band superconductors and has a direct connection to the quantum-geometric corrections to thermodynamic coefficients. We also discuss their potential ability to emulate exotic pair potentials and engineer intriguing superconducting phenomena including topological superconductivity.	cond-mat.supr-con	9 pages, 2 figures (+9 pages)
7	TCRA-LLM: Token Compression Retrieval Augmented Large Language Model for Inference Cost Reduction	Junyi Liu,Liangzhi Li,Tong Xiang,Bowen Wang,Yiming Qian	Since ChatGPT released its API for public use, the number of applications built on top of commercial large language models (LLMs) increase exponentially. One popular usage of such models is leveraging its in-context learning ability and generating responses given user queries leveraging knowledge obtained by retrieval augmentation. One problem of deploying commercial retrieval-augmented LLMs is the cost due to the additionally retrieved context that largely increases the input token size of the LLMs. To mitigate this, we propose a token compression scheme that includes two methods: summarization compression and semantic compression. The first method applies a T5-based model that is fine-tuned by datasets generated using self-instruct containing samples with varying lengths and reduce token size by doing summarization. The second method further compresses the token size by removing words with lower impact on the semantic. In order to adequately evaluate the effectiveness of the proposed methods, we propose and utilize a dataset called Food-Recommendation DB (FRDB) focusing on food recommendation for women around pregnancy period or infants. Our summarization compression can reduce 65% of the retrieval token size with further 0.3% improvement on the accuracy; semantic compression provides a more flexible way to trade-off the token size with performance, for which we can reduce the token size by 20% with only 1.6% of accuracy drop.	cs.CL	EMNLP 2023 Findings
8	Transfer learning for day-ahead load forecasting: a case study on European national electricity demand time series	Alexandros-Menelaos Tzortzis,Sotiris Pelekis,Evangelos Spiliotis,Spiros Mouzakitis,John Psarras,Dimitris Askounis	Short-term load forecasting (STLF) is crucial for the daily operation of power grids. However, the non-linearity, non-stationarity, and randomness characterizing electricity demand time series renders STLF a challenging task. Various forecasting approaches have been proposed for improving STLF, including neural network (NN) models which are trained using data from multiple electricity demand series that may not necessary include the target series. In the present study, we investigate the performance of this special case of STLF, called transfer learning (TL), by considering a set of 27 time series that represent the national day-ahead electricity demand of indicative European countries. We employ a popular and easy-to-implement NN model and perform a clustering analysis to identify similar patterns among the series and assist TL. In this context, two different TL approaches, with and without the clustering step, are compiled and compared against each other as well as a typical NN training setup. Our results demonstrate that TL can outperform the conventional approach, especially when clustering techniques are considered.	cs.LG	None
9	A general center manifold theorem on fields of Banach spaces	Mazyar Ghani Varzaneh,Sebastian Riedel	A general local center manifold theorem around stationary trajectories is proved for nonlinear cocycles acting on measurable fields of Banach spaces.	math.PR	None
0	Unveiling Multilinguality in Transformer Models: Exploring Language Specificity in Feed-Forward Networks	Sunit Bhattacharya,Ondrej Bojar	Recent research suggests that the feed-forward module within Transformers can be viewed as a collection of key-value memories, where the keys learn to capture specific patterns from the input based on the training examples. The values then combine the output from the 'memories' of the keys to generate predictions about the next token. This leads to an incremental process of prediction that gradually converges towards the final token choice near the output layers. This interesting perspective raises questions about how multilingual models might leverage this mechanism. Specifically, for autoregressive models trained on two or more languages, do all neurons (across layers) respond equally to all languages? No! Our hypothesis centers around the notion that during pretraining, certain model parameters learn strong language-specific features, while others learn more language-agnostic (shared across languages) features. To validate this, we conduct experiments utilizing parallel corpora of two languages that the model was initially pretrained on. Our findings reveal that the layers closest to the network's input or output tend to exhibit more language-specific behaviour compared to the layers in the middle.	cs.CL	None
1	Universal bifurcations to explosive synchronization for networks of coupled oscillators with higher-order interactions	Lauren D Smith,Penghao Liu	We determine critical parameter sets for transitions from gradual to explosive synchronization in coupled oscillator networks with higher-order coupling using self-consistency analysis. We obtain analytic bifurcation values for generic symmetric natural frequency distributions. We show that non-synchronized, drifting, oscillators are non-negligible, and play a crucial role in bifurcation. As such, the entire natural frequency distribution must be accounted for, rather than just the shape at the center. We verify our results for Lorentzian and Gaussian distributed natural frequencies.	nlin.AO	None
2	PET Synthesis via Self-supervised Adaptive Residual Estimation Generative Adversarial Network	Yuxin Xue,Lei Bi,Yige Peng,Michael Fulham,David Dagan Feng,Jinman Kim	Positron emission tomography (PET) is a widely used, highly sensitive molecular imaging in clinical diagnosis. There is interest in reducing the radiation exposure from PET but also maintaining adequate image quality. Recent methods using convolutional neural networks (CNNs) to generate synthesized high-quality PET images from low-dose counterparts have been reported to be state-of-the-art for low-to-high image recovery methods. However, these methods are prone to exhibiting discrepancies in texture and structure between synthesized and real images. Furthermore, the distribution shift between low-dose PET and standard PET has not been fully investigated. To address these issues, we developed a self-supervised adaptive residual estimation generative adversarial network (SS-AEGAN). We introduce (1) An adaptive residual estimation mapping mechanism, AE-Net, designed to dynamically rectify the preliminary synthesized PET images by taking the residual map between the low-dose PET and synthesized output as the input, and (2) A self-supervised pre-training strategy to enhance the feature representation of the coarse generator. Our experiments with a public benchmark dataset of total-body PET images show that SS-AEGAN consistently outperformed the state-of-the-art synthesis methods with various dose reduction factors.	eess.IV	This work has been submitted to the IEEE for possible publication.   Copyright may be transferred without notice, after which this version may no   longer be accessible
3	Algorithmic Regularization in Tensor Optimization: Towards a Lifted Approach in Matrix Sensing	Ziye Ma,Javad Lavaei,Somayeh Sojoudi	Gradient descent (GD) is crucial for generalization in machine learning models, as it induces implicit regularization, promoting compact representations. In this work, we examine the role of GD in inducing implicit regularization for tensor optimization, particularly within the context of the lifted matrix sensing framework. This framework has been recently proposed to address the non-convex matrix sensing problem by transforming spurious solutions into strict saddles when optimizing over symmetric, rank-1 tensors. We show that, with sufficiently small initialization scale, GD applied to this lifted problem results in approximate rank-1 tensors and critical points with escape directions. Our findings underscore the significance of the tensor parametrization of matrix sensing, in combination with first-order methods, in achieving global optimality in such problems.	math.OC	NeurIPS23 Poster
4	Knowledge-driven Meta-learning for CSI Feedback	Han Xiao,Wenqiang Tian,Wendong Liu,Jiajia Guo,Zhi Zhang,Shi Jin,Zhihua Shi,Li Guo,Jia Shen	Accurate and effective channel state information (CSI) feedback is a key technology for massive multiple-input and multiple-output systems. Recently, deep learning (DL) has been introduced for CSI feedback enhancement through massive collected training data and lengthy training time, which is quite costly and impractical for realistic deployment. In this article, a knowledge-driven meta-learning approach is proposed, where the DL model initialized by the meta model obtained from meta training phase is able to achieve rapid convergence when facing a new scenario during target retraining phase. Specifically, instead of training with massive data collected from various scenarios, the meta task environment is constructed based on the intrinsic knowledge of spatial-frequency characteristics of CSI for meta training. Moreover, the target task dataset is also augmented by exploiting the knowledge of statistical characteristics of wireless channel, so that the DL model can achieve higher performance with small actually collected dataset and short training time. In addition, we provide analyses of rationale for the improvement yielded by the knowledge in both phases. Simulation results demonstrate the superiority of the proposed approach from the perspective of feedback performance and convergence speed.	eess.SP	arXiv admin note: text overlap with arXiv:2301.13475
5	Robust and Deterministic Preparation of Bosonic Logical States in a Trapped Ion	V. G. Matsos,C. H. Valahu,T. Navickas,A. D. Rao,M. J. Millican,M. J. Biercuk,T. R. Tan	Encoding logical qubits in bosonic modes provides a potentially hardware-efficient implementation of fault-tolerant quantum information processing. Recent advancements in trapped ions and superconducting microwave cavities have led to experimental realizations of high-quality bosonic states and demonstrations of error-corrected logical qubits encoded in bosonic modes. However, current protocols for preparing bosonic code words lack robustness to common noise sources and can be experimentally challenging to implement, limiting the quality and breadth of codes that have been realized to date. Here, we combine concepts of error suppression via robust control with quantum error correction encoding and experimentally demonstrate high-fidelity, deterministic preparation of highly non-classical target bosonic states in the mechanical motion of a trapped ion. Our approach implements numerically optimized dynamical modulation of laser-driven spin-motion interactions to generate the target state in a single step. The optimized control pulses are tailored towards experimental constraints and are designed to be robust against the dominant source of error. Using these protocols, we demonstrate logical fidelities for the Gottesman-Kitaev-Preskill (GKP) state as high as $\bar{\mathcal{F}}=0.940(8)$, achieve the first realization of a distance-3 binomial logical state with an average fidelity of $\mathcal{F}=0.807(7)$, and demonstrate a 12.91(5) dB squeezed vacuum state.	quant-ph	12 pages, 8 figures
6	Infinite product formulae for semilocal Solomon zeta functions	Sean B. Lynch	Lustig gave an infinite product formula for the zeta function of a commutative two-dimensional regular local ring with finite residue field. We extend this to the noncommutative setting with a method based on filtration by an invertible ideal. Our main formula may be viewed as a two-dimensional analogue of Hey's formula. In fact, upon revisiting Solomon's proof of Hey's formula, we find that our main two-dimensional zeta functions depend only on Artin-Wedderburn data for the top. This applies to zeta functions of local models for terminal orders on arithmetic surfaces, and we even suggest an analogy between our main formula and the Gottsche-Larsen-Lunts formula for the generating function of Hilbert schemes of a smooth surface. Our method gives us a more general and complicated formula than our main formula. It does, however, simplify to a general principle about the extent to which the zeta function of a module is determined by the module modulo an invertible ideal. The general formula also gives us a weird identity involving q-binomial coefficients.	math.NT	24 pages
7	Asymptotic tracking by funnel control with internal models	Thomas Berger,Christoph M. Hackl,Stephan Trenn	Funnel control achieves output tracking with guaranteed tracking performance for unknown systems and arbitrary reference signals. In particular, the tracking error is guaranteed to satisfy time-varying error bounds for all times (it evolves in the funnel). However, convergence to zero cannot be guaranteed, but the error often stays close to the funnel boundary, inducing a comparatively large feedback gain. This has several disadvantages (e.g. poor tracking performance and sensitivity to noise due to the underlying high-gain feedback principle). In this paper, therefore, the usually known reference signal is taken into account during funnel controller design, i.e. we propose to combine the well-known internal model principle with funnel control. We focus on linear systems with linear reference internal models and show that under mild adjustments of funnel control, we can achieve asymptotic tracking for a whole class of linear systems (i.e. without relying on the knowledge of system parameters).	math.OC	None
8	Segue: Side-information Guided Generative Unlearnable Examples for Facial Privacy Protection in Real World	Zhiling Zhang,Jie Zhang,Kui Zhang,Wenbo Zhou,Weiming Zhang,Nenghai Yu	"The widespread use of face recognition technology has given rise to privacy concerns, as many individuals are worried about the collection and utilization of their facial data. To address these concerns, researchers are actively exploring the concept of ``unlearnable examples"", by adding imperceptible perturbation to data in the model training stage, which aims to prevent the model from learning discriminate features of the target face. However, current methods are inefficient and cannot guarantee transferability and robustness at the same time, causing impracticality in the real world. To remedy it, we propose a novel method called Segue: Side-information guided generative unlearnable examples. Specifically, we leverage a once-trained multiple-used model to generate the desired perturbation rather than the time-consuming gradient-based method. To improve transferability, we introduce side information such as true labels and pseudo labels, which are inherently consistent across different scenarios. For robustness enhancement, a distortion layer is integrated into the training pipeline. Extensive experiments demonstrate that the proposed Segue is much faster than previous methods (1000$\times$) and achieves transferable effectiveness across different datasets and model architectures. Furthermore, it can resist JPEG compression, adversarial training, and some standard data augmentations."	cs.CR	None
9	Symmetry-preserving graph attention network to solve routing problems at multiple resolutions	Cong Dao Tran,Thong Bach,Truong Son Hy	Travelling Salesperson Problems (TSPs) and Vehicle Routing Problems (VRPs) have achieved reasonable improvement in accuracy and computation time with the adaptation of Machine Learning (ML) methods. However, none of the previous works completely respects the symmetries arising from TSPs and VRPs including rotation, translation, permutation, and scaling. In this work, we introduce the first-ever completely equivariant model and training to solve combinatorial problems. Furthermore, it is essential to capture the multiscale structure (i.e. from local to global information) of the input graph, especially for the cases of large and long-range graphs, while previous methods are limited to extracting only local information that can lead to a local or sub-optimal solution. To tackle the above limitation, we propose a Multiresolution scheme in combination with Equivariant Graph Attention network (mEGAT) architecture, which can learn the optimal route based on low-level and high-level graph resolutions in an efficient way. In particular, our approach constructs a hierarchy of coarse-graining graphs from the input graph, in which we try to solve the routing problems on simple low-level graphs first, then utilize that knowledge for the more complex high-level graphs. Experimentally, we have shown that our model outperforms existing baselines and proved that symmetry preservation and multiresolution are important recipes for solving combinatorial problems in a data-driven manner. Our source code is publicly available at https://github.com/HySonLab/Multires-NP-hard	cs.LG	None
0	Improving Language Models Meaning Understanding and Consistency by Learning Conceptual Roles from Dictionary	Myeongjun Erik Jang,Thomas Lukasiewicz	The non-humanlike behaviour of contemporary pre-trained language models (PLMs) is a leading cause undermining their trustworthiness. A striking phenomenon of such faulty behaviours is the generation of inconsistent predictions, which produces logically contradictory results, such as generating different predictions for texts delivering the same meaning or violating logical properties. Previous studies exploited data augmentation or implemented specialised loss functions to alleviate the issue. However, their usage is limited, because they consume expensive training resources for large-sized PLMs and can only handle a certain consistency type. To this end, we propose a practical approach that alleviates the inconsistent behaviour issue by fundamentally improving PLMs' meaning awareness. Based on the conceptual role theory, our method allows PLMs to capture accurate meaning by learning precise interrelationships between concepts from word-definition pairs in a dictionary. Next, we propose an efficient parameter integration technique that updates only a few additional parameters to combine the learned interrelationship with PLMs' pre-trained knowledge. Our experimental results reveal that the approach can concurrently improve multiple types of consistency, enables efficient knowledge integration, and easily applies to other languages.	cs.CL	15 pages
1	Phase chimera states on non-local hyperrings	Riccardo Muolo,Thierry Njougouo,Lucia Valentina Gambuzza,Timoteo Carletti,Mattia Frasca	"Chimera states are dynamical states where regions of synchronous trajectories coexist with incoherent ones. A significant amount of research has been devoted to study chimera states in systems of identical oscillators, non-locally coupled through pairwise interactions. Nevertheless, there is an increasing evidence, also supported by available data, that complex systems are composed by multiple units experiencing many-body interactions, that can be modeled by using higher-order structures beyond the paradigm of classic pairwise networks. In this work we investigate whether phase chimera states appear in this framework, by focusing on a novel topology solely involving many-body, non-local and non-regular interactions, hereby named non-local d-hyperring, being (d+1) the order of the interactions. We present the theory by using the paradigmatic Stuart-Landau oscillators as node dynamics, and show that phase chimera states emerge in a variety of structures and with different coupling functions. For comparison, we show that, when higher-order interactions are ""flattened"" to pairwise ones, the chimera behavior is weaker and more elusive."	nlin.PS	None
2	SteloCoder: a Decoder-Only LLM for Multi-Language to Python Code Translation	Jialing Pan,Adrien Sad√©,Jin Kim,Eric Soriano,Guillem Sole,Sylvain Flamant	With the recent focus on Large Language Models (LLMs), both StarCoder (Li et al., 2023) and Code Llama (Rozi\`ere et al., 2023) have demonstrated remarkable performance in code generation. However, there is still a need for improvement in code translation functionality with efficient training techniques. In response to this, we introduce SteloCoder, a decoder-only StarCoder-based LLM designed specifically for multi-programming language-to-Python code translation. In particular, SteloCoder achieves C++, C#, JavaScript, Java, or PHP-to-Python code translation without specifying the input programming language. We modified StarCoder model architecture by incorporating a Mixture-of-Experts (MoE) technique featuring five experts and a gating network for multi-task handling. Experts are obtained by StarCoder fine-tuning. Specifically, we use a Low-Rank Adaptive Method (LoRA) technique, limiting each expert size as only 0.06% of number of StarCoder's parameters. At the same time, to enhance training efficiency in terms of time, we adopt curriculum learning strategy and use self-instruct data for efficient fine-tuning. As a result, each expert takes only 6 hours to train on one single 80Gb A100 HBM. With experiments on XLCoST datasets, SteloCoder achieves an average of 73.76 CodeBLEU score in multi-programming language-to-Python translation, surpassing the top performance from the leaderboard by at least 3.5. This accomplishment is attributed to only 45M extra parameters with StarCoder as the backbone and 32 hours of valid training on one 80GB A100 HBM. The source code is release here: https://github.com/sade-adrien/SteloCoder.	cs.CL	None
3	The three way Dirac operator and dynamical Turing and Dirac induced patterns on nodes and links	Riccardo Muolo,Timoteo Carletti,Ginestra Bianconi	Topological signals are dynamical variables not only defined on nodes but also on links of a network that are gaining significant attention in non-linear dynamics and topology and have important applications in brain dynamics. Here we show that topological signals on nodes and links of a network can generate dynamical patterns when coupled together. In particular, dynamical patterns require at least three topological signals, here taken to be two node signals and one link signal. In order to couple these signals, we formulate the 3-way topological Dirac operator that generalizes previous definitions of the 2-way and 4-way topological Dirac operators. We characterize the spectral properties of the 3-way Dirac operator and we investigate the dynamical properties of the resulting Turing and Dirac induced patterns. Here we emphasize the distinct dynamical properties of the Dirac induced patterns which involve topological signals only coupled by the 3-way topological Dirac operator in absence of the Hodge-Laplacian coupling. While the observed Turing patterns generalize the Turing patterns typically investigated on networks, the Dirac induced patterns have no equivalence within the framework of node based Turing patterns. These results open new scenarios in the study of Turing patterns with possible application to neuroscience and more generally to the study of emergent patterns in complex systems.	nlin.PS	None
4	Integrable (3+1)-dimensional generalization for dispersionless Davey--Stewartson system	Antonio J. Pan-Collantes	This paper introduces a (3+1)-dimensional dispersionless integrable system, utilizing a Lax pair involving contact vector fields, in alignment with methodologies presented by A. Sergyeyev in 2018. Significantly, it is shown that the proposed system serves as an integrable (3+1)-dimensional generalization of the well-studied (2+1)-dimensional dispersionless Davey-Stewartson system. This way, an interesting new example on integrability in higher dimensions is presented, with potential applications in modern mathematical physics. The work lays the foundation for future research into symmetries, conservation laws, and Hamiltonian structures, offering avenues for further exploration.	nlin.SI	None
5	Learning with Noisy Labels Using Collaborative Sample Selection and Contrastive Semi-Supervised Learning	Qing Miao,Xiaohe Wu,Chao Xu,Yanli Ji,Wangmeng Zuo,Yiwen Guo,Zhaopeng Meng	Learning with noisy labels (LNL) has been extensively studied, with existing approaches typically following a framework that alternates between clean sample selection and semi-supervised learning (SSL). However, this approach has a limitation: the clean set selected by the Deep Neural Network (DNN) classifier, trained through self-training, inevitably contains noisy samples. This mixture of clean and noisy samples leads to misguidance in DNN training during SSL, resulting in impaired generalization performance due to confirmation bias caused by error accumulation in sample selection. To address this issue, we propose a method called Collaborative Sample Selection (CSS), which leverages the large-scale pre-trained model CLIP. CSS aims to remove the mixed noisy samples from the identified clean set. We achieve this by training a 2-Dimensional Gaussian Mixture Model (2D-GMM) that combines the probabilities from CLIP with the predictions from the DNN classifier. To further enhance the adaptation of CLIP to LNL, we introduce a co-training mechanism with a contrastive loss in semi-supervised learning. This allows us to jointly train the prompt of CLIP and the DNN classifier, resulting in improved feature representation, boosted classification performance of DNNs, and reciprocal benefits to our Collaborative Sample Selection. By incorporating auxiliary information from CLIP and utilizing prompt fine-tuning, we effectively eliminate noisy samples from the clean set and mitigate confirmation bias during training. Experimental results on multiple benchmark datasets demonstrate the effectiveness of our proposed method in comparison with the state-of-the-art approaches.	cs.CV	None
6	Role of sea quarks in the nucleon transverse spin	Chunhua Zeng,Hongxin Dong,Tianbo Liu,Peng Sun,Yuxiang Zhao	We present a phenomenological extraction of transversity distribution functions and Collins fragmentation functions by simultaneously fitting to semi-inclusive deep inelastic scattering and electron-positron annihilation data. The analysis is performed within the transverse momentum dependent factorization formalism, and sea quark transversity distributions are taken into account for the first time. We find the $\bar u$ quark favors a negative transversity distribution while that of the $\bar d$ quark is consistent with zero according to the current accuracy. In addition, based on a combined analysis of world data and simulated data, we quantitatively demonstrate the impact of the proposed Electron-ion Collider in China on precise determinations of the transversity distributions, especially for sea quarks, and the Collins fragmentation functions.	hep-ph	None
7	Constraining exotic dark matter models with the dark ages 21-cm signal	Rajesh Mondal,Rennan Barkana,Anastasia Fialkov	The 21-cm signal from the dark ages is a powerful tool for fundamental cosmology and for probing new physics. While it can be used for precision measurements within standard cosmology, here we study two non-standard models: an excess radio background (ERB) model (possibly generated by dark matter decay) and the millicharged dark matter (mDM) model. These models were inspired by the possible EDGES detection of a strong global 21-cm absorption during cosmic dawn, but more generally they provide a way to anticipate the potential discovery space. We find that during the dark ages the 21-cm global signal in the ERB model reaches a saturated form for an amplitude $A_{\rm r}=0.4$, where $A_{\rm r}$ is the radio background intensity at cosmic dawn relative to the cosmic microwave background. This amplitude is one fifth of the minimum required to explain the EDGES signal, and corresponds to just 0.1\% of the observed extragalactic background; it would give a signal that can be detected at 5.9$\sigma$ significance (compared to 4.1$\sigma$ for the standard signal) and distinguished from the standard (no ERB) signal at 8.5$\sigma$, all with a 1,000 hour global signal measurement. A lower $A_{\rm r}=0.039$ could be distinguished at 5$\sigma$. The 21-cm power spectrum has potentially much more information, but far greater resources would be required for comparable constraints on the ERB signal. For the mDM model, over a range of viable parameters, the global signal detection significance would be $4.7-7.2\,\sigma$, and it could be distinguished from standard at $2.2-9.3\,\sigma$. With an array of global signal antennas achieving an effective 100,000 hr integration, the significance would be 10$\times$ better. Our analysis helps motivate the development of lunar and space-based dark ages experiments.	astro-ph.CO	11 pages, 11 figures, 8 tables, comments are welcome
8	Algebraic Sunflowers	Nathanael Ackerman,Mostafa Mirabi	We study sunflowers within the context of finitely generated substructures of ultrahomogeneous structures. In particular, we look at bounds on how large a set system is needed to guarantee the existence of sunflowers of a given size. We show that if we fix the size of the sunflower, the function which takes the size of the substructures in our set system and outputs the size of a set system needed to guarantee a sunflower of the desired size can grow arbitrarily slowly.	math.CO	None
9	Privacy Amplification for Matrix Mechanisms	Christopher A. Choquette-Choo,Arun Ganesh,Thomas Steinke,Abhradeep Thakurta	"Privacy amplification exploits randomness in data selection to provide tighter differential privacy (DP) guarantees. This analysis is key to DP-SGD's success in machine learning, but, is not readily applicable to the newer state-of-the-art algorithms. This is because these algorithms, known as DP-FTRL, use the matrix mechanism to add correlated noise instead of independent noise as in DP-SGD.   In this paper, we propose ""MMCC"", the first algorithm to analyze privacy amplification via sampling for any generic matrix mechanism. MMCC is nearly tight in that it approaches a lower bound as $\epsilon\to0$. To analyze correlated outputs in MMCC, we prove that they can be analyzed as if they were independent, by conditioning them on prior outputs. Our ""conditional composition theorem"" has broad utility: we use it to show that the noise added to binary-tree-DP-FTRL can asymptotically match the noise added to DP-SGD with amplification. Our amplification algorithm also has practical empirical utility: we show it leads to significant improvement in the privacy-utility trade-offs for DP-FTRL algorithms on standard benchmarks."	cs.LG	None
0	Optimization of process parameters in additive manufacturing based on the finite element method	Jingyi Wang,Panayiotis Papadopoulos	A design optimization framework for process parameters of additive manufacturing based on finite element simulation is proposed. The finite element method uses a coupled thermomechanical model developed for fused deposition modeling from the authors' previous work. Both gradient-based and gradient-free optimization methods are proposed. The gradient-based approach, which solves a PDE-constrained optimization problem, requires sensitivities computed from the fully discretized finite element model. We show the derivation of the sensitivities and apply them in a projected gradient descent algorithm. For the gradient-free approach, we propose two distinct algorithms: a local search algorithm called the method of local variations and a Bayesian optimization algorithm using Gaussian processes. To illustrate the effectiveness and differences of the methods, we provide two-dimensional design optimization examples using all three proposed algorithms.	math.NA	None
1	On the Inherent Privacy Properties of Discrete Denoising Diffusion Models	Rongzhe Wei,Eleonora Kreaƒçiƒá,Haoyu Wang,Haoteng Yin,Eli Chien,Vamsi K. Potluru,Pan Li	Privacy concerns have led to a surge in the creation of synthetic datasets, with diffusion models emerging as a promising avenue. Although prior studies have performed empirical evaluations on these models, there has been a gap in providing a mathematical characterization of their privacy-preserving capabilities. To address this, we present the pioneering theoretical exploration of the privacy preservation inherent in discrete diffusion models (DDMs) for discrete dataset generation. Focusing on per-instance differential privacy (pDP), our framework elucidates the potential privacy leakage for each data point in a given training dataset, offering insights into data preprocessing to reduce privacy risks of the synthetic dataset generation via DDMs. Our bounds also show that training with $s$-sized data points leads to a surge in privacy leakage from $(\epsilon, \mathcal{O}(\frac{1}{s^2\epsilon}))$-pDP to $(\epsilon, \mathcal{O}(\frac{1}{s\epsilon}))$-pDP during the transition from the pure noise to the synthetic clean data phase, and a faster decay in diffusion coefficients amplifies the privacy guarantee. Finally, we empirically verify our theoretical findings on both synthetic and real-world datasets.	cs.LG	None
2	Generative and Contrastive Paradigms Are Complementary for Graph Self-Supervised Learning	Yuxiang Wang,Xiao Yan,Chuang Hu,Fangcheng Fu,Wentao Zhang,Hao Wang,Shuo Shang,Jiawei Jiang	For graph self-supervised learning (GSSL), masked autoencoder (MAE) follows the generative paradigm and learns to reconstruct masked graph edges or node features. Contrastive Learning (CL) maximizes the similarity between augmented views of the same graph and is widely used for GSSL. However, MAE and CL are considered separately in existing works for GSSL. We observe that the MAE and CL paradigms are complementary and propose the graph contrastive masked autoencoder (GCMAE) framework to unify them. Specifically, by focusing on local edges or node features, MAE cannot capture global information of the graph and is sensitive to particular edges and features. On the contrary, CL excels in extracting global information because it considers the relation between graphs. As such, we equip GCMAE with an MAE branch and a CL branch, and the two branches share a common encoder, which allows the MAE branch to exploit the global information extracted by the CL branch. To force GCMAE to capture global graph structures, we train it to reconstruct the entire adjacency matrix instead of only the masked edges as in existing works. Moreover, a discrimination loss is proposed for feature reconstruction, which improves the disparity between node embeddings rather than reducing the reconstruction error to tackle the feature smoothing problem of MAE. We evaluate GCMAE on four popular graph tasks (i.e., node classification, node clustering, link prediction, and graph classification) and compare with 14 state-of-the-art baselines. The results show that GCMAE consistently provides good accuracy across these tasks, and the maximum accuracy improvement is up to 3.2% compared with the best-performing baseline.	cs.LG	None
3	Optimization of quantum noise in space gravitational-wave antenna DECIGO with optical-spring quantum locking considering mixture of vacuum fluctuations in homodyne detection	Kenji Tsuji,Tomohiro Ishikawa,Kentaro Komori,Koji Nagano,Yutaro Enomoto,Yuta Michimura,Kurumi Umemura,Ryuma Shimizu,Bin Wu,Shoki Iwaguchi,Yuki Kawasaki,Akira Furusawa,Seiji Kawamura	Quantum locking using optical spring and homodyne detection has been devised to reduce quantum noise that limits the sensitivity of DECIGO, a space-based gravitational wave antenna in the frequency band around 0.1 Hz for detection of primordial gravitational waves. The reduction in the upper limit of energy density ${\Omega}_{\mathrm{GW}}$ from $2{\times}10^{-15}$ to $1{\times}10^{-16}$, as inferred from recent observations, necessitates improved sensitivity in DECIGO to meet its primary science goals. To accurately evaluate the effectiveness of this method, this paper considers a detection mechanism that takes into account the influence of vacuum fluctuations on homodyne detection. In addition, an advanced signal processing method is devised to efficiently utilize signals from each photodetector, and design parameters for this configuration are optimized for the quantum noise. Our results show that this method is effective in reducing quantum noise, despite the detrimental impact of vacuum fluctuations on its sensitivity.	gr-qc	12 pages, 5 figures
4	Zr-Co-Al bulk metallic glass composites containing B2 ZrCo via rapid quenching and annealing	Yu Chen,Chunguang Tang,Kevin Laws,Qiang Zhu,Michael Ferry	As a promising remedy for overcoming the limited ductility and work softening of bulk metallic glasses (BMGs), BMG composites incorporating a B2 crystalline phase have attracted considerable attention. Here, we explore the formation of Zr-Co-Al BMG composites by quenching alloys Zr$_{55}$Co$_{31}$Al$_{14}$, Zr$_{54.5}$Co$_{33.5}$Al$_{12}$, Zr$_{53.5}$Co$_{36.5}$Al$_{10}$, Zr$_{52.5}$Co$_{37.5}$Al$_{10}$, and Zr$_{43}$Co$_{43}$Al$_{14}$. We found the first alloy fully amorphous whereas the fifth was fully crystallized upon quenching. The other three were quenched to generate composite structures, with a higher fraction of B2 ZrCo phase with increasing Co/Zr ratio and decreasing Al content. For comparison, the formation of B2 ZrCo in annealed Zr$_{55}$Co$_{31}$Al$_{14}$ was also studied. For both approaches the influence of crystalline phases on hardness was examined.	cond-mat.mtrl-sci	None
5	Graph Attention-based Deep Reinforcement Learning for solving the Chinese Postman Problem with Load-dependent costs	Cong Dao Tran,Truong Son Hy	Recently, Deep reinforcement learning (DRL) models have shown promising results in solving routing problems. However, most DRL solvers are commonly proposed to solve node routing problems, such as the Traveling Salesman Problem (TSP). Meanwhile, there has been limited research on applying neural methods to arc routing problems, such as the Chinese Postman Problem (CPP), since they often feature irregular and complex solution spaces compared to TSP. To fill these gaps, this paper proposes a novel DRL framework to address the CPP with load-dependent costs (CPP-LC) (Corberan et al., 2018), which is a complex arc routing problem with load constraints. The novelty of our method is two-fold. First, we formulate the CPP-LC as a Markov Decision Process (MDP) sequential model. Subsequently, we introduce an autoregressive model based on DRL, namely Arc-DRL, consisting of an encoder and decoder to address the CPP-LC challenge effectively. Such a framework allows the DRL model to work efficiently and scalably to arc routing problems. Furthermore, we propose a new bio-inspired meta-heuristic solution based on Evolutionary Algorithm (EA) for CPP-LC. Extensive experiments show that Arc-DRL outperforms existing meta-heuristic methods such as Iterative Local Search (ILS) and Variable Neighborhood Search (VNS) proposed by (Corberan et al., 2018) on large benchmark datasets for CPP-LC regarding both solution quality and running time; while the EA gives the best solution quality with much more running time. We release our C++ implementations for metaheuristics such as EA, ILS and VNS along with the code for data generation and our generated data at https://github.com/HySonLab/Chinese_Postman_Problem	cs.LG	None
6	Fighting Fire with Fire: The Dual Role of LLMs in Crafting and Detecting Elusive Disinformation	Jason Lucas,Adaku Uchendu,Michiharu Yamashita,Jooyoung Lee,Shaurya Rohatgi,Dongwon Lee	"Recent ubiquity and disruptive impacts of large language models (LLMs) have raised concerns about their potential to be misused (.i.e, generating large-scale harmful and misleading content). To combat this emerging risk of LLMs, we propose a novel ""Fighting Fire with Fire"" (F3) strategy that harnesses modern LLMs' generative and emergent reasoning capabilities to counter human-written and LLM-generated disinformation. First, we leverage GPT-3.5-turbo to synthesize authentic and deceptive LLM-generated content through paraphrase-based and perturbation-based prefix-style prompts, respectively. Second, we apply zero-shot in-context semantic reasoning techniques with cloze-style prompts to discern genuine from deceptive posts and news articles. In our extensive experiments, we observe GPT-3.5-turbo's zero-shot superiority for both in-distribution and out-of-distribution datasets, where GPT-3.5-turbo consistently achieved accuracy at 68-72%, unlike the decline observed in previous customized and fine-tuned disinformation detectors. Our codebase and dataset are available at https://github.com/mickeymst/F3."	cs.CL	Accepted at EMNLP 2023
7	Probing Luttinger Liquid Properties in Multichannel Two-Site Charge Kondo Simulator	A. V. Parafilo,V. M. Kovalev,I. G. Savenko	We study the influence of many-body interactions on the transport properties in a two-site charge Kondo circuit recently implemented in a hybrid metal-semiconductor double-quantum dot device [W.~Pouse {\it et al.}, Nat.~Phys.~{\bf 19}, 492 (2023)]. There emerge two principal types of interactions: (i) an intrinsic one, described by the Luttinger liquid model, and (ii) an induced one, which appears due to the coupling of the system to an Ohmic environment. Case (i) could be achieved if the charge Kondo circuit operates in the fractional quantum Hall regime, while case (ii) can be implemented via a finite number of open ballistic channels coupled to both the quantum dots. We demonstrate that the conductance scaling for the case of strong and weak interdot coupling is fully determined by the effective interaction parameter, which is the combination of the fractional filling factor $\nu=1/m$ and the number of transmitting channels. Furthermore, we predict that the fractional filling factor $\nu$ defines a universal Kondo scaling in the vicinity of a special triple quantum critical point featured by the emergence of a $\mathbb{Z}_3$ parafermion.	cond-mat.mes-hall	None
8	A Joint Matrix Factorization Analysis of Multilingual Representations	Zheng Zhao,Yftah Ziser,Bonnie Webber,Shay B. Cohen	We present an analysis tool based on joint matrix factorization for comparing latent representations of multilingual and monolingual models. An alternative to probing, this tool allows us to analyze multiple sets of representations in a joint manner. Using this tool, we study to what extent and how morphosyntactic features are reflected in the representations learned by multilingual pre-trained models. We conduct a large-scale empirical study of over 33 languages and 17 morphosyntactic categories. Our findings demonstrate variations in the encoding of morphosyntactic information across upper and lower layers, with category-specific differences influenced by language properties. Hierarchical clustering of the factorization outputs yields a tree structure that is related to phylogenetic trees manually crafted by linguists. Moreover, we find the factorization outputs exhibit strong associations with performance observed across different cross-lingual tasks. We release our code to facilitate future research.	cs.CL	Accepted to Findings of EMNLP 2023
9	Inference for Rank-Rank Regressions	Denis Chetverikov,Daniel Wilhelm	Slope coefficients in rank-rank regressions are popular measures of intergenerational mobility, for instance in regressions of a child's income rank on their parent's income rank. In this paper, we first point out that commonly used variance estimators such as the homoskedastic or robust variance estimators do not consistently estimate the asymptotic variance of the OLS estimator in a rank-rank regression. We show that the probability limits of these estimators may be too large or too small depending on the shape of the copula of child and parent incomes. Second, we derive a general asymptotic theory for rank-rank regressions and provide a consistent estimator of the OLS estimator's asymptotic variance. We then extend the asymptotic theory to other regressions involving ranks that have been used in empirical work. Finally, we apply our new inference methods to three empirical studies. We find that the confidence intervals based on estimators of the correct variance may sometimes be substantially shorter and sometimes substantially longer than those based on commonly used variance estimators. The differences in confidence intervals concern economically meaningful values of mobility and thus lead to different conclusions when comparing mobility in U.S. commuting zones with mobility in other countries.	econ.EM	None
0	KITAB: Evaluating LLMs on Constraint Satisfaction for Information Retrieval	Marah I Abdin,Suriya Gunasekar,Varun Chandrasekaran,Jerry Li,Mert Yuksekgonul,Rahee Ghosh Peshawaria,Ranjita Naik,Besmira Nushi	We study the ability of state-of-the art models to answer constraint satisfaction queries for information retrieval (e.g., 'a list of ice cream shops in San Diego'). In the past, such queries were considered to be tasks that could only be solved via web-search or knowledge bases. More recently, large language models (LLMs) have demonstrated initial emergent abilities in this task. However, many current retrieval benchmarks are either saturated or do not measure constraint satisfaction. Motivated by rising concerns around factual incorrectness and hallucinations of LLMs, we present KITAB, a new dataset for measuring constraint satisfaction abilities of language models. KITAB consists of book-related data across more than 600 authors and 13,000 queries, and also offers an associated dynamic data collection and constraint verification approach for acquiring similar test data for other authors. Our extended experiments on GPT4 and GPT3.5 characterize and decouple common failure modes across dimensions such as information popularity, constraint types, and context availability. Results show that in the absence of context, models exhibit severe limitations as measured by irrelevant information, factual errors, and incompleteness, many of which exacerbate as information popularity decreases. While context availability mitigates irrelevant information, it is not helpful for satisfying constraints, identifying fundamental barriers to constraint satisfaction. We open source our contributions to foster further research on improving constraint satisfaction abilities of future models.	cs.LG	23 pages
1	Natural liquid organic hydrogen carrier with low dehydrogenation energy: A first principles study	Chunguang Tang,Shunxin Fei,G. David Lin,Yun Liu	Liquid organic hydrogen carriers (LOHCs) represent a promising approach for hydrogen storage due to their favorable properties including stability and compatibility with the existing infrastructure. However, fossil-based LOHC molecules are not green or sustainable. Here we examined the possibility of using norbelladine and trisphaeridine, two typical structures of Amaryllidaceae alkaloids, as the LOHCs from the sustainable and renewable sources of natural products. Our first principles thermodynamics calculations reveal low reversibility for the reaction of norbelladine to/from perhydro-norbelladine because of the existence of stabler isomers of perhydro-norbelladine. On the other hand, trisphaeridine is found promising due to its high hydrogen storage capacity ($\sim$5.9 wt\%) and favorable energetics. Dehydrogenation of perhydro-trisphaeridine has an average standard enthalpy change of $\sim$54 KJ/mol-H$_2$, similar to that of perhydro-\textit{N}-ethylcarbazole, a typical LOHC known for its low dehydrogenation enthalpy. This work is a first exploration of Amaryllidaceae alkaloids for hydrogen storage and the results demonstrate, more generally, the potential of bio-based molecules as a new sustainable resource for future large-scale hydrogen storage.	physics.chem-ph	None
2	Dual frequency master oscillator generation and distribution for ALS and ALS-U	Shreeharshini Dharanesh Murthy,Angel Jurado,Michael Betz,Qiang Du,Benjamin Flugstad	The ongoing work to upgrade ALS to ALS-U demands strict RF requirements such as low jitter and low spurs frequency reference to meet its accelerator and science goals. A low phase noise dual frequency Master Oscillator (MO), where the two frequencies are related by a fractional ratio of 608/609 and flexible divide by four frequency outputs has been consolidated into a single chassis. Optical fiber clock distribution system has been selected over the old coax system used in ALS to distribute these signals to various clients across the facility, providing high electrical isolation between outputs and therefore lower phase errors. A Xilinx FPGA ties the MO chassis together by providing a RS-485 interface to monitor and control the system. The new system aims to deliver phase-continuous frequencies with a phase noise (integrated RMS jitter) from 1 Hz to 1 MHz of less than 200 femtosecond per output. This paper will discuss the design, implementation, performance and installation of the new MO generation and distribution system.	physics.acc-ph	Poster presented at LLRF Workshop 2023 (LLRF2023, arXiv: 2310.03199)
3	Spacetime surgery for black hole fireworks	Wei-Chen Lin,Dong-han Yeom,Dejan Stojkovic	We construct an explicit model for the black hole to white hole transition (known as the black hole fireworks scenario) using the cut-and-paste technique. We model a black hole collapse using the evolution of a time-like shell in the background of the loop quantum gravity inspired metric. We then use the space-like shell analysis to construct the firework geometry. Our simple and well defined analysis removes some subtle issues that were present in the previous literature. In particular, we demonstrate that the null energy condition must be violated for the bounce. We also calculate the proper time scales required for the black to white hole transition, which in any valid scenario must be shorter than the evaporation time scale. In contrast, we show that the bouncing time for the distant observer can be chosen arbitrarily, since it is determined by how one cuts and pastes the spacetimes outside the event horizon, and thus does not have any obvious connection to quantum gravity effects.	gr-qc	16 pages, 8 figures
4	Non-propagating ghost in covariant $f(Q)$ gravity	Kun Hu,Makishi Yamakoshi,Taishi Katsuragawa,Shin'ichi Nojiri,Taotao Qiu	"$f(Q)$ gravity is an extension of the symmetric teleparallel equivalent to general relativity (STEGR). This work shows that based on the scalar-nonmetricity formulation, a scalar mode in $f(Q)$ gravity has a negative kinetic energy. This conclusion holds regardless of the coincident gauge frequently used in STEGR and $f(Q)$ gravity. To study the scalar mode, we further consider the covariant $f(Q)$ gravity as a special class in Higher-Order Scalar Tensor (HOST) theory and rewrite the four scalar fields, which play a role of the St\""{u}eckelberg fields associated with the diffeomorphism, by vector fields. Applying the standard Arnowitt-Deser-Misner (ADM) formulation to the new formulation of the $f(Q)$ gravity, we demonstrate that the ghost scalar mode can be eliminated by the second-class constraints, thus ensuring that $f(Q)$ gravity is a healthy theory."	gr-qc	23 pages, 0 figures
5	Topology Optimization with Text-Guided Stylization	Shengze Zhong,Parinya Punpongsanon,Daisuke Iwai,Kosuke Sato	We propose an approach for the generation of topology-optimized structures with text-guided appearance stylization. This methodology aims to enrich the concurrent design of a structure's physical functionality and aesthetic appearance. Users can effortlessly input descriptive text to govern the style of the structure. Our system employs a hash-encoded neural network as the implicit structure representation backbone, which serves as the foundation for the co-optimization of structural mechanical performance, style, and connectivity, to ensure full-color, high-quality 3D-printable solutions. We substantiate the effectiveness of our system through extensive comparisons, demonstrations, and a 3D printing test.	cs.CE	None
6	The Quantum Tortoise and the Classical Hare: A simple framework for understanding which problems quantum computing will accelerate (and which it will not)	Sukwoong Choi,William S. Moses,Neil Thompson	Quantum computing promises transformational gains for solving some problems, but little to none for others. For anyone hoping to use quantum computers now or in the future, it is important to know which problems will benefit. In this paper, we introduce a framework for answering this question both intuitively and quantitatively. The underlying structure of the framework is a race between quantum and classical computers, where their relative strengths determine when each wins. While classical computers operate faster, quantum computers can sometimes run more efficient algorithms. Whether the speed advantage or the algorithmic advantage dominates determines whether a problem will benefit from quantum computing or not. Our analysis reveals that many problems, particularly those of small to moderate size that can be important for typical businesses, will not benefit from quantum computing. Conversely, larger problems or those with particularly big algorithmic gains will benefit from near-term quantum computing. Since very large algorithmic gains are rare in practice and theorized to be rare even in principle, our analysis suggests that the benefits from quantum computing will flow either to users of these rare cases, or practitioners processing very large data.	cs.DS	None
7	Cross-view Self-localization from Synthesized Scene-graphs	Ryogo Yamamoto,Kanji Tanaka	Cross-view self-localization is a challenging scenario of visual place recognition in which database images are provided from sparse viewpoints. Recently, an approach for synthesizing database images from unseen viewpoints using NeRF (Neural Radiance Fields) technology has emerged with impressive performance. However, synthesized images provided by these techniques are often of lower quality than the original images, and furthermore they significantly increase the storage cost of the database. In this study, we explore a new hybrid scene model that combines the advantages of view-invariant appearance features computed from raw images and view-dependent spatial-semantic features computed from synthesized images. These two types of features are then fused into scene graphs, and compressively learned and recognized by a graph neural network. The effectiveness of the proposed method was verified using a novel cross-view self-localization dataset with many unseen views generated using a photorealistic Habitat simulator.	cs.CV	5 pages, 5 figures, technical report
8	Evolution of MHD Torus and Mass Outflow Around Spinning AGN	Ramiz Aktar,Kuo-Chuan Pan,Toru Okuda	"We perform axisymmetric, two-dimensional magnetohydrodynamic (MHD) simulations to investigate accretion flows around spinning AGN. To mimic the space-time geometry of spinning black holes, we consider effective Kerr potential, and the mass of the black holes is $10^8 M_{\odot}$. We initialize the accretion disc with a magnetized torus by adopting the toroidal component of the magnetic vector potential. The initial magnetic field strength is set by using the plasma beta parameter ($\beta_0$). We observe self-consistent turbulence generated by magneto rotational instability (MRI) in the disc. The MRI turbulence transports angular momentum in the disc, resulting in an angular momentum distribution that approaches a Keplerian distribution. We investigate the effect of the magnetic field on the dynamics of the torus and associated mass outflow from the disc around a maximally spinning black hole $(a_k = 0.99)$. For the purpose of our analysis, we investigate the magnetic state of our simulation model. The model $\beta_0 = 10$ indicates the behaviour similar to the ""magnetically arrested disk (MAD)'' state, and all the other low magnetic model remains in the SANE state. We observe that mass outflow rates are significantly enhanced with the increased magnetic field in the disc. We find a positive correlation between the magnetic field and mass outflow rates. We also investigate the effect of black hole spin on the magnetized torus evolution. However, we have not found any significant effect of black hole spin on mass outflows in our model. Finally, we discuss the possible astrophysical applications of our simulation results."	astro-ph.HE	15 pages, 13 figures (2 appendix figures), Accepted for publication   in MNRAS
9	Multi-split configuration design for fluid-based thermal management systems	Saeid Bayat,Nastaran Shahmansouri,Satya RT Peddada,Alexander Tessier,Adrian Butscher,James T Allison	High power density systems require efficient cooling to maintain their thermal performance. Despite this, as systems get larger and more complex, human practice and insight may not suffice to determine the desired thermal management system designs. To this end, a framework for automatic architecture exploration is presented in this article for a class of single-phase, multi-split cooling systems. For this class of systems, heat generation devices are clustered based on their spatial information, and flow-split are added only when required and at the location of heat devices. To generate different architectures, candidate architectures are represented as graphs. From these graphs, dynamic physics models are created automatically using a graph-based thermal modeling framework. Then, an optimal fluid flow distribution problem is solved by addressing temperature constraints in the presence of exogenous heat loads to achieve optimal performance. The focus in this work is on the design of general multi-split heat management systems. The architectures discussed here can be used for various applications in the domain of configuration design. The multi-split algorithm can produce configurations where splitting can occur at any of the vertices. The results presented include 3 categories of cases and are discussed in detail.	eess.SY	11 pages, 18 figures
0	Generalized Box-Cox method to estimate sample mean and standard deviation for Meta-analysis	Olivia Xiao,Stacy Wang,Min Chen	Meta-analysis is the aggregation of data from multiple studies to find patterns across a broad range relating to a particular subject. It is becoming increasingly useful to apply meta-analysis to summarize these studies being done across various fields. In meta-analysis, it is common to use the mean and standard deviation from each study to compare for analysis. While many studies reported mean and standard deviation for their summary statistics, some report other values including the minimum, maximum, median, and first and third quantiles. Often, the quantiles and median are reported when the data is skewed and does not follow a normal distribution. In order to correctly summarize the data and draw conclusions from multiple studies, it is necessary to estimate the mean and standard deviation from each study, considering variation and skewness within each study. In past literature, methods have been proposed to estimate the mean and standard deviation, but do not consider negative values. Data that include negative values are common and would increase the accuracy and impact of the me-ta-analysis. We propose a method that implements a generalized Box-Cox transformation to estimate the mean and standard deviation accounting for such negative values while maintaining similar accuracy.	stat.ME	9 pages, 6 figures
1	AMG: Automated Efficient Approximate Multiplier Generator for FPGAs via Bayesian Optimization	Zhen Li,Hao Zhou,Lingli Wang	Approximate computing is a promising approach to reduce the power, delay, and area in hardware design for many error-resilient applications such as machine learning (ML) and digital signal processing (DSP) systems, in which multipliers usually are key arithmetic units. Due to the underlying architectural differences between ASICs and FPGAs, existing ASIC-based approximate multipliers do not offer symmetrical gains when they are implemented by FPGA resources. In this paper, we propose AMG, an open-source automated approximate multiplier generator for FPGAs driven by Bayesian optimization (BO) with parallel evaluation. The proposed method simplifies the exact half adders (HAs) for the initial partial product (PP) compression in a multiplier while preserving coarse-grained additions for the following accumulation. The generated multipliers can be effectively mapped to lookup tables (LUTs) and carry chains provided by modern FPGAs, reducing hardware costs with acceptable errors. Compared with 1167 multipliers from previous works, our generated multipliers can form a Pareto front with 28.70%-38.47% improvements in terms of the product of hardware cost and error on average. All source codes, reproduced multipliers, and our generated multipliers are available at https://github.com/phyzhenli/AMG.	cs.AR	7 pages, 2023 IEEE International Conference on Field-Programmable   Technology (ICFPT)
2	TRAMS: Training-free Memory Selection for Long-range Language Modeling	Haofei Yu,Cunxiang wang,Yue Zhang,Wei Bi	The Transformer architecture is crucial for numerous AI models, but it still faces challenges in long-range language modeling. Though several specific transformer architectures have been designed to tackle issues of long-range dependencies, existing methods like Transformer-XL are plagued by a high percentage of ineffective memories. In this study, we present a plug-and-play strategy, known as TRAining-free Memory Selection (TRAMS), that selects tokens participating in attention calculation based on one simple metric. This strategy allows us to keep tokens that are likely to have a high attention score with the current queries and ignore the other ones. We have tested our approach on the word-level benchmark (WikiText-103) and the character-level benchmark (enwik8), and the results indicate an improvement without having additional training or adding additional parameters.	cs.CL	None
3	$P_c$ states in the mixture of molecular and pentaquark pictures	Kai Xu,Kanokphon Phumphan,Wiriya Ruangyoo,Chia-Chu Chen,Ayut Limphirat,Yupeng Yan	We systematically study hidden charm pentaquark states in the constituent quark model with a general Hamiltonian for multiquark systems, considering the coupling between the $\Sigma_c^{(*)}\bar{D}^{(*)}$ molecular states and the $q^3c\bar c$ compact pentaquark states by the one-gluon exchange hyperfine interaction. The ground state hidden-charm pentaquark mass spectra and the strong decay widths are calculated. This work suggests that $P_c(4312)$, $P_c(4457)$ and $P_c(4380)$ resonances might be mainly $\Sigma_c \bar D$, $\Sigma_c \bar D^*$ and $\Sigma_c^* \bar D$ hadronic molecules respectively, and $P_c(4440)$ might include sizable pentaquark components.	hep-ph	None
4	Robust Representation Learning for Unified Online Top-K Recommendation	Minfang Lu,Yuchen Jiang,Huihui Dong,Qi Li,Ziru Xu,Yuanlin Liu,Lixia Wu,Haoyuan Hu,Han Zhu,Yuning Jiang,Jian Xu,Bo Zheng	In large-scale industrial e-commerce, the efficiency of an online recommendation system is crucial in delivering highly relevant item/content advertising that caters to diverse business scenarios. However, most existing studies focus solely on item advertising, neglecting the significance of content advertising. This oversight results in inconsistencies within the multi-entity structure and unfair retrieval. Furthermore, the challenge of retrieving top-k advertisements from multi-entity advertisements across different domains adds to the complexity. Recent research proves that user-entity behaviors within different domains exhibit characteristics of differentiation and homogeneity. Therefore, the multi-domain matching models typically rely on the hybrid-experts framework with domain-invariant and domain-specific representations. Unfortunately, most approaches primarily focus on optimizing the combination mode of different experts, failing to address the inherent difficulty in optimizing the expert modules themselves. The existence of redundant information across different domains introduces interference and competition among experts, while the distinct learning objectives of each domain lead to varying optimization challenges among experts. To tackle these issues, we propose robust representation learning for the unified online top-k recommendation. Our approach constructs unified modeling in entity space to ensure data fairness. The robust representation learning employs domain adversarial learning and multi-view wasserstein distribution learning to learn robust representations. Moreover, the proposed method balances conflicting objectives through the homoscedastic uncertainty weights and orthogonality constraints. Various experiments validate the effectiveness and rationality of our proposed method, which has been successfully deployed online to serve real business scenarios.	cs.IR	14 pages, 6 figures, submitted to ICDE
5	Generalized Cardy conditions of topological defect lines	Xia Gu,Xianjin Xie	We propose a systematic procedure to work out systems of topological defect lines (TDLs) in minimal models. The only input of this method is the modular invariant partition function. For diagonal and permutation diagonal models, we prove there is a bijection between simple TDLs and primary fields preserving fusion rules. For block-diagonal models, we work out simple TDLs in the $3$-state Potts model as an example. The results agree with those in $3D$ topological field theory methods.	hep-th	30 pages, 12 figures
6	RIS-based IMT-2030 Testbed for MmWave Multi-stream Ultra-massive MIMO Communications	Shuhao Zeng,Boya Di,Hongliang Zhang,Jiahao Gao,Shaohua Yue,Xinyuan Hu,Rui Fu,Jiaqi Zhou,Xu Liu,Haobo Zhang,Yuhan Wang,Shaohui Sun,Haichao Qin,Xin Su,Mengjun Wang,Lingyang Song	As one enabling technique of the future sixth generation (6G) network, ultra-massive multiple-input-multiple-output (MIMO) can support high-speed data transmissions and cell coverage extension. However, it is hard to realize the ultra-massive MIMO via traditional phased arrays due to unacceptable power consumption. To address this issue, reconfigurable intelligent surface-based (RIS-based) antennas are an energy-efficient enabler of the ultra-massive MIMO, since they are free of energy-hungry phase shifters. In this article, we report the performances of the RIS-enabled ultra-massive MIMO via a project called Verification of MmWave Multi-stream Transmissions Enabled by RIS-based Ultra-massive MIMO for 6G (V4M), which was proposed to promote the evolution towards IMT-2030. In the V4M project, we manufacture RIS-based antennas with 1024 one-bit elements working at 26 GHz, based on which an mmWave dual-stream ultra-massive MIMO prototype is implemented for the first time. To approach practical settings, the Tx and Rx of the prototype are implemented by one commercial new radio base station and one off-the-shelf user equipment, respectively. The measured data rate of the dual-stream prototype approaches the theoretical peak rate. Our contributions to the V4M project are also discussed by presenting technological challenges and corresponding solutions.	cs.IT	8 pages, 5 figures, to be published in IEEE Wireless Communications
7	NuTrea: Neural Tree Search for Context-guided Multi-hop KGQA	Hyeong Kyu Choi,Seunghun Lee,Jaewon Chu,Hyunwoo J. Kim	Multi-hop Knowledge Graph Question Answering (KGQA) is a task that involves retrieving nodes from a knowledge graph (KG) to answer natural language questions. Recent GNN-based approaches formulate this task as a KG path searching problem, where messages are sequentially propagated from the seed node towards the answer nodes. However, these messages are past-oriented, and they do not consider the full KG context. To make matters worse, KG nodes often represent proper noun entities and are sometimes encrypted, being uninformative in selecting between paths. To address these problems, we propose Neural Tree Search (NuTrea), a tree search-based GNN model that incorporates the broader KG context. Our model adopts a message-passing scheme that probes the unreached subtree regions to boost the past-oriented embeddings. In addition, we introduce the Relation Frequency-Inverse Entity Frequency (RF-IEF) node embedding that considers the global KG context to better characterize ambiguous KG nodes. The general effectiveness of our approach is demonstrated through experiments on three major multi-hop KGQA benchmark datasets, and our extensive analyses further validate its expressiveness and robustness. Overall, NuTrea provides a powerful means to query the KG with complex natural language questions. Code is available at https://github.com/mlvlab/NuTrea.	cs.CL	Neural Information Processing Systems (NeurIPS) 2023
8	Salient Object Detection in RGB-D Videos	Ao Mou,Yukang Lu,Jiahao He,Dingyao Min,Keren Fu,Qijun Zhao	Given the widespread adoption of depth-sensing acquisition devices, RGB-D videos and related data/media have gained considerable traction in various aspects of daily life. Consequently, conducting salient object detection (SOD) in RGB-D videos presents a highly promising and evolving avenue. Despite the potential of this area, SOD in RGB-D videos remains somewhat under-explored, with RGB-D SOD and video SOD (VSOD) traditionally studied in isolation. To explore this emerging field, this paper makes two primary contributions: the dataset and the model. On one front, we construct the RDVS dataset, a new RGB-D VSOD dataset with realistic depth and characterized by its diversity of scenes and rigorous frame-by-frame annotations. We validate the dataset through comprehensive attribute and object-oriented analyses, and provide training and testing splits. Moreover, we introduce DCTNet+, a three-stream network tailored for RGB-D VSOD, with an emphasis on RGB modality and treats depth and optical flow as auxiliary modalities. In pursuit of effective feature enhancement, refinement, and fusion for precise final prediction, we propose two modules: the multi-modal attention module (MAM) and the refinement fusion module (RFM). To enhance interaction and fusion within RFM, we design a universal interaction module (UIM) and then integrate holistic multi-modal attentive paths (HMAPs) for refining multi-modal low-level features before reaching RFMs. Comprehensive experiments, conducted on pseudo RGB-D video datasets alongside our RDVS, highlight the superiority of DCTNet+ over 17 VSOD models and 14 RGB-D SOD models. Ablation experiments were performed on both pseudo and realistic RGB-D video datasets to demonstrate the advantages of individual modules as well as the necessity of introducing realistic depth. Our code together with RDVS dataset will be available at https://github.com/kerenfu/RDVS/.	cs.CV	None
9	Entanglement asymmetry in 1+1-dimensional Conformal Field Theories	Miao Chen,Hui-Huang Chen	In this paper, we consider the entanglement asymmetry of excited states in the 1+1 dimensional free compact boson conformal field theory (CFT) at equilibrium. We obtain a universal CFT expression written by correlation functions for the charged moments via the replica trick. We provide detailed analytic computations in the free compact boson CFT for the excited states $\psi=V_{\beta}+V_{-\beta}$ and $\psi=V_{\beta}+i\partial\phi$ with $V_{\beta}$ and $i\partial\phi$ being the vertex operator and current operator respectively. We make numerical tests of the universal CFT computations using the XX spin chain model. Taking the non-Hermite RDMs into consideration, we propose an effective way to test them numerically, which can be applied to other excited states. The CFT predictions are in perfect agreement with the exact numerical calculations.	hep-th	23 pages, 4 figures
0	AutoDiff: combining Auto-encoder and Diffusion model for tabular data synthesizing	Namjoon Suh,Xiaofeng Lin,Din-Yin Hsieh,Merhdad Honarkhah,Guang Cheng	Diffusion model has become a main paradigm for synthetic data generation in many subfields of modern machine learning, including computer vision, language model, or speech synthesis. In this paper, we leverage the power of diffusion model for generating synthetic tabular data. The heterogeneous features in tabular data have been main obstacles in tabular data synthesis, and we tackle this problem by employing the auto-encoder architecture. When compared with the state-of-the-art tabular synthesizers, the resulting synthetic tables from our model show nice statistical fidelities to the real data, and perform well in downstream tasks for machine learning utilities. We conducted the experiments over 15 publicly available datasets. Notably, our model adeptly captures the correlations among features, which has been a long-standing challenge in tabular data synthesis. Our code is available upon request and will be publicly released if paper is accepted.	stat.ML	None
1	CRaSh: Clustering, Removing, and Sharing Enhance Fine-tuning without Full Large Language Model	Kaiyan Zhang,Ning Ding,Biqing Qi,Xuekai Zhu,Xinwei Long,Bowen Zhou	Instruction tuning has recently been recognized as an effective way of aligning Large Language Models (LLMs) to enhance their generalization ability across various tasks. However, when tuning publicly accessible, centralized LLMs with private instruction data, privacy concerns are inevitable. While direct transfer of parameterized modules between models is a plausible approach to address this, its implications and effectiveness need further exploration. This paper focuses on Offsite-Tuning (OFT), a representative technique that transfers transformer blocks between centralized LLMs and downstream emulators. Given the limited understanding of the underlying mechanism of OFT, we perform an empirical analysis on LLMs from the perspectives of representation and functional similarity. Interestingly, our findings reveal a unique modular structure within the layers of LLMs that appears to emerge as the model size expands. Simultaneously, we note subtle but potentially significant changes in representation and intermediate predictions across the layers. Inspired by these observations, we propose CRaSh, involving Clustering, Removing, and Sharing, a training-free strategy to derive improved emulators from LLMs. CRaSh significantly boosts performance of OFT with billions of parameters. Furthermore, we investigate the optimal solutions yielded by fine-tuning with and without full model through the lens of loss landscape. Our findings demonstrate a linear connectivity among these optima falling over the same basin, thereby highlighting the effectiveness of CRaSh and OFT. The source code is publicly available at https://github.com/TsinghuaC3I/CRaSh.	cs.CL	Accepted to EMNLP 2023 (Main Conference)
2	Trade-off relations of geometric coherence	Bingyu Hu,Ming-Jing Zhao	Quantum coherence is an important quantum resource and it is intimately related to various research fields. The geometric coherence is a coherence measure both operationally and geometrically. We study the trade-off relation of geometric coherence in qubit systems. We first derive an upper bound for the geometric coherence by the purity of quantum states. Based on this, a complementarity relation between the quantum coherence and the mixedness is established. We then derive the quantum uncertainty relations of the geometric coherence on two and three general measurement bases in terms of the incompatibility respectively, which turn out to be state-independent for pure states. These trade-off relations provide the limit to the amount of quantum coherence. As a byproduct,the complementarity relation between the minimum error probability for discriminating a pure-states ensemble and the mixedness of quantum states is established.	quant-ph	19 pages
3	Vanishing of DHKK complexities for singularity categories and generation of syzygy modules	Tokuji Araya,Kei-ichiro Iima,Ryo Takahashi	Let R be a commutative noetherian ring. In this paper, we study, for the singularity category of R, the vanishing of the complexity $\delta_t(X,Y)$ in the sense of Dimitrov, Haiden, Katzarkov and Kontsevich. We prove that the set of real numbers t such that $\delta_t(X,Y)$ does not vanish is bounded in various cases. We do it by building the high syzygy modules and maximal Cohen-Macaulay modules out of a single module only by taking direct summands and extensions.	math.AC	10 pages
4	Interpretable Survival Analysis for Heart Failure Risk Prediction	Mike Van Ness,Tomas Bosschieter,Natasha Din,Andrew Ambrosy,Alexander Sandhu,Madeleine Udell	Survival analysis, or time-to-event analysis, is an important and widespread problem in healthcare research. Medical research has traditionally relied on Cox models for survival analysis, due to their simplicity and interpretability. Cox models assume a log-linear hazard function as well as proportional hazards over time, and can perform poorly when these assumptions fail. Newer survival models based on machine learning avoid these assumptions and offer improved accuracy, yet sometimes at the expense of model interpretability, which is vital for clinical use. We propose a novel survival analysis pipeline that is both interpretable and competitive with state-of-the-art survival models. Specifically, we use an improved version of survival stacking to transform a survival analysis problem to a classification problem, ControlBurn to perform feature selection, and Explainable Boosting Machines to generate interpretable predictions. To evaluate our pipeline, we predict risk of heart failure using a large-scale EHR database. Our pipeline achieves state-of-the-art performance and provides interesting and novel insights about risk factors for heart failure.	cs.LG	None
5	Continual Event Extraction with Semantic Confusion Rectification	Zitao Wang,Xinyi Wang,Wei Hu	We study continual event extraction, which aims to extract incessantly emerging event information while avoiding forgetting. We observe that the semantic confusion on event types stems from the annotations of the same text being updated over time. The imbalance between event types even aggravates this issue. This paper proposes a novel continual event extraction model with semantic confusion rectification. We mark pseudo labels for each sentence to alleviate semantic confusion. We transfer pivotal knowledge between current and previous models to enhance the understanding of event types. Moreover, we encourage the model to focus on the semantics of long-tailed event types by leveraging other associated types. Experimental results show that our model outperforms state-of-the-art baselines and is proficient in imbalanced datasets.	cs.CL	Accepted in the 2023 Conference on Empirical Methods in Natural   Language Processing (EMNLP 2023)
6	The Janus Interface: How Fine-Tuning in Large Language Models Amplifies the Privacy Risks	Xiaoyi Chen,Siyuan Tang,Rui Zhu,Shijun Yan,Lei Jin,Zihao Wang,Liya Su,XiaoFeng Wang,Haixu Tang	The era post-2018 marked the advent of Large Language Models (LLMs), with innovations such as OpenAI's ChatGPT showcasing prodigious linguistic prowess. As the industry galloped toward augmenting model parameters and capitalizing on vast swaths of human language data, security and privacy challenges also emerged. Foremost among these is the potential inadvertent accrual of Personal Identifiable Information (PII) during web-based data acquisition, posing risks of unintended PII disclosure. While strategies like RLHF during training and Catastrophic Forgetting have been marshaled to control the risk of privacy infringements, recent advancements in LLMs, epitomized by OpenAI's fine-tuning interface for GPT-3.5, have reignited concerns. One may ask: can the fine-tuning of LLMs precipitate the leakage of personal information embedded within training datasets? This paper reports the first endeavor to seek the answer to the question, particularly our discovery of a new LLM exploitation avenue, called the Janus attack. In the attack, one can construct a PII association task, whereby an LLM is fine-tuned using a minuscule PII dataset, to potentially reinstate and reveal concealed PIIs. Our findings indicate that, with a trivial fine-tuning outlay, LLMs such as GPT-3.5 can transition from being impermeable to PII extraction to a state where they divulge a substantial proportion of concealed PII. This research, through its deep dive into the Janus attack vector, underscores the imperative of navigating the intricate interplay between LLM utility and privacy preservation.	cs.CR	None
7	Empowering Distributed Solutions in Renewable Energy Systems and Grid Optimization	Mohammad Mohammadi,Ali Mohammadi	This study delves into the shift from centralized to decentralized approaches in the electricity industry, with a particular focus on how machine learning (ML) advancements play a crucial role in empowering renewable energy sources and improving grid management. ML models have become increasingly important in predicting renewable energy generation and consumption, utilizing various techniques like artificial neural networks, support vector machines, and decision trees. Furthermore, data preprocessing methods, such as data splitting, normalization, decomposition, and discretization, are employed to enhance prediction accuracy.   The incorporation of big data and ML into smart grids offers several advantages, including heightened energy efficiency, more effective responses to demand, and better integration of renewable energy sources. Nevertheless, challenges like handling large data volumes, ensuring cybersecurity, and obtaining specialized expertise must be addressed. The research investigates various ML applications within the realms of solar energy, wind energy, and electric distribution and storage, illustrating their potential to optimize energy systems. To sum up, this research demonstrates the evolving landscape of the electricity sector as it shifts from centralized to decentralized solutions through the application of ML innovations and distributed decision-making, ultimately shaping a more efficient and sustainable energy future.	cs.LG	None
8	Policy Optimization of Finite-Horizon Kalman Filter with Unknown Noise Covariance	Haoran Li,Yuan-Hua Ni	This paper is on learning the Kalman gain by policy optimization method. Firstly, we reformulate the finite-horizon Kalman filter as a policy optimization problem of the dual system. Secondly, we obtain the global linear convergence of exact gradient descent method in the setting of known parameters. Thirdly, the gradient estimation and stochastic gradient descent method are proposed to solve the policy optimization problem, and further the global linear convergence and sample complexity of stochastic gradient descent are provided for the setting of unknown noise covariance matrices and known model parameters.	math.OC	None
9	EKGNet: A 10.96ŒºW Fully Analog Neural Network for Intra-Patient Arrhythmia Classification	Benyamin Haghi,Lin Ma,Sahin Lale,Anima Anandkumar,Azita Emami	We present an integrated approach by combining analog computing and deep learning for electrocardiogram (ECG) arrhythmia classification. We propose EKGNet, a hardware-efficient and fully analog arrhythmia classification architecture that archives high accuracy with low power consumption. The proposed architecture leverages the energy efficiency of transistors operating in the subthreshold region, eliminating the need for analog-to-digital converters (ADC) and static random access memory (SRAM). The system design includes a novel analog sequential Multiply-Accumulate (MAC) circuit that mitigates process, supply voltage, and temperature variations. Experimental evaluations on PhysioNet's MIT-BIH and PTB Diagnostics datasets demonstrate the effectiveness of the proposed method, achieving average balanced accuracy of 95% and 94.25% for intra-patient arrhythmia classification and myocardial infarction (MI) classification, respectively. This innovative approach presents a promising avenue for developing low-power arrhythmia classification systems with enhanced accuracy and transferability in biomedical applications.	cs.LG	Accepted on IEEE Biomedical Circuits and Systems (BioCAS) 2023
0	A universal meta-heuristic framework for influence maximization in hypergraphs	Ming Xie,Xiu-Xiu Zhan,Chuang Liu,Zi-Ke Zhang	Influence maximization (IM) aims to select a small number of nodes that are able to maximize their influence in a network and covers a wide range of applications. Despite numerous attempts to provide effective solutions in ordinary networks, higher-order interactions between entities in various real-world systems are not usually taken into account. In this paper, we propose a versatile meta-heuristic approach, hyper genetic algorithm (HGA), to tackle the IM problem in hypergraphs, which is based on the concept of genetic evolution. Systematic validations in synthetic and empirical hypergraphs under both simple and complex contagion models indicate that HGA achieves universal and plausible performance compared to baseline methods. We explore the cause of the excellent performance of HGA through ablation studies and correlation analysis. The findings show that the solution of HGA is distinct from that of other prior methods. Moreover, a closer look at the local topological features of the seed nodes acquired by different algorithms reveals that the selection of seed nodes cannot be based on a single topological characteristic, but should involve a combination of multiple topological features to address the IM problem.	physics.soc-ph	None
1	Interpreting Answers to Yes-No Questions in User-Generated Content	Shivam Mathur,Keun Hee Park,Dhivya Chinnappa,Saketh Kotamraju,Eduardo Blanco	Interpreting answers to yes-no questions in social media is difficult. Yes and no keywords are uncommon, and the few answers that include them are rarely to be interpreted what the keywords suggest. In this paper, we present a new corpus of 4,442 yes-no question-answer pairs from Twitter. We discuss linguistic characteristics of answers whose interpretation is yes or no, as well as answers whose interpretation is unknown. We show that large language models are far from solving this problem, even after fine-tuning and blending other corpora for the same problem but outside social media.	cs.CL	Accepted at the Findings of EMNLP 2023
2	Nested Control Co-design of a Spar Buoy Horizontal-axis Floating Offshore Wind Turbine	Saeid Bayat,Yong Hoon Lee,James T. Allison	Floating offshore wind turbine (FOWT) systems involve several coupled physical analysis disciplines, including aeroelasticity, multi-body structural dynamics, hydrodynamics, and controls. Conventionally, physical structure (plant) and control design decisions are treated as two separate problems, and generally, control design is performed after the plant design is complete. However, this sequential design approach cannot fully capitalize upon the synergy between plant and control design decisions. These conventional design practices produce suboptimal designs, especially in cases with strong coupling between plant and control design decisions. Control co-design (CCD) is a holistic design approach that accounts fully for plant-control design coupling by optimizing these decisions simultaneously. CCD is especially advantageous for system design problems with complex interactions between physics disciplines, which is the case for FOWT systems. This paper presents and demonstrates a nested CCD approach using open-loop optimal control (OLOC) for a simplified reduced-order model that simulates FOWT dynamic behavior. This simplified model is helpful for optimization studies due to its computational efficiency, but is still sufficiently rich enough to capture important multidisciplinary physics couplings and plant-control design coupling associated with a horizontal-axis FOWT system with a spar buoy floating platform. The CCD result shows an improvement in the objective function, annual energy production (AEP), compared to the baseline design by more than eleven percent. Optimization studies at this fidelity level can provide system design engineers with insights into design directions that leverage design coupling to improve performance. These studies also provide a template for future more detailed turbine CCD optimization studies that utilize higher fidelity models and design representations.	eess.SY	21 pages, 15 figures, 5 tables
3	Facilitating Self-Guided Mental Health Interventions Through Human-Language Model Interaction: A Case Study of Cognitive Restructuring	Ashish Sharma,Kevin Rushton,Inna Wanyin Lin,Theresa Nguyen,Tim Althoff	"Self-guided mental health interventions, such as ""do-it-yourself"" tools to learn and practice coping strategies, show great promise to improve access to mental health care. However, these interventions are often cognitively demanding and emotionally triggering, creating accessibility barriers that limit their wide-scale implementation and adoption. In this paper, we study how human-language model interaction can support self-guided mental health interventions. We take cognitive restructuring, an evidence-based therapeutic technique to overcome negative thinking, as a case study. In an IRB-approved randomized field study on a large mental health website with 15,531 participants, we design and evaluate a system that uses language models to support people through various steps of cognitive restructuring. Our findings reveal that our system positively impacts emotional intensity for 67% of participants and helps 65% overcome negative thoughts. Although adolescents report relatively worse outcomes, we find that tailored interventions that simplify language model generations improve overall effectiveness and equity."	cs.HC	None
4	Strategies to mitigate bias from time recording errors in pharmacokinetic studies	Hannah L Weeks,Matthew S Shotwell	Opportunistic pharmacokinetic (PK) studies have sparse and imbalanced clinical measurement data, and the impact of sample time errors is an important concern when seeking accurate estimates of treatment response. We evaluated an approximate Bayesian model for individualized pharmacokinetics in the presence of time recording errors (TREs), considering both a short and long infusion dosing pattern. We found that the long infusion schedule generally had lower bias in estimates of the pharmacodynamic (PD) endpoint relative to the short infusion schedule. We investigated three different design strategies for their ability to mitigate the impact of TREs: (i) shifting blood draws taken during an active infusion to the post-infusion period, (ii) identifying the best next sample time by minimizing bias in the presence of TREs, and (iii) collecting additional information on a subset of patients based on estimate uncertainty or quadrature-estimated variance in the presence of TREs. Generally, the proposed strategies led to a decrease in bias of the PD estimate for the short infusion schedule, but had a negligible impact for the long infusion schedule. Dosing regimens with periods of high non-linearity may benefit from design modifications, while more stable concentration-time profiles are generally more robust to TREs with no design modifications.	stat.AP	None
5	A distributed-memory parallel algorithm for discretized integral equations using Julia	Tianyu Liang,Chao Chen,Per-Gunnar Martinsson,George Biros	Boundary value problems involving elliptic PDEs such as the Laplace and the Helmholtz equations are ubiquitous in physics and engineering. Many such problems have alternative formulations as integral equations that are mathematically more tractable than their PDE counterparts. However, the integral equation formulation poses a challenge in solving the dense linear systems that arise upon discretization. In cases where iterative methods converge rapidly, existing methods that draw on fast summation schemes such as the Fast Multipole Method are highly efficient and well established. More recently, linear complexity direct solvers that sidestep convergence issues by directly computing an invertible factorization have been developed. However, storage and compute costs are high, which limits their ability to solve large-scale problems in practice. In this work, we introduce a distributed-memory parallel algorithm based on an existing direct solver named ``strong recursive skeletonization factorization.'' The analysis of its parallel scalability applies generally to a class of existing methods that exploit the so-called strong admissibility. Specifically, we apply low-rank compression to certain off-diagonal matrix blocks in a way that minimizes data movement. Given a compression tolerance, our method constructs an approximate factorization of a discretized integral operator (dense matrix), which can be used to solve linear systems efficiently in parallel. Compared to iterative algorithms, our method is particularly suitable for problems involving ill-conditioned matrices or multiple right-hand sides. Large-scale numerical experiments are presented to demonstrate the performance of our implementation using the Julia language.	math.NA	None
6	An Unconditionally Stable Iterative Decoupled Algorithm for Multiple-Network Poroelasticity Model	Meng Lei,Mingchao Cai,Feng Wang	In this work, we introduce an iterative decoupled algorithm designed for addressing the quasi-static multiple-network poroelasticity problem. This problem pertains to the simultaneous modeling of fluid flow and deformations within an elastic porous medium permeated by multiple fluid networks, each with distinct characteristics. Our approach focuses on the total-pressure-based formulation, which treats the solid displacement, total pressure, and network pressures as primary unknowns. This formulation transforms the original problem into a combination of the generalized Stokes problem and the parabolic problem, offering certain advantages such as mitigating elastic locking effects and streamlining the discretization process. Notably, the algorithm ensures unconditional convergence to the solution of the total-pressure-based coupled algorithm. To validate the accuracy and efficiency of our method, we present numerical experiments. The robustness of the algorithm with respect to the physical parameters and the discretization parameters is carefully investigated.	math.NA	to be submitted
7	Substantial Doubt Remains about the Efficacy of Anti-Amyloid Antibodies	Leonardino A. Digma MD,Joseph R. Winer PhD,Michael D. Greicius MD	Alzheimer's disease (AD) is a prevalent, progressive, and ultimately fatal neurodegenerative disorder that is defined pathologically by the accumulation of amyloid plaques and tau neurofibrillary tangles in the brain. There remains an unmet need for therapies that can halt or slow the course of AD. To address this need, the FDA has provided a mechanism, under its Accelerated Approval pathway, for potential therapeutics to be approved based in part on their ability to reduce brain amyloid. Through this pathway, two monoclonal anti-amyloid antibodies, aducanumab and lecanemab, have been approved for clinical use. More recently, another amyloid-lowering antibody, donanemab, generated a statistically significant outcome in a phase 3 clinical trial and will shortly come under FDA review. While these monoclonal antibodies are not yet routinely used in clinical practice, the series of recent positive clinical trials has fostered enthusiasm amongst some AD experts. Here, we discuss three key limitations regarding recent anti-amyloid clinical trials: (1) there is little to no evidence that amyloid reduction correlates with clinical outcome, (2) the reported efficacy of anti-amyloid therapies may be partly, or wholly, explained by functional unblinding, and (3) donanemab in its phase 3 trial had no effect on tau burden, the pathological hallmark more closely related to cognition. Taken together, these observations call into question the efficacy of anti-amyloid therapies.	q-bio.TO	12 pages, 2 figures
8	UI Layout Generation with LLMs Guided by UI Grammar	Yuwen Lu,Ziang Tong,Qinyi Zhao,Chengzhi Zhang,Toby Jia-Jun Li	The recent advances in Large Language Models (LLMs) have stimulated interest among researchers and industry professionals, particularly in their application to tasks concerning mobile user interfaces (UIs). This position paper investigates the use of LLMs for UI layout generation. Central to our exploration is the introduction of UI grammar -- a novel approach we proposed to represent the hierarchical structure inherent in UI screens. The aim of this approach is to guide the generative capacities of LLMs more effectively and improve the explainability and controllability of the process. Initial experiments conducted with GPT-4 showed the promising capability of LLMs to produce high-quality user interfaces via in-context learning. Furthermore, our preliminary comparative study suggested the potential of the grammar-based approach in improving the quality of generative results in specific aspects.	cs.HC	ICML 2023 Workshop on AI and HCI
9	Private Learning with Public Features	Walid Krichene,Nicolas Mayoraz,Steffen Rendle,Shuang Song,Abhradeep Thakurta,Li Zhang	We study a class of private learning problems in which the data is a join of private and public features. This is often the case in private personalization tasks such as recommendation or ad prediction, in which features related to individuals are sensitive, while features related to items (the movies or songs to be recommended, or the ads to be shown to users) are publicly available and do not require protection. A natural question is whether private algorithms can achieve higher utility in the presence of public features. We give a positive answer for multi-encoder models where one of the encoders operates on public features. We develop new algorithms that take advantage of this separation by only protecting certain sufficient statistics (instead of adding noise to the gradient). This method has a guaranteed utility improvement for linear regression, and importantly, achieves the state of the art on two standard private recommendation benchmarks, demonstrating the importance of methods that adapt to the private-public feature separation.	cs.LG	None
0	Critical dehydrogenation steps of perhydro-N-ethylcarbazole on Ru(0001) surface	Chunguang Tang,Preetham Permude,Shunxin Fei,Terry J. Frankcombe,Sean C. Smith,Yun Liu	Understanding of the critical atomistic steps during the dehydrogenation process of liquid organic hydrogen carriers (LOHCs) is important to the design of cost-efficient, high-performance LOHC catalysts. Based on the density functional theory (DFT) we studied the thermodynamics and kinetics of the complete dehydrogenation path of perhydro-N-ethylcarbazole (12H-NEC) on Ru(0001) surface, involving the adsorption of 12H-NEC, the discharge of H ions onto Ru surface, and the desorption of H2 and hydrogen-lean NEC. It was found that the bonding of nH-NEC is significantly strengthened for n $\le$ 4 because of the flat aromatic ring. Although the whole dehydrogenation process is endothermic, the release of H from nH-NEC, with H adsorbed onto the Ru surface, was found to be exothermic. The desorption of flat, hydrogen-lean NEC, which costs ~255 kJ/mol, was identified as the most energy demanding step. In addition, the effect of surface morphology on adsorption was studied based on an amorphous surface model. Overall, the results imply more efficient dehydrogenation could be achieved from relatively weak bonding of NEC to catalysts, either through engineering catalyst surface (such as surface defects or smaller catalyst particles) or different catalyst materials. Our calculations also revealed possible dealkylation at elevated temperatures.	cond-mat.mtrl-sci	None
1	General Identifiability and Achievability for Causal Representation Learning	Burak Varƒ±cƒ±,Emre Acart√ºrk,Karthikeyan Shanmugam,Ali Tajer	This paper focuses on causal representation learning (CRL) under a general nonparametric causal latent model and a general transformation model that maps the latent data to the observational data. It establishes \textbf{identifiability} and \textbf{achievability} results using two hard \textbf{uncoupled} interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled environments). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees for the algorithm. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the existing identifiability result for two hard \textbf{coupled} interventions, that is when metadata about the pair of environments that have the same node intervened is known. It is noteworthy that the existing results on non-parametric identifiability require assumptions on interventions and additional faithfulness assumptions. This paper shows that when observational data is available, additional faithfulness assumptions are unnecessary.	cs.LG	None
2	DeepIron: Predicting Unwarped Garment Texture from a Single Image	Hyun-Song Kwon,Sung-Hee Lee	Realistic reconstruction of 3D clothing from an image has wide applications, such as avatar creation and virtual try-on. This paper presents a novel framework that reconstructs the texture map for 3D garments from a single image with pose. Assuming that 3D garments are modeled by stitching 2D garment sewing patterns, our specific goal is to generate a texture image for the sewing patterns. A key component of our framework, the Texture Unwarper, infers the original texture image from the input clothing image, which exhibits warping and occlusion of texture due to the user's body shape and pose. The Texture Unwarper effectively transforms between the input and output images by mapping the latent spaces of the two images. By inferring the unwarped original texture of the input garment, our method helps reconstruct 3D garment models that can show high-quality texture images realistically deformed for new poses. We validate the effectiveness of our approach through a comparison with other methods and ablation studies. Additionally, we release a large dataset of garment sewing patterns with textures and images of avatars wearing the garments, which will be useful for future research on garment texture reconstruction and synthesis.	cs.GR	None
3	What are acceptable reductions? Perspectives from proof-theoretic semantics and type theory	Sara Ayhan	It has been argued that reduction procedures are closely connected to the question about identity of proofs and that accepting certain reductions would lead to a trivialization of identity of proofs in the sense that every derivation of the same conclusion would have to be identified. In this paper it will be shown that the question, which reductions we accept in our system, is not only important if we see them as generating a theory of proof identity but is also decisive for the more general question whether a proof has meaningful content. There are certain reductions which would not only force us to identify proofs of different arbitrary formulas but which would render derivations in a system allowing them meaningless. To exclude such cases, a minimal criterion is proposed which reductions have to fulfill to be acceptable.	cs.LO	None
4	Fast Propagation is Better: Accelerating Single-Step Adversarial Training via Sampling Subnetworks	Xiaojun Jia,Jianshu Li,Jindong Gu,Yang Bai,Xiaochun Cao	Adversarial training has shown promise in building robust models against adversarial examples. A major drawback of adversarial training is the computational overhead introduced by the generation of adversarial examples. To overcome this limitation, adversarial training based on single-step attacks has been explored. Previous work improves the single-step adversarial training from different perspectives, e.g., sample initialization, loss regularization, and training strategy. Almost all of them treat the underlying model as a black box. In this work, we propose to exploit the interior building blocks of the model to improve efficiency. Specifically, we propose to dynamically sample lightweight subnetworks as a surrogate model during training. By doing this, both the forward and backward passes can be accelerated for efficient adversarial training. Besides, we provide theoretical analysis to show the model robustness can be improved by the single-step adversarial training with sampled subnetworks. Furthermore, we propose a novel sampling strategy where the sampling varies from layer to layer and from iteration to iteration. Compared with previous methods, our method not only reduces the training cost but also achieves better model robustness. Evaluations on a series of popular datasets demonstrate the effectiveness of the proposed FB-Better. Our code has been released at https://github.com/jiaxiaojunQAQ/FP-Better.	cs.CV	None
5	Special Lagrangian pair of pants	Yang Li	We construct special Lagrangian pair of pants in general dimensions, inside the cotangent bundle of $T^n$ with the Euclidean structure.	math.DG	None
6	Direct measurements of cosmic rays and their possible interpretations	Igor V. Moskalenko	The last two decades have brought spectacular advances in astrophysics of cosmic rays (CRs) and space- and ground-based astronomy. Launches of missions that employ forefront detector technologies enabled measurements with large effective areas, wide fields of view, and precision that we recently could not even dream of. Meanwhile, interpretation of the individual slices of information about the internal working of the Milky Way provided by such experiments poses challenges to the traditional astrophysical models. New mysteries arise in the composition and spectra of CR species at low and high energies, in the energy range where we thought the main features were already understood fairly well. This accumulation of unsolved puzzles highlights the peculiarity of the current epoch and means that major breakthroughs are still ahead. In my talk, I review the current state of direct measurements of CRs and discuss their possible interpretations. Unfortunately, many important ideas and publications are not discussed here due to the space limitations.	astro-ph.HE	24 pages, invited review talk, Proceedings of the 38th International   Cosmic Ray Conference (ICRC2023), 26 July - 3 August, 2023, Nagoya, Japan.   The DOI link provides an access to the slides (Supplementary files)
7	Learning Dynamics in Linear VAE: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with KL Annealing	Yuma Ichikawa,Koji Hukushima	Variational autoencoders (VAEs) face a notorious problem wherein the variational posterior often aligns closely with the prior, a phenomenon known as posterior collapse, which hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter $\beta$ and a strategy for annealing this parameter, called KL annealing, are proposed. This study presents a theoretical analysis of the learning dynamics in a minimal VAE. It is rigorously proved that the dynamics converge to a deterministic process within the limit of large input dimensions, thereby enabling a detailed dynamical analysis of the generalization error. Furthermore, the analysis shows that the VAE initially learns entangled representations and gradually acquires disentangled representations. A fixed-point analysis of the deterministic process reveals that when $\beta$ exceeds a certain threshold, posterior collapse becomes inevitable regardless of the learning period. Additionally, the superfluous latent variables for the data-generative factors lead to overfitting of the background noise; this adversely affects both generalization and learning convergence. The analysis further unveiled that appropriately tuned KL annealing can accelerate convergence.	stat.ML	24 pages, 5 figures
8	K-HATERS: A Hate Speech Detection Corpus in Korean with Target-Specific Ratings	Chaewon Park,Soohwan Kim,Kyubyong Park,Kunwoo Park	Numerous datasets have been proposed to combat the spread of online hate. Despite these efforts, a majority of these resources are English-centric, primarily focusing on overt forms of hate. This research gap calls for developing high-quality corpora in diverse languages that also encapsulate more subtle hate expressions. This study introduces K-HATERS, a new corpus for hate speech detection in Korean, comprising approximately 192K news comments with target-specific offensiveness ratings. This resource is the largest offensive language corpus in Korean and is the first to offer target-specific ratings on a three-point Likert scale, enabling the detection of hate expressions in Korean across varying degrees of offensiveness. We conduct experiments showing the effectiveness of the proposed corpus, including a comparison with existing datasets. Additionally, to address potential noise and bias in human annotations, we explore a novel idea of adopting the Cognitive Reflection Test, which is widely used in social science for assessing an individual's cognitive ability, as a proxy of labeling quality. Findings indicate that annotations from individuals with the lowest test scores tend to yield detection models that make biased predictions toward specific target groups and are less accurate. This study contributes to the NLP research on hate speech detection and resource construction. The code and dataset can be accessed at https://github.com/ssu-humane/K-HATERS.	cs.CL	15 pages, EMNLP 2023 (Findings)
9	VGX: Large-Scale Sample Generation for Boosting Learning-Based Software Vulnerability Analyses	Yu Nong,Richard Fang,Guangbei Yi,Kunsong Zhao,Xiapu Luo,Feng Chen,Haipeng Cai	Accompanying the successes of learning-based defensive software vulnerability analyses is the lack of large and quality sets of labeled vulnerable program samples, which impedes further advancement of those defenses. Existing automated sample generation approaches have shown potentials yet still fall short of practical expectations due to the high noise in the generated samples. This paper proposes VGX, a new technique aimed for large-scale generation of high-quality vulnerability datasets. Given a normal program, VGX identifies the code contexts in which vulnerabilities can be injected, using a customized Transformer featured with a new value-flowbased position encoding and pre-trained against new objectives particularly for learning code structure and context. Then, VGX materializes vulnerability-injection code editing in the identified contexts using patterns of such edits obtained from both historical fixes and human knowledge about real-world vulnerabilities. Compared to four state-of-the-art (SOTA) baselines (pattern-, Transformer-, GNN-, and pattern+Transformer-based), VGX achieved 99.09-890.06% higher F1 and 22.45%-328.47% higher label accuracy. For in-the-wild sample production, VGX generated 150,392 vulnerable samples, from which we randomly chose 10% to assess how much these samples help vulnerability detection, localization, and repair. Our results show SOTA techniques for these three application tasks achieved 19.15-330.80% higher F1, 12.86-19.31% higher top-10 accuracy, and 85.02-99.30% higher top-50 accuracy, respectively, by adding those samples to their original training data. These samples also helped a SOTA vulnerability detector discover 13 more real-world vulnerabilities (CVEs) in critical systems (e.g., Linux kernel) that would be missed by the original model.	cs.SE	None
0	PromptInfuser: How Tightly Coupling AI and UI Design Impacts Designers' Workflows	Savvas Petridis,Michael Terry,Carrie J. Cai	Prototyping AI applications is notoriously difficult. While large language model (LLM) prompting has dramatically lowered the barriers to AI prototyping, designers are still prototyping AI functionality and UI separately. We investigate how coupling prompt and UI design affects designers' workflows. Grounding this research, we developed PromptInfuser, a Figma plugin that enables users to create semi-functional mockups, by connecting UI elements to the inputs and outputs of prompts. In a study with 14 designers, we compare PromptInfuser to designers' current AI-prototyping workflow. PromptInfuser was perceived to be significantly more useful for communicating product ideas, more capable of producing prototypes that realistically represent the envisioned artifact, more efficient for prototyping, and more helpful for anticipating UI issues and technical constraints. PromptInfuser encouraged iteration over prompt and UI together, which helped designers identify UI and prompt incompatibilities and reflect upon their total solution. Together, these findings inform future systems for prototyping AI applications.	cs.HC	None
1	Off-Policy Evaluation for Large Action Spaces via Policy Convolution	Noveen Sachdeva,Lequn Wang,Dawen Liang,Nathan Kallus,Julian McAuley	Developing accurate off-policy estimators is crucial for both evaluating and optimizing for new policies. The main challenge in off-policy estimation is the distribution shift between the logging policy that generates data and the target policy that we aim to evaluate. Typically, techniques for correcting distribution shift involve some form of importance sampling. This approach results in unbiased value estimation but often comes with the trade-off of high variance, even in the simpler case of one-step contextual bandits. Furthermore, importance sampling relies on the common support assumption, which becomes impractical when the action space is large. To address these challenges, we introduce the Policy Convolution (PC) family of estimators. These methods leverage latent structure within actions -- made available through action embeddings -- to strategically convolve the logging and target policies. This convolution introduces a unique bias-variance trade-off, which can be controlled by adjusting the amount of convolution. Our experiments on synthetic and benchmark datasets demonstrate remarkable mean squared error (MSE) improvements when using PC, especially when either the action space or policy mismatch becomes large, with gains of up to 5 - 6 orders of magnitude over existing estimators.	cs.LG	Under review. 36 pages, 31 figures
2	A Review of Economic Incentives for Efficient Operation of Flexible Transmission	Xinyang Rui,Omid Mirzapour,Brittany Pruneau,Mostafa Sahraei-Ardakani	The growing penetration of renewable energy requires upgrades to the transmission network to ensure the deliverability of renewable generation. As an efficient alternative to transmission expansion, flexible transmission technologies, whose benefits have been widely studied, can alleviate transmission system congestion and enhance renewable energy integration. However, under the current market structure, investments for these technologies only receive a regulated rate of return, providing little to no incentive for efficient operation. Additionally, a regulated rate of return creates an incentive for building more transmission lines rather than efficient utilization of the existing system. Therefore, investments in flexible transmission technologies remain rather limited. To facilitate the deployment of flexible transmission, improve system efficiency, and accommodate renewable energy integration, a proper incentive structure for flexible transmission technologies, compatible with the current market design, is vital. This paper reviews the current market-based mechanisms for various flexible transmission technologies, including impedance control, dynamic line rating, and transmission switching. This review pinpoints current challenges of the market-based operation of flexible transmission and provides insights for future endeavors in designing efficient price signals for flexible transmission operation.	eess.SY	2023 55th North American Power Symposium (NAPS)
3	What Makes it Ok to Set a Fire? Iterative Self-distillation of Contexts and Rationales for Disambiguating Defeasible Social and Moral Situations	Kavel Rao,Liwei Jiang,Valentina Pyatkin,Yuling Gu,Niket Tandon,Nouha Dziri,Faeze Brahman,Yejin Choi	Moral or ethical judgments rely heavily on the specific contexts in which they occur. Understanding varying shades of defeasible contextualizations (i.e., additional information that strengthens or attenuates the moral acceptability of an action) is critical to accurately represent the subtlety and intricacy of grounded human moral judgment in real-life scenarios.   We introduce defeasible moral reasoning: a task to provide grounded contexts that make an action more or less morally acceptable, along with commonsense rationales that justify the reasoning. To elicit high-quality task data, we take an iterative self-distillation approach that starts from a small amount of unstructured seed knowledge from GPT-3 and then alternates between (1) self-distillation from student models; (2) targeted filtering with a critic model trained by human judgment (to boost validity) and NLI (to boost diversity); (3) self-imitation learning (to amplify the desired data quality). This process yields a student model that produces defeasible contexts with improved validity, diversity, and defeasibility. From this model we distill a high-quality dataset, \delta-Rules-of-Thumb, of 1.2M entries of contextualizations and rationales for 115K defeasible moral actions rated highly by human annotators 85.9% to 99.8% of the time. Using \delta-RoT we obtain a final student model that wins over all intermediate student models by a notable margin.	cs.CL	Camera Ready EMNLP Findings 2023. First two authors contributed   equally
4	ConstitutionMaker: Interactively Critiquing Large Language Models by Converting Feedback into Principles	Savvas Petridis,Ben Wedin,James Wexler,Aaron Donsbach,Mahima Pushkarna,Nitesh Goyal,Carrie J. Cai,Michael Terry	Large language model (LLM) prompting is a promising new approach for users to create and customize their own chatbots. However, current methods for steering a chatbot's outputs, such as prompt engineering and fine-tuning, do not support users in converting their natural feedback on the model's outputs to changes in the prompt or model. In this work, we explore how to enable users to interactively refine model outputs through their feedback, by helping them convert their feedback into a set of principles (i.e. a constitution) that dictate the model's behavior. From a formative study, we (1) found that users needed support converting their feedback into principles for the chatbot and (2) classified the different principle types desired by users. Inspired by these findings, we developed ConstitutionMaker, an interactive tool for converting user feedback into principles, to steer LLM-based chatbots. With ConstitutionMaker, users can provide either positive or negative feedback in natural language, select auto-generated feedback, or rewrite the chatbot's response; each mode of feedback automatically generates a principle that is inserted into the chatbot's prompt. In a user study with 14 participants, we compare ConstitutionMaker to an ablated version, where users write their own principles. With ConstitutionMaker, participants felt that their principles could better guide the chatbot, that they could more easily convert their feedback into principles, and that they could write principles more efficiently, with less mental demand. ConstitutionMaker helped users identify ways to improve the chatbot, formulate their intuitive responses to the model into feedback, and convert this feedback into specific and clear principles. Together, these findings inform future tools that support the interactive critiquing of LLM outputs.	cs.HC	None
5	Fluid-gravity correspondence and causal first-order relativistic viscous hydrodynamics	Luca Ciambelli,Luis Lehner	The fluid-gravity correspondence is a duality between anti-de Sitter Einstein gravity and a relativistic fluid living at the conformal boundary. We show that one can accommodate the causal first-order viscous hydrodynamics recently developed by Bemfica, Disconzi, Noronha, and Kovtun in this framework, by requiring a set of natural conditions for the geometric data at the horizon. The latter hosts an induced Carrollian fluid, whose equations of motion are shown to be tightly tied to the ones describing the fluid at the boundary. Functional expressions for the transport coefficients are found --with those associated to viscosity and heat flux uniquely determined--, satisfying a set of known causality requirements for the underlying equations of motion.	hep-th	V1
6	zonoLAB: A MATLAB toolbox for set-based control systems analysis using hybrid zonotopes	Justin Koeln,Trevor J. Bird,Jacob Siefert,Justin Ruths,Herschel Pangborn,Neera Jain	This paper introduces zonoLAB, a MATLAB-based toolbox for set-based control system analysis using the hybrid zonotope set representation. Hybrid zonotopes have proven to be an expressive set representation that can exactly represent the reachable sets of mixed-logical dynamical systems and tightly approximate the reachable sets of nonlinear dynamic systems. Moreover, hybrid zonotopes can exactly represent the continuous piecewise linear control laws associated with model predictive control and the input-output mappings of neural networks with piecewise linear activation functions. The hybrid zonotope set representation is also highly exploitable, where efficient methods developed for mixed-integer linear programming can be directly used for set operation and analysis. The zonoLAB toolbox is designed to make these capabilities accessible to the dynamic systems and controls community, with functionality spanning fundamental operations with hybrid zonotope, constrained zonotope, and zonotope set representations, powerful set analysis tools, and general-purpose algorithms for reachability analysis of open- and closed-loop systems.	eess.SY	None
7	The Mason-Alberta Phonetic Segmenter: A forced alignment system based on deep neural networks and interpolation	Matthew C. Kelley,Scott James Perry,Benjamin V. Tucker	Forced alignment systems automatically determine boundaries between segments in speech data, given an orthographic transcription. These tools are commonplace in phonetics to facilitate the use of speech data that would be infeasible to manually transcribe and segment. In the present paper, we describe a new neural network-based forced alignment system, the Mason-Alberta Phonetic Segmenter (MAPS). The MAPS aligner serves as a testbed for two possible improvements we pursue for forced alignment systems. The first is treating the acoustic model in a forced aligner as a tagging task, rather than a classification task, motivated by the common understanding that segments in speech are not truly discrete and commonly overlap. The second is an interpolation technique to allow boundaries more precise than the common 10 ms limit in modern forced alignment systems. We compare configurations of our system to a state-of-the-art system, the Montreal Forced Aligner. The tagging approach did not generally yield improved results over the Montreal Forced Aligner. However, a system with the interpolation technique had a 27.92% increase relative to the Montreal Forced Aligner in the amount of boundaries within 10 ms of the target on the test set. We also reflect on the task and training process for acoustic modeling in forced alignment, highlighting how the output targets for these models do not match phoneticians' conception of similarity between phones and that reconciliation of this tension may require rethinking the task and output targets or how speech itself should be segmented.	eess.AS	submitted for publication
8	Linear response of molecular polaritons	Joel Yuen-Zhou,Arghadip Koner	In this article, we show that the collective light-matter strong coupling regime, where $N$ molecular emitters couple to the photon mode of an optical cavity, can be mapped to a quantum impurity model where the photon is the impurity that is coupled to a bath of anharmonic transitions. In the thermodynamic limit where $N\gg1$, we argue that the bath can be replaced with an effective harmonic bath, leading to a dramatic simplification of the problem into one of coupled harmonic oscillators. We derive simple analytical expressions for linear optical spectra (transmission, reflection, and absorption) where the only molecular input required is the molecular linear susceptibility. This formalism is applied to a series of illustrative examples showcasing the role of temperature, disorder, vibronic coupling, and optical saturation of the molecular ensemble, explaining that it is useful even when describing an important class of nonlinear optical experiments. For completeness, we provide a comprehensive Appendix that includes a self-contained derivation of the relevant spectroscopic observables for arbitrary anharmonic systems (for both large and small $N$) within the rotating-wave approximation. While some of the presented results herein have already been reported in the literature, we provide a unified presentation of the results as well as new interpretations that connect powerful concepts in open quantum systems and linear response theory with molecular polaritonics.	quant-ph	15 pages, 6 figures
9	Electric quadrupole second harmonic generation revealing dual magnetic orders in a magnetic Weyl semimetal	Youngjun Ahn,Xiaoyu Guo,Rui Xue,Kejian Qu,Kai Sun,David Mandrus,Liuyan Zhao	Broken symmetries and electronic topology are nicely manifested together in the second order nonlinear optical responses from topologically nontrivial materials. While second order nonlinear optical effects from the electric dipole (ED) contribution have been extensively explored in polar Weyl semimetals (WSMs) with broken spatial inversion (SI) symmetry, they are rarely studied in centrosymmetric magnetic WSMs with broken time reversal (TR) symmetry due to complete suppression of the ED contribution. Here, we report experimental demonstration of optical second harmonic generation (SHG) in a magnetic WSM Co$_{3}$Sn$_{2}$S$_{2}$ from the electric quadrupole (EQ) contribution. By tracking the temperature dependence of the rotation anisotropy (RA) of SHG, we capture two magnetic phase transitions, with both the SHG intensity increasing and its RA pattern rotating at $T_{C,1}$=175K and $T_{C,2}$=120K subsequently. The fitted critical exponents for the SHG intensity and RA orientation near $T_{C,1}$ and $T_{C,2}$ suggest that the magnetic phase at $T_{C,1}$ is a 3D Ising-type out-of-plane ferromagnetism while the other at $T_{C,2}$ is a 3D XY-type all-in-all-out in-plane antiferromagnetism. Our results show the success of detection and exploration of EQ SHG in a centrosymmetric magnetic WSM, and hence open the pathway towards the future investigation of its tie to the band topology.	cond-mat.mtrl-sci	19 pages, 4 figures
0	G2-MonoDepth: A General Framework of Generalized Depth Inference from Monocular RGB+X Data	Haotian Wang,Meng Yang,Nanning Zheng	Monocular depth inference is a fundamental problem for scene perception of robots. Specific robots may be equipped with a camera plus an optional depth sensor of any type and located in various scenes of different scales, whereas recent advances derived multiple individual sub-tasks. It leads to additional burdens to fine-tune models for specific robots and thereby high-cost customization in large-scale industrialization. This paper investigates a unified task of monocular depth inference, which infers high-quality depth maps from all kinds of input raw data from various robots in unseen scenes. A basic benchmark G2-MonoDepth is developed for this task, which comprises four components: (a) a unified data representation RGB+X to accommodate RGB plus raw depth with diverse scene scale/semantics, depth sparsity ([0%, 100%]) and errors (holes/noises/blurs), (b) a novel unified loss to adapt to diverse depth sparsity/errors of input raw data and diverse scales of output scenes, (c) an improved network to well propagate diverse scene scales from input to output, and (d) a data augmentation pipeline to simulate all types of real artifacts in raw depth maps for training. G2-MonoDepth is applied in three sub-tasks including depth estimation, depth completion with different sparsity, and depth enhancement in unseen scenes, and it always outperforms SOTA baselines on both real-world data and synthetic data.	cs.CV	18 pages, 16 figures
1	FANToM: A Benchmark for Stress-testing Machine Theory of Mind in Interactions	Hyunwoo Kim,Melanie Sclar,Xuhui Zhou,Ronan Le Bras,Gunhee Kim,Yejin Choi,Maarten Sap	Theory of mind (ToM) evaluations currently focus on testing models using passive narratives that inherently lack interactivity. We introduce FANToM, a new benchmark designed to stress-test ToM within information-asymmetric conversational contexts via question answering. Our benchmark draws upon important theoretical requisites from psychology and necessary empirical considerations when evaluating large language models (LLMs). In particular, we formulate multiple types of questions that demand the same underlying reasoning to identify illusory or false sense of ToM capabilities in LLMs. We show that FANToM is challenging for state-of-the-art LLMs, which perform significantly worse than humans even with chain-of-thought reasoning or fine-tuning.	cs.CL	EMNLP 2023. Code and dataset can be found here:   https://hyunw.kim/fantom
2	"Let the Pretrained Language Models ""Imagine"" for Short Texts Topic Modeling"	Pritom Saha Akash,Jie Huang,Kevin Chen-Chuan Chang	Topic models are one of the compelling methods for discovering latent semantics in a document collection. However, it assumes that a document has sufficient co-occurrence information to be effective. However, in short texts, co-occurrence information is minimal, which results in feature sparsity in document representation. Therefore, existing topic models (probabilistic or neural) mostly fail to mine patterns from them to generate coherent topics. In this paper, we take a new approach to short-text topic modeling to address the data-sparsity issue by extending short text into longer sequences using existing pre-trained language models (PLMs). Besides, we provide a simple solution extending a neural topic model to reduce the effect of noisy out-of-topics text generation from PLMs. We observe that our model can substantially improve the performance of short-text topic modeling. Extensive experiments on multiple real-world datasets under extreme data sparsity scenarios show that our models can generate high-quality topics outperforming state-of-the-art models.	cs.CL	None
3	Fast multiplication of random dense matrices with fixed sparse matrices	Tianyu Liang,Riley Murray,Aydƒ±n Bulu√ß,James Demmel	This work focuses on accelerating the multiplication of a dense random matrix with a (fixed) sparse matrix, which is frequently used in sketching algorithms. We develop a novel scheme that takes advantage of blocking and recomputation (on-the-fly random number generation) to accelerate this operation. The techniques we propose decrease memory movement, thereby increasing the algorithm's parallel scalability in shared memory architectures. On the Intel Frontera architecture, our algorithm can achieve 2x speedups over libraries such as Eigen and Intel MKL on some examples. In addition, with 32 threads, we can obtain a parallel efficiency of up to approximately 45%. We also present a theoretical analysis for the memory movement lower bound of our algorithm, showing that under mild assumptions, it's possible to beat the data movement lower bound of general matrix-matrix multiply (GEMM) by a factor of $\sqrt M$, where $M$ is the cache size. Finally, we incorporate our sketching algorithm into a randomized least squares solver. For extremely over-determined sparse input matrices, we show that our results are competitive with SuiteSparse; in some cases, we obtain a speedup of 10x over SuiteSparse.	cs.CE	None
4	Fractal Landscapes in Policy Optimization	Tao Wang,Sylvia Herbert,Sicun Gao	"Policy gradient lies at the core of deep reinforcement learning (RL) in continuous domains. Despite much success, it is often observed in practice that RL training with policy gradient can fail for many reasons, even on standard control problems with known solutions. We propose a framework for understanding one inherent limitation of the policy gradient approach: the optimization landscape in the policy space can be extremely non-smooth or fractal for certain classes of MDPs, such that there does not exist gradient to be estimated in the first place. We draw on techniques from chaos theory and non-smooth analysis, and analyze the maximal Lyapunov exponents and H\""older exponents of the policy optimization objectives. Moreover, we develop a practical method that can estimate the local smoothness of objective function from samples to identify when the training process has encountered fractal landscapes. We show experiments to illustrate how some failure cases of policy optimization can be explained by such fractal landscapes."	cs.LG	18 pages and 28 figures
5	A Semantic-driven Approach for Maintenance Digitalization in the Pharmaceutical Industry	Ju Wu,Xiaochen Zheng,Marco Madlena,Dimitrios Kyritsis	The digital transformation of pharmaceutical industry is a challenging task due to the high complexity of involved elements and the strict regulatory compliance. Maintenance activities in the pharmaceutical industry play an essential role in ensuring product quality and integral functioning of equipment and premises. This paper first identifies the key challenges of digitalization in pharmaceutical industry and creates the corresponding problem space for key involved elements. A literature review is conducted to investigate the mainstream maintenance strategies, digitalization models, tools and official guidance from authorities in pharmaceutical industry. Based on the review result, a semantic-driven digitalization framework is proposed aiming to improve the digital continuity and cohesion of digital resources and technologies for maintenance activities in the pharmaceutical industry. A case study is conducted to verify the feasibility of the proposed framework based on the water sampling activities in Merck Serono facility in Switzerland. A tool-chain is presented to enable the functional modules of the framework. Some of the key functional modules within the framework are implemented and have demonstrated satisfactory performance. As one of the outcomes, a digital sampling assistant with web-based services is created to support the automated workflow of water sampling activities. The implementation result proves the potential of the proposed framework to solve the identified problems of maintenance digitalization in the pharmaceutical industry.	eess.SY	None
6	Nominality Score Conditioned Time Series Anomaly Detection by Point-Sequential Reconstruction	Chih-Yu Lai,Fan-Keng Sun,Zhengqi Gao,Jeffrey H. Lang,Duane S. Boning	Time series anomaly detection is challenging due to the complexity and variety of patterns that can occur. One major difficulty arises from modeling time-dependent relationships to find contextual anomalies while maintaining detection accuracy for point anomalies. In this paper, we propose a framework for unsupervised time series anomaly detection that utilizes point-based and sequence-based reconstruction models. The point-based model attempts to quantify point anomalies, and the sequence-based model attempts to quantify both point and contextual anomalies. Under the formulation that the observed time point is a two-stage deviated value from a nominal time point, we introduce a nominality score calculated from the ratio of a combined value of the reconstruction errors. We derive an induced anomaly score by further integrating the nominality score and anomaly score, then theoretically prove the superiority of the induced anomaly score over the original anomaly score under certain conditions. Extensive studies conducted on several public datasets show that the proposed framework outperforms most state-of-the-art baselines for time series anomaly detection.	cs.LG	NeurIPS 2023 (https://neurips.cc/virtual/2023/poster/70582)
7	Mind the Gap Between Conversations for Improved Long-Term Dialogue Generation	Qiang Zhang,Jason Naradowsky,Yusuke Miyao	Knowing how to end and resume conversations over time is a natural part of communication, allowing for discussions to span weeks, months, or years. The duration of gaps between conversations dictates which topics are relevant and which questions to ask, and dialogue systems which do not explicitly model time may generate responses that are unnatural. In this work we explore the idea of making dialogue models aware of time, and present GapChat, a multi-session dialogue dataset in which the time between each session varies. While the dataset is constructed in real-time, progress on events in speakers' lives is simulated in order to create realistic dialogues occurring across a long timespan. We expose time information to the model and compare different representations of time and event progress. In human evaluation we show that time-aware models perform better in metrics that judge the relevance of the chosen topics and the information gained from the conversation.	cs.CL	Accepted in the Findings of EMNLP 2023
8	Diverse Conventions for Human-AI Collaboration	Bidipta Sarkar,Andy Shih,Dorsa Sadigh	Conventions are crucial for strong performance in cooperative multi-agent games, because they allow players to coordinate on a shared strategy without explicit communication. Unfortunately, standard multi-agent reinforcement learning techniques, such as self-play, converge to conventions that are arbitrary and non-diverse, leading to poor generalization when interacting with new partners. In this work, we present a technique for generating diverse conventions by (1) maximizing their rewards during self-play, while (2) minimizing their rewards when playing with previously discovered conventions (cross-play), stimulating conventions to be semantically different. To ensure that learned policies act in good faith despite the adversarial optimization of cross-play, we introduce \emph{mixed-play}, where an initial state is randomly generated by sampling self-play and cross-play transitions and the player learns to maximize the self-play reward from this initial state. We analyze the benefits of our technique on various multi-agent collaborative games, including Overcooked, and find that our technique can adapt to the conventions of humans, surpassing human-level performance when paired with real users.	cs.AI	25 pages, 9 figures, 37th Conference on Neural Information Processing   Systems (NeurIPS 2023)
9	Sensor Attacks and Resilient Defense on HVAC Systems for Energy Market Signal Tracking	Guanyu Tian,Qun Zhou Sun,Yiyuan Qiao	The power flexibility from smart buildings makes them suitable candidates for providing grid services. The building automation system (BAS) that employs model predictive control (MPC) for grid services relies heavily on sensor data gathered from IoT-based HVAC systems through communication networks. However, cyber-attacks that tamper sensor values can compromise the accuracy and flexibility of HVAC system power adjustment. Existing studies on grid-interactive buildings mainly focus on the efficiency and flexibility of buildings' participation in grid operations, while the security aspect is lacking. In this paper, we investigate the effects of cyber-attacks on HVAC systems in grid-interactive buildings, specifically their power-tracking performance. We design a stochastic optimization-based stealthy sensor attack and a corresponding defense strategy using a resilient control framework. The attack and its defense are tested in a physical model of a test building with a single-chiller HVAC system. Simulation results demonstrate that minor falsifications caused by a stealthy sensor attack can significantly alter the power profile, leading to large power tracking errors. However, the resilient control framework can reduce the power tracking error by over 70% under such attacks without filtering out compromised data.	eess.SY	None
0	Quantum Multiphoton Rabi Oscillations in Waveguide QED	Debsuvra Mukhopadhyay,Jung-Tsung Shen	The future of quantum information processing hinges on chip-scale nanophotonics, specifically cavity QED and waveguide QED. One of the foremost processes underpinning quantum photonic technologies is the phenomenon of Rabi oscillations, which manifests when a qubit is irradiated by an intense laser source. Departing from the conventional semiclassical framework, we expound on the more general, quantum-theoretic case where the optical excitation takes the form of a multiphoton Fock state, and the qubit couples to a continuum of radiation modes. By employing the real-space formalism, we analytically explore the scattering dynamics of the photonic Fock state as it interfaces with a two-level emitter. The resulting amplitude for atomic excitation features a linear superposition of various independent scattering events that are triggered by the potential of sequential photon absorptions and emissions. The lowest-order excitation event, initiated by the stochastic scattering of one of the several photons, aptly characterizes the dynamics in a weak-field environment. This is complemented by a multitude of higher-order scattering events ensuing from repeated atom-photon interactions. The temporal evolution of the qubit excitation in our configuration closely mirrors the semiclassical predictions, particularly in the strong-pumping limit where Rabi oscillations unfold. Notably, this compatibility with the semiclassical paradigm applies both to the weak-driving and large-detuning limits. Our analysis, therefore, extends the existing results on quantum Rabi oscillations pertinent to single-mode cavity QED, to the multimode, waveguide-QED configurations wherein flying photons are the information carriers. Finally, we explore the scattering dynamics of pulsed wave packets, highlighting the potential to substantially enhance excitation efficiency, even in scenarios involving just a few photons.	quant-ph	None
1	Initial-final mass relation from white dwarfs within 40 pc	Tim Cunningham,Pier-Emmanuel Tremblay,Mairi O'Brien	We present an initial-final mass relation derived from the spectroscopically-complete volume-limited 40 pc sample of white dwarfs. The relation is modelled using population synthesis methods to derive an initial stellar population which can be fit to the observed mass distribution of white dwarfs. The population synthesis accounts for binary evolution, where higher-mass white dwarfs are more likely to be merger products than their lower-mass counterparts. Uncertainties are accounted from the initial mass function, stellar metallicity and age of the Galactic disc. We also consider biases induced by the spectral type of the white dwarf where pure-hydrogen atmosphere white dwarfs are likely to have more accurate masses, whilst the full white dwarf sample will have fewer biases arising from spectral evolution. We provide a four-piece segmented linear regression using Monte Carlo methods to sample the 1-$\sigma$ range of uncertainty on the initial stellar population. The derived initial-final mass relation provides a self-consistent determination of the progenitor mass for white dwarfs in the Solar neighbourhood which will be useful to study the local stellar formation history.	astro-ph.SR	Eleven pages. Accepted for publication in MNRAS
2	Visual Elements and Cognitive Biases Influence Interpretations of Trends in Scatter Plots	Alexandre Filipowicz,Scott Carter,Nayeli Bravo,Rumen Iliev,Shabnam Hakimi,David Ayman Shamma,Kent Lyons,Candice Hogan,Charlene Wu	Visualizations are common methods to convey information but also increasingly used to spread misinformation. It is therefore important to understand the factors people use to interpret visualizations. In this paper, we focus on factors that influence interpretations of scatter plots, investigating the extent to which common visual aspects of scatter plots (outliers and trend lines) and cognitive biases (people's beliefs) influence perception of correlation trends. We highlight three main findings: outliers skew trend perception but exert less influence than other points; trend lines make trends seem stronger but also mitigate the influence of some outliers; and people's beliefs have a small influence on perceptions of weak, but not strong correlations. From these results we derive guidelines for adjusting visual elements to mitigate the influence of factors that distort interpretations of scatter plots. We explore how these guidelines may generalize to other visualization types and make recommendations for future studies.	cs.HC	18 pages, 6 figure, 2 tables
3	Adaptive Fuzzy Tracking Control for Nonlinear State Constrained Pure-Feedback Systems With Input Delay via Dynamic Surface Technique	Ju Wu,Tong Wang	"This brief constructs the adaptive backstepping control scheme for a class of pure-feedback systems with input delay and full state constraints. With the help of Mean Value Theorem, the pure-feedback system is transformed into strict-feedback one. Barrier Lyapunov functions are employed to guarantee all of the states remain constrained within predefined sets. By introducing the Pade approximation method and corresponding intermediate, the impact generated by input delay on the output tracking performance of the system can be eliminated. Furthermore, a low-pass filter driven by a newly-defined control input, is employed to generate the actual control input, which facilitates the design of backstepping control. To approximate the unknown functions with a desired level of accuracy, the fuzzy logic systems (FLSs) are utilized by choosing appropriate fuzzy rules, logics and so on. The minimal learning parameter (MLP) technique is employed to decrease the number of nodes and parameters in FLSs, and dynamic surface control (DSC) technique is leveraged to avoid so-called ""explosion of complexity"". Moreover, smooth robust compensators are introduced to circumvent the influences of external disturbance and approximation errors. By stability analysis, it is proved that all of signals in the closed-loop system are semi-globally ultimately uniform bounded, and the tracking error can be within a arbitrary small neighbor of origin via selecting appropriate parameters of controllers. Finally, the results of numerical illustration are provided to demonstrate the effectiveness of the designed method."	eess.SY	arXiv admin note: text overlap with arXiv:2310.15407
4	GPT-4 as an Effective Zero-Shot Evaluator for Scientific Figure Captions	Ting-Yao Hsu,Chieh-Yang Huang,Ryan Rossi,Sungchul Kim,C. Lee Giles,Ting-Hao K. Huang	There is growing interest in systems that generate captions for scientific figures. However, assessing these systems output poses a significant challenge. Human evaluation requires academic expertise and is costly, while automatic evaluation depends on often low-quality author-written captions. This paper investigates using large language models (LLMs) as a cost-effective, reference-free method for evaluating figure captions. We first constructed SCICAP-EVAL, a human evaluation dataset that contains human judgments for 3,600 scientific figure captions, both original and machine-made, for 600 arXiv figures. We then prompted LLMs like GPT-4 and GPT-3 to score (1-6) each caption based on its potential to aid reader understanding, given relevant context such as figure-mentioning paragraphs. Results show that GPT-4, used as a zero-shot evaluator, outperformed all other models and even surpassed assessments made by Computer Science and Informatics undergraduates, achieving a Kendall correlation score of 0.401 with Ph.D. students rankings	cs.CL	To Appear in EMNLP 2023 Findings
5	Renormalizaci√≥n conforme de teor√≠as escalar-tensor de la gravedad	Mairym Busnego-Barrientos	In this thesis, we investigate the method of conformal renormalization applied to theories with degrees of freedom beyond the metric ones. Specifically, we examine this method in the presence of a scalar field. To do this, as part of a review, we revisit the action principle of General Relativity and Einstein's equations, in addition to re-examining the conditions for this theory to have a well-defined variational principle when Dirichlet boundary conditions are imposed. We then explore various methods for calculating conserved charges in asymptotically flat spaces. In asymptotically anti-de Sitter spaces, we study two renormalization schemes that are relevant to this work. To motivate the method used here, we observe that Conformal Gravity is finite for spaces that are asymptotically anti-de Sitter, as demonstrated in [Grumiller, 2014]. This guiding principle gives us a clue as to how conformal symmetry may be related to renormalization in spacetimes with such asymptotics. The basis of this construction is the extension of a covariant tensor under Weyl rescalings composed of the metric and the scalar field as proposed in [Oliva and Ray, 2011]. This extension ensures that the conformal weight of this tensor is equal to that of the Weyl tensor. We extend this realization by considering tensor-scalar theories with conformal symmetry, coupled with the Einstein-AdS action written in the MacDowell-Mansouri form. Despite the fact that the Einstein-AdS sector breaks conformal symmetry, we show that the entire theory can still be renormalized if the scalar field has an appropriate decay when considering asymptotically anti-de Sitter solutions. Finally, we study black hole-type solutions, calculating their Hawking temperature and the Euclidean on-shell action, explicitly demonstrating that the latter is finite for asymptotically anti-de Sitter spaces.	hep-th	Master's thesis based on arXiv:2212.04364
6	Towards contrast-agnostic soft segmentation of the spinal cord	Sandrine B√©dard,Naga Karthik Enamundram,Charidimos Tsagkas,Emanuele Pravat√†,Cristina Granziera,Andrew Smith,Kenneth Arnold Weber II,Julien Cohen-Adad	Spinal cord segmentation is clinically relevant and is notably used to compute spinal cord cross-sectional area (CSA) for the diagnosis and monitoring of cord compression or neurodegenerative diseases such as multiple sclerosis. While several semi and automatic methods exist, one key limitation remains: the segmentation depends on the MRI contrast, resulting in different CSA across contrasts. This is partly due to the varying appearance of the boundary between the spinal cord and the cerebrospinal fluid that depends on the sequence and acquisition parameters. This contrast-sensitive CSA adds variability in multi-center studies where protocols can vary, reducing the sensitivity to detect subtle atrophies. Moreover, existing methods enhance the CSA variability by training one model per contrast, while also producing binary masks that do not account for partial volume effects. In this work, we present a deep learning-based method that produces soft segmentations of the spinal cord. Using the Spine Generic Public Database of healthy participants ($\text{n}=267$; $\text{contrasts}=6$), we first generated participant-wise soft ground truth (GT) by averaging the binary segmentations across all 6 contrasts. These soft GT, along with a regression-based loss function, were then used to train a UNet model for spinal cord segmentation. We evaluated our model against state-of-the-art methods and performed ablation studies involving different GT mask types, loss functions, and contrast-specific models. Our results show that using the soft average segmentations along with a regression loss function reduces CSA variability ($p < 0.05$, Wilcoxon signed-rank test). The proposed spinal cord segmentation model generalizes better than the state-of-the-art contrast-specific methods amongst unseen datasets, vendors, contrasts, and pathologies (compression, lesions), while accounting for partial volume effects.	eess.IV	Submitted to Medical Image Analysis
7	Non-destructive characterization techniques for battery performance and lifecycle assessment	Charlotte Gervillie-Mouravieff,Wurigumula Bao,Daniel A Steingart,Ying Shirley-Meng	As global energy demands escalate, and the use of non-renewable resources become untenable, renewable resources and electric vehicles require far better batteries to stabilize the new energy landscape. To maximize battery performance and lifetime, understanding and monitoring the fundamental mechanisms that govern their operation throughout their life cycle is crucial. Unfortunately, from the moment batteries are sealed until their end-of-life, they remain a black box, and our current knowledge of a commercial battery s health status is limited to current (I), voltage (V), temperature (T), and impedance (R) measurements, at the cell or even module level during use. Electrochemical models work best when the battery is new, and as state reckoning drifts leading to an over-reliance on insufficient data to establish conservative safety margins resulting in the systematic under-utilization of cells and batteries. While the field of operando characterization is not new, the emergence of techniques capable of tracking commercial battery properties under realistic conditions has unlocked a trove of chemical, thermal, and mechanical data that has the potential to revolutionize the development and utilization strategies of both new and used lithium-ion devices. In this review, we examine the latest advances in non-destructive operando characterization techniques, including electrical sensors, optical fibers, acoustic transducers, X-ray-based imaging and thermal imaging (IR camera or calorimetry), and their potential to improve our comprehension of degradation mechanisms, reduce time and cost, and enhance battery performance throughout its life cycle.	cond-mat.mtrl-sci	None
8	Sigma models as Gross-Neveu models. II	Dmitri Bykov	We summarize some (mostly geometric) facts underlying the relation between 2D integrable sigma models and generalized Gross-Neveu models, emphasizing connections to the theory of nilpotent orbits, Springer resolutions and quiver varieties. This is meant to shed light on the general setup when this correspondence holds.	hep-th	17 pages, 1 figure
9	DoGE: Domain Reweighting with Generalization Estimation	Simin Fan,Matteo Pagliardini,Martin Jaggi	The coverage and composition of the pretraining data corpus significantly impacts the generalization ability of large language models. Conventionally, the pretraining corpus is composed of various source domains (e.g. CommonCrawl, Wikipedia, Github etc.) according to certain sampling probabilities (domain weights). However, current methods lack a principled way to optimize domain weights for ultimate goal for generalization. We propose DOmain reweighting with Generalization Estimation (DoGE), where we reweigh the sampling probability from each domain based on its contribution to the final generalization objective assessed by a gradient-based generalization estimation function. First, we train a small-scale proxy model with a min-max optimization to obtain the reweighted domain weights. At each step, the domain weights are updated to maximize the overall generalization gain by mirror descent. Finally we use the obtained domain weights to train a larger scale full-size language model. On SlimPajama-6B dataset, with universal generalization objective, DoGE achieves better average perplexity and zero-shot reasoning accuracy. On out-of-domain generalization tasks, DoGE reduces perplexity on the target domain by a large margin. We further apply a parameter-selection scheme which improves the efficiency of generalization estimation.	cs.LG	None
0	A Global Fit of Non-Relativistic Effective Dark Matter Operators Including Solar Neutrinos	Neal P. Avis Kozar,Pat Scott,Aaron C. Vincent	We perform a global fit of dark matter interactions with nucleons using a non-relativistic effective operator description, considering both direct detection and neutrino data. We examine the impact of combining the direct detection experiments CDMSlite, CRESST-II, CRESST-III, DarkSide-50, LUX, LZ, PandaX-II, PandaX-4T, PICO-60, SIMPLE, SuperCDMS, XENON100, and XENON1T along with neutrino data from IceCube and ANTARES. While current neutrino telescope data lead to increased sensitivity compared to underground nuclear scattering experiments for dark matter masses above 100 GeV, our future projections show that the next generation of underground experiments will significantly outpace solar searches for most dark matter-nucleon elastic scattering interactions.	hep-ph	12+9 pages, 26 figures, Likelihoods available at   https://zenodo.org/records/10032218
1	MEMPSEP III. A machine learning-oriented multivariate data set for forecasting the Occurrence and Properties of Solar Energetic Particle Events using a Multivariate Ensemble Approach	Kimberly Moreland,Maher Dayeh,Hazel M. Bain,Subhamoy Chatterjee,Andres Munoz-Jaramillo,Samuel Hart	We introduce a new multivariate data set that utilizes multiple spacecraft collecting in-situ and remote sensing heliospheric measurements shown to be linked to physical processes responsible for generating solar energetic particles (SEPs). Using the Geostationary Operational Environmental Satellites (GOES) flare event list from Solar Cycle (SC) 23 and part of SC 24 (1998-2013), we identify 252 solar events (flares) that produce SEPs and 17,542 events that do not. For each identified event, we acquire the local plasma properties at 1 au, such as energetic proton and electron data, upstream solar wind conditions, and the interplanetary magnetic field vector quantities using various instruments onboard GOES and the Advanced Composition Explorer (ACE) spacecraft. We also collect remote sensing data from instruments onboard the Solar Dynamic Observatory (SDO), Solar and Heliospheric Observatory (SoHO), and the Wind solar radio instrument WAVES. The data set is designed to allow for variations of the inputs and feature sets for machine learning (ML) in heliophysics and has a specific purpose for forecasting the occurrence of SEP events and their subsequent properties. This paper describes a dataset created from multiple publicly available observation sources that is validated, cleaned, and carefully curated for our machine-learning pipeline. The dataset has been used to drive the newly-developed Multivariate Ensemble of Models for Probabilistic Forecast of Solar Energetic Particles (MEMPSEP; see MEMPSEP I (Chatterjee et al., 2023) and MEMPSEP II (Dayeh et al., 2023) for associated papers).	astro-ph.SR	None
2	Irreducible Curriculum for Language Model Pretraining	Simin Fan,Martin Jaggi	Automatic data selection and curriculum design for training large language models is challenging, with only a few existing methods showing improvements over standard training. Furthermore, current schemes focus on domain-level selection, overlooking the more fine-grained contributions of each individual training point. It is difficult to apply traditional datapoint selection methods on large language models: most online batch selection methods perform two-times forward or backward passes, which introduces considerable extra costs with large-scale models. To mitigate these obstacles, we propose irreducible curriculum as a curriculum learning algorithm for language model pretraining, which prioritizes samples with higher learnability. Specifically, to avoid prohibitive extra computation overhead, we simulate the sample loss along the main model's training trajectory using a small-scale proxy model. Our experiments on the RedPajama-1B dataset demonstrate a consistent improvement on validation perplexity across all 7 domains compared to random uniform baseline and the anti-curriculum strategy. Our method also reduces the sharpness of the network and illustrates a better 5-shot accuracy on MMLU benchmarks.	cs.CL	None
3	Remote Heart Rate Monitoring in Smart Environments from Videos with Self-supervised Pre-training	Divij Gupta,Ali Etemad	Recent advances in deep learning have made it increasingly feasible to estimate heart rate remotely in smart environments by analyzing videos. However, a notable limitation of deep learning methods is their heavy reliance on extensive sets of labeled data for effective training. To address this issue, self-supervised learning has emerged as a promising avenue. Building on this, we introduce a solution that utilizes self-supervised contrastive learning for the estimation of remote photoplethysmography (PPG) and heart rate monitoring, thereby reducing the dependence on labeled data and enhancing performance. We propose the use of 3 spatial and 3 temporal augmentations for training an encoder through a contrastive framework, followed by utilizing the late-intermediate embeddings of the encoder for remote PPG and heart rate estimation. Our experiments on two publicly available datasets showcase the improvement of our proposed approach over several related works as well as supervised learning baselines, as our results approach the state-of-the-art. We also perform thorough experiments to showcase the effects of using different design choices such as the video representation learning method, the augmentations used in the pre-training stage, and others. We also demonstrate the robustness of our proposed method over the supervised learning approaches on reduced amounts of labeled data.	cs.CV	Accepted in IEEE Internet of Things Journal 2023
4	Error analysis of generative adversarial network	Mahmud Hasan,Hailin Sang	The generative adversarial network (GAN) is an important model developed for high-dimensional distribution learning in recent years. However, there is a pressing need for a comprehensive method to understand its error convergence rate. In this research, we focus on studying the error convergence rate of the GAN model that is based on a class of functions encompassing the discriminator and generator neural networks. These functions are VC type with bounded envelope function under our assumptions, enabling the application of the Talagrand inequality. By employing the Talagrand inequality and Borel-Cantelli lemma, we establish a tight convergence rate for the error of GAN. This method can also be applied on existing error estimations of GAN and yields improved convergence rates. In particular, the error defined with the neural network distance is a special case error in our definition.	stat.ML	16 pages
5	Course Correcting Koopman Representations	Mahan Fathi,Clement Gehring,Jonathan Pilault,David Kanaa,Pierre-Luc Bacon,Ross Goroshin	Koopman representations aim to learn features of nonlinear dynamical systems (NLDS) which lead to linear dynamics in the latent space. Theoretically, such features can be used to simplify many problems in modeling and control of NLDS. In this work we study autoencoder formulations of this problem, and different ways they can be used to model dynamics, specifically for future state prediction over long horizons. We discover several limitations of predicting future states in the latent space and propose an inference-time mechanism, which we refer to as Periodic Reencoding, for faithfully capturing long term dynamics. We justify this method both analytically and empirically via experiments in low and high dimensional NLDS.	cs.LG	None
6	Containerized Vertical Farming Using Cobots	Dasharadhan Mahalingam,Aditya Patankar,Khiem Phi,Nilanjan Chakraborty,Ryan McGann,IV Ramakrishnan	Containerized vertical farming is a type of vertical farming practice using hydroponics in which plants are grown in vertical layers within a mobile shipping container. Space limitations within shipping containers make the automation of different farming operations challenging. In this paper, we explore the use of cobots (i.e., collaborative robots) to automate two key farming operations, namely, the transplantation of saplings and the harvesting of grown plants. Our method uses a single demonstration from a farmer to extract the motion constraints associated with the tasks, namely, transplanting and harvesting, and can then generalize to different instances of the same task. For transplantation, the motion constraint arises during insertion of the sapling within the growing tube, whereas for harvesting, it arises during extraction from the growing tube. We present experimental results to show that using RGBD camera images (obtained from an eye-in-hand configuration) and one demonstration for each task, it is feasible to perform transplantation of saplings and harvesting of leafy greens using a cobot, without task-specific programming.	cs.RO	None
7	GD-COMET: A Geo-Diverse Commonsense Inference Model	Mehar Bhatia,Vered Shwartz	With the increasing integration of AI into everyday life, it's becoming crucial to design AI systems that serve users from diverse backgrounds by making them culturally aware. In this paper, we present GD-COMET, a geo-diverse version of the COMET commonsense inference model. GD-COMET goes beyond Western commonsense knowledge and is capable of generating inferences pertaining to a broad range of cultures. We demonstrate the effectiveness of GD-COMET through a comprehensive human evaluation across 5 diverse cultures, as well as extrinsic evaluation on a geo-diverse task. The evaluation shows that GD-COMET captures and generates culturally nuanced commonsense knowledge, demonstrating its potential to benefit NLP applications across the board and contribute to making NLP more inclusive.	cs.CL	Accepted to EMNLP 2023 Main Conference
8	Topological constraints on general relativistic galaxies: Exploring novel conical singularity networks	Marco Galoppo	The van Stockum-Bonner class of spacetimes can be interpreted as fully general relativistic models for rigidly rotating disc galaxies. Frame-dragging effects in these geometries demand a recalibration of the dark matter content relative to models based on Newtonian gravity. We investigate the previously overlooked topological structure of these spacetimes, in relation to the viability of fully general relativistic galaxy toy models. We discuss the appropriate boundary conditions for these solutions to model disc galaxies. For this class of spacetimes, we show the existence of a network of quasi-regular singularities along the rotation axis of the galaxies. The existence of such novel conical defect structures further restricts the physical viability of the van Stockum-Bonner class. Unwinding these issues is key to avoiding pathologies in future fully general relativistic modelling of alternative to dark matter.	gr-qc	13 pages, 1 figure
9	General Approach to Neutrino Mass Mechanisms with Sterile Neutrinos	Yale Fan,Anil Thapa	We present a mathematical framework for constructing the most general neutrino mass matrices that yield the observed spectrum of light active neutrino masses in conjunction with arbitrarily many heavy sterile neutrinos, without the need to assume a hierarchy between Dirac and Majorana mass terms. The seesaw mechanism is a byproduct of the formalism, along with many other possibilities for generating tiny neutrino masses. We comment on phenomenological applications of this approach, in particular deriving a mechanism to address the long-standing $(g-2)_\mu$ anomaly in the context of the left-right symmetric model.	hep-ph	5 pages and appendices, 2 figures
0	Spectral properties of generalized Paley graphs	Ricardo A. Podest√°,Denis E. Videla	We study the spectrum of generalized Paley graphs $\Gamma(k,q)=Cay(\mathbb{F}_q,R_k)$, undirected or not, with $R_k=\{x^k:x\in \mathbb{F}_q^*\}$ where $q=p^m$ with $p$ prime and $k\mid q-1$. We first show that the eigenvalues of $\Gamma(k,q)$ are given by the Gaussian periods $\eta_{i}^{(k,q)}$ with $0\le i\le k-1$. Then, we explicitly compute the spectrum of $\Gamma(k,q)$ with $1\le k \le 4$ and of $\Gamma(5,q)$ for $p\equiv 1\pmod 5$ and $5\mid m$. Also, we characterize those GP-graphs having integral spectrum, showing that $\Gamma(k,q)$ is integral if and only if $p$ divides $(q-1)/(p-1)$. Next, we focus on the family of semiprimitive GP-graphs. We show that they are integral strongly regular graphs (of pseudo-Latin square type). Finally, we characterize all integral Ramanujan graphs $\Gamma(k,q)$ with $1\le k \le 4$ or where $(k,q)$ is a semiprimitive pair.	math.CO	29 pages, 2 tables. The old manuscript arXiv:1908.08097 has grown and   we divided it into two different manuscripts with different names, this is   the first half, and the other one is in progress
1	Initial conditions for Starobinsky Inflation with a positive spatial curvature	Daniel M√ºller,Alexey Toporensky	"We have found numerically initial conditions in the $(R, H)$ plane leading to a successful Starobinsky inflation in $R+R^2$ gravity for a isotropic metrics with positive spatial curvature. Trajectories can reach inflation regime either directly or going through a bounce, and even recollapse followed by a bounce. Our numerical plots indicate that ``good"" initial conditions exist even for big initial spatial curvature, however, we argue that such a trajectory must cross a region of rather big $R$ or $H$. This means that the range of viability of $R+R^2$ theory in the $(R,H)$ plane directly affect the question of viability of Starobinsky inflation for a positive spatial curvature isotropic Universe."	gr-qc	None
2	The operator growth hypothesis in open quantum systems	N. S. Srivatsa,Curt von Keyserlingk	The operator growth hypothesis (OGH) is a technical conjecture about the behaviour of operators -- specifically, the asymptotic growth of their Lanczos coefficients -- under repeated action by a Liouvillian. It is expected to hold for a sufficiently generic closed many-body system. When it holds, it yields bounds on the high frequency behavior of local correlation functions and measures of chaos (like OTOCs). It also gives a route to numerically estimating response functions. Here we investigate the generalisation of OGH to open quantum systems, where the Liouvillian is replaced by a Lindbladian. For a quantum system with local Hermitian jump operators, we show that the OGH is modified: we define a generalisation of the Lanczos coefficient and show that it initially grows linearly as in the original OGH, but experiences exponentially growing oscillations on scales determined by the dissipation strength. We see this behavior manifested in a semi-analytically solvable model (large-q SYK with dissipation), numerically for an ergodic spin chain, and in a solvable toy model for operator growth in the presence of dissipation (which resembles a non-Hermitian single-particle hopping process). Finally, we show that the modified OGH connects to a fundamental difference between Lindblad and closed systems: at high frequencies, the spectral functions of the former decay algebraically, while in the latter they decay exponentially. This is an experimentally testable statement, which also places limitations on the applicability of Lindbladians to systems in contact with equilibrium environments.	quant-ph	9 pages, 6 figures
3	Optimal Structured Matrix Approximation for Robustness to Incomplete Biosequence Data	Chris Salahub,Jeffrey Uhlmann	We propose a general method for optimally approximating an arbitrary matrix $\mathbf{M}$ by a structured matrix $\mathbf{T}$ (circulant, Toeplitz/Hankel, etc.) and examine its use for estimating the spectra of genomic linkage disequilibrium matrices. This application is prototypical of a variety of genomic and proteomic problems that demand robustness to incomplete biosequence information. We perform a simulation study and corroborative test of our method using real genomic data from the Mouse Genome Database. The results confirm the predicted utility of the method and provide strong evidence of its potential value to a wide range of bioinformatics applications. Our optimal general matrix approximation method is expected to be of independent interest to an even broader range of applications in applied mathematics and engineering.	stat.AP	None
4	Orbital evolution of LIGO-Virgo binaries in stellar clusters driven by cluster tides, stellar encounters and general relativity	Alexander Rasskazov,Roman R. Rafikov	Origin of LIGO/Virgo gravitational wave events may involve production of binaries with relativistic components in dense stellar systems - globular or nuclear star clusters - and their subsequent evolution towards merger. Orbital parameters of these binaries (the inner orbit) and their motion inside the cluster (the outer orbit) evolve due to both external agents - random encounters with cluster stars and cluster tides due to the smooth cluster potential - and the internal ones - various sources of dissipation and precession within the binary. We present a numerical framework - Binary Evolution in Stellar Clusters (BESC) - that follows the evolution of the binary inner and outer orbits accounting for all these effects simultaneously, enabling efficient Monte Carlo studies. The secular effect of cluster tides is computed in the singly-averaged approximation, without averaging over the outer binary orbit. As to stellar encounters, we include the effects of both close and distant flybys on the inner and outer orbits of the binary, respectively. In particular, this allows us to explicitly account for the dynamical friction sinking the binary towards the cluster centre. Also, given our focus on the LIGO/Virgo sources, we include the general relativistic precession (which suppresses cluster tides at high eccentricities) and the gravitational wave emission (shrinking the binary orbit). We use BESC to illustrate a number of characteristic binary evolutionary outcomes and discuss relative contributions of different physical processes. BESC can also be used to study other objects in clusters, e.g. blue stragglers, hot Jupiters, X-ray binaries, etc.	astro-ph.GA	20 pages, 16 figures, submitted to MNRAS
5	Semantic Data Management in Data Lakes	Sayed Hoseini,Johannes Theissen-Lipp,Christoph Quix	In recent years, data lakes emerged as away to manage large amounts of heterogeneous data for modern data analytics. One way to prevent data lakes from turning into inoperable data swamps is semantic data management. Some approaches propose the linkage of metadata to knowledge graphs based on the Linked Data principles to provide more meaning and semantics to the data in the lake. Such a semantic layer may be utilized not only for data management but also to tackle the problem of data integration from heterogeneous sources, in order to make data access more expressive and interoperable. In this survey, we review recent approaches with a specific focus on the application within data lake systems and scalability to Big Data. We classify the approaches into (i) basic semantic data management, (ii) semantic modeling approaches for enriching metadata in data lakes, and (iii) methods for ontologybased data access. In each category, we cover the main techniques and their background, and compare latest research. Finally, we point out challenges for future work in this research area, which needs a closer integration of Big Data and Semantic Web technologies.	cs.DB	None
6	EpiK-Eval: Evaluation for Language Models as Epistemic Models	Gabriele Prato,Jerry Huang,Prasannna Parthasarathi,Shagun Sodhani,Sarath Chandar	In the age of artificial intelligence, the role of large language models (LLMs) is becoming increasingly central. Despite their growing prevalence, their capacity to consolidate knowledge from different training documents - a crucial ability in numerous applications - remains unexplored. This paper presents the first study examining the capability of LLMs to effectively combine such information within their parameter space. We introduce EpiK-Eval, a novel question-answering benchmark tailored to evaluate LLMs' proficiency in formulating a coherent and consistent knowledge representation from segmented narratives. Evaluations across various LLMs reveal significant weaknesses in this domain. We contend that these shortcomings stem from the intrinsic nature of prevailing training objectives. Consequently, we advocate for refining the approach towards knowledge consolidation, as it harbors the potential to dramatically improve their overall effectiveness and performance. The findings from this study offer insights for developing more robust and reliable LLMs. Our code and benchmark are available at https://github.com/chandar-lab/EpiK-Eval	cs.CL	None
7	Vicinal Feature Statistics Augmentation for Federated 3D Medical Volume Segmentation	Yongsong Huang,Wanqing Xie,Mingzhen Li,Mingmei Cheng,Jinzhou Wu,Weixiao Wang,Jane You,Xiaofeng Liu	"Federated learning (FL) enables multiple client medical institutes collaboratively train a deep learning (DL) model with privacy protection. However, the performance of FL can be constrained by the limited availability of labeled data in small institutes and the heterogeneous (i.e., non-i.i.d.) data distribution across institutes. Though data augmentation has been a proven technique to boost the generalization capabilities of conventional centralized DL as a ""free lunch"", its application in FL is largely underexplored. Notably, constrained by costly labeling, 3D medical segmentation generally relies on data augmentation. In this work, we aim to develop a vicinal feature-level data augmentation (VFDA) scheme to efficiently alleviate the local feature shift and facilitate collaborative training for privacy-aware FL segmentation. We take both the inner- and inter-institute divergence into consideration, without the need for cross-institute transfer of raw data or their mixup. Specifically, we exploit the batch-wise feature statistics (e.g., mean and standard deviation) in each institute to abstractly represent the discrepancy of data, and model each feature statistic probabilistically via a Gaussian prototype, with the mean corresponding to the original statistic and the variance quantifying the augmentation scope. From the vicinal risk minimization perspective, novel feature statistics can be drawn from the Gaussian distribution to fulfill augmentation. The variance is explicitly derived by the data bias in each individual institute and the underlying feature statistics characterized by all participating institutes. The added-on VFDA consistently yielded marked improvements over six advanced FL methods on both 3D brain tumor and cardiac segmentation."	eess.IV	28th biennial international conference on Information Processing in   Medical Imaging (IPMI 2023): Oral Paper
8	Layer-by-Layer Assembled Nanowire Networks Enable Graph Theoretical Design of Multifunctional Coatings	Wenbing Wu,Alain Kadar,Sang Hyun Lee,Bum Chul Park,Jeffery E. Raymond,Thomas K. Tsotsis,Carlos E. S. Cesnik,Sharon C. Glotzer,Valerie Goss,Nicholas A. Kotov	Multifunctional coatings are central for information, biomedical, transportation and energy technologies. These coatings must possess hard-to-attain properties and be scalable, adaptable, and sustainable, which makes layer-by-layer assembly (LBL) of nanomaterials uniquely suitable for these technologies. What remains largely unexplored is that LBL enables computational methodologies for structural design of these composites. Utilizing silver nanowires (NWs), we develop and validate a graph theoretical (GT) description of their LBL composites. GT successfully describes the multilayer structure with nonrandom disorder and enables simultaneous rapid assessment of several properties of electrical conductivity, electromagnetic transparency, and anisotropy. GT models for property assessment can be rapidly validated due to (1) quasi-2D confinement of NWs and (2) accurate microscopy data for stochastic organization of the NW networks. We finally show that spray-assisted LBL offers direct translation of the GT-based design of composite coatings to additive, scalable manufacturing of drone wings with straightforward extensions to other technologies.	physics.app-ph	None
9	Deep Integrated Explanations	Oren Barkan,Yehonathan Elisha,Jonathan Weill,Yuval Asher,Amit Eshel,Noam Koenigstein	This paper presents Deep Integrated Explanations (DIX) - a universal method for explaining vision models. DIX generates explanation maps by integrating information from the intermediate representations of the model, coupled with their corresponding gradients. Through an extensive array of both objective and subjective evaluations spanning diverse tasks, datasets, and model configurations, we showcase the efficacy of DIX in generating faithful and accurate explanation maps, while surpassing current state-of-the-art methods.	cs.CV	CIKM 2023
0	Hodge theory for tropical fans	Omid Amini,Matthieu Piquerez	"This paper is the first in a series devoted to the development of a Hodge theory for tropical varieties. We introduce a notion of T-stability for tropical fans and prove that various geometric properties of tropical fans are T-stable. As a consequence, we establish K\""ahler properties for the Chow ring in a large class of tropical fans, going beyond the case of matroids and their Bergman fans. As a by-product, we obtain a new proof of the K\""ahler package for combinatorial geometries. The approach makes it possible to deal with tropical fans with general weights."	math.CO	68 pages, 4 figures. Comments welcome! arXiv admin note: substantial   text overlap with arXiv:2105.01504
1	Immediate Afterglow Physical Characteristics and Broadband Spectra Evidence Synchrotron self-Compton Emission as the Reason for VHE Production in TeV GRB 190114C	Aadi Krishna	Long GRB 190114C, identified on January 14th, 2019, was the first Gamma-ray Burst that substantially violated the defined 10 GeV energy limit of the Synchrotron model, with an observed emission between 0.2 - 1 TeV and a low redshift of z = 0.425. This paper analyzes its immediate afterglow broadband spectrum from 10$^{17}$ to 10$^{26}$ Hz based on observations by the Swift X-ray Telescope (XRT), Fermi Gamma-Ray Burst Monitor (GBM), Swift Burst Alert Telescope (BAT), Fermi Large Area Telescope (LAT), and Major Atmospheric Gamma Imaging Cherenkov Telescope (MAGIC). We first calculate the physical characteristics necessary to understand the conditions in the burst's emitting region, then conduct temporal and spectral analyses by deriving light curves and spectra using a chain polynomial best-fit in the context of the forward shock model in a homogeneous circumburst density. The Spectral Energy Distributions are found to be double-peaked for T$_0$ + 68-180s, and we show the distribution consists of a distinct Synchrotron component followed by an inverse Compton component explained by high-energy electrons up-scattering Synchrotron photons. We find our calculated Bulk Lorentz Factor = 351 sufficiently explains the peak of the inverse Compton component at sub-TeV energy levels in the immediate afterglow, and that the Comptonization of the burst proceeds in the Klein-Nishina regime. We conclude this further evidences Synchrotron self-Compton emission as the mechanism behind the production of Very-High-Energy photons in GRB 190114C.	astro-ph.HE	7 pages, 5 figures, Proceedings of the 40th Annual Meeting of the   Astronomical Society of India
2	Prandtl number effects on extreme mixing events in forced stratified turbulence	Nicolaos Petropoulos,Miles M. P. Couchman,Ali Mashayek,Stephen M. de Bruyn Kops,Colm-cille P. Caulfield	Relatively strongly stratified turbulent flows tend to self-organise into a 'layered anisotropic stratified turbulence' (LAST) regime, characterised by relatively deep and well-mixed density 'layers' separated by relatively thin 'interfaces' of enhanced density gradient. Understanding the associated mixing dynamics is a central problem in geophysical fluid dynamics. It is challenging to study 'LAST' mixing, as it is associated with Reynolds numbers $Re := UL/\nu \gg 1$ and Froude numbers $Fr :=(2\pi U)/(L N) \ll 1$, ($U$ and $L$ being characteristic velocity and length scales, $\nu$ being the kinematic viscosity and $N$ the buoyancy frequency). Since a sufficiently large dynamic range (largely) unaffected by stratification and viscosity is required, it is also necessary for the buoyancy Reynolds number $Re_{b} := \epsilon/(\nu N^{2}) \gg 1$ where $\epsilon$ is the (appropriately volume-averaged) turbulent kinetic energy dissipation rate. This requirement is exacerbated for oceanically relevant flows, as the Prandtl number $Pr := \nu/\kappa = \mathcal{O}(10)$ in thermally-stratified water (where $\kappa$ is the thermal diffusivity), thus leading (potentially) to even finer density field structures. We report here on four forced fully resolved direct numerical simulations of stratified turbulence at various Froude ($Fr=0.5, 2$) and Prandtl numbers ($Pr=1, 7$) forced so that $Re_{b}=50$, with resolutions up to $30240 \times 30240 \times 3780$. We find that, as $Pr$ increases, emergent 'interfaces' become finer and their contribution to bulk mixing characteristics decreases at the expense of the small-scale density structures populating the well-mixed 'layers'. However, extreme mixing events (as quantified by significantly elevated local destruction rates of buoyancy variance $\chi_0$) are always preferentially found in the (statically stable) interfaces, irrespective of the value of $Pr$.	physics.flu-dyn	10 pages, 4 figures
3	Filter-adapted spatiotemporal sampling for real-time rendering	William Donnelly,Alan Wolfe,Judith B√ºtepage,Jon Vald√©s	Stochastic sampling techniques are ubiquitous in real-time rendering, where performance constraints force the use of low sample counts, leading to noisy intermediate results. To remove this noise, the post-processing step of temporal and spatial denoising is an integral part of the real-time graphics pipeline. The main insight presented in this paper is that we can optimize the samples used in stochastic sampling such that the post-processing error is minimized. The core of our method is an analytical loss function which measures post-filtering error for a class of integrands - multidimensional Heaviside functions. These integrands are an approximation of the discontinuous functions commonly found in rendering. Our analysis applies to arbitrary spatial and spatiotemporal filters, scalar and vector sample values, and uniform and non-uniform probability distributions. We show that the spectrum of Monte Carlo noise resulting from our sampling method is adapted to the shape of the filter, resulting in less noisy final images. We demonstrate improvements over state-of-the-art sampling methods in three representative rendering tasks: ambient occlusion, volumetric ray-marching, and color image dithering. Common use noise textures, and noise generation code is available at https://github.com/electronicarts/fastnoise.	cs.GR	18 pages, 12 figures
4	Optimal scenario for road evacuation in an urban environment	Mickael Bestard,Emmanuel Franck,Laurent Navoret,Yannick Privat	How to free a road from vehicle traffic as efficiently as possible and in a given time, in order to allow for example the passage of emergency vehicles? We are interested in this question which we reformulate as an optimal control problem. We consider a macroscopic road traffic model on networks, semi-discretized in space and decide to give ourselves the possibility to control the flow at junctions. Our target is to smooth the traffic along a given path within a fixed time. A parsimony constraint is imposed on the controls, in order to ensure that the optimal strategies are feasible in practice. We perform an analysis of the resulting optimal control problem, proving the existence of an optimal control and deriving optimality conditions, which we rewrite as a single functional equation. We then use this formulation to derive a new mixed algorithm interpreting it as a mix between two methods: a descent method combined with a fixed point method allowing global perturbations. We verify with numerical experiments the efficiency of this method on examples of graphs, first simple, then more complex. We highlight the efficiency of our approach by comparing it to standard methods. We propose an open source code implementing this approach in the Julia language.	math.OC	None
5	Learning Fair Representations with High-Confidence Guarantees	Yuhong Luo,Austin Hoag,Philip S. Thomas	Representation learning is increasingly employed to generate representations that are predictive across multiple downstream tasks. The development of representation learning algorithms that provide strong fairness guarantees is thus important because it can prevent unfairness towards disadvantaged groups for all downstream prediction tasks. To prevent unfairness towards disadvantaged groups in all downstream tasks, it is crucial to provide representation learning algorithms that provide fairness guarantees. In this paper, we formally define the problem of learning representations that are fair with high confidence. We then introduce the Fair Representation learning with high-confidence Guarantees (FRG) framework, which provides high-confidence guarantees for limiting unfairness across all downstream models and tasks, with user-defined upper bounds. After proving that FRG ensures fairness for all downstream models and tasks with high probability, we present empirical evaluations that demonstrate FRG's effectiveness at upper bounding unfairness for multiple downstream models and tasks.	cs.LG	None
6	Why LLMs Hallucinate, and How to Get (Evidential) Closure: Perceptual, Intensional, and Extensional Learning for Faithful Natural Language Generation	Adam Bouyamourn	We show that LLMs hallucinate because their output is not constrained to be synonymous with claims for which they have evidence: a condition that we call evidential closure. Information about the truth or falsity of sentences is not statistically identified in the standard neural probabilistic language model setup, and so cannot be conditioned on to generate new strings. We then show how to constrain LLMs to produce output that does satisfy evidential closure. A multimodal LLM must learn about the external world (perceptual learning); it must learn a mapping from strings to states of the world (extensional learning); and, to achieve fluency when generalizing beyond a body of evidence, it must learn mappings from strings to their synonyms (intensional learning). The output of a unimodal LLM must be synonymous with strings in a validated evidence set. Finally, we present a heuristic procedure, Learn-Babble-Prune, that yields faithful output from an LLM by rejecting output that is not synonymous with claims for which the LLM has evidence.	cs.CL	None
7	Data-driven representations of conical, convex, and affine behaviors	Alberto Padoan,Florian D√∂rfler,John Lygeros	The paper studies conical, convex, and affine models in the framework of behavioral systems theory. We investigate basic properties of such behaviors and address the problem of constructing models from measured data. We prove that closed, shift-invariant, conical, convex, and affine models have the intersection property, thereby enabling the definition of most powerful unfalsified models based on infinite-horizon measurements. We then provide necessary and sufficient conditions for representing conical, convex, and affine finite-horizon behaviors using raw data matrices, expressing persistence of excitation requirements in terms of non-negative rank conditions. The applicability of our results is demonstrated by a numerical example arising in population ecology.	math.OC	None
8	The Landau-Streater Channel as a Noisy Channel Model	Shayan Roofeh,Vahid Karimipour	In three dimensions, the Landau-Streater channel is nothing but the Werner-Holevo channel. Such a channel has no continuous parameter and hence cannot model an environmental noise. We consider its convex combination with the identity channel, making it suitable as a one-parameter noise model on qutrits. Moreover, whereas the original Werner-Holevo channel exhibits covariance under the complete unitary group $SU(3)$, the extended family maintains covariance only under the group $SO(3)$. This symmetry reduction allows us to investigate its impact on various properties of the original channel. Specifically, we examine its influence on the channel's spectrum, divisibility, complementary channel, and exact or approximate degradability, as well as its various kinds of capacities. Specifically, we derive analytical expressions for the one-shot classical capacity and the entanglement-assisted capacity, accompanied by the establishment of lower and upper bounds for the quantum capacity.	quant-ph	None
9	Random Exploration in Bayesian Optimization: Order-Optimal Regret and Computational Efficiency	Sudeep Salgia,Sattar Vakili,Qing Zhao	We consider Bayesian optimization using Gaussian Process models, also referred to as kernel-based bandit optimization. We study the methodology of exploring the domain using random samples drawn from a distribution. We show that this random exploration approach achieves the optimal error rates. Our analysis is based on novel concentration bounds in an infinite dimensional Hilbert space established in this work, which may be of independent interest. We further develop an algorithm based on random exploration with domain shrinking and establish its order-optimal regret guarantees under both noise-free and noisy settings. In the noise-free setting, our analysis closes the existing gap in regret performance and thereby resolves a COLT open problem. The proposed algorithm also enjoys a computational advantage over prevailing methods due to the random exploration that obviates the expensive optimization of a non-convex acquisition function for choosing the query points at each iteration.	cs.LG	None
0	Metastability and dynamic modes in magnetic island chains	G. M. Wysin	The uniform states of a model for one-dimensional chains of thin magnetic islands on a nonmagnetic substrate coupled via dipolar interactions are described here. Magnetic islands oriented with their long axes perpendicular to the chain direction are assumed, whose shape anisotropy imposes a preference for the dipoles to point perpendicular to the chain. The competition between anisotropy and dipolar interactions leads to three types of uniform states of distinctly different symmetries, including metastable transverse or remanent states, transverse antiferromagnetic states, and longitudinal states where all dipoles align with the chain direction. The stability limits and normal modes of oscillation are found for all three types of states, even including infinite range dipole interactions. The normal mode frequencies are shown to be determined from the eigenvalues of the stability problem.	cond-mat.mes-hall	None
1	Scalable machine learning-assisted clear-box characterization for optimally controlled photonic circuits	Andreas Fyrillas,Olivier Faure,Nicolas Maring,Jean Senellart,Nadia Belabas	Photonic integrated circuits offer a compact and stable platform for generating, manipulating, and detecting light. They are instrumental for classical and quantum applications. Imperfections stemming from fabrication constraints, tolerances and operation wavelength impose limitations on the accuracy and thus utility of current photonic integrated devices. Mitigating these imperfections typically necessitates a model of the underlying physical structure and the estimation of parameters that are challenging to access. Direct solutions are currently lacking for mesh configurations extending beyond trivial cases. We introduce a scalable and innovative method to characterize photonic chips through an iterative machine learning-assisted procedure. Our method is based on a clear-box approach that harnesses a fully modeled virtual replica of the photonic chip to characterize. The process is sample-efficient and can be carried out with a continuous-wave laser and powermeters. The model estimates individual passive phases, crosstalk, beamsplitter reflectivity values and relative input/output losses. Building upon the accurate characterization results, we mitigate imperfections to enable enhanced control over the device. We validate our characterization and imperfection mitigation methods on a 12-mode Clements-interferometer equipped with 126 phase shifters, achieving beyond state-of-the-art chip control with an average 99.77 % amplitude fidelity on 100 implemented Haar-random unitary matrices.	physics.optics	None
2	Quench-induced spontaneous currents in rings of ultracold fermionic atoms	Daniel G. Allman,Parth Sabharwal,Kevin C. Wright	We have measured the rate of spontaneous current formation in ring-shaped ensembles of fermionic $^6$Li atoms, following a thermal quench through the BCS superfluid phase transition. For the fastest quenches, the mean square winding number follows a scaling law with exponent $\sigma$ = 0.24(2), in line with predictions of the Kibble-Zurek (KZ) model for mean-field BCS theory. We use a hybrid quench protocol involving simultaneous evaporation and interaction ramps, with a long system lifetime allowing characterization of a different rate of spontaneous current formation in the slow-quench regime, where finite-size effects are important. Comparing our observations to a quasi-1D stochastic Ginzburg-Landau model, we find quantitative agreement for fast quenches, but only qualitative agreement for slow quenches.	cond-mat.quant-gas	6 pages, 4 figures
3	Generation of THz radiation through molecular modulation in hydrogen-filled hybrid anti-resonant fibers	Sebastien Loranger,Foroogh Jafari,Joseba Zubia,David Novoa	We study the generation of narrowband terahertz (THz) pulses by stimulated Raman scattering and molecular modulation in hydrogen-filled hybrid hollow-core fibers. Using a judicious combination of materials and transverse structures, this waveguide design enables simultaneous confinement of optical and THz signals with reasonably low attenuation, as well as high nonlinear overlap. The THz pulses are then generated as the second Stokes band of a ns-long near-infrared pump pulse, aided by Raman coherence waves excited in the gaseous core by the beat-note created by the pump and its first Stokes band. Optimization of the fiber characteristics facilitates phase matching between the corresponding transitions and coherence waves while avoiding coherent gain suppression, resulting in optical-to-THz conversion efficiencies up to 60%, as confirmed by rigorous numerical modelling under ideal conditions. When the current optical material constraints are considered, however, the attainable efficiencies relax to 0.2%, a still competitive value compared to other systems. The approach is in principle power and energy scalable, as well as tunable in the 1 - 10 THz range without any spectral gaps, thereby opening new pathways to the development of fiber-based THz sources complementary to other mature technologies such as quantum cascade lasers.	physics.optics	11 pages, 7 figures
4	Modeling and Testing Superconducting Artificial CPW Lines Suitable for Parametric Amplification	F. P. Mena,D. Valenzuela,C. Espinoza,F. Pizarro,B. -K. Tan,D. J. Thoen,J. J. A. Baselmans,R. Finger	Achieving amplification with high gain and quantum-limited noise is a difficult problem to solve. Parametric amplification using a superconducting transmission line with high kinetic inductance is a promising technology not only to solve this problem but also adding several benefits. When compared with other technologies, they have the potential of improving power saturation, achieving larger fractional bandwidths and operating at higher frequencies. In this type of amplifiers, selecting the proper transmission line is a key element in their design. Given current fabrication limitations, traditional lines such as coplanar waveguides (CPW), are not ideal for this purpose since it is difficult to make them with the proper characteristic impedance for good matching and slow-enough phase velocity for making them more compact. Capacitively-loaded lines, also known as artificial lines, are a good solution to this problem. However, few design rules or models have been presented to guide their accurate design. This fact is even more crucial considering that they are usually fabricated in the form of Floquet lines that have to be designed carefully to suppress undesired harmonics appearing in the parametric process. In this article we present, firstly, a new modelling strategy, based on the use of electromagnetic-simulation software, and, secondly, a first-principles model that facilitate and speed the design of CPW artificial lines and of Floquet lines made out of them. Then, we present comparisons with experimental results that demonstrate their accuracy. Finally, the theoretical model allows to predict the high-frequency behaviour of the artificial lines showing that they are good candidates for implementing parametric amplifiers above 100 GHz.	physics.app-ph	7 pages, 11 figures, submitted to IEEE Transactions on Applied   Superconductivity
5	Burgers' pinns with implicit euler transfer learning	Vit√≥ria Biesek,Pedro Henrique de Almeida Konzen	The Burgers equation is a well-established test case in the computational modeling of several phenomena such as fluid dynamics, gas dynamics, shock theory, cosmology, and others. In this work, we present the application of Physics-Informed Neural Networks (PINNs) with an implicit Euler transfer learning approach to solve the Burgers equation. The proposed approach consists in seeking a time-discrete solution by a sequence of Artificial Neural Networks (ANNs). At each time step, the previous ANN transfers its knowledge to the next network model, which learns the current time solution by minimizing a loss function based on the implicit Euler approximation of the Burgers equation. The approach is tested for two benchmark problems: the first with an exact solution and the other with an alternative analytical solution. In comparison to the usual PINN models, the proposed approach has the advantage of requiring smaller neural network architectures with similar accurate results and potentially decreasing computational costs.	cs.LG	11 pages, 3 figures, conference paper XXVI ENMC/XIV ECTM 2023, Nova   Friburgo, Brazil
6	Towards Hybrid-grained Feature Interaction Selection for Deep Sparse Network	Fuyuan Lyu,Xing Tang,Dugang Liu,Chen Ma,Weihong Luo,Liang Chen,Xiuqiang He,Xue Liu	Deep sparse networks are widely investigated as a neural network architecture for prediction tasks with high-dimensional sparse features, with which feature interaction selection is a critical component. While previous methods primarily focus on how to search feature interaction in a coarse-grained space, less attention has been given to a finer granularity. In this work, we introduce a hybrid-grained feature interaction selection approach that targets both feature field and feature value for deep sparse networks. To explore such expansive space, we propose a decomposed space which is calculated on the fly. We then develop a selection algorithm called OptFeature, which efficiently selects the feature interaction from both the feature field and the feature value simultaneously. Results from experiments on three large real-world benchmark datasets demonstrate that OptFeature performs well in terms of accuracy and efficiency. Additional studies support the feasibility of our method.	cs.LG	NeurIPS 2023 poster
7	On the monotonicity of $Q^2$ spectral element method for Laplacian on quasi-uniform rectangular meshes	Logan J. Cross,Xiangxiong Zhang	The monotonicity of discrete Laplacian implies discrete maximum principle, which in general does not hold for high order schemes. The $Q^2$ spectral element method has been proven monotone on a uniform rectangular mesh. In this paper we prove the monotonicity of the $Q^2$ spectral element method on quasi-uniform rectangular meshes under certain mesh constraints. In particular, we propose a relaxed Lorenz's condition for proving monotonicity.	math.NA	arXiv admin note: substantial text overlap with arXiv:2010.07282
8	The Adaptive Optics System for the Gemini Infrared Multi-Object Spectrograph: Performance Modeling	Uriel Conod,Kate Jackson,Paolo Turri,Scott Chapman,Olivier Lardi√®re,Masen Lamb,Carlos Correia,Gaetano Sivo,Suresh Sivanandam,Jean-Pierre V√©ran	The Gemini Infrared Multi-Object Spectrograph (GIRMOS) will be a near-infrared, multi-object, medium spectral resolution, integral field spectrograph (IFS) for Gemini North Telescope, designed to operate behind the future Gemini North Adaptive Optics system (GNAO). In addition to a first ground layer Adaptive Optics (AO) correction in closed loop carried out by GNAO, each of the four GIRMOS IFSs will independently perform additional multi-object AO correction in open loop, resulting in an improved image quality that is critical to achieve top level science requirements. We present the baseline parameters and simulated performance of GIRMOS obtained by modeling both the GNAO and GIRMOS AO systems. The image quality requirement for GIRMOS is that 57% of the energy of an unresolved point-spread function ensquared within a 0.1 x 0.1 arcsecond at 2.0 {\mu} m. It was established that GIRMOS will be an order 16 x 16 adaptive optics (AO) system after examining the tradeoffs between performance, risks and costs. The ensquared energy requirement will be met in median atmospheric conditions at Maunakea at 30{\deg} from zenith.	astro-ph.IM	13 pages, 10 figures, Publications of the Astronomical Society of the   Pacific
9	Moral Foundations of Large Language Models	Marwa Abdulhai,Gregory Serapio-Garcia,Cl√©ment Crepy,Daria Valter,John Canny,Natasha Jaques	Moral foundations theory (MFT) is a psychological assessment tool that decomposes human moral reasoning into five factors, including care/harm, liberty/oppression, and sanctity/degradation (Graham et al., 2009). People vary in the weight they place on these dimensions when making moral decisions, in part due to their cultural upbringing and political ideology. As large language models (LLMs) are trained on datasets collected from the internet, they may reflect the biases that are present in such corpora. This paper uses MFT as a lens to analyze whether popular LLMs have acquired a bias towards a particular set of moral values. We analyze known LLMs and find they exhibit particular moral foundations, and show how these relate to human moral foundations and political affiliations. We also measure the consistency of these biases, or whether they vary strongly depending on the context of how the model is prompted. Finally, we show that we can adversarially select prompts that encourage the moral to exhibit a particular set of moral foundations, and that this can affect the model's behavior on downstream tasks. These findings help illustrate the potential risks and unintended consequences of LLMs assuming a particular moral stance.	cs.AI	None
0	ADMM Training Algorithms for Residual Networks: Convergence, Complexity and Parallel Training	Jintao Xu,Yifei Li,Wenxun Xing	We design a series of serial and parallel proximal point (gradient) ADMMs for the fully connected residual networks (FCResNets) training problem by introducing auxiliary variables. Convergence of the proximal point version is proven based on a Kurdyka-Lojasiewicz (KL) property analysis framework, and we can ensure a locally R-linear or sublinear convergence rate depending on the different ranges of the Kurdyka-Lojasiewicz (KL) exponent, in which a necessary auxiliary function is constructed to realize our goal. Moreover, the advantages of the parallel implementation in terms of lower time complexity and less (per-node) memory consumption are analyzed theoretically. To the best of our knowledge, this is the first work analyzing the convergence, convergence rate, time complexity and (per-node) runtime memory requirement of the ADMM applied in the FCResNets training problem theoretically. Experiments are reported to show the high speed, better performance, robustness and potential in the deep network training tasks. Finally, we present the advantage and potential of our parallel training in large-scale problems.	cs.LG	None
1	Engineering higher order Van Hove singularities in two dimensions: the example of the surface layer of Sr$_2$RuO$_4$	Anirudh Chandrasekaran,Luke C. Rhodes,Edgar Abarca Morales,Carolina A. Marques,Phil D. C. King,Peter Wahl,Joseph J. Betouras	The properties of correlated electron materials are often intricately linked to Van Hove singularities (VHs) in the vicinity of the Fermi energy. The class of these VHs is of great importance, with higher order ones -- with power-law divergence in the density of states -- leaving frequently distinct signatures in physical properties. We use a new theoretical method to detect and analyse higher order Van Hove singularities (HOVHs) in two-dimensional materials and apply it to the electronic structure of the surface layer of Sr$_2$RuO$_4$. We then constrain a low energy model of the VHs of the surface layer of Sr$_2$RuO$_4$ against angle-resolved photoemission spectroscopy and quasiparticle interference data to analyse the VHs near the Fermi level. We show how these VHs can be engineered into HOVHs.	cond-mat.str-el	8 pages including Supplemental Material, 5 figures
2	Unsupervised Federated Learning: A Federated Gradient EM Algorithm for Heterogeneous Mixture Models with Robustness against Adversarial Attacks	Ye Tian,Haolei Weng,Yang Feng	While supervised federated learning approaches have enjoyed significant success, the domain of unsupervised federated learning remains relatively underexplored. In this paper, we introduce a novel federated gradient EM algorithm designed for the unsupervised learning of mixture models with heterogeneous mixture proportions across tasks. We begin with a comprehensive finite-sample theory that holds for general mixture models, then apply this general theory on Gaussian Mixture Models (GMMs) and Mixture of Regressions (MoRs) to characterize the explicit estimation error of model parameters and mixture proportions. Our proposed federated gradient EM algorithm demonstrates several key advantages: adaptability to unknown task similarity, resilience against adversarial attacks on a small fraction of data sources, protection of local data privacy, and computational and communication efficiency.	stat.ML	43 pages, 1 figure
3	Serverless Federated Learning with flwr-serverless	Sanjeev V. Namjoshi,Reese Green,Krishi Sharma,Zhangzhang Si	Federated learning is becoming increasingly relevant and popular as we witness a surge in data collection and storage of personally identifiable information. Alongside these developments there have been many proposals from governments around the world to provide more protections for individuals' data and a heightened interest in data privacy measures. As deep learning continues to become more relevant in new and existing domains, it is vital to develop strategies like federated learning that can effectively train data from different sources, such as edge devices, without compromising security and privacy. Recently, the Flower (\texttt{Flwr}) Python package was introduced to provide a scalable, flexible, and easy-to-use framework for implementing federated learning. However, to date, Flower is only able to run synchronous federated learning which can be costly and time-consuming to run because the process is bottlenecked by client-side training jobs that are slow or fragile. Here, we introduce \texttt{flwr-serverless}, a wrapper around the Flower package that extends its functionality to allow for both synchronous and asynchronous federated learning with minimal modification to Flower's design paradigm. Furthermore, our approach to federated learning allows the process to run without a central server, which increases the domains of application and accessibility of its use. This paper presents the design details and usage of this approach through a series of experiments that were conducted using public datasets. Overall, we believe that our approach decreases the time and cost to run federated training and provides an easier way to implement and experiment with federated learning systems.	cs.LG	Technical report for an open source machine learning python package
4	DeepVox and SAVE-CT: a contrast- and dose-independent 3D deep learning approach for thoracic aorta segmentation and aneurysm prediction using computed tomography scans	Matheus del-Valle,Lariza Laura de Oliveira,Henrique Cursino Vieira,Henrique Min Ho Lee,Lucas Lembran√ßa Pinheiro,Maria Fernanda Portugal,Newton Shydeo Brand√£o Miyoshi,Nelson Wolosker	Thoracic aortic aneurysm (TAA) is a fatal disease which potentially leads to dissection or rupture through progressive enlargement of the aorta. It is usually asymptomatic and screening recommendation are limited. The gold-standard evaluation is performed by computed tomography angiography (CTA) and radiologists time-consuming assessment. Scans for other indications could help on this screening, however if acquired without contrast enhancement or with low dose protocol, it can make the clinical evaluation difficult, besides increasing the scans quantity for the radiologists. In this study, it was selected 587 unique CT scans including control and TAA patients, acquired with low and standard dose protocols, with or without contrast enhancement. A novel segmentation model, DeepVox, exhibited dice score coefficients of 0.932 and 0.897 for development and test sets, respectively, with faster training speed in comparison to models reported in the literature. The novel TAA classification model, SAVE-CT, presented accuracies of 0.930 and 0.922 for development and test sets, respectively, using only the binary segmentation mask from DeepVox as input, without hand-engineered features. These two models together are a potential approach for TAA screening, as they can handle variable number of slices as input, handling thoracic and thoracoabdominal sequences, in a fully automated contrast- and dose-independent evaluation. This may assist to decrease TAA mortality and prioritize the evaluation queue of patients for radiologists.	eess.IV	23 pages, 4 figures, 7 tables
5	On Quark Substructures in an Inspired Unified Model	Adil Belhaj,Salah Eddine Ennadifi	"Motivated by the growing attention devoted to the Quantum Chromodynamics sector of the Standard Model, and the recent observations of non-standard hadronic states, a possible substructure of quarks $q_{f}\equiv C_{ij}|k_{i}k_{j}\rangle $ in terms of four colorless bound particles $% k_{i(=0,\ldots,3)}$ ""hyperquarks"" is investigated in a $SO(10)$-inspired unified model. This aims to define a subtle structure of matter as well as an explanation of some particularities of quarks. Precisley, these hyperquarks $k_{i}$ are bound by a $SU(3)_{h}$ ""hyperstrong force"" under which they are assumed to be charged. Exploiting certain known data, the masses and the charges of such fundamental particles are discussed along with the emerged four extra quarks $q_{f}\equiv \delta_{ii}|k_{i}k_{i}\rangle $ and three hyperweak bosons $W_{h}$."	hep-ph	Latex, 11 pages, 1 figure and 4 tables
6	Specialist or Generalist? Instruction Tuning for Specific NLP Tasks	Chufan Shi,Yixuan Su,Cheng Yang,Yujiu Yang,Deng Cai	The potential of large language models (LLMs) to simultaneously perform a wide range of natural language processing (NLP) tasks has been the subject of extensive research. Although instruction tuning has proven to be a data-efficient method for transforming LLMs into such generalist models, their performance still lags behind specialist models trained exclusively for specific tasks. In this paper, we investigate whether incorporating broad-coverage generalist instruction tuning can contribute to building a specialist model. We hypothesize that its efficacy depends on task specificity and skill requirements. Our experiments assess four target tasks with distinct coverage levels, revealing that integrating generalist instruction tuning consistently enhances model performance when the task coverage is broad. The effect is particularly pronounced when the amount of task-specific training data is limited. Further investigation into three target tasks focusing on different capabilities demonstrates that generalist instruction tuning improves understanding and reasoning abilities. However, for tasks requiring factual knowledge, generalist data containing hallucinatory information may negatively affect the model's performance. Overall, our work provides a systematic guide for developing specialist models with general instruction tuning. Our code and other related resources can be found at https://github.com/DavidFanzz/Generalist_or_Specialist.	cs.CL	Accepted to EMNLP 2023
7	LXMERT Model Compression for Visual Question Answering	Maryam Hashemi,Ghazaleh Mahmoudi,Sara Kodeiri,Hadi Sheikhi,Sauleh Eetemadi	Large-scale pretrained models such as LXMERT are becoming popular for learning cross-modal representations on text-image pairs for vision-language tasks. According to the lottery ticket hypothesis, NLP and computer vision models contain smaller subnetworks capable of being trained in isolation to full performance. In this paper, we combine these observations to evaluate whether such trainable subnetworks exist in LXMERT when fine-tuned on the VQA task. In addition, we perform a model size cost-benefit analysis by investigating how much pruning can be done without significant loss in accuracy. Our experiment results demonstrate that LXMERT can be effectively pruned by 40%-60% in size with 3% loss in accuracy.	cs.CV	To appear in The Fourth Annual West Coast NLP (WeCNLP) Summit
8	Videoprompter: an ensemble of foundational models for zero-shot video understanding	Adeel Yousaf,Muzammal Naseer,Salman Khan,Fahad Shahbaz Khan,Mubarak Shah	Vision-language models (VLMs) classify the query video by calculating a similarity score between the visual features and text-based class label representations. Recently, large language models (LLMs) have been used to enrich the text-based class labels by enhancing the descriptiveness of the class names. However, these improvements are restricted to the text-based classifier only, and the query visual features are not considered. In this paper, we propose a framework which combines pre-trained discriminative VLMs with pre-trained generative video-to-text and text-to-text models. We introduce two key modifications to the standard zero-shot setting. First, we propose language-guided visual feature enhancement and employ a video-to-text model to convert the query video to its descriptive form. The resulting descriptions contain vital visual cues of the query video, such as what objects are present and their spatio-temporal interactions. These descriptive cues provide additional semantic knowledge to VLMs to enhance their zeroshot performance. Second, we propose video-specific prompts to LLMs to generate more meaningful descriptions to enrich class label representations. Specifically, we introduce prompt techniques to create a Tree Hierarchy of Categories for class names, offering a higher-level action context for additional visual cues, We demonstrate the effectiveness of our approach in video understanding across three different zero-shot settings: 1) video action recognition, 2) video-to-text and textto-video retrieval, and 3) time-sensitive video tasks. Consistent improvements across multiple benchmarks and with various VLMs demonstrate the effectiveness of our proposed framework. Our code will be made publicly available.	cs.CV	None
9	How gravity stabilises instability: the case of magnetic micro-convection	LƒÅsma Puƒ∑ina-Slava,Andrejs Tatuƒºƒçenkovs,Andrejs Cƒìbers,Guntars Kitenbergs	Finding solutions for better mixing in microfluidics remains an important challenge, including understanding fundamental aspects of these processes. Here we investigate the magnetic micro-convection on water and miscible magnetic fluid interface in a vertical microfluidic chip to understand what is the role of gravity, as fluids have different densities. Our model is reduced to two dimensionless quantities - magnetic and gravitational Rayleigh numbers. Numerical simulation results show that static magnetic field generate rich dynamics. This is confirmed quantitatively with careful experiments in initially stagnant fluids. We also show that the length of resulting mixing is limited by gravity. For this we construct a master curve, exploiting the measurements of critical field. A three-fluid layer model and linear stability analysis on its interfaces allows us to explain the limitation mechanism. Our results can help in the development of instability based micromixers.	physics.flu-dyn	6 supplementary movies; This draft was prepared using the LaTeX style   file belonging to the Journal of Fluid Mechanics
0	Conserved quantities for the plane waves in TEGR and STEGR	E. Emtsova,A. N. Petrov,A. V. Toporensky	We study the energy-momentum characteristics of the plane ``+''-polarised gravitational wave solution of general relativity in the Teleparallel Equivalent of General Relativity (TEGR) and the Symmetric Teleparallel Equivalent of General Relativity (STEGR) using the previously constructed Noether currents. These currents can describe locally measured by observer energy-momentum if the displacement vector $\xi$ is equal to the observer's 4-velocity. To determine the non-dynamical connection in these theories we use the unified ``turning off'' gravity principle. For a constructive analysis of the values of Noether currents and superpotentials in TEGR and STEGR, we use the concept of ``gauges''. The gauge changing can affect the Noether current values. We study under what conditions the Noether current for the freely falling observer is zero because this can be interpreted as the equivalence principle. We highlight two important cases with positive and zero energy, which reproduce the results of previous works with a different approach to determine gravitational energy-momentum in TEGR, and give their interpretation.	gr-qc	None
1	Hallucination Detection for Grounded Instruction Generation	Lingjun Zhao,Khanh Nguyen,Hal Daum√© III	We investigate the problem of generating instructions to guide humans to navigate in simulated residential environments. A major issue with current models is hallucination: they generate references to actions or objects that are inconsistent with what a human follower would perform or encounter along the described path. We develop a model that detects these hallucinated references by adopting a model pre-trained on a large corpus of image-text pairs, and fine-tuning it with a contrastive loss that separates correct instructions from instructions containing synthesized hallucinations. Our final model outperforms several baselines, including using word probability estimated by the instruction-generation model, and supervised models based on LSTM and Transformer.	cs.CL	None
2	HetGPT: Harnessing the Power of Prompt Tuning in Pre-Trained Heterogeneous Graph Neural Networks	Yihong Ma,Ning Yan,Jiayu Li,Masood Mortazavi,Nitesh V. Chawla	"Graphs have emerged as a natural choice to represent and analyze the intricate patterns and rich information of the Web, enabling applications such as online page classification and social recommendation. The prevailing ""pre-train, fine-tune"" paradigm has been widely adopted in graph machine learning tasks, particularly in scenarios with limited labeled nodes. However, this approach often exhibits a misalignment between the training objectives of pretext tasks and those of downstream tasks. This gap can result in the ""negative transfer"" problem, wherein the knowledge gained from pre-training adversely affects performance in the downstream tasks. The surge in prompt-based learning within Natural Language Processing (NLP) suggests the potential of adapting a ""pre-train, prompt"" paradigm to graphs as an alternative. However, existing graph prompting techniques are tailored to homogeneous graphs, neglecting the inherent heterogeneity of Web graphs. To bridge this gap, we propose HetGPT, a general post-training prompting framework to improve the predictive performance of pre-trained heterogeneous graph neural networks (HGNNs). The key is the design of a novel prompting function that integrates a virtual class prompt and a heterogeneous feature prompt, with the aim to reformulate downstream tasks to mirror pretext tasks. Moreover, HetGPT introduces a multi-view neighborhood aggregation mechanism, capturing the complex neighborhood structure in heterogeneous graphs. Extensive experiments on three benchmark datasets demonstrate HetGPT's capability to enhance the performance of state-of-the-art HGNNs on semi-supervised node classification."	cs.LG	submitted to ACM TheWebConf 2024
3	Exploring the Potential of Large Language Models in Generating Code-Tracing Questions for Introductory Programming Courses	Aysa Xuemo Fan,Ranran Haoran Zhang,Luc Paquette,Rui Zhang	In this paper, we explore the application of large language models (LLMs) for generating code-tracing questions in introductory programming courses. We designed targeted prompts for GPT4, guiding it to generate code-tracing questions based on code snippets and descriptions. We established a set of human evaluation metrics to assess the quality of questions produced by the model compared to those created by human experts. Our analysis provides insights into the capabilities and potential of LLMs in generating diverse code-tracing questions. Additionally, we present a unique dataset of human and LLM-generated tracing questions, serving as a valuable resource for both the education and NLP research communities. This work contributes to the ongoing dialogue on the potential uses of LLMs in educational settings.	cs.CL	Accepted by Findings of EMNLP, 2023
4	Probing Representations for Document-level Event Extraction	Barry Wang,Xinya Du,Claire Cardie	The probing classifiers framework has been employed for interpreting deep neural network models for a variety of natural language processing (NLP) applications. Studies, however, have largely focused on sentencelevel NLP tasks. This work is the first to apply the probing paradigm to representations learned for document-level information extraction (IE). We designed eight embedding probes to analyze surface, semantic, and event-understanding capabilities relevant to document-level event extraction. We apply them to the representations acquired by learning models from three different LLM-based document-level IE approaches on a standard dataset. We found that trained encoders from these models yield embeddings that can modestly improve argument detections and labeling but only slightly enhance event-level tasks, albeit trade-offs in information helpful for coherence and event-type prediction. We further found that encoder models struggle with document length and cross-sentence discourse.	cs.CL	To appear in EMNLP 2023 Findings
5	Prospects for Neutron Star Parameter Estimation using Gravitational Waves from f-modes Associated with Magnetar Flares	Matthew Ball,Raymond Frey,Kara Merfeld	Magnetar vibrational modes are theorized to be associated with energetic X-ray flares. Regular searches for gravitational waves from these modes have been performed by Advanced LIGO and Advanced Virgo, with no detections so far. Presently, search results are given in limits on the root-sum-square of the integrated gravitational-wave strain. However, the increased sensitivity of current detectors and the promise of future detectors invite the consideration of more astrophysically motivated methods. We present a framework for augmenting gravitational wave searches to measure or place direct limits on magnetar astrophysical properties in various search scenarios using a set of phenomenological and analytic models.	astro-ph.HE	9 pages, 5 figures
6	Combining linear-scaling quantum transport and machine-learning molecular dynamics to study thermal and electronic transports in complex materials	Zheyong Fan,Yang Xiao,Yanzhou Wang,Penghua Ying,Shunda Chen,Haikuan Dong	We propose an efficient approach for simultaneous prediction of thermal and electronic transport properties in complex materials. Firstly, a highly efficient machine-learned neuroevolution potential is trained using reference data from quantum-mechanical density-functional theory calculations. This trained potential is then applied in large-scale molecular dynamics simulations, enabling the generation of realistic structures and accurate characterization of thermal transport properties. In addition, molecular dynamics simulations of atoms and linear-scaling quantum transport calculations of electrons are coupled to account for the electron-phonon scattering and other disorders that affect the charge carriers governing the electronic transport properties. We demonstrate the usefulness of this unified approach by studying thermoelectric transport properties of a graphene antidot lattice.	cond-mat.mtrl-sci	8 pages, 4 figures
7	A short proof of the Almkvist-Meurman theorem	Ira M. Gessel	We give a short generating function proof of the Almkvist-Meurman theorem: For integers $h$ and $k\ne0$, define the numbers $M_n(h,k)$ by $kx(e^{hx}-1)/(e^{kx}-1)=\sum_{n=0}^\infty M_n(h,k) x^n/n!$. Equivalently, $M_n(h,k) = k^n(B_n(h/k) - B_n)$, where $B_n(u)$ is the Bernoulli polynomial. Then $M_n(h,k)$ is an integer. The proof is related to Postnikov's functional equation for the generating function for intransitive trees.	math.NT	None
8	Entropy production and thermodynamic inference for stochastic microswimmers	Michalis Chatzittofi,Jaime Agudo-Canalejo,Ramin Golestanian	The question of characterization of the degree of non-equilibrium activity in active matter systems is studied in the context of a stochastic microswimmer model driven by a chemical cycle. The resulting dynamical properties and entropy production rate unravel a complex interplay between the chemical and the hydrodynamic degrees of freedom beyond linear response, which is not captured by conventional phenomenological approaches. By studying the precision-dissipation trade-off, a new protocol is proposed in which microscopic chemical driving forces can be inferred experimentally. Our findings highlight subtleties associated with the stochastic thermodynamics of autonomous microswimmers.	cond-mat.stat-mech	None
9	SAM-CLIP: Merging Vision Foundation Models towards Semantic and Spatial Understanding	Haoxiang Wang,Pavan Kumar Anasosalu Vasu,Fartash Faghri,Raviteja Vemulapalli,Mehrdad Farajtabar,Sachin Mehta,Mohammad Rastegari,Oncel Tuzel,Hadi Pouransari	The landscape of publicly available vision foundation models (VFMs), such as CLIP and Segment Anything Model (SAM), is expanding rapidly. VFMs are endowed with distinct capabilities stemming from their pre-training objectives. For instance, CLIP excels in semantic understanding, while SAM specializes in spatial understanding for segmentation. In this work, we introduce a simple recipe to efficiently merge VFMs into a unified model that assimilates their expertise. Our proposed method integrates multi-task learning, continual learning techniques, and teacher-student distillation. This strategy entails significantly less computational cost compared to traditional multi-task training from scratch. Additionally, it only demands a small fraction of the pre-training datasets that were initially used to train individual models. By applying our method to SAM and CLIP, we derive SAM-CLIP: a unified model that amalgamates the strengths of SAM and CLIP into a single backbone, making it apt for edge device applications. We show that SAM-CLIP learns richer visual representations, equipped with both localization and semantic features, suitable for a broad range of vision tasks. SAM-CLIP obtains improved performance on several head probing tasks when compared with SAM and CLIP. We further show that SAM-CLIP not only retains the foundational strengths of its precursor models but also introduces synergistic functionalities, most notably in zero-shot semantic segmentation, where SAM-CLIP establishes new state-of-the-art results on 5 benchmarks. It outperforms previous models that are specifically designed for this task by a large margin, including +6.8% and +5.9% mean IoU improvement on Pascal-VOC and COCO-Stuff datasets, respectively.	cs.CV	None
0	Toward a Critical Toponymy Framework for Named Entity Recognition: A Case Study of Airbnb in New York City	Mikael Brunila,Jack LaViolette,Sky CH-Wang,Priyanka Verma,Clara F√©r√©,Grant McKenzie	Critical toponymy examines the dynamics of power, capital, and resistance through place names and the sites to which they refer. Studies here have traditionally focused on the semantic content of toponyms and the top-down institutional processes that produce them. However, they have generally ignored the ways in which toponyms are used by ordinary people in everyday discourse, as well as the other strategies of geospatial description that accompany and contextualize toponymic reference. Here, we develop computational methods to measure how cultural and economic capital shape the ways in which people refer to places, through a novel annotated dataset of 47,440 New York City Airbnb listings from the 2010s. Building on this dataset, we introduce a new named entity recognition (NER) model able to identify important discourse categories integral to the characterization of place. Our findings point toward new directions for critical toponymy and to a range of previously understudied linguistic signals relevant to research on neighborhood status, housing and tourism markets, and gentrification.	cs.CL	Accepted at EMNLP 2023 (main track)
1	Neural Network with Local Converging Input (NNLCI) for Supersonic Flow Problems with Unstructured Grids	Weiming Ding,Haoxiang Huang,Tzu Jung Lee,Yingjie Liu,Vigor Yang	In recent years, surrogate models based on deep neural networks (DNN) have been widely used to solve partial differential equations, which were traditionally handled by means of numerical simulations. This kind of surrogate models, however, focuses on global interpolation of the training dataset, and thus requires a large network structure. The process is both time consuming and computationally costly, thereby restricting their use for high-fidelity prediction of complex physical problems. In the present study, we develop a neural network with local converging input (NNLCI) for high-fidelity prediction using unstructured data. The framework utilizes the local domain of dependence with converging coarse solutions as input, which greatly reduces computational resource and training time. As a validation case, the NNLCI method is applied to study inviscid supersonic flows in channels with bumps. Different bump geometries and locations are considered to benchmark the effectiveness and versability of the proposed approach. Detailed flow structures, including shock-wave interactions, are examined systematically.	math.NA	23 pages, 21 figures
2	TaskDiff: A Similarity Metric for Task-Oriented Conversations	Ankita Bhaumik,Praveen Venkateswaran,Yara Rizk,Vatche Isahagian	The popularity of conversational digital assistants has resulted in the availability of large amounts of conversational data which can be utilized for improved user experience and personalized response generation. Building these assistants using popular large language models like ChatGPT also require additional emphasis on prompt engineering and evaluation methods. Textual similarity metrics are a key ingredient for such analysis and evaluations. While many similarity metrics have been proposed in the literature, they have not proven effective for task-oriented conversations as they do not take advantage of unique conversational features. To address this gap, we present TaskDiff, a novel conversational similarity metric that utilizes different dialogue components (utterances, intents, and slots) and their distributions to compute similarity. Extensive experimental evaluation of TaskDiff on a benchmark dataset demonstrates its superior performance and improved robustness over other related approaches.	cs.CL	Accepted to the main conference at EMNLP 2023
3	DeTiME: Diffusion-Enhanced Topic Modeling using Encoder-decoder based LLM	Weijie Xu,Wenxiang Hu,Fanyou Wu,Srinivasan Sengamedu	In the burgeoning field of natural language processing, Neural Topic Models (NTMs) and Large Language Models (LLMs) have emerged as areas of significant research interest. Despite this, NTMs primarily utilize contextual embeddings from LLMs, which are not optimal for clustering or capable for topic generation. Our study addresses this gap by introducing a novel framework named Diffusion-Enhanced Topic Modeling using Encoder-Decoder-based LLMs (DeTiME). DeTiME leverages ncoder-Decoder-based LLMs to produce highly clusterable embeddings that could generate topics that exhibit both superior clusterability and enhanced semantic coherence compared to existing methods. Additionally, by exploiting the power of diffusion, our framework also provides the capability to generate content relevant to the identified topics. This dual functionality allows users to efficiently produce highly clustered topics and related content simultaneously. DeTiME's potential extends to generating clustered embeddings as well. Notably, our proposed framework proves to be efficient to train and exhibits high adaptability, demonstrating its potential for a wide array of applications.	cs.CL	19 pages, 4 figures, EMNLP 2023
4	An index theorem for Z-2-harmonic spinors branching along a graph	Andriy Haydys,Rafe Mazzeo,Ryosuke Takahashi	We prove an index formula for the Dirac operator acting on two-valued spinors on a $3$-manifold $M$ which branch along a smoothly embedded graph $\Sigma \subset M$, and with respect to a boundary condition along $\Sigma$ inspired by an instance of this setting related to the deformation theory of $\mathbb Z_2$-harmonic spinors. When $\Sigma$ is a smooth embedded curve, this index vanishes; this was proved earlier by one of us, but the proof here is different and extends to the more general setting where $\Sigma$ also has vertices. We focus primarily on the Dirac operator itself, but also show how our results apply to more general twisted Dirac operators and to the closely related $\mathbb Z_2$ harmonic $1$-forms.	math.DG	None
5	Adaptive End-to-End Metric Learning for Zero-Shot Cross-Domain Slot Filling	Yuanjun Shi,Linzhi Wu,Minglai Shao	Recently slot filling has witnessed great development thanks to deep learning and the availability of large-scale annotated data. However, it poses a critical challenge to handle a novel domain whose samples are never seen during training. The recognition performance might be greatly degraded due to severe domain shifts. Most prior works deal with this problem in a two-pass pipeline manner based on metric learning. In practice, these dominant pipeline models may be limited in computational efficiency and generalization capacity because of non-parallel inference and context-free discrete label embeddings. To this end, we re-examine the typical metric-based methods, and propose a new adaptive end-to-end metric learning scheme for the challenging zero-shot slot filling. Considering simplicity, efficiency and generalizability, we present a cascade-style joint learning framework coupled with context-aware soft label representations and slot-level contrastive representation learning to mitigate the data and label shift problems effectively. Extensive experiments on public benchmarks demonstrate the superiority of the proposed approach over a series of competitive baselines.	cs.CL	Accepted to EMNLP 2023 (Main, Long Paper)
6	A ballistic electron source with magnetically-controlled valley polarization in bilayer graphene	Josep Ingla-Ayn√©s,Antonio L. R. Manesco,Talieh S. Ghiasi,Kenji Watanabe,Takashi Taniguchi,Herre S. J. van der Zant	The achievement of valley-polarized electron currents is a cornerstone for the realization of valleytronic devices. Here, we report on ballistic coherent transport experiments where two opposite quantum point contacts (QPCs) are defined by electrostatic gating in a bilayer graphene (BLG) channel. By steering the ballistic currents with an out-of-plane magnetic field we observe two current jets, a consequence of valley-dependent trigonal warping. Tuning the BLG carrier density and number of QPC modes (m) with a gate voltage we find that the two jets are present for m=1 and up to m=6, indicating the robustness of the effect. Semiclassical simulations which account for size quantization and trigonal warping of the Fermi surface quantitatively reproduce our data without fitting parameters, confirming the origin of the signals. In addition, our model shows that the ballistic currents collected for non-zero magnetic fields are valley-polarized independently of m, but their polarization depends on the magnetic field sign, envisioning such devices as ballistic current sources with tuneable valley-polarization.	cond-mat.mes-hall	15 pages, 11 figures
7	Fast and Reliable Generation of EHR Time Series via Diffusion Models	Muhang Tian,Bernie Chen,Allan Guo,Shiyi Jiang,Anru R. Zhang	Electronic Health Records (EHRs) are rich sources of patient-level data, including laboratory tests, medications, and diagnoses, offering valuable resources for medical data analysis. However, concerns about privacy often restrict access to EHRs, hindering downstream analysis. Researchers have explored various methods for generating privacy-preserving EHR data. In this study, we introduce a new method for generating diverse and realistic synthetic EHR time series data using Denoising Diffusion Probabilistic Models (DDPM). We conducted experiments on six datasets, comparing our proposed method with seven existing methods. Our results demonstrate that our approach significantly outperforms all existing methods in terms of data utility while requiring less training effort. Our approach also enhances downstream medical data analysis by providing diverse and realistic synthetic EHR data.	cs.LG	None
8	Inclusion in Virtual Reality Technology: A Scoping Review	Xiaofeng Yong,Ali Arya	Despite the significant growth in virtual reality applications and research, the notion of inclusion in virtual reality is not well studied. Inclusion refers to the active involvement of different groups of people in the adoption, use, design, and development of VR technology and applications. In this review, we provide a scoping analysis of existing virtual reality research literature about inclusion. We categorize the literature based on target group into ability, gender, and age, followed by those that study community-based design of VR experiences. In the latter group, we focus mainly on Indigenous Peoples as a clearer and more important example. We also briefly review the approaches to model and consider the role of users in technology adoption and design as a background for inclusion studies. We identify a series of generic barriers and research gaps and some specific ones for each group, resulting in suggested directions for future research.	cs.HC	None
9	Active teacher selection for reinforcement learning from human feedback	Rachel Freedman,Justin Svegliato,Kyle Wray,Stuart Russell	Reinforcement learning from human feedback (RLHF) enables machine learning systems to learn objectives from human feedback. A core limitation of these systems is their assumption that all feedback comes from a single human teacher, despite querying a range of distinct teachers. We propose the Hidden Utility Bandit (HUB) framework to model differences in teacher rationality, expertise, and costliness, formalizing the problem of learning from multiple teachers. We develop a variety of solution algorithms and apply them to two real-world domains: paper recommendation systems and COVID-19 vaccine testing. We find that the Active Teacher Selection (ATS) algorithm outperforms baseline algorithms by actively selecting when and which teacher to query. The HUB framework and ATS algorithm demonstrate the importance of leveraging differences between teachers to learn accurate reward models, facilitating future research on active teacher selection for robust reward modeling.	cs.AI	None
0	Early Career Perspectives For the NASA SMD Bridge Program	Jenna M. Cann,Arturo O. Martinez,Amethyst Barnes,Sara Doan,Feyi Ilesanmi,Margaret Lazzarini,Teresa Monsue,Carlos Pinedo,Nicole Cabrera Salazar,Amy Steele	In line with the Astro2020 Decadal Report State of the Profession findings and the NASA core value of Inclusion, the NASA Science Mission Directorate (SMD) Bridge Program was created to provide financial and programmatic support to efforts that work to increase the representation and inclusion of students from under-represented minorities in the STEM fields. To ensure an effective program, particularly for those who are often left out of these conversations, the NASA SMD Bridge Program Workshop was developed as a way to gather feedback from a diverse group of people about their unique needs and interests. The Early Career Perspectives Working Group was tasked with examining the current state of bridge programs, academia in general, and its effect on students and early career professionals. The working group, comprised of 10 early career and student members, analyzed the discussions and responses from workshop breakout sessions and two surveys, as well as their own experiences, to develop specific recommendations and metrics for implementing a successful and supportive bridge program. In this white paper, we will discuss the key themes that arose through our work, and highlight select recommendations for the NASA SMD Bridge Program to best support students and early career professionals.	astro-ph.IM	White paper developed by the Early Career Perspectives Working Group   for the NASA SMD Bridge Program Workshop. 11 pages
1	On the Dimensionality of Sentence Embeddings	Hongwei Wang,Hongming Zhang,Dong Yu	Learning sentence embeddings is a fundamental problem in natural language processing. While existing research primarily focuses on enhancing the quality of sentence embeddings, the exploration of sentence embedding dimensions is limited. Here we present a comprehensive and empirical analysis of the dimensionality of sentence embeddings. First, we demonstrate that the optimal dimension of sentence embeddings is usually smaller than the default value. Subsequently, to compress the dimension of sentence embeddings with minimum performance degradation, we identify two components contributing to the overall performance loss: the encoder's performance loss and the pooler's performance loss. Therefore, we propose a two-step training method for sentence representation learning models, wherein the encoder and the pooler are optimized separately to mitigate the overall performance loss in low-dimension scenarios. Experimental results on seven STS tasks and seven sentence classification tasks demonstrate that our method significantly improves the performance of low-dimensional sentence embeddings.	cs.CL	None
2	Total $\mathbb{A}$-variation-type flows for general integrands	David Meyer	We study the $L^2$-gradient flows for functionals of the type $\int_{\Omega}f(x,\mathbb{A}u)\,\mathrm{dx}$, where $f$ is a convex function of linear growth and $\mathbb{A}$ is some first-order linear constant-coefficient differential operator.   To this end we identify the relaxation of the functional to the space $\mathrm{BV}^{\mathbb{A}}\cap L^2$, identify its subdifferential, and show pointwise representation formulas for the relaxation and the subdifferential, both with and without Dirichlet boundary conditions. The existence and uniqueness then follow from abstract semigroup theory.   Another main novelty of our work is that we require no regularity or continuity assumptions for $f$.	math.AP	None
3	Final velocity and radiated energy in numerical simulations of binary black holes	Emmanuel A. Tassone,Carlos N. Kozameh	The evolution of global binary black holes variables such as energy or linear momentum are mainly obtained by applying numerical methods near coalescence, post-Newtonian (PN) expansions, or a combination of both. In this paper, we use a fully relativistic formalism presented several years ago that only uses global variables defined at null infinity together with the gravitational radiation emitted by the source to obtain the time evolution of such variables for binary black holes (BBH) systems. For that, we use the Rochester catalog composed of 776 BBHs simulations. We compute the final velocity, radiated energy, and intrinsic angular momentum predicted by the dynamical equations in this formalism for nonspinning, aligned and antialigned spins, and several different precessing configurations. We compare obtained values with reported values in numerical simulations. As BBHs parameter space is still not completely covered by numerical simulations, we fit phenomenological formulas for practical applications to the radiated energy and final velocities obtained. Also, we compare the fits with reported values. In conclusion, we see that our formulae and correlations for the variables described in this work are consistent with those found in the general literature.	gr-qc	12 pages, 16 figures
4	UncertaintyPlayground: A Fast and Simplified Python Library for Uncertainty Estimation	Ilia Azizi	This paper introduces UncertaintyPlayground, a Python library built on PyTorch and GPyTorch for uncertainty estimation in supervised learning tasks. The library offers fast training for Gaussian and multi-modal outcome distributions through Sparse and Variational Gaussian Process Regressions (SVGPRs) for normally distributed outcomes and Mixed Density Networks (MDN) for mixed distributions. In addition to model training with various hyperparameters, UncertaintyPlayground can visualize the prediction intervals of one or more instances. Due to using tensor operations, the library can be trained both on CPU and GPU and offers various PyTorch-specific techniques for speed optimization. The library contains unit tests for each module and ensures multi-platform continuous integration with GitHub Workflows (online integration) and Tox (local integration). Finally, the code is documented with Google-style docstrings and offers a documentation website created with MkDocs and MkDocStrings.	stat.ML	None
5	The linear system for Sudoku and a fractional completion threshold	Peter J. Dukes,Kate Nimegeers	We study a system of linear equations associated with Sudoku latin squares. The coefficient matrix $M$ of the normal system has various symmetries arising from Sudoku. From this, we find the eigenvalues and eigenvectors of $M$, and compute a generalized inverse. Then, using linear perturbation methods, we obtain a fractional completion guarantee for sufficiently large and sparse rectangular-box Sudoku puzzles.	math.CO	None
6	Triple Simplex Matrix Completion for Expense Forecasting	Cheng Qian,Lucas Glass,Nikos Sidiropoulos	Forecasting project expenses is a crucial step for businesses to avoid budget overruns and project failures. Traditionally, this has been done by financial analysts or data science techniques such as time-series analysis. However, these approaches can be uncertain and produce results that differ from the planned budget, especially at the start of a project with limited data points. This paper proposes a constrained non-negative matrix completion model that predicts expenses by learning the likelihood of the project correlating with certain expense patterns in the latent space. The model is constrained on three probability simplexes, two of which are on the factor matrices and the third on the missing entries. Additionally, the predicted expense values are guaranteed to meet the budget constraint without the need of post-processing. An inexact alternating optimization algorithm is developed to solve the associated optimization problem and is proven to converge to a stationary point. Results from two real datasets demonstrate the effectiveness of the proposed method in comparison to state-of-the-art algorithms.	cs.LG	5 pages 2 figures
7	Systematic AI Approach for AGI: Addressing Alignment, Energy, and AGI Grand Challenges	Eren Kurshan	AI faces a trifecta of grand challenges the Energy Wall, the Alignment Problem and the Leap from Narrow AI to AGI. Contemporary AI solutions consume unsustainable amounts of energy during model training and daily operations.Making things worse, the amount of computation required to train each new AI model has been doubling every 2 months since 2020, directly translating to increases in energy consumption.The leap from AI to AGI requires multiple functional subsystems operating in a balanced manner, which requires a system architecture. However, the current approach to artificial intelligence lacks system design; even though system characteristics play a key role in the human brain from the way it processes information to how it makes decisions. Similarly, current alignment and AI ethics approaches largely ignore system design, yet studies show that the brains system architecture plays a critical role in healthy moral decisions.In this paper, we argue that system design is critically important in overcoming all three grand challenges. We posit that system design is the missing piece in overcoming the grand challenges.We present a Systematic AI Approach for AGI that utilizes system design principles for AGI, while providing ways to overcome the energy wall and the alignment challenges.	cs.AI	International Journal on Semantic Computing (2024) Categories:   Artificial Intelligence; AI; Artificial General Intelligence; AGI; System   Design; System Architecture
8	Are fermionic conformal field theories more entangled?	Gilles Parez,William Witczak-Krempa	We study the entanglement between disjoint subregions in quantum critical systems through the lens of the logarithmic negativity. We work with conformal field theories (CFTs) in general dimensions, and their corresponding lattice Hamiltonians. At small separations, the logarithmic negativity is big and shows universal behaviour, but we show non-perturbatively that it decays faster than any power at large separations. This can already be seen in the minimal setting of single-spin subregions. The corresponding absence of distillable entanglement at large separations generalises the 1d result, and indicates that quantum critical groundstates do not possess long range bipartite entanglement, at least for bosons. For systems with fermions, a more suitable definition of the logarithmic negativity exists that takes into account fermion parity, and we show that it decays algebraically. Along the way we obtain general CFT results for the moments of the partially transposed density matrix.	cond-mat.str-el	6+3 pages
9	Elliptical micropillars for efficient generation and detection of coherent acoustic phonons	Chushuang Xiang,Anne Rodriguez,Edson Rafael Cardozo de Oliveira,Luc Le Gratiet,Isabelle Sagnes,Martina Morassi,Aristide Lemaitre,Norberto Daniel Lanzillotti-Kimura	Coherent acoustic phonon generation and detection assisted by optical resonances are at the core of efficient optophononic transduction processes. However, when dealing with a single optical resonance, the optimum generation and detection conditions take place at different laser wavelengths, i.e. different detunings from the cavity mode. In this work, we theoretically propose and experimentally demonstrate the use of elliptical micropillars to reach these conditions simultaneously at a single wavelength. Elliptical micropillar optophononic resonators present two optical modes with orthogonal polarizations at different wavelengths. By employing a cross-polarized scheme pump-probe experiment, we exploit the mode splitting and couple the pump beam to one mode while the probe is detuned from the other one. In this way, at a particular micropillar ellipticity, both phonon generation and detection processes are enhanced. We report an enhancement of a factor of ~3.1 when comparing the signals from elliptical and circular micropillars. Our findings constitute a step forward in tailoring the light-matter interaction for more efficient ultrahigh-frequency optophononic devices.	physics.optics	10 pages, 5 figures
0	Scattering theory with matter fields of classical gravitons in the null surface formulation	Carlos N. Kozameha,Emmanuel A. Tassone	Using a set of field equations in the null surface formulation we obtain the linearized coupling between the gravitational and matter fields. We first derive a formula for the metric of the space time and then we use this formula to study the scattering of incoming gravitational waves when matter is present, obtaining explicit formulae relating the radiation modes at past and future null infinity for a general asymptotically flat spacetime. An example application is made at the end of this work when the matter field is a massless real scalar field. The relevance of this result for a perturbation procedure is discussed.	gr-qc	13 Pages
1	GradSim: Gradient-Based Language Grouping for Effective Multilingual Training	Mingyang Wang,Heike Adel,Lukas Lange,Jannik Str√∂tgen,Hinrich Sch√ºtze	Most languages of the world pose low-resource challenges to natural language processing models. With multilingual training, knowledge can be shared among languages. However, not all languages positively influence each other and it is an open research question how to select the most suitable set of languages for multilingual training and avoid negative interference among languages whose characteristics or data distributions are not compatible. In this paper, we propose GradSim, a language grouping method based on gradient similarity. Our experiments on three diverse multilingual benchmark datasets show that it leads to the largest performance gains compared to other similarity measures and it is better correlated with cross-lingual model performance. As a result, we set the new state of the art on AfriSenti, a benchmark dataset for sentiment analysis on low-resource African languages. In our extensive analysis, we further reveal that besides linguistic features, the topics of the datasets play an important role for language grouping and that lower layers of transformer models encode language-specific features while higher layers capture task-specific information.	cs.LG	None
2	Heat-Flux Limited Cloud Activity and Vertical Mixing in Giant Planet Atmospheres with an Application to Uranus and Neptune	Huazhi Ge,Cheng Li,Xi Zhang,Chris Moeckel	Storms operated by moist convection and the condensation of $\rm CH_{4}$ or $\rm H_{2}S$ have been observed on Uranus and Neptune. However, the mechanism of cloud formation, thermal structure, and mixing efficiency of ice giant weather layers remains unclear. In this paper, we show that moist convection is limited by heat transport on giant planets, especially on ice giants where planetary heat flux is weak. Latent heat associated with condensation and evaporation can efficiently bring heat across the weather layer through precipitations. This effect was usually neglected in previous studies without a complete hydrological cycle. We first derive analytical theories and show the upper limit of cloud density is determined by the planetary heat flux and microphysics of clouds but independent of the atmospheric composition. The eddy diffusivity of moisture depends on the heat fluxes, atmospheric composition, and gravity of the planet but is not directly related to cloud microphysics. We then conduct convection- and cloud-resolving simulations with SNAP to validate our analytical theory. The simulated cloud density and eddy diffusivity are smaller than the results acquired from the equilibrium cloud condensation model and mixing length theory by several orders of magnitude but consistent with our analytical solutions. Meanwhile, the mass-loading effect of $\rm CH_{4}$ and $\rm H_{2}S$ leads to superadiabatic and stable weather layers. Our simulations produced three cloud layers that are qualitatively similar to recent observations. This study has important implications for cloud formation and eddy mixing in giant planet atmospheres in general and observations for future space missions and ground-based telescopes.	astro-ph.EP	23 pages, 7 figures, and 2 tables. Accepted for publication in PSJ
3	Besicovitch-Eggleston sets for finite GLS number systems with redundancy	Jonny Imbierski,Charlene Kalle,Reza Mohammadpour	In this article we study Besicovitch-Eggleston sets for finite GLS number systems with redundancy. These number systems produce number expansions reminiscent of Cantor base expansions. The redundancy refers to the fact that each number $x \in [0,1]$ has uncountably many representations in the system. We distinguish between these representations by adding an extra dimension and describing the system as a diagonally affine IFS on $\mathbb R^2$. For the associated two dimensional level sets of digit frequencies we give the Birkhoff spectrum and an expression for the Hausdorff dimension. To obtain these results we first prove a more general result on the Hausdorff dimension of level sets for Birkhoff averages of continuous potentials for a certain family of diagonally affine IFS's. We also study the Hausdorff dimension of digit frequency sets along fibres.	math.DS	21 pages, 1 figure
4	Towards Possibilities & Impossibilities of AI-generated Text Detection: A Survey	Soumya Suvra Ghosal,Souradip Chakraborty,Jonas Geiping,Furong Huang,Dinesh Manocha,Amrit Singh Bedi	Large Language Models (LLMs) have revolutionized the domain of natural language processing (NLP) with remarkable capabilities of generating human-like text responses. However, despite these advancements, several works in the existing literature have raised serious concerns about the potential misuse of LLMs such as spreading misinformation, generating fake news, plagiarism in academia, and contaminating the web. To address these concerns, a consensus among the research community is to develop algorithmic solutions to detect AI-generated text. The basic idea is that whenever we can tell if the given text is either written by a human or an AI, we can utilize this information to address the above-mentioned concerns. To that end, a plethora of detection frameworks have been proposed, highlighting the possibilities of AI-generated text detection. But in parallel to the development of detection frameworks, researchers have also concentrated on designing strategies to elude detection, i.e., focusing on the impossibilities of AI-generated text detection. This is a crucial step in order to make sure the detection frameworks are robust enough and it is not too easy to fool a detector. Despite the huge interest and the flurry of research in this domain, the community currently lacks a comprehensive analysis of recent developments. In this survey, we aim to provide a concise categorization and overview of current work encompassing both the prospects and the limitations of AI-generated text detection. To enrich the collective knowledge, we engage in an exhaustive discussion on critical and challenging open questions related to ongoing research on AI-generated text detection.	cs.CL	None
5	One-hot Generalized Linear Model for Switching Brain State Discovery	Chengrui Li,Soon Ho Kim,Chris Rodgers,Hannah Choi,Anqi Wu	Exposing meaningful and interpretable neural interactions is critical to understanding neural circuits. Inferred neural interactions from neural signals primarily reflect functional interactions. In a long experiment, subject animals may experience different stages defined by the experiment, stimuli, or behavioral states, and hence functional interactions can change over time. To model dynamically changing functional interactions, prior work employs state-switching generalized linear models with hidden Markov models (i.e., HMM-GLMs). However, we argue they lack biological plausibility, as functional interactions are shaped and confined by the underlying anatomical connectome. Here, we propose a novel prior-informed state-switching GLM. We introduce both a Gaussian prior and a one-hot prior over the GLM in each state. The priors are learnable. We will show that the learned prior should capture the state-constant interaction, shedding light on the underlying anatomical connectome and revealing more likely physical neuron interactions. The state-dependent interaction modeled by each GLM offers traceability to capture functional variations across multiple brain states. Our methods effectively recover true interaction structures in simulated data, achieve the highest predictive likelihood with real neural datasets, and render interaction structures and hidden states more interpretable when applied to real neural data.	q-bio.NC	None
6	Data Augmentation Techniques for Machine Translation of Code-Switched Texts: A Comparative Study	Injy Hamed,Nizar Habash,Ngoc Thang Vu	Code-switching (CSW) text generation has been receiving increasing attention as a solution to address data scarcity. In light of this growing interest, we need more comprehensive studies comparing different augmentation approaches. In this work, we compare three popular approaches: lexical replacements, linguistic theories, and back-translation (BT), in the context of Egyptian Arabic-English CSW. We assess the effectiveness of the approaches on machine translation and the quality of augmentations through human evaluation. We show that BT and CSW predictive-based lexical replacement, being trained on CSW parallel data, perform best on both tasks. Linguistic theories and random lexical replacement prove to be effective in the lack of CSW parallel data, where both approaches achieve similar results.	cs.CL	Findings of EMNLP 2023
7	Modality Dropout for Multimodal Device Directed Speech Detection using Verbal and Non-Verbal Features	Gautam Krishna,Sameer Dharur,Oggi Rudovic,Pranay Dighe,Saurabh Adya,Ahmed Hussen Abdelaziz,Ahmed H Tewfik	Device-directed speech detection (DDSD) is the binary classification task of distinguishing between queries directed at a voice assistant versus side conversation or background speech. State-of-the-art DDSD systems use verbal cues, e.g acoustic, text and/or automatic speech recognition system (ASR) features, to classify speech as device-directed or otherwise, and often have to contend with one or more of these modalities being unavailable when deployed in real-world settings. In this paper, we investigate fusion schemes for DDSD systems that can be made more robust to missing modalities. Concurrently, we study the use of non-verbal cues, specifically prosody features, in addition to verbal cues for DDSD. We present different approaches to combine scores and embeddings from prosody with the corresponding verbal cues, finding that prosody improves DDSD performance by upto 8.5% in terms of false acceptance rate (FA) at a given fixed operating point via non-linear intermediate fusion, while our use of modality dropout techniques improves the performance of these models by 7.4% in terms of FA when evaluated with missing modalities during inference time.	cs.SD	5 pages
8	Reference Free Domain Adaptation for Translation of Noisy Questions with Question Specific Rewards	Baban Gain,Ramakrishna Appicharla,Soumya Chennabasavaraj,Nikesh Garera,Asif Ekbal,Muthusamy Chelliah	Community Question-Answering (CQA) portals serve as a valuable tool for helping users within an organization. However, making them accessible to non-English-speaking users continues to be a challenge. Translating questions can broaden the community's reach, benefiting individuals with similar inquiries in various languages. Translating questions using Neural Machine Translation (NMT) poses more challenges, especially in noisy environments, where the grammatical correctness of the questions is not monitored. These questions may be phrased as statements by non-native speakers, with incorrect subject-verb order and sometimes even missing question marks. Creating a synthetic parallel corpus from such data is also difficult due to its noisy nature. To address this issue, we propose a training methodology that fine-tunes the NMT system only using source-side data. Our approach balances adequacy and fluency by utilizing a loss function that combines BERTScore and Masked Language Model (MLM) Score. Our method surpasses the conventional Maximum Likelihood Estimation (MLE) based fine-tuning approach, which relies on synthetic target data, by achieving a 1.9 BLEU score improvement. Our model exhibits robustness while we add noise to our baseline, and still achieve 1.1 BLEU improvement and large improvements on TER and BLEURT metrics. Our proposed methodology is model-agnostic and is only necessary during the training phase. We make the codes and datasets publicly available at \url{https://www.iitp.ac.in/~ai-nlp-ml/resources.html#DomainAdapt} for facilitating further research.	cs.CL	Published at: Findings of EMNLP 2023
9	Breaking the Language Barrier: Improving Cross-Lingual Reasoning with Structured Self-Attention	Negar Foroutan,Mohammadreza Banaei,Karl Aberer,Antoine Bosselut	In this work, we study whether multilingual language models (MultiLMs) can transfer logical reasoning abilities to other languages when they are fine-tuned for reasoning in a different language. We evaluate the cross-lingual reasoning abilities of MultiLMs in two schemes: (1) where the language of the context and the question remain the same in the new languages that are tested (i.e., the reasoning is still monolingual, but the model must transfer the learned reasoning ability across languages), and (2) where the language of the context and the question is different (which we term code-switched reasoning). On two logical reasoning datasets, RuleTaker and LeapOfThought, we demonstrate that although MultiLMs can transfer reasoning ability across languages in a monolingual setting, they struggle to transfer reasoning abilities in a code-switched setting. Following this observation, we propose a novel attention mechanism that uses a dedicated set of parameters to encourage cross-lingual attention in code-switched sequences, which improves the reasoning performance by up to 14% and 4% on the RuleTaker and LeapOfThought datasets, respectively.	cs.CL	EMNLP 2023 - Findings
0	Chemical Doppelgangers in GALAH DR3: the Distinguishing Power of Neutron-Capture Elements Among Milky Way Disk Stars	Catherine Manea,Keith Hawkins,Melissa K. Ness,Sven Buder,Sarah L. Martell,Daniel B. Zucker	"The observed chemical diversity of Milky Way stars places important constraints on Galactic chemical evolution and the mixing processes that operate within the interstellar medium. Recent works have found that the chemical diversity of disk stars is low. For example, the APOGEE ""chemical doppelganger rate,"" or the rate at which random pairs of field stars appear as chemically similar as stars born together, is high, and the chemical distributions of APOGEE stars in some Galactic populations are well-described by two-dimensional models. However, limited attention has been paid to the heavy elements (Z > 30) in this context. In this work, we probe the potential for neutron-capture elements to enhance the chemical diversity of stars by determining their effect on the chemical doppelganger rate. We measure the doppelganger rate in GALAH DR3, with abundances rederived using The Cannon, and find that considering the neutron-capture elements decreases the doppelganger rate from 2.2% to 0.4%, nearly a factor of 6, for stars with -0.1 < [Fe/H] < 0.1. While chemical similarity correlates with similarity in age and dynamics, including neutron-capture elements does not appear to select stars that are more similar in these characteristics. Our results highlight that the neutron-capture elements contain information that is distinct from that of the lighter elements and thus add at least one dimension to Milky Way abundance space. This work illustrates the importance of considering the neutron-capture elements when chemically characterizing stars and motivates ongoing work to improve their atomic data and measurements in spectroscopic surveys."	astro-ph.SR	23 pages, 16 figures, 1 table. Submitted to AAS Journals, comments   welcome. Associated catalog of high precision, Cannon-rederived abundances   for GALAH giants to be made publicly available upon acceptance and available   now upon request. See Walsen et al. 2023 for a complementary, high precision,   Cannon-rederived abundance catalog for GALAH solar twins
1	SimBIG: Field-level Simulation-Based Inference of Galaxy Clustering	Pablo Lemos,Liam Parker,ChangHoon Hahn,Shirley Ho,Michael Eickenberg,Jiamin Hou,Elena Massara,Chirag Modi,Azadeh Moradinezhad Dizgah,Bruno Regaldo-Saint Blancard,David Spergel	We present the first simulation-based inference (SBI) of cosmological parameters from field-level analysis of galaxy clustering. Standard galaxy clustering analyses rely on analyzing summary statistics, such as the power spectrum, $P_\ell$, with analytic models based on perturbation theory. Consequently, they do not fully exploit the non-linear and non-Gaussian features of the galaxy distribution. To address these limitations, we use the {\sc SimBIG} forward modelling framework to perform SBI using normalizing flows. We apply SimBIG to a subset of the BOSS CMASS galaxy sample using a convolutional neural network with stochastic weight averaging to perform massive data compression of the galaxy field. We infer constraints on $\Omega_m = 0.267^{+0.033}_{-0.029}$ and $\sigma_8=0.762^{+0.036}_{-0.035}$. While our constraints on $\Omega_m$ are in-line with standard $P_\ell$ analyses, those on $\sigma_8$ are $2.65\times$ tighter. Our analysis also provides constraints on the Hubble constant $H_0=64.5 \pm 3.8 \ {\rm km / s / Mpc}$ from galaxy clustering alone. This higher constraining power comes from additional non-Gaussian cosmological information, inaccessible with $P_\ell$. We demonstrate the robustness of our analysis by showcasing our ability to infer unbiased cosmological constraints from a series of test simulations that are constructed using different forward models than the one used in our training dataset. This work not only presents competitive cosmological constraints but also introduces novel methods for leveraging additional cosmological information in upcoming galaxy surveys like DESI, PFS, and Euclid.	astro-ph.CO	14 pages, 4 figures. A previous version of the paper was published in   the ICML 2023 Workshop on Machine Learning for Astrophysics
2	An ALMA Survey of M-dwarfs in the Beta Pictoris Moving Group with Two New Debris Disc Detections	Patrick F. Cronin-Coltsmann,Grant M. Kennedy,Quentin Kral,Jean-Fran√ßois Lestrade,Sebastian Marino,Luca Matr√†,Mark C. Wyatt	Previous surveys in the far-infrared have found very few, if any, M-dwarf debris discs among their samples. It has been questioned whether M-dwarf discs are simply less common than earlier types, or whether the low detection rate derives from the wavelengths and sensitivities available to those studies. The highly sensitive, long wavelength Atacama Large Millimetre/submillimetre Array can shed light on the problem. This paper presents a survey of M-dwarf stars in the young and nearby Beta Pictoris Moving Group with ALMA at Band 7 (880\,$\mu$m). From the observational sample we detect two new sub-mm excesses that likely constitute unresolved debris discs around GJ\,2006\,A and AT\,Mic\,A and model distributions of the disc fractional luminosities and temperatures. From the science sample of 36 M-dwarfs including AU\,Mic we find a disc detection rate of 4/36 or 11.1$^{+7.4}_{-3.3}$\% that rises to 23.1$^{+8.3}_{-5.5}$\% when adjusted for completeness. We conclude that this detection rate is consistent with the detection rate of discs around G and K type stars and that the disc properties are also likely consistent with earlier type stars. We additionally conclude that M-dwarf stars are not less likely to host debris discs, but instead their detection requires longer wavelength and higher sensitivity observations than have previously been employed.	astro-ph.SR	Accepted to MNRAS
3	Diffuse supernova neutrino background with up-to-date star formation rate measurements and long-term multi-dimensional supernova simulations	Nick Ekanger,Shunsaku Horiuchi,Hiroki Nagakura,Samantha Reitz	The sensitivity of current and future neutrino detectors like Super-Kamiokande (SK), JUNO, Hyper-Kamiokande (HK), and DUNE is expected to allow for the detection of the diffuse supernova neutrino background (DSNB). However, the DSNB model ingredients like the core-collapse supernova (CCSN) rate, neutrino emission spectra, and the fraction of failed supernovae are not precisely known. We quantify the uncertainty on each of these ingredients by (i) compiling a large database of recent star formation rate density measurements, (ii) combining neutrino emission from long-term axisymmetric CCSNe simulations and strategies for estimating the emission from the protoneutron star cooling phase, and (iii) assuming different models of failed supernovae. Finally, we calculate the fluxes and event rates at multiple experiments and perform a simplified statistical estimate of the time required to significantly detect the DSNB at SK with the gadolinium upgrade and JUNO. Our fiducial model predicts a flux of $5.1\pm0.4^{+0.0+0.5}_{-2.0-2.7}\,{\rm cm^2~s^{-1}}$ at SK employing Gd-tagging, or $3.6\pm0.3^{+0.0+0.8}_{-1.6-1.9}$ events per year, where the errors represent our uncertainty from star formation rate density measurements, uncertainty in neutrino emission, and uncertainty in the failed-supernova scenario. In this fiducial calculation, we could see a $3\sigma$ detection by $\sim2030$ with SK-Gd and a $5\sigma$ detection by $\sim2035$ with a joint SK-Gd/JUNO analysis, but background reduction remains crucial.	astro-ph.HE	19 pages, 9 figures, 3+2 tables. Comments welcome
4	Shared randomness allows violation of macroscopic realism using a single measurement	Shubhayan Sarkar	"Macro-realistic description of systems is based majorly on two basic intuitions about the classical world, namely, macrorealism per se, that is, the system is always in a distinct state, and non-invasive measurements, that is, measurements do not disturb the system. Given the assumption of no-signalling in time, one utilizes Leggett-Garg inequalities to observe a violation of macroscopic realism which requires at least three measurements. In this work, we show that if one has access to shared randomness then one can observe a violation of macroscopic realism using a single measurement even if no signalling in time is satisfied. Interestingly, using the proposed scheme one can also rule out a larger class of models, which we term ""macroscopic no-signalling"" theories which can not violate the no-signalling in time conditions. We further construct a witness to observe the violation of macroscopic no-signalling."	quant-ph	4 pages, 2 Figures. Comments are welcome:)
5	${\rm S{\scriptsize IM}BIG}$: Galaxy Clustering Analysis with the Wavelet Scattering Transform	Bruno R√©galdo-Saint Blancard,ChangHoon Hahn,Shirley Ho,Jiamin Hou,Pablo Lemos,Elena Massara,Chirag Modi,Azadeh Moradinezhad Dizgah,Liam Parker,Yuling Yao,Michael Eickenberg	The non-Gaussisan spatial distribution of galaxies traces the large-scale structure of the Universe and therefore constitutes a prime observable to constrain cosmological parameters. We conduct Bayesian inference of the $\Lambda$CDM parameters $\Omega_m$, $\Omega_b$, $h$, $n_s$, and $\sigma_8$ from the BOSS CMASS galaxy sample by combining the wavelet scattering transform (WST) with a simulation-based inference approach enabled by the ${\rm S{\scriptsize IM}BIG}$ forward model. We design a set of reduced WST statistics that leverage symmetries of redshift-space data. Posterior distributions are estimated with a conditional normalizing flow trained on 20,000 simulated ${\rm S{\scriptsize IM}BIG}$ galaxy catalogs with survey realism. We assess the accuracy of the posterior estimates using simulation-based calibration and quantify generalization and robustness to the change of forward model using a suite of 2,000 test simulations. When probing scales down to $k_{\rm max}=0.5~h/\text{Mpc}$, we are able to derive accurate posterior estimates that are robust to the change of forward model for all parameters, except $\sigma_8$. We mitigate the robustness issues with $\sigma_8$ by removing the WST coefficients that probe scales smaller than $k \sim 0.3~h/\text{Mpc}$. Applied to the BOSS CMASS sample, our WST analysis yields seemingly improved constraints obtained from a standard PT-based power spectrum analysis with $k_{\rm max}=0.25~h/\text{Mpc}$ for all parameters except $h$. However, we still raise concerns on these results. The observational predictions significantly vary across different normalizing flow architectures, which we interpret as a form of model misspecification. This highlights a key challenge for forward modeling approaches when using summary statistics that are sensitive to detailed model-specific or observational imprints on galaxy clustering.	astro-ph.CO	11+5 pages, 8+2 figures
6	Molecular modelling of odd viscoelastic fluids	Pawe≈Ç Matus,Ruben Lier,Piotr Sur√≥wka	We consider an active, stochastic microscopic model of particles suspended in a fluid and show that the coarse-grained description of this model renders odd viscoelasticity. The model is made up of odd dumbbells, each featuring a robotic device as the bead, which exhibits a particular torque response. We analytically compute the stress-stress correlator and corroborate the results using molecular dynamics simulations. We also provide a unified analytical framework for several experimental and numerical setups designed to elucidate odd effects in fluids.	cond-mat.soft	17 pages, 7 figures
7	Electric Fields in Liquid Water Irradiated with Protons at Ultrahigh Dose Rates	F. Gobet,P. Barberet,M. -H. Delville,G. Dev√®s,T. Gu√©rin,R. Li√©nard,H. N. Tran,C. Vecco-Garda,A. W√ºrger,S. Zein,H. Seznec	We study the effects of irradiating water with 3 MeV protons at high doses by observing the motion of charged polystyrene beads outside the proton beam. By single-particle tracking, we measure a radial velocity of the order of microns per second. Combining electrokinetic theory with simulations of the beam-generated reaction products and their outward diffusion, we find that the bead motion is due to electrophoresis in the electric field induced by the mobility contrast of cations and anions. This work sheds light on the perturbation of biological systems by high-dose radiations and paves the way for the manipulation of colloid or macromolecular dispersions by radiation-induced diffusiophoresis.	physics.chem-ph	None
8	Radial acceleration relation of galaxies with joint kinematic and weak-lensing data	Tobias Mistele,Stacy McGaugh,Federico Lelli,James Schombert,Pengfei Li	We combine kinematic and gravitational lensing data to construct the Radial Acceleration Relation (RAR) of galaxies over a large dynamic range. We improve on previous weak-lensing studies in two ways. First, we compute stellar masses using the same stellar population model as for the kinematic data. Second, we introduce a new method for converting excess surface density profiles to radial accelerations. This method is based on a new deprojection formula which is exact, computationally efficient, and gives smaller systematic uncertainties than previous methods. We find that the RAR inferred from weak-lensing data smoothly continues that inferred from kinematic data by about $2.5\,\mathrm{dex}$ in acceleration. Contrary to previous studies, we find that early- and late-type galaxies lie on the same joint RAR when a sufficiently strict isolation criterion is adopted and their stellar and gas masses are estimated consistently with the kinematic RAR.	astro-ph.GA	39 pages, 16 figures
9	SyncFusion: Multimodal Onset-synchronized Video-to-Audio Foley Synthesis	Marco Comunit√†,Riccardo F. Gramaccioni,Emilian Postolache,Emanuele Rodol√†,Danilo Comminiello,Joshua D. Reiss	Sound design involves creatively selecting, recording, and editing sound effects for various media like cinema, video games, and virtual/augmented reality. One of the most time-consuming steps when designing sound is synchronizing audio with video. In some cases, environmental recordings from video shoots are available, which can aid in the process. However, in video games and animations, no reference audio exists, requiring manual annotation of event timings from the video. We propose a system to extract repetitive actions onsets from a video, which are then used - in conjunction with audio or textual embeddings - to condition a diffusion model trained to generate a new synchronized sound effects audio track. In this way, we leave complete creative control to the sound designer while removing the burden of synchronization with video. Furthermore, editing the onset track or changing the conditioning embedding requires much less effort than editing the audio track itself, simplifying the sonification process. We provide sound examples, source code, and pretrained models to faciliate reproducibility	cs.SD	None
0	${\rm S{\scriptsize IM}BIG}$: The First Cosmological Constraints from Non-Gaussian and Non-Linear Galaxy Clustering	ChangHoon Hahn,Pablo Lemos,Liam Parker,Bruno R√©galdo-Saint Blancard,Michael Eickenberg,Shirley Ho,Jiamin Hou,Elena Massara,Chirag Modi,Azadeh Moradinezhad Dizgah,David Spergel	The 3D distribution of galaxies encodes detailed cosmological information on the expansion and growth history of the Universe. We present the first cosmological constraints that exploit non-Gaussian cosmological information on non-linear scales from galaxy clustering, inaccessible with current standard analyses. We analyze a subset of the BOSS galaxy survey using ${\rm S{\scriptsize IM}BIG}$, a new framework for cosmological inference that leverages high-fidelity simulations and deep generative models. We use two clustering statistics beyond the standard power spectrum: the bispectrum and a convolutional neural network based summary of the galaxy field. We infer constraints on $\Lambda$CDM parameters, $\Omega_b$, $h$, $n_s$, $\Omega_m$, and $\sigma_8$, that are 1.6, 1.5, 1.7, 1.2, and 2.3$\times$ tighter than power spectrum analyses. With this increased precision, we derive constraints on the Hubble constant, $H_0$, and $S_8 = \sigma_8 \sqrt{\Omega_m/0.3}$ that are competitive with other cosmological probes, even with a sample that only spans 10% of the full BOSS volume. Our $H_0$ constraints, imposing the Big Bang Nucleosynthesis prior on the baryon density, are consistent with the early time constraints from the cosmic microwave background (CMB). Meanwhile, our $S_8$ constraints are consistent with weak lensing experiments and similarly lie below CMB constraints. Lastly, we present forecasts to show that future work extending ${\rm S{\scriptsize IM}BIG}$ to upcoming spectroscopic galaxy surveys (DESI, PFS, Euclid) will produce leading $H_0$ and $S_8$ constraints that bridge the gap between early and late time measurements and shed light on current cosmic tensions.	astro-ph.CO	13 pages, 5 figures, submitted to Nature Astronomy, comments welcome
1	${\rm S{\scriptsize IM}BIG}$: The First Cosmological Constraints from the Non-Linear Galaxy Bispectrum	ChangHoon Hahn,Michael Eickenberg,Shirley Ho,Jiamin Hou,Pablo Lemos,Elena Massara,Chirag Modi,Azadeh Moradinezhad Dizgah,Liam Parker,Bruno R√©galdo-Saint Blancard	We present the first cosmological constraints from analyzing higher-order galaxy clustering on non-linear scales. We use ${\rm S{\scriptsize IM}BIG}$, a forward modeling framework for galaxy clustering analyses that employs simulation-based inference to perform highly efficient cosmological inference using normalizing flows. It leverages the predictive power of high-fidelity simulations and robustly extracts cosmological information from regimes inaccessible with current standard analyses. In this work, we apply ${\rm S{\scriptsize IM}BIG}$ to a subset of the BOSS galaxy sample and analyze the redshift-space bispectrum monopole, $B_0(k_1, k_2, k_3)$, to $k_{\rm max}=0.5\,h/{\rm Mpc}$. We achieve 1$\sigma$ constraints of $\Omega_m=0.293^{+0.027}_{-0.027}$ and $\sigma_8= 0.783^{+0.040}_{-0.038}$, which are more than 1.2 and 2.4$\times$ tighter than constraints from standard power spectrum analyses of the same dataset. We also derive 1.4, 1.4, 1.7$\times$ tighter constraints on $\Omega_b$, $h$, $n_s$. This improvement comes from additional cosmological information in higher-order clustering on non-linear scales and, for $\sigma_8$, is equivalent to the gain expected from a standard analysis on a $\sim$4$\times$ larger galaxy sample. Even with our BOSS subsample, which only spans 10% of the full BOSS volume, we derive competitive constraints on the growth of structure: $S_8 = 0.774^{+0.056}_{-0.053}$. Our constraint is consistent with results from both cosmic microwave background and weak lensing. Combined with a $\omega_b$ prior from Big Bang Nucleosynthesis, we also derive a constraint on $H_0=67.6^{+2.2}_{-1.8}\,{\rm km\,s^{-1}\,Mpc^{-1}}$ that is consistent with early universe constraints.	astro-ph.CO	13 pages, 7 figures, submitted to PRD, comments welcome
2	Regulating star formation in a magnetized disk galaxy	Hector Robinson,James Wadsley	We use high-resolution MHD simulations of isolated disk galaxies to investigate the co-evolution of magnetic fields with a self-regulated, star-forming interstellar medium (ISM). The simulations are conducted using the Ramses AMR code on the standard Agora initial condition, with gas cooling, star formation and feedback. We run galaxies with a variety of initial magnetic field strengths. The fields grow rapidly and achieve approximate saturation within 500 Myr, but at different levels. The galaxies reach a quasi-steady state, with slowly declining star formation due to both gas consumption and increases in the field strength at intermediate ISM densities. We connect this behaviour to differences in the gas properties and overall structure of the galaxies. In particular, strong fields limit feedback bubbles. Different cases support the ISM using varying combinations of magnetic pressure, turbulence and thermal energy. Magnetic support is closely linked to stellar feedback in the case of initially weak fields but not for initially strong fields. The spatial distribution of these supports is also different in each case, and this is reflected in the stability of the gas disk. We relate this back to the overall distribution of star formation in each case. We conclude that a weak initial field can grow to produce a realistic model of a local disk galaxy, but starting with typical field strengths will not.	astro-ph.GA	12 pages, 11 figures. Submitted to MNRAS
3	Accessibility, planar graphs, and quasi-isometries	Joseph MacManus	We prove that a connected, locally finite, quasi-transitive graph which is quasi-isometric to a planar graph is necessarily accessible. This leads to a complete classification of the finitely generated groups which are quasi-isometric to planar graphs. In particular, such groups are virtually free products of free and surface groups.	math.GR	44 pages, 8 figures. Comments welcome
4	Predictions for Electromagnetic Counterparts to Neutron Star Mergers Discovered during LIGO-Virgo-KAGRA Observing Runs 4 and 5	Ved G. Shah,Gautham Narayan,Haille M. L. Perkins,Ryan J. Foley,Deep Chatterjee,Bryce Cousins,Phillip Macias	We present a comprehensive, configurable open-source framework for estimating the rate of electromagnetic detection of kilonovae (KNe) associated with gravitational wave detections of binary neutron star (BNS) mergers. We simulate the current LIGO-Virgo-KAGRA (LVK) observing run (O4) using up-to-date sensitivity and up-time values as well as the next observing run (O5) using predicted sensitivities. We find the number of discoverable kilonovae during LVK O4 to be ${ 1}_{- 1}^{+ 4}$ or ${ 2 }_{- 2 }^{+ 3 }$, (at 90% confidence) depending on the distribution of NS masses in coalescing binaries, with the number increasing by an order of magnitude during O5 to ${ 19 }_{- 11 }^{+ 24 }$. Regardless of mass model, we predict at most five detectable KNe (at 95% confidence) in O4. We also produce optical and near-infrared light curves that correspond to the physical properties of each merging system. We have collated important information for allocating observing resources and directing search and follow-up observations including distributions of peak magnitudes in several broad bands and timescales for which specific facilities can detect each KN. The framework is easily adaptable, and new simulations can quickly be produced as input information such as merger rates and NS mass distributions are refined. Finally, we compare our suite of simulations to the thus-far completed portion of O4 (as of October 14, 2023), finding a median number of discoverable KNe of 0 and a 95-percentile upper limit of 2, consistent with no detection so far in O4.	astro-ph.HE	16 pages, 13 figures, submitted to MNRAS
5	CRoW: Benchmarking Commonsense Reasoning in Real-World Tasks	Mete Ismayilzada,Debjit Paul,Syrielle Montariol,Mor Geva,Antoine Bosselut	Recent efforts in natural language processing (NLP) commonsense reasoning research have yielded a considerable number of new datasets and benchmarks. However, most of these datasets formulate commonsense reasoning challenges in artificial scenarios that are not reflective of the tasks which real-world NLP systems are designed to solve. In this work, we present CRoW, a manually-curated, multi-task benchmark that evaluates the ability of models to apply commonsense reasoning in the context of six real-world NLP tasks. CRoW is constructed using a multi-stage data collection pipeline that rewrites examples from existing datasets using commonsense-violating perturbations. We use CRoW to study how NLP systems perform across different dimensions of commonsense knowledge, such as physical, temporal, and social reasoning. We find a significant performance gap when NLP systems are evaluated on CRoW compared to humans, showcasing that commonsense reasoning is far from being solved in real-world task settings. We make our dataset and leaderboard available to the research community at https://github.com/mismayil/crow.	cs.CL	37 pages, camera-ready for EMNLP 2023
6	Hyperbolic Conduction: A Fast, Physical Conduction Model Implemented in Smoothed Particle Hydrodynamics	N. A. Owens,J. Wadsley	We present the first implementation of hyperbolic thermal conduction in smoothed particle hydrodynamics (SPH). Hyperbolic conduction is a physically-motivated alternative to traditional, parabolic conduction. It incorporates a relaxation time, which ensures that heat propagates no faster than a physical signal speed. This allows for larger, Courant like, time steps for explicit schemes. Numerical solutions of the hyperbolic conduction equations require added dissipation to remain stable at discontinuities and we present a novel scheme for this. Test cases include a simple step, the Sod shock tube, the Sedov-Taylor blast, and a super bubble. We demonstrate how longer relaxation times limit conduction, recovering the purely hydrodynamical results, while short relaxation times converge on the parabolic conduction result. We demonstrate that our scheme is stable with explicit Courant-like time steps and can be orders of magnitude faster than explicit parabolic conduction, depending on the application.	astro-ph.IM	None
7	Gromov-Witten-Hilbert versus AdS3-CFT2 Correspondence	Wolfgang Lerche	"We consider the boundary dual of AdS3xS3xK3 for NS5-flux Q5=1, which is described by a sigma model with target space given by the d-fold symmetric product of K3. Building on results in algebraic geometry, we address the problem of deforming it away from the orbifold point from the viewpoint of topological strings. We propose how the 't Hooft expansion can be geometrized in terms of Gromow-Witten invariants and, in favorable settings, how it can be summed up to all orders in closed form. We consider an explicit example in detail for which we discuss the genus expansion around the orbifold point, as well as the divergence in the strong coupling regime. We find that within the domain of convergence, scale separation does not occur. However, in order for the mathematical framework to be applicable in the first place, we need to consider ""reduced"" Gromow-Witten invariants that fit, as we argue, naturally to topologically twisted N=4 strings. There are some caveats and thus to what extent this toy model captures the physics of strings on AdS3xS3xK3 remains to be seen."	hep-th	39 pages, 4 figures
8	Black hole bulk-cone singularities	Matthew Dodelson,Cristoforo Iossa,Robin Karlsson,Alexandru Lupsasca,Alexander Zhiboedov	"Lorentzian correlators of local operators exhibit surprising singularities in theories with gravity duals. These are associated with null geodesics in an emergent bulk geometry. We analyze singularities of the thermal response function dual to propagation of waves on the AdS Schwarzschild black hole background. We derive the analytic form of the leading singularity dual to a bulk geodesic that winds around the black hole. Remarkably, it exhibits a boundary group velocity larger than the speed of light, whose dual is the angular velocity of null geodesics at the photon sphere. The strength of this singularity is controlled by the classical Lyapunov exponent associated with the instability of nearly bound photon orbits. In this sense, the bulk-cone singularity can be identified as the universal feature that encodes the ubiquitous black hole photon sphere in a dual holographic CFT. To perform the computation analytically, we express the two-point correlator as an infinite sum over Regge poles, and then evaluate this sum using WKB methods. We also compute the smeared correlator numerically, which in particular allows us to check and support our analytic predictions. We comment on the resolution of black hole bulk-cone singularities by stringy and gravitational effects into black hole bulk-cone ""bumps"". We conclude that these bumps are robust, and could serve as a target for simulations of black hole-like geometries in table-top experiments."	hep-th	63 pages, 17 figures
9	Field-level simulation-based inference with galaxy catalogs: the impact of systematic effects	Natal√≠ S. M. de Santi,Francisco Villaescusa-Navarro,L. Raul Abramo,Helen Shao,Lucia A. Perez,Tiago Castro,Yueying Ni,Christopher C. Lovell,Elena Hernandez-Martinez,Federico Marinacci,David N. Spergel,Klaus Dolag,Lars Hernquist,Mark Vogelsberger	It has been recently shown that a powerful way to constrain cosmological parameters from galaxy redshift surveys is to train graph neural networks to perform field-level likelihood-free inference without imposing cuts on scale. In particular, de Santi et al. (2023) developed models that could accurately infer the value of $\Omega_{\rm m}$ from catalogs that only contain the positions and radial velocities of galaxies that are robust to uncertainties in astrophysics and subgrid models. However, observations are affected by many effects, including 1) masking, 2) uncertainties in peculiar velocities and radial distances, and 3) different galaxy selections. Moreover, observations only allow us to measure redshift, intertwining galaxies' radial positions and velocities. In this paper we train and test our models on galaxy catalogs, created from thousands of state-of-the-art hydrodynamic simulations run with different codes from the CAMELS project, that incorporate these observational effects. We find that, although the presence of these effects degrades the precision and accuracy of the models, and increases the fraction of catalogs where the model breaks down, the fraction of galaxy catalogs where the model performs well is over 90 %, demonstrating the potential of these models to constrain cosmological parameters even when applied to real data.	astro-ph.CO	29 pages, 11 figures. For the reference in the abstract (de Santi et   al. 2023) see arXiv:2302.14101
0	TREVR2: Illuminating fast $N\log_2\,N$ radiative transfer	James W. Wadsley,Bernhard Baumschlager,Sijing Shen	We present TREVR2 (Tree-based REVerse Ray Tracing 2), a fast, general algorithm for computing the radiation field, suitable for both particle and mesh codes. It is designed to self-consistently evolve chemistry for zoomed-in astrophysical simulations, such as cosmological galaxies with both internal sources and prescribed background radiation, rather than large periodic volumes. Light is propagated until absorbed, with no imposed speed limit other than those due to opacity changes (e.g. ionization fronts). TREVR2 searches outward from receiving gas in discrete directions set by the HEALPIX algorithm (unlike its slower predecessor TREVR), accumulating optical depth and adding the flux due to sources combined into progressively larger tree cells with distance. We demonstrate $N_\textrm{active}\log_2 N$ execution time with absorption and many sources. This allows multi-band RT costs comparable to tree-based gravity and hydrodynamics, and the usual speed-up when active particles evolve on individual timesteps. Sources embedded in non-homogeneous absorbing material introduce systematic errors. We introduce transmission averaging instead of absorption averaging which dramatically reduces these systematic effects. We outline other ways to address systematics including an explicit complex source model. We demonstrate the overall performance of the method via a set of astrophysical test problems.	astro-ph.IM	Submitted to MNRAS
1	Direct detection and characterization of exoplanets using imaging Fourier transform spectroscopy	Jingwen Zhang,Michael Bottom,Eugene Serabyn	Space-based direct imaging provides prospects for detection and spectral characterization of exoplanets at optical and near-infrared wavelengths. Integral field spectrographs (IFS) have been historically baselined for these mission concepts. However, multiple studies have revealed that detector noise is a serious obstacle for such instruments when observing extremely faint targets such as Earth-like planets. Imaging Fourier transform spectrographs (iFTS) are generally less sensitive to detector noise, and have several other compelling features such as simultaneous imaging and spectroscopy, smaller-format detector requirements, and variable spectral resolution. To date, they have not been studied as options for such missions.   In this work, we compare the capabilities of integral field spectrographs and imaging Fourier transform spectrographs to directly obtain spectra from an Earth-like planet using analytic and numerical models. Specifically, we compare the required exposure time to achieve the same signal-to-noise ratio of the two architectures over a range of detector and optical system parameters. We find that for a 6-meter telescope, an IFS outperforms an iFTS at optical wavelengths. In the near-IR, the relative efficiency of an IFS and iFTS depends on the instrument design and detector noise. An iFTS will be more efficient than an IFS if the readout noise of near-IR detector is above 2-3 e-/pix/frame (t_frame=1000s), which correspond to half to one-third of detector noise of the state-of-art. However, if the readout noise is further reduced to below this threshold, the performance of an IFS will experience a substantial improvement and become more efficient. These results motivate consideration of an iFTS as an alternative option for future direct imaging space missions in the near-IR.	astro-ph.EP	26 pages, 13 pages, submitted to PASP
2	Galaxies Going Bananas: Inferring the 3D Geometry of High-Redshift Galaxies with JWST-CEERS	Viraj Pandya,Haowen Zhang,Marc Huertas-Company,Kartheik G. Iyer,Elizabeth McGrath,Guillermo Barro,Steven L. Finkelstein,Martin Kuemmel,William G. Hartley,Henry C. Ferguson,Jeyhan S. Kartaltepe,Joel Primack,Avishai Dekel,Sandra M. Faber,David C. Koo,Greg L. Bryan,Rachel S. Somerville,Ricardo O. Amorin,Pablo Arrabal Haro,Micaela B. Bagley,Eric F. Bell,Emmanuel Bertin,Luca Costantin,Romeel Dave,Mark Dickinson,Robert Feldmann,Adriano Fontana,Raphael Gavazzi,Mauro Giavalisco,Andrea Grazian,Norman A. Grogin,Yuchen Guo,ChangHoon Hahn,Benne W. Holwerda,Lisa J. Kewley,Allison Kirkpatrick,Anton M. Koekemoer,Jennifer M. Lotz,Ray A. Lucas,Laura Pentericci,Pablo G. Perez-Gonzalez,Nor Pirzkal,Dale D. Kocevski,Casey Papovich,Swara Ravindranath,Caitlin Rose,Marc Schefer,Raymond C. Simons,Amber N. Straughn,Sandro Tacchella,Jonathan R. Trump,Alexander de la Vega,Stephen M. Wilkins,Stijn Wuyts,Guang Yang,L. Y. Aaron Yung	The 3D geometry of high-redshift galaxies remains poorly understood. We build a differentiable Bayesian model and use Hamiltonian Monte Carlo to efficiently and robustly infer the 3D shapes of star-forming galaxies in JWST-CEERS observations with $\log M_*/M_{\odot}=9.0-10.5$ at $z=0.5-8.0$. We reproduce previous results from HST-CANDELS in a fraction of the computing time and constrain the mean ellipticity, triaxiality, size and covariances with samples as small as $\sim50$ galaxies. We find high 3D ellipticities for all mass-redshift bins suggesting oblate (disky) or prolate (elongated) geometries. We break that degeneracy by constraining the mean triaxiality to be $\sim1$ for $\log M_*/M_{\odot}=9.0-9.5$ dwarfs at $z>1$ (favoring the prolate scenario), with significantly lower triaxialities for higher masses and lower redshifts indicating the emergence of disks. The prolate population traces out a ``banana'' in the projected $b/a-\log a$ diagram with an excess of low $b/a$, large $\log a$ galaxies. The dwarf prolate fraction rises from $\sim25\%$ at $z=0.5-1.0$ to $\sim50-80\%$ at $z=3-8$. If these are disks, they cannot be axisymmetric but instead must be unusually oval (triaxial) unlike local circular disks. We simultaneously constrain the 3D size-mass relation and its dependence on 3D geometry. High-probability prolate and oblate candidates show remarkably similar S\'ersic indices ($n\sim1$), non-parametric morphological properties and specific star formation rates. Both tend to be visually classified as disks or irregular but edge-on oblate candidates show more dust attenuation. We discuss selection effects, follow-up prospects and theoretical implications.	astro-ph.GA	Submitted to ApJ, main body is 35 pages of which ~half are full-page   figures, comments welcome
3	A new approach to template banks of gravitational waves with higher harmonics: reducing matched-filtering cost by over an order of magnitude	Digvijay Wadekar,Tejaswi Venumadhav,Ajit Kumar Mehta,Javier Roulet,Seth Olsen,Jonathan Mushkin,Barak Zackay,Matias Zaldarriaga	Searches for gravitational wave events use models, or templates, for the signals of interest. The templates used in current searches in the LIGO-Virgo-Kagra (LVK) data model the dominant quadrupole mode $(\ell,m)=(2,2)$ of the signals, and omit sub-dominant higher-order modes (HM) such as $(\ell,m)=(3,3)$, $(4,4)$, which are predicted by general relativity. Hence, these searches could lose sensitivity to black hole mergers in interesting parts of parameter space, such as systems with high-masses and asymmetric mass ratios. We develop a new strategy to include HM in template banks that exploits the natural connection between the modes. We use a combination of post-Newtonian formulae and machine learning tools to model aligned-spin $(3,3)$, $(4,4)$ waveforms corresponding to a given $(2,2)$ waveform. Each of these modes can be individually filtered against the data to yield separate timeseries of signal-to-noise ratios (SNR), which can be combined in a relatively inexpensive way to marginalize over extrinsic parameters of the signals. This leads to a HM search pipeline whose matched-filtering cost is just $\approx 3\times$ that of a quadrupole-only search (in contrast to being $\approx\! 100 \times$, as in previously proposed HM search methods). Our method is effectual and is generally applicable for template banks constructed with either stochastic or geometric placement techniques. Additionally, we discuss compression of $(2,2)$-only geometric-placement template banks using machine learning algorithms.	gr-qc	12+2 pages, 7+1 figures. The template bank described here will be   publicly available at   https://github.com/JayWadekar/GW_higher_harmonics_search
4	Machine Learning Classification of Sphalerons and Black Holes at the LHC	Aurora Singstad Grefsrud,Trygve Buanes,Fotis Koutroulis,Anna Lipniacka,Rafa≈Ç Mase≈Çek,Andreas Papaefstathiou,Kazuki Sakurai,Therese B. Sjursen,Igor Slazyk	"In models with large extra dimensions, ""miniature"" black holes (BHs) might be produced in high-energy proton-proton collisions at the Large Hadron Collider (LHC). In the semi-classical regime, those BHs thermally decay, giving rise to large-multiplicity final states with jets and leptons. On the other hand, similar final states are also expected in the production of electroweak sphaleron/instanton-induced processes. We investigate whether one can discriminate these scenarios when BH or sphaleron-like events are observed in the LHC using Machine Learning (ML) methods. Classification among several BH scenarios with different numbers of extra dimensions and the minimal BH masses is also examined. In this study we consider three ML models: XGBoost algorithms with (1) high- and (2) low-level inputs, and (3) a Residual Convolutional Neural Network. In the latter case, the low-level detector information is converted into an input format of three-layer binned event images, where the value of each bin corresponds to the energy deposited in various detector subsystems. We demonstrate that only a few detected events are sufficient to effectively discriminate between the sphaleron and BH processes. Separation among BH scenarios with different minimal BH masses is also possible with a reasonable number of events, that can be collected in the LHC Run-2, -3 and the high-luminosity LHC (HL-LHC). We find, however, that a large number of events is needed to discriminate between BH hypotheses with the same minimal BH mass, but different numbers of extra dimensions."	hep-ph	18 pages, 5 figures
5	Anomalous long-distance RKKY interaction in quasicrystals	Junmo Jeon,SungBin Lee	The Ruderman-Kittel-Kasuya-Yoshida (RKKY) interaction is a key mechanism to understand the coupling between localized magnetic moments in the presence of itinerant electrons. Such indirect exchange coupling generally shows the typical oscillation with 2$k_F$ where $k_F$ is the Fermi momentum and the power law decaying as a function of the distance. In this paper, we argue this paradigm is not valid anymore in quasicrystals and discuss anomalous behavior of the RKKY interaction in quasicrystals. Rather than the uniform decaying, the RKKY interaction becomes significant between the moments in non-local region. In other words, it realizes a strong coupling between the moments which are far separated, where their distance can be controlled via quasi-periodicity of the systems. It turns out that such anomalous RKKY interaction is originated from the critical states of itinerant electrons, which are neither localized nor extended wave functions and mediate the RKKY interactions on behalf of the extended itinerant electrons. Moreover, the RKKY interaction also shows the fractal structure from the self-similarity of the critical wave functions. Finally, we also discuss a possible non-local manipulation of the magnetic moments due to such anomalous RKKY coupling in quasicrystals.	cond-mat.str-el	11 pages, 7 figures
6	Tunable room temperature nonlinear Hall effect from the surfaces of elementary bismuth thin films	Pavlo Makushko,Sergey Kovalev,Yevhen Zabila,Igor Ilyakov,Alexey Ponomaryov,Atiqa Arshad,Gulloo Lal Prajapati,Thales V. A. G. de Oliveira,Jan-Christoph Deinert,Paul Chekhonin,Igor Veremchuk,Tobias Kosub,Yurii Skourski,Fabian Ganss,Denys Makarov,Carmine Ortix	The nonlinear Hall effect (NLHE) with time-reversal symmetry constitutes the appearance of a transverse voltage quadratic in the applied electric field. It is a second-order electronic transport phenomenon that induces frequency doubling and occurs in non-centrosymmetric crystals with large Berry curvature -- an emergent magnetic field encoding the geometric properties of electronic wavefunctions. The design of (opto)electronic devices based on the NLHE is however hindered by the fact that this nonlinear effect typically appears at low temperatures and in complex compounds characterized by Dirac or Weyl electrons. Here, we show a strong room temperature NLHE in the centrosymmetric elemental material bismuth synthesized in the form of technologically relevant polycrystalline thin films. The ($1\,1\,1$) surface electrons of this material are equipped with a Berry curvature triple that activates side jumps and skew scatterings generating nonlinear transverse currents. We also report a boost of the zero field nonlinear transverse voltage in arc-shaped bismuth stripes due to an extrinsic geometric classical counterpart of the NLHE. This electrical frequency doubling in curved geometries is then extended to optical second harmonic generation in the terahertz (THz) spectral range. The strong nonlinear electrodynamical responses of the surface states are further demonstrated by a concomitant highly efficient THz third harmonic generation which we achieve in a broad range of frequencies in Bi and Bi-based heterostructures. Combined with the possibility of growth on CMOS-compatible and mechanically flexible substrates, these results highlight the potential of Bi thin films for THz (opto)electronic applications.	cond-mat.mes-hall	44 pages, 21 figures
7	Fast Forward Modelling of Galaxy Spatial and Statistical Distributions	Pascale Berner,Alexandre Refregier,Beatrice Moser,Luca Tortorelli,Luis Fernando Machado Poletti Valle,Tomasz Kacprzak	A forward modelling approach provides simple, fast and realistic simulations of galaxy surveys, without a complex underlying model. For this purpose, galaxy clustering needs to be simulated accurately, both for the usage of clustering as its own probe and to control systematics. We present a forward model to simulate galaxy surveys, where we extend the Ultra-Fast Image Generator to include galaxy clustering. We use the distribution functions of the galaxy properties, derived from a forward model adjusted to observations. This population model jointly describes the luminosity functions, sizes, ellipticities, SEDs and apparent magnitudes. To simulate the positions of galaxies, we then use a two-parameter relation between galaxies and halos with Subhalo Abundance Matching (SHAM). We simulate the halos and subhalos using the fast PINOCCHIO code, and a method to extract the surviving subhalos from the merger history. Our simulations contain a red and a blue galaxy population, for which we build a SHAM model based on star formation quenching. For central galaxies, mass quenching is controlled with the parameter M$_{\mathrm{limit}}$, with blue galaxies residing in smaller halos. For satellite galaxies, environmental quenching is implemented with the parameter t$_{\mathrm{quench}}$, where blue galaxies occupy only recently merged subhalos. We build and test our model by comparing to imaging data from the Dark Energy Survey Year 1. To ensure completeness in our simulations, we consider the brightest galaxies with $i<20$. We find statistical agreement between our simulations and the data for two-point correlation functions on medium to large scales. Our model provides constraints on the two SHAM parameters M$_{\mathrm{limit}}$ and t$_{\mathrm{quench}}$ and offers great prospects for the quick generation of galaxy mock catalogues, optimized to agree with observations.	astro-ph.GA	Prepared for submission to JCAP. 28 pages, 15 figures
8	Emergent particles of de Sitter universe: thermal interpretation of the stochastic formalism and beyond	TaeHun Kim	A thermal interpretation of the stochastic formalism of a slow-rolling scalar field in a de Sitter (dS) universe is given. By introducing a notion of emergent particles and a dual description of scalar fields, we show that the stochastic evolution of the infrared part of the field is equivalent to the Brownian motion in an abstract space filled with a heat bath of massless particles. The 1st slow-roll condition and the Hubble expansion are also reinterpreted in the abstract space as the speed of light and a transfer of conserved energy, respectively. Inspired by this, we sketch the quantum emergent particles, which may realize the Hubble expansion by an exponential particle production. This gives another meaning of dS entropy as entropy per Hubble volume in the global dS universe.	gr-qc	15 pages, 3 figures
9	Spin pumping in an altermagnet-normal metal bilayer	Erik Wegner Hodt,Jacob Linder	Altermagnetism is a subclass of antiferromagnetism that features spin-polarized electron bands of a non-relativistic origin despite the absence of a net magnetiation in the material. We here theoretically study spin pumping from an altermagnetic insulator into a normal metal. The symmetry properties of the lattice and spin order of the altermagnet alters the magnon dispersion compared to a conventional square lattice antiferromagnet. Nevertheless, the pumped spin current turns out to be equal to the current which is pumped from a conventional antiferromagnet. This occurs so long that the magnetic field which sets the altermagnetic spins into precessional motion is spatially homogeneous. These results show that while spin pumping is possible using altermagnets, the altermagnetic spin order does not readily leave unique fingerprints in the pumped spin current. Our model provides a suitable starting point for investigating more complex models where finite momentum magnons contribute to spin pumping due to magnon-magnon interactions or where the magnetic field inducing spin pumping is spatially inhomogeneous.	cond-mat.mes-hall	12 pages, 2 figures
0	The most stringent upper limit from dynamical models on the mass of a central black hole in 47 Tucanae	Alessandro Della Croce,Raffaele Pascale,Eric Giunchi,Carlo Nipoti,Michele Cignoni,Emanuele Dalessandro	Globular clusters (GCs) were proposed as promising sites for discovering intermediate-mass black holes (IMBHs), possibly providing crucial insights into the formation and evolution of these elusive objects. The Galactic GC 47 Tucanae (also known as NGC 104) has been suggested as a potential IMBH host, but, previous studies have yielded conflicting results. We, therefore, present self-consistent dynamical models based on distribution functions (DFs) that depend on action integrals to assess the presence (or absence) of an IMBH in 47 Tucanae. Leveraging state-of-the-art Multi Unit Spectroscopic Explorer and Hubble Space Telescope data, we analyzed the three-dimensional (3D) kinematics of the cluster's central regions, fitting individual star velocities down to the sub-arcsec scale (approximately $10^{-2}$ pc). According to our analysis, the inner kinematics of 47 Tucanae is incompatible with a central BH more massive than 578 M$_\odot$ (at $3\sigma$). This is the most stringent upper limit on the mass of a putative IMBH in 47 Tucanae that has been put by any dynamical study.	astro-ph.GA	10 pages, 6 figures, accepted for publication in Astronomy and   Astrophysics (A&A)
1	RoboDepth: Robust Out-of-Distribution Depth Estimation under Corruptions	Lingdong Kong,Shaoyuan Xie,Hanjiang Hu,Lai Xing Ng,Benoit R. Cottereau,Wei Tsang Ooi	Depth estimation from monocular images is pivotal for real-world visual perception systems. While current learning-based depth estimation models train and test on meticulously curated data, they often overlook out-of-distribution (OoD) situations. Yet, in practical settings -- especially safety-critical ones like autonomous driving -- common corruptions can arise. Addressing this oversight, we introduce a comprehensive robustness test suite, RoboDepth, encompassing 18 corruptions spanning three categories: i) weather and lighting conditions; ii) sensor failures and movement; and iii) data processing anomalies. We subsequently benchmark 42 depth estimation models across indoor and outdoor scenes to assess their resilience to these corruptions. Our findings underscore that, in the absence of a dedicated robustness evaluation framework, many leading depth estimation models may be susceptible to typical corruptions. We delve into design considerations for crafting more robust depth estimation models, touching upon pre-training, augmentation, modality, model capacity, and learning paradigms. We anticipate our benchmark will establish a foundational platform for advancing robust OoD depth estimation.	cs.CV	NeurIPS 2023; 45 pages, 25 figures, 13 tables; Code at   https://github.com/ldkong1205/RoboDepth
2	FreeNoise: Tuning-Free Longer Video Diffusion Via Noise Rescheduling	Haonan Qiu,Menghan Xia,Yong Zhang,Yingqing He,Xintao Wang,Ying Shan,Ziwei Liu	With the availability of large-scale video datasets and the advances of diffusion models, text-driven video generation has achieved substantial progress. However, existing video generation models are typically trained on a limited number of frames, resulting in the inability to generate high-fidelity long videos during inference. Furthermore, these models only support single-text conditions, whereas real-life scenarios often require multi-text conditions as the video content changes over time. To tackle these challenges, this study explores the potential of extending the text-driven capability to generate longer videos conditioned on multiple texts. 1) We first analyze the impact of initial noise in video diffusion models. Then building upon the observation of noise, we propose FreeNoise, a tuning-free and time-efficient paradigm to enhance the generative capabilities of pretrained video diffusion models while preserving content consistency. Specifically, instead of initializing noises for all frames, we reschedule a sequence of noises for long-range correlation and perform temporal attention over them by window-based function. 2) Additionally, we design a novel motion injection method to support the generation of videos conditioned on multiple text prompts. Extensive experiments validate the superiority of our paradigm in extending the generative capabilities of video diffusion models. It is noteworthy that compared with the previous best-performing method which brought about 255% extra time cost, our method incurs only negligible time cost of approximately 17%. Generated video samples are available at our website: http://haonanqiu.com/projects/FreeNoise.html.	cs.CV	Project Page: http://haonanqiu.com/projects/FreeNoise.html Code Repo:   https://github.com/arthur-qiu/LongerCrafter
3	Oxygen abundance of gamma Vel from [O III] 88um Herschel-PACS spectroscopy	Paul A Crowther,M J Barlow,P Royer,D J Hillier,J M Bestenlehner,P W Morris,R Wesson	We present Herschel PACS spectroscopy of the [O III] 88.4um fine-structure line in the nearby WC8+O binary system gamma Vel to determine its oxygen abundance. The critical density of this line corresponds to several 10^5 R* such that it is spatially extended in PACS observations at the 336 pc distance to gamma Vel. Two approaches are used, the first involving a detailed stellar atmosphere analysis of gamma Vel using CMFGEN, extending to Ne ~ 10^0 cm^-3 in order to fully sample the line formation region of [O III] 88.4um. The second approach involves the analytical model introduced by Barlow et al. and revised by Dessart et al, additionally exploiting ISO LWS spectroscopy of [O III] 51.8um. We obtain higher luminosities for the WR and O components of gamma Vel with respect to De Marco et al, log L/L_sun = 5.31 and 5.56, respectively, primarily as a result of the revised (higher) interferometric distance. We obtain an oxygen mass fraction of X_O = 1.0+/- 0.3% for an outer wind volume filling factor of f = 0.5+/-0.25, favouring either standard or slightly reduced Kunz et al. rates for the ^12C(alpha, gamma)^16O reaction from comparison with BPASS binary population synthesis models. We also revisit sulphur and neon abundances in the outer wind of gamma Vel from ISO SWS spectroscopy of [S IV] 10.5um and [Ne III] 15.5um. The sulphur abundance of X_S = 0.04 +/- 0.01% agrees with the solar abundance, as expected for unprocessed elements, with the inferred neon abundance X_Ne = 1.5-0.5+0.3%, in good agreement with BPASS predictions.	astro-ph.SR	13 pages, 10 figures, plus Appendices, submitted to MNRAS
4	Ghost on the Shell: An Expressive Representation of General 3D Shapes	Zhen Liu,Yao Feng,Yuliang Xiu,Weiyang Liu,Liam Paull,Michael J. Black,Bernhard Sch√∂lkopf	The creation of photorealistic virtual worlds requires the accurate modeling of 3D surface geometry for a wide range of objects. For this, meshes are appealing since they 1) enable fast physics-based rendering with realistic material and lighting, 2) support physical simulation, and 3) are memory-efficient for modern graphics pipelines. Recent work on reconstructing and statistically modeling 3D shape, however, has critiqued meshes as being topologically inflexible. To capture a wide range of object shapes, any 3D representation must be able to model solid, watertight, shapes as well as thin, open, surfaces. Recent work has focused on the former, and methods for reconstructing open surfaces do not support fast reconstruction with material and lighting or unconditional generative modelling. Inspired by the observation that open surfaces can be seen as islands floating on watertight surfaces, we parameterize open surfaces by defining a manifold signed distance field on watertight templates. With this parameterization, we further develop a grid-based and differentiable representation that parameterizes both watertight and non-watertight meshes of arbitrary topology. Our new representation, called Ghost-on-the-Shell (G-Shell), enables two important applications: differentiable rasterization-based reconstruction from multiview images and generative modelling of non-watertight meshes. We empirically demonstrate that G-Shell achieves state-of-the-art performance on non-watertight mesh reconstruction and generation tasks, while also performing effectively for watertight meshes.	cs.CV	Technical Report (26 pages, 16 figures, Project Page:   https://gshell3d.github.io/)
5	Large Language Models are Visual Reasoning Coordinators	Liangyu Chen,Bo Li,Sheng Shen,Jingkang Yang,Chunyuan Li,Kurt Keutzer,Trevor Darrell,Ziwei Liu	Visual reasoning requires multimodal perception and commonsense cognition of the world. Recently, multiple vision-language models (VLMs) have been proposed with excellent commonsense reasoning ability in various domains. However, how to harness the collective power of these complementary VLMs is rarely explored. Existing methods like ensemble still struggle to aggregate these models with the desired higher-order communications. In this work, we propose Cola, a novel paradigm that coordinates multiple VLMs for visual reasoning. Our key insight is that a large language model (LLM) can efficiently coordinate multiple VLMs by facilitating natural language communication that leverages their distinct and complementary capabilities. Extensive experiments demonstrate that our instruction tuning variant, Cola-FT, achieves state-of-the-art performance on visual question answering (VQA), outside knowledge VQA, visual entailment, and visual spatial reasoning tasks. Moreover, we show that our in-context learning variant, Cola-Zero, exhibits competitive performance in zero and few-shot settings, without finetuning. Through systematic ablation studies and visualizations, we validate that a coordinator LLM indeed comprehends the instruction prompts as well as the separate functionalities of VLMs; it then coordinates them to enable impressive visual reasoning capabilities.	cs.CV	Accepted at NeurIPS 2023
6	Handling Data Heterogeneity via Architectural Design for Federated Visual Recognition	Sara Pieri,Jose Renato Restom,Samuel Horvath,Hisham Cholakkal	Federated Learning (FL) is a promising research paradigm that enables the collaborative training of machine learning models among various parties without the need for sensitive information exchange. Nonetheless, retaining data in individual clients introduces fundamental challenges to achieving performance on par with centrally trained models. Our study provides an extensive review of federated learning applied to visual recognition. It underscores the critical role of thoughtful architectural design choices in achieving optimal performance, a factor often neglected in the FL literature. Many existing FL solutions are tested on shallow or simple networks, which may not accurately reflect real-world applications. This practice restricts the transferability of research findings to large-scale visual recognition models. Through an in-depth analysis of diverse cutting-edge architectures such as convolutional neural networks, transformers, and MLP-mixers, we experimentally demonstrate that architectural choices can substantially enhance FL systems' performance, particularly when handling heterogeneous data. We study 19 visual recognition models from five different architectural families on four challenging FL datasets. We also re-investigate the inferior performance of convolution-based architectures in the FL setting and analyze the influence of normalization layers on the FL performance. Our findings emphasize the importance of architectural design for computer vision tasks in practical scenarios, effectively narrowing the performance gap between federated and centralized learning. Our source code is available at https://github.com/sarapieri/fed_het.git.	cs.CV	to be published in NeurIPS 2023
7	LINC: A Neurosymbolic Approach for Logical Reasoning by Combining Language Models with First-Order Logic Provers	Theo X. Olausson,Alex Gu,Benjamin Lipkin,Cedegao E. Zhang,Armando Solar-Lezama,Joshua B. Tenenbaum,Roger Levy	Logical reasoning, i.e., deductively inferring the truth value of a conclusion from a set of premises, is an important task for artificial intelligence with wide potential impacts on science, mathematics, and society. While many prompting-based strategies have been proposed to enable Large Language Models (LLMs) to do such reasoning more effectively, they still appear unsatisfactory, often failing in subtle and unpredictable ways. In this work, we investigate the validity of instead reformulating such tasks as modular neurosymbolic programming, which we call LINC: Logical Inference via Neurosymbolic Computation. In LINC, the LLM acts as a semantic parser, translating premises and conclusions from natural language to expressions in first-order logic. These expressions are then offloaded to an external theorem prover, which symbolically performs deductive inference. Leveraging this approach, we observe significant performance gains on FOLIO and a balanced subset of ProofWriter for three different models in nearly all experimental conditions we evaluate. On ProofWriter, augmenting the comparatively small open-source StarCoder+ (15.5B parameters) with LINC even outperforms GPT-3.5 and GPT-4 with Chain-of-Thought (CoT) prompting by an absolute 38% and 10%, respectively. When used with GPT-4, LINC scores 26% higher than CoT on ProofWriter while performing comparatively on FOLIO. Further analysis reveals that although both methods on average succeed roughly equally often on this dataset, they exhibit distinct and complementary failure modes. We thus provide promising evidence for how logical reasoning over natural language can be tackled through jointly leveraging LLMs alongside symbolic provers. All corresponding code is publicly available at https://github.com/benlipkin/linc	cs.CL	None
8	SAM-Med3D	Haoyu Wang,Sizheng Guo,Jin Ye,Zhongying Deng,Junlong Cheng,Tianbin Li,Jianpin Chen,Yanzhou Su,Ziyan Huang,Yiqing Shen,Bin Fu,Shaoting Zhang,Junjun He,Yu Qiao	Although the Segment Anything Model (SAM) has demonstrated impressive performance in 2D natural image segmentation, its application to 3D volumetric medical images reveals significant shortcomings, namely suboptimal performance and unstable prediction, necessitating an excessive number of prompt points to attain the desired outcomes. These issues can hardly be addressed by fine-tuning SAM on medical data because the original 2D structure of SAM neglects 3D spatial information. In this paper, we introduce SAM-Med3D, the most comprehensive study to modify SAM for 3D medical images. Our approach is characterized by its comprehensiveness in two primary aspects: firstly, by comprehensively reformulating SAM to a thorough 3D architecture trained on a comprehensively processed large-scale volumetric medical dataset; and secondly, by providing a comprehensive evaluation of its performance. Specifically, we train SAM-Med3D with over 131K 3D masks and 247 categories. Our SAM-Med3D excels at capturing 3D spatial information, exhibiting competitive performance with significantly fewer prompt points than the top-performing fine-tuned SAM in the medical domain. We then evaluate its capabilities across 15 datasets and analyze it from multiple perspectives, including anatomical structures, modalities, targets, and generalization abilities. Our approach, compared with SAM, showcases pronouncedly enhanced efficiency and broad segmentation capabilities for 3D volumetric medical images. Our code is released at https://github.com/uni-medical/SAM-Med3D.	cs.CV	None
9	FreeMask: Synthetic Images with Dense Annotations Make Stronger Segmentation Models	Lihe Yang,Xiaogang Xu,Bingyi Kang,Yinghuan Shi,Hengshuang Zhao	Semantic segmentation has witnessed tremendous progress due to the proposal of various advanced network architectures. However, they are extremely hungry for delicate annotations to train, and the acquisition is laborious and unaffordable. Therefore, we present FreeMask in this work, which resorts to synthetic images from generative models to ease the burden of both data collection and annotation procedures. Concretely, we first synthesize abundant training images conditioned on the semantic masks provided by realistic datasets. This yields extra well-aligned image-mask training pairs for semantic segmentation models. We surprisingly observe that, solely trained with synthetic images, we already achieve comparable performance with real ones (e.g., 48.3 vs. 48.5 mIoU on ADE20K, and 49.3 vs. 50.5 on COCO-Stuff). Then, we investigate the role of synthetic images by joint training with real images, or pre-training for real images. Meantime, we design a robust filtering principle to suppress incorrectly synthesized regions. In addition, we propose to inequally treat different semantic masks to prioritize those harder ones and sample more corresponding synthetic images for them. As a result, either jointly trained or pre-trained with our filtered and re-sampled synthesized images, segmentation models can be greatly enhanced, e.g., from 48.7 to 52.0 on ADE20K. Code is available at https://github.com/LiheYoung/FreeMask.	cs.CV	Accepted by NeurIPS 2023
0	Probing Transverse Momentum Dependent Structures with Azimuthal Dependence of Energy Correlators	Zhong-Bo Kang,Kyle Lee,Ding Yu Shao,Fanyi Zhao	We study the azimuthal angle dependence of the energy-energy correlators $\langle \mathcal{E}(\hat{n}_1)\mathcal{E}(\hat{n}_2)\rangle$ in the back-to-back region for $e^+e^-$ annihilation and deep inelastic scattering (DIS) processes with general polarization of the proton beam. We demonstrate that the polarization information of the beam and the underlying partons from the hard scattering is propagated into the azimuthal angle dependence of the energy-energy correlators. In the process, we define the Collins-type EEC jet functions and introduce a new EEC observable using the lab-frame angles in the DIS process. Furthermore, we extend our formalism to explore the two-point energy correlation between hadrons with different quantum numbers $\mathbb{S}_i$ in the back-to-back limit $\langle \mathcal{E}_{\mathbb{S}_1}(\hat{n}_1)\mathcal{E}_{\mathbb{S}_2}(\hat{n}_2)\rangle$. We find that in the Operator Product Expansion (OPE) region the nonperturbative information is entirely encapsulated by a single number. Using our formalism, we present several phenomenological studies that showcase how energy correlators can be used to probe transverse momentum dependent structures.	hep-ph	36 pages, 7 figures
1	Ages and metallicities of stellar clusters using S-PLUS narrow-band integrated photometry: the Small Magellanic Cloud	Gabriel Fabiano de Souza,Pieter Westera,Felipe Almeida-Fernandes,Guilherme Limberg,Bruno Dias,Jos√© A. Hernandez-Jimenez,F√°bio R. Herpich,Leandro O. Kerber,Eduardo Machado-Pereira,H√©lio D. Perottoni,Rafael Guer√ßo,Liana Li,Laura Sampedro,Antonio Kanaan,Tiago Ribeiro,William Schoenell,Claudia Mendes de Oliveira	The Magellanic Clouds are the most massive and closest satellite galaxies of the Milky Way, with stars covering ages from a few Myr up to 13 Gyr. This makes them important for validating integrated light methods to study stellar populations and star-formation processes, which can be applied to more distant galaxies. We characterized a set of stellar clusters in the Small Magellanic Cloud (SMC), using the $\textit{Southern Photometric Local Universe Survey}$. This is the first age (metallicity) determination for 11 (65) clusters of this sample. Through its 7 narrow bands, centered on important spectral features, and 5 broad bands, we can retrieve detailed information about stellar populations. We obtained ages and metallicities for all stellar clusters using the Bayesian spectral energy distribution fitting code $\texttt{BAGPIPES}$. With a sample of clusters in the color range $-0.20 < r-z < +0.35$, for which our determined parameters are most reliable, we modeled the age-metallicity relation of SMC. At any given age, the metallicities of SMC clusters are lower than those of both the Gaia Sausage-Enceladus disrupted dwarf galaxy and the Milky Way. In comparison with literature values, differences are $\Delta$log(age)$\approx0.31$ and $\Delta$[Fe/H]$\approx0.41$, which is comparable to low-resolution spectroscopy of individual stars. Finally, we confirm a previously known gradient, with younger clusters in the center and older ones preferentially located in the outermost regions. On the other hand, we found no evidence of a significant metallicity gradient.	astro-ph.GA	Accepted to MNRAS. 12 pages, 11 figures
2	A Realist Interpretation of Unitarity in Quantum Gravity	Indrajit Sen,Stephon Alexander,Justin Dressel	Unitarity is a difficult concept to implement in canonical quantum gravity because of state non-normalizability and the problem of time. In this work, we take a realist approach based on pilot-wave theory to address this issue in the Ashtekar formulation of the Wheeler-de Witt equation. We use the postulate of a definite configuration in the theory to define a global time for the gravitational-fermionic system recently discussed in (Phys. Rev. D 106.10 (2022): 106012), by parameterizing a variation of a Weyl-spinor that depends on the Kodama state. The total Hamiltonian constraint yields a time-dependent Schrodinger equation, without semi-classical approximations, which we use to derive a local continuity equation over the configuration space. We implement the reality conditions at the level of the guidance equation, and obtain a real spin-connection, extrinsic curvature and triad along the system trajectory. The non-normalizable Kodama state is naturally factored out of the full quantum state in the conserved current density, opening the possibility for quantum-mechanical unitarity. We also give a pilot-wave generalisation of the notion of unitarity applicable to non-normalizable states, and show the existence of equilibrium density for our system. Lastly, we find unitary states in mini-superspace by finding an approximate solution to the Hamiltonian constraint.	gr-qc	Comments welcomed
3	Linear Representations of Sentiment in Large Language Models	Curt Tigges,Oskar John Hollinsworth,Atticus Geiger,Neel Nanda	Sentiment is a pervasive feature in natural language text, yet it is an open question how sentiment is represented within Large Language Models (LLMs). In this study, we reveal that across a range of models, sentiment is represented linearly: a single direction in activation space mostly captures the feature across a range of tasks with one extreme for positive and the other for negative. Through causal interventions, we isolate this direction and show it is causally relevant in both toy tasks and real world datasets such as Stanford Sentiment Treebank. Through this case study we model a thorough investigation of what a single direction means on a broad data distribution.   We further uncover the mechanisms that involve this direction, highlighting the roles of a small subset of attention heads and neurons. Finally, we discover a phenomenon which we term the summarization motif: sentiment is not solely represented on emotionally charged words, but is additionally summarized at intermediate positions without inherent sentiment, such as punctuation and names. We show that in Stanford Sentiment Treebank zero-shot classification, 76% of above-chance classification accuracy is lost when ablating the sentiment direction, nearly half of which (36%) is due to ablating the summarized sentiment direction exclusively at comma positions.	cs.LG	None
4	Accelerate Microstructure Evolution Simulation Using Graph Neural Networks with Adaptive Spatiotemporal Resolution	Shaoxun Fan,Andrew L. Hitt,Ming Tang,Babak Sadigh,Fei Zhou	Surrogate models driven by sizeable datasets and scientific machine-learning methods have emerged as an attractive microstructure simulation tool with the potential to deliver predictive microstructure evolution dynamics with huge savings in computational costs. Taking 2D and 3D grain growth simulations as an example, we present a completely overhauled computational framework based on graph neural networks with not only excellent agreement to both the ground truth phase-field methods and theoretical predictions, but enhanced accuracy and efficiency compared to previous works based on convolutional neural networks. These improvements can be attributed to the graph representation, both improved predictive power and a more flexible data structure amenable to adaptive mesh refinement. As the simulated microstructures coarsen, our method can adaptively adopt remeshed grids and larger timesteps to achieve further speedup. The data-to-model pipeline with training procedures together with the source codes are provided.	cond-mat.mtrl-sci	28 pages, 11 figures
5	Function Vectors in Large Language Models	Eric Todd,Millicent L. Li,Arnab Sen Sharma,Aaron Mueller,Byron C. Wallace,David Bau	We report the presence of a simple neural mechanism that represents an input-output function as a vector within autoregressive transformer language models (LMs). Using causal mediation analysis on a diverse range of in-context-learning (ICL) tasks, we find that a small number attention heads transport a compact representation of the demonstrated task, which we call a function vector (FV). FVs are robust to changes in context, i.e., they trigger execution of the task on inputs such as zero-shot and natural text settings that do not resemble the ICL contexts from which they are collected. We test FVs across a range of tasks, models, and layers and find strong causal effects across settings in middle layers. We investigate the internal structure of FVs and find while that they often contain information that encodes the output space of the function, this information alone is not sufficient to reconstruct an FV. Finally, we test semantic vector composition in FVs, and find that to some extent they can be summed to create vectors that trigger new complex tasks. Taken together, our findings suggest that LLMs contain internal abstractions of general-purpose functions that can be invoked in a variety of contexts.	cs.CL	43 pages, 25 figures, 20 tables, Code and data at   https://functions.baulab.info
6	Verb Conjugation in Transformers Is Determined by Linear Encodings of Subject Number	Sophie Hao,Tal Linzen	"Deep architectures such as Transformers are sometimes criticized for having uninterpretable ""black-box"" representations. We use causal intervention analysis to show that, in fact, some linguistic features are represented in a linear, interpretable format. Specifically, we show that BERT's ability to conjugate verbs relies on a linear encoding of subject number that can be manipulated with predictable effects on conjugation accuracy. This encoding is found in the subject position at the first layer and the verb position at the last layer, but distributed across positions at middle layers, particularly when there are multiple cues to subject number."	cs.CL	To appear in Findings of the Association for Computational   Linguistics: EMNLP 2023
7	Online Detection of AI-Generated Images	David C. Epstein,Ishan Jain,Oliver Wang,Richard Zhang	With advancements in AI-generated images coming on a continuous basis, it is increasingly difficult to distinguish traditionally-sourced images (e.g., photos, artwork) from AI-generated ones. Previous detection methods study the generalization from a single generator to another in isolation. However, in reality, new generators are released on a streaming basis. We study generalization in this setting, training on N models and testing on the next (N+k), following the historical release dates of well-known generation methods. Furthermore, images increasingly consist of both real and generated components, for example through image inpainting. Thus, we extend this approach to pixel prediction, demonstrating strong performance using automatically-generated inpainted data. In addition, for settings where commercial models are not publicly available for automatic data generation, we evaluate if pixel detectors can be trained solely on whole synthetic images.	cs.CV	ICCV DeepFake Analysis and Detection Workshop, 2023
8	Unlocking the Transferability of Tokens in Deep Models for Tabular Data	Qi-Le Zhou,Han-Jia Ye,Le-Ye Wang,De-Chuan Zhan	Fine-tuning a pre-trained deep neural network has become a successful paradigm in various machine learning tasks. However, such a paradigm becomes particularly challenging with tabular data when there are discrepancies between the feature sets of pre-trained models and the target tasks. In this paper, we propose TabToken, a method aims at enhancing the quality of feature tokens (i.e., embeddings of tabular features). TabToken allows for the utilization of pre-trained models when the upstream and downstream tasks share overlapping features, facilitating model fine-tuning even with limited training examples. Specifically, we introduce a contrastive objective that regularizes the tokens, capturing the semantics within and across features. During the pre-training stage, the tokens are learned jointly with top-layer deep models such as transformer. In the downstream task, tokens of the shared features are kept fixed while TabToken efficiently fine-tunes the remaining parts of the model. TabToken not only enables knowledge transfer from a pre-trained model to tasks with heterogeneous features, but also enhances the discriminative ability of deep tabular models in standard classification and regression tasks.	cs.LG	None
9	Physics informed neural networks learning a two-qubit Hamiltonian	Leonardo K. Castelano,Iann Cunha,Fabricio S. Luiz,Marcelo V. de Souza Prado,Felipe F. Fanchini	Machine learning techniques are employed to perform the full characterization of a quantum system. The particular artificial intelligence technique used to learn the Hamiltonian is called physics informed neural network (PINN). The idea behind PINN is the universal approximation theorem, which claims that any function can be approximate by a neural network if it contains enough complexity. Consequently, a neural network can be a solution of a physical model. Moreover, by means of extra data provided by the user, intrinsic physical parameters can be extracted from the approach called inverse-PINN. Here, we apply inverse-PINN with the goal of extracting all the physical parameters that constitutes a two qubit Hamiltonian. We find that this approach is very efficient. To probe the robustness of the inverse-PINN to learn the Hamiltonian of a two-qubit system, we use the IBM quantum computers as experimental platforms to obtain the data that is plugged in the PINN. We found that our method is able to predict the two-qubit parameters with 5% of accuracy on average.	quant-ph	5 pages, 4 figures
0	S3Eval: A Synthetic, Scalable, Systematic Evaluation Suite for Large Language Models	Fangyu Lei,Qian Liu,Yiming Huang,Shizhu He,Jun Zhao,Kang Liu	The rapid development of Large Language Models (LLMs) has led to great strides in model capabilities like reasoning and long-context understanding. However, as LLMs are able to process longer contexts, it becomes more challenging to evaluate whether they have acquired certain capabilities, since the length of text (e.g., 100K tokens) they can process far exceeds what humans can reliably assess in a reasonable duration. In this paper, we propose using complex synthetic tasks as a proxy evaluation method, and present S3Eval, a Synthetic, Scalable, Systematic evaluation suite for LLMs evaluation. As a synthetic benchmark, S3Eval enables the creation of any number of evaluation examples that are theoretically invisible to LLMs, mitigating the test set contamination issue. The synthetic nature of S3Eval provides users full control over the dataset, allowing them to systematically probe LLM capabilities by scaling text length and varying task difficulty across diverse scenarios. The strong correlation between S3Eval performance and scores of real-world benchmarks like Big-Bench Hard (BBH) demonstrates the soundness of using S3Eval for evaluation of LLMs. The in-depth analysis also uncover additional insights, including performance drop when the answer is sparsely distributed or located in the middle context, as well as some counter-intuitive trends of model performance.	cs.CL	Work in progress
1	When Should the FDA Inspect Pharmaceutical Manufacturing Facilities to Better Mitigate Drug Shortages?	Daniel Kosmas,√ñzlem Ergun	Drug shortages have been a persistent problem in American healthcare for decades, and the resulting lack of access to necessary drugs has been disastrous to patient health. A majority of these shortages were caused by quality issues related to problems in the manufacturing process. More frequent inspections can reduce quality concerns, but deciding when to inspect is a complex problem; strict regulation enforcement can force low-profit facilities to close due to excessive maintenance costs, while lax enforcement allows for regulation violations to persist, both of which can cause drug shortages. We propose a novel model to assist the FDA in determining when to inspect manufacturing facilities. We formulate this problem as a finite-horizon partially observable Markov decision process (POMDP) based on the classifications the FDA assigns to each facility after inspection, as well two disruptive events: a manufacturing failure occurring or the facility closing for non-mandatory maintenance. We theoretically show that this problem can be reduced to only needing to consider whether or not to inspect immediately, which is independent of the time horizon. We additionally determine the sensitivity of the optimal inspection time on the penalty incurred for an unexpected disruptive event occurring. Our computational study demonstrates a quadratic relationship between the relative difference in average value accumulated between inspecting based on the optimal inspection time produced by our model and inspecting based on the expected time to an unexpected disruptive event, highlighting the importance of allocating more inspection resources to high-risk facilities that produce drugs that highly impact public health. We additionally find that optimal inspection time is more sensitive to changes in the penalty incurred from a disruptive event occurring the longer it has been since the last inspection.	math.OC	None
2	Robot Fine-Tuning Made Easy: Pre-Training Rewards and Policies for Autonomous Real-World Reinforcement Learning	Jingyun Yang,Max Sobol Mark,Brandon Vu,Archit Sharma,Jeannette Bohg,Chelsea Finn	The pre-train and fine-tune paradigm in machine learning has had dramatic success in a wide range of domains because the use of existing data or pre-trained models on the internet enables quick and easy learning of new tasks. We aim to enable this paradigm in robotic reinforcement learning, allowing a robot to learn a new task with little human effort by leveraging data and models from the Internet. However, reinforcement learning often requires significant human effort in the form of manual reward specification or environment resets, even if the policy is pre-trained. We introduce RoboFuME, a reset-free fine-tuning system that pre-trains a multi-task manipulation policy from diverse datasets of prior experiences and self-improves online to learn a target task with minimal human intervention. Our insights are to utilize calibrated offline reinforcement learning techniques to ensure efficient online fine-tuning of a pre-trained policy in the presence of distribution shifts and leverage pre-trained vision language models (VLMs) to build a robust reward classifier for autonomously providing reward signals during the online fine-tuning process. In a diverse set of five real robot manipulation tasks, we show that our method can incorporate data from an existing robot dataset collected at a different institution and improve on a target task within as little as 3 hours of autonomous real-world experience. We also demonstrate in simulation experiments that our method outperforms prior works that use different RL algorithms or different approaches for predicting rewards. Project website: https://robofume.github.io	cs.RO	None
3	DEsignBench: Exploring and Benchmarking DALL-E 3 for Imagining Visual Design	Kevin Lin,Zhengyuan Yang,Linjie Li,Jianfeng Wang,Lijuan Wang	"We introduce DEsignBench, a text-to-image (T2I) generation benchmark tailored for visual design scenarios. Recent T2I models like DALL-E 3 and others, have demonstrated remarkable capabilities in generating photorealistic images that align closely with textual inputs. While the allure of creating visually captivating images is undeniable, our emphasis extends beyond mere aesthetic pleasure. We aim to investigate the potential of using these powerful models in authentic design contexts. In pursuit of this goal, we develop DEsignBench, which incorporates test samples designed to assess T2I models on both ""design technical capability"" and ""design application scenario."" Each of these two dimensions is supported by a diverse set of specific design categories. We explore DALL-E 3 together with other leading T2I models on DEsignBench, resulting in a comprehensive visual gallery for side-by-side comparisons. For DEsignBench benchmarking, we perform human evaluations on generated images in DEsignBench gallery, against the criteria of image-text alignment, visual aesthetic, and design creativity. Our evaluation also considers other specialized design capabilities, including text rendering, layout composition, color harmony, 3D design, and medium style. In addition to human evaluations, we introduce the first automatic image generation evaluator powered by GPT-4V. This evaluator provides ratings that align well with human judgments, while being easily replicable and cost-efficient. A high-resolution version is available at https://github.com/design-bench/design-bench.github.io/raw/main/designbench.pdf?download="	cs.CV	Project page at https://design-bench.github.io/
4	Hyperparameter optimization of hp-greedy reduced basis for gravitational wave surrogates	Franco Cerino,Andr√©s Diaz-Pace,Emmanuel Tassone,Manuel Tiglio,Atuel Villegas	In a previous work we introduced, in the context of gravitational wave science, an initial study on an automated domain-decomposition approach for reduced basis through hp-greedy refinement. The approach constructs local reduced bases of lower dimensionality than global ones, with the same or higher accuracy. These ``light'' local bases should imply both faster evaluations when predicting new waveforms and faster data analysis, in particular faster statistical inference (the forward and inverse problems, respectively). In this approach, however, we have previously found important dependence on several hyperparameters, which do not appear in global reduced basis. This naturally leads to the problem of hyperparameter optimization (HPO), which is the subject of this paper. We tackle the problem through a Bayesian optimization, and show its superiority when compared to grid or random searches. We find that for gravitational waves from the collision of two spinning but non-precessing black holes, for the same accuracy, local hp-greedy reduced bases with HPO have a lower dimensionality of up to $4 \times$ for the cases here studied, depending on the desired accuracy. This factor should directly translate in a parameter estimation speedup, for instance. Such acceleration might help in the near real-time requirements for electromagnetic counterparts of gravitational waves from compact binary coalescences. In addition, we find that the Bayesian approach used in this paper for HPO is two orders of magnitude faster than, for example, a grid search, with about a $100 \times$ acceleration. The code developed for this project is available as open source from public repositories.	gr-qc	"This paper is an invited contribution to the Special Issue ""Recent   Advances in Gravity: A Themed Issue in Honor of Prof. Jorge Pullin on his   60th Anniversary''"
5	SpecTr: Fast Speculative Decoding via Optimal Transport	Ziteng Sun,Ananda Theertha Suresh,Jae Hun Ro,Ahmad Beirami,Himanshu Jain,Felix Yu	Autoregressive sampling from large language models has led to state-of-the-art results in several natural language tasks. However, autoregressive sampling generates tokens one at a time making it slow, and even prohibitive in certain tasks. One way to speed up sampling is $\textit{speculative decoding}$: use a small model to sample a $\textit{draft}$ (block or sequence of tokens), and then score all tokens in the draft by the large language model in parallel. A subset of the tokens in the draft are accepted (and the rest rejected) based on a statistical method to guarantee that the final output follows the distribution of the large model. In this work, we provide a principled understanding of speculative decoding through the lens of optimal transport (OT) with $\textit{membership cost}$. This framework can be viewed as an extension of the well-known $\textit{maximal-coupling}$ problem. This new formulation enables us to generalize the speculative decoding method to allow for a set of $k$ candidates at the token-level, which leads to an improved optimal membership cost. We show that the optimal draft selection algorithm (transport plan) can be computed via linear programming, whose best-known runtime is exponential in $k$. We then propose a valid draft selection algorithm whose acceptance probability is $(1-1/e)$-optimal multiplicatively. Moreover, it can be computed in time almost linear with size of domain of a single token. Using this $new draft selection$ algorithm, we develop a new autoregressive sampling algorithm called $\textit{SpecTr}$, which provides speedup in decoding while ensuring that there is no quality degradation in the decoded output. We experimentally demonstrate that for state-of-the-art large language models, the proposed approach achieves a wall clock speedup of 2.13X, a further 1.37X speedup over speculative decoding on standard benchmarks.	cs.LG	None
6	AutoDAN: Automatic and Interpretable Adversarial Attacks on Large Language Models	Sicheng Zhu,Ruiyi Zhang,Bang An,Gang Wu,Joe Barrow,Zichao Wang,Furong Huang,Ani Nenkova,Tong Sun	Safety alignment of Large Language Models (LLMs) can be compromised with manual jailbreak attacks and (automatic) adversarial attacks. Recent work suggests that patching LLMs against these attacks is possible: manual jailbreak attacks are human-readable but often limited and public, making them easy to block; adversarial attacks generate gibberish prompts that can be detected using perplexity-based filters. In this paper, we show that these solutions may be too optimistic. We propose an interpretable adversarial attack, \texttt{AutoDAN}, that combines the strengths of both types of attacks. It automatically generates attack prompts that bypass perplexity-based filters while maintaining a high attack success rate like manual jailbreak attacks. These prompts are interpretable and diverse, exhibiting strategies commonly used in manual jailbreak attacks, and transfer better than their non-readable counterparts when using limited training data or a single proxy model. We also customize \texttt{AutoDAN}'s objective to leak system prompts, another jailbreak application not addressed in the adversarial attack literature. Our work provides a new way to red-team LLMs and to understand the mechanism of jailbreak attacks.	cs.CR	None
7	(Quantum) discreteness, spectrum compactness and uniform continuity	Alexandru Chirvasitu	We prove a number of results linking properties of actions by compact groups (both quantum and classical) on Banach spaces, such as uniform continuity, spectrum finiteness and extensibility of the actions across several constructions. Examples include: (a) a unitary representation of a compact quantum group induces a continuous action on the $C^*$-algebra of bounded operators if and only if it has finitely many isotypic components, and hence is uniformly continuous; (b) a compact quantum group is finite if and only if its continuous actions on $C^*$-algebras lift to continuous actions on either the multiplier algebras or von Neumann envelopes thereof; (c) a (classical) locally compact group $\mathbb{G}$ is discrete if and only if the forgetful functor from $\mathbb{G}$-acted-upon compact $T_2$ spaces back to compact $T_2$ spaces creates coproducts; (d) a representation of a linearly reductive quantum group has finitely many isotypic components if and only if its restrictions to two topologically-generating quantum subgroups, one of which is normal, do; (e) equivalent characterizations of uniform continuity for actions of compact groups on Banach spaces, e.g. that such an action is uniformly continuous if and only if its restrictions to a pro-torus and to pro-$p$ subgroups are.	math.OA	20 pages + references
8	Factorial growth at low orders in perturbative~QCD: Control over truncation uncertainties	Andreas S. Kronfeld	A method, known as ``minimal renormalon subtraction'' [Phys. Rev. D 97 (2018) 034503, JHEP 2017 (2017) 62], relates the factorial growth of a perturbative series (in QCD) to the power~$p$ of a power correction $\Lambda^p/Q^p$. ($\Lambda$ is the QCD scale, $Q$ some hard scale.) Here, the derivation is simplified and generalized to any~$p$, more than one such correction, and cases with anomalous dimensions. Strikingly, the well-known factorial growth is seen to emerge already at low or medium orders, as a consequence of constraints on the $Q$ dependence from the renormalization group. The effectiveness of the method is studied with the gluonic energy between a static quark and static antiquark (the ``static energy''). Truncation uncertainties are found to be under control after next-to-leading order, despite the small exponent of the power correction ($p=1$) and associated rapid growth seen in the first four coefficients of the perturbative series.	hep-ph	25 pp + title page, 8 figures
9	$B \to K ŒΩ\barŒΩ$, MiniBooNE and muon $g-2$ anomalies from a dark sector	Alakabha Datta,Danny Marfatia,Lopamudra Mukherjee	Belle II has reported the first evidence for $B^+ \to K^+\nu\bar\nu$ with a branching ratio $2.8 \sigma$ higher than the standard model expectation. We explain this, and the MiniBooNE and muon anomalous magnetic moment anomalies in a model with a dark scalar that couples to a slightly heavier sterile Dirac neutrino and that communicates with the visible sector via a Higgs portal. We make predictions for rare kaon and other $B$ meson decays.	hep-ph	9 pages, 3 figures, 3 tables
0	Quantifying the Dialect Gap and its Correlates Across Languages	Anjali Kantharuban,Ivan Vuliƒá,Anna Korhonen	Historically, researchers and consumers have noticed a decrease in quality when applying NLP tools to minority variants of languages (i.e. Puerto Rican Spanish or Swiss German), but studies exploring this have been limited to a select few languages. Additionally, past studies have mainly been conducted in a monolingual context, so cross-linguistic trends have not been identified and tied to external factors. In this work, we conduct a comprehensive evaluation of the most influential, state-of-the-art large language models (LLMs) across two high-use applications, machine translation and automatic speech recognition, to assess their functionality on the regional dialects of several high- and low-resource languages. Additionally, we analyze how the regional dialect gap is correlated with economic, social, and linguistic factors. The impact of training data, including related factors like dataset size and its construction procedure, is shown to be significant but not consistent across models or languages, meaning a one-size-fits-all approach cannot be taken in solving the dialect gap. This work will lay the foundation for furthering the field of dialectal NLP by laying out evident disparities and identifying possible pathways for addressing them through mindful data collection.	cs.CL	Accepted to EMNLP Findings 2023
1	Marginal perturbation theory of integrable XXX critical spin chains revisited: renormalon and power correction	Yizhuang Liu	In this work, inspired by recent work on resurgence of 2D integrable QFTs in the UV limit, we investigate the marginal perturbation theory of integrable critical spin chains for the small external field limit $h\rightarrow 0$ of the ground state energy. Starting from the Bethe equation, we generate the perturbative series in a natural running coupling constant and study its renormalon ambiguity/power correction. We found that for $s=\frac{1}{2}$, the perturbative series relates to the $\beta^2=8\pi^-$ sine-Gordon bootstrap theory with a sign flip of the coupling constant. On the other hand, for $s>1$, the leading singularity in the Borel plane is located at $t=\frac{1}{s}$ and generates fractional power corrections of the form $h^{\frac{2}{s}}$.	hep-th	16 pages. v^4 results added
2	Viability under Degraded Control Authority	Hamza El-Kebir,Richard Berlin,Joseph Bentsman,Melkior Ornik	In this work, we solve the problem of quantifying and mitigating control authority degradation in real time. Here, our target systems are controlled nonlinear affine-in-control evolution equations with finite control input and finite- or infinite-dimensional state. We consider two cases of control input degradation: finitely many affine maps acting on unknown disjoint subsets of the inputs and general Lipschitz continuous maps. These degradation modes are encountered in practice due to actuator wear and tear, hard locks on actuator ranges due to over-excitation, as well as more general changes in the control allocation dynamics. We derive sufficient conditions for identifiability of control authority degradation, and propose a novel real-time algorithm for identifying or approximating control degradation modes. We demonstrate our method on a nonlinear distributed parameter system, namely a one-dimensional heat equation with a velocity-controlled moveable heat source, motivated by autonomous energy-based surgery.	eess.SY	Submitted to the American Control Conference 2024 and IEEE Control   Systems Letters
3	Rothman diagrams: the geometry of causal inference in epidemiology	Eben Kenah	Here, we explain and illustrate a geometric perspective on causal inference in cohort studies that can help epidemiologists understand the role of standardization in causal inference as well as the distinctions between confounding, effect modification, and noncollapsibility. For simplicity, we focus on a binary exposure X, a binary outcome D, and a binary confounder C that is not causally affected by X. Rothman diagrams plot risk in the unexposed on the x-axis and risk in the exposed on the y-axis. The crude risks define one point in the unit square, and the stratum-specific risks define two other points in the unit square. These three points can be used to identify confounding and effect modification, and we show briefly how these concepts generalize to confounders with more than two levels. We propose a simplified but equivalent definition of collapsibility in terms of standardization, and we show that a measure of association is collapsible if and only if all of its contour lines are straight. We illustrate these ideas using data from a study conducted in Newcastle upon Tyne, United Kingdom, where the causal effect of smoking on 20-year mortality was confounded by age. We conclude that causal inference should be taught using geometry before using regression models.	math.ST	22 pages, 7 figures
4	Novel-View Acoustic Synthesis from 3D Reconstructed Rooms	Byeongjoo Ahn,Karren Yang,Brian Hamilton,Jonathan Sheaffer,Anurag Ranjan,Miguel Sarabia,Oncel Tuzel,Jen-Hao Rick Chang	We investigate the benefit of combining blind audio recordings with 3D scene information for novel-view acoustic synthesis. Given audio recordings from 2-4 microphones and the 3D geometry and material of a scene containing multiple unknown sound sources, we estimate the sound anywhere in the scene. We identify the main challenges of novel-view acoustic synthesis as sound source localization, separation, and dereverberation. While naively training an end-to-end network fails to produce high-quality results, we show that incorporating room impulse responses (RIRs) derived from 3D reconstructed rooms enables the same network to jointly tackle these tasks. Our method outperforms existing methods designed for the individual tasks, demonstrating its effectiveness at utilizing 3D visual information. In a simulated study on the Matterport3D-NVAS dataset, our model achieves near-perfect accuracy on source localization, a PSNR of 26.44 dB and a SDR of 14.23 dB for source separation and dereverberation, resulting in a PSNR of 25.55 dB and a SDR of 14.20 dB on novel-view acoustic synthesis. Code, pretrained model, and video results are available on the project webpage (https://github.com/apple/ml-nvas3d).	cs.SD	None
5	Location-Aware Visual Question Generation with Lightweight Models	Nicholas Collin Suwono,Justin Chih-Yao Chen,Tun Min Hung,Ting-Hao Kenneth Huang,I-Bin Liao,Yung-Hui Li,Lun-Wei Ku,Shao-Hua Sun	This work introduces a novel task, location-aware visual question generation (LocaVQG), which aims to generate engaging questions from data relevant to a particular geographical location. Specifically, we represent such location-aware information with surrounding images and a GPS coordinate. To tackle this task, we present a dataset generation pipeline that leverages GPT-4 to produce diverse and sophisticated questions. Then, we aim to learn a lightweight model that can address the LocaVQG task and fit on an edge device, such as a mobile phone. To this end, we propose a method which can reliably generate engaging questions from location-aware information. Our proposed method outperforms baselines regarding human evaluation (e.g., engagement, grounding, coherence) and automatic evaluation metrics (e.g., BERTScore, ROUGE-2). Moreover, we conduct extensive ablation studies to justify our proposed techniques for both generating the dataset and solving the task.	cs.CL	EMNLP 2023
6	Projected Stochastic Gradient Descent with Quantum Annealed Binary Gradients	Maximilian Krahn,Michelle Sasdelli,Fengyi Yang,Vladislav Golyanik,Juho Kannala,Tat-Jun Chin,Tolga Birdal	We present, QP-SBGD, a novel layer-wise stochastic optimiser tailored towards training neural networks with binary weights, known as binary neural networks (BNNs), on quantum hardware. BNNs reduce the computational requirements and energy consumption of deep learning models with minimal loss in accuracy. However, training them in practice remains to be an open challenge. Most known BNN-optimisers either rely on projected updates or binarise weights post-training. Instead, QP-SBGD approximately maps the gradient onto binary variables, by solving a quadratic constrained binary optimisation. Under practically reasonable assumptions, we show that this update rule converges with a rate of $\mathcal{O}(1 / \sqrt{T})$. Moreover, we show how the $\mathcal{NP}$-hard projection can be effectively executed on an adiabatic quantum annealer, harnessing recent advancements in quantum computation. We also introduce a projected version of this update rule and prove that if a fixed point exists in the binary variable space, the modified updates will converge to it. Last but not least, our algorithm is implemented layer-wise, making it suitable to train larger networks on resource-limited quantum hardware. Through extensive evaluations, we show that QP-SBGD outperforms or is on par with competitive and well-established baselines such as BinaryConnect, signSGD and ProxQuant when optimising the Rosenbrock function, training BNNs as well as binary graph neural networks.	cs.CV	None
7	Open-Ended Instructable Embodied Agents with Memory-Augmented Large Language Models	Gabriel Sarch,Yue Wu,Michael J. Tarr,Katerina Fragkiadaki	Pre-trained and frozen LLMs can effectively map simple scene re-arrangement instructions to programs over a robot's visuomotor functions through appropriate few-shot example prompting. To parse open-domain natural language and adapt to a user's idiosyncratic procedures, not known during prompt engineering time, fixed prompts fall short. In this paper, we introduce HELPER, an embodied agent equipped with an external memory of language-program pairs that parses free-form human-robot dialogue into action programs through retrieval-augmented LLM prompting: relevant memories are retrieved based on the current dialogue, instruction, correction or VLM description, and used as in-context prompt examples for LLM querying. The memory is expanded during deployment to include pairs of user's language and action plans, to assist future inferences and personalize them to the user's language and routines. HELPER sets a new state-of-the-art in the TEACh benchmark in both Execution from Dialog History (EDH) and Trajectory from Dialogue (TfD), with 1.7x improvement over the previous SOTA for TfD. Our models, code and video results can be found in our project's website: https://helper-agent-llm.github.io.	cs.AI	https://helper-agent-llm.github.io
8	Mixed-Variable Global Sensitivity Analysis For Knowledge Discovery And Efficient Combinatorial Materials Design	Yigitcan Comlek,Liwei Wang,Wei Chen	Global Sensitivity Analysis (GSA) is the study of the influence of any given inputs on the outputs of a model. In the context of engineering design, GSA has been widely used to understand both individual and collective contributions of design variables on the design objectives. So far, global sensitivity studies have often been limited to design spaces with only quantitative (numerical) design variables. However, many engineering systems also contain, if not only, qualitative (categorical) design variables in addition to quantitative design variables. In this paper, we integrate Latent Variable Gaussian Process (LVGP) with Sobol' analysis to develop the first metamodel-based mixed-variable GSA method. Through numerical case studies, we validate and demonstrate the effectiveness of our proposed method for mixed-variable problems. Furthermore, while the proposed GSA method is general enough to benefit various engineering design applications, we integrate it with multi-objective Bayesian optimization (BO) to create a sensitivity-aware design framework in accelerating the Pareto front design exploration for metal-organic framework (MOF) materials with many-level combinatorial design spaces. Although MOFs are constructed only from qualitative variables that are notoriously difficult to design, our method can utilize sensitivity analysis to navigate the optimization in the many-level large combinatorial design space, greatly expediting the exploration of novel MOF candidates.	stat.ML	35 Pages, 10 Figures, 2 Tables
9	Branch-Solve-Merge Improves Large Language Model Evaluation and Generation	Swarnadeep Saha,Omer Levy,Asli Celikyilmaz,Mohit Bansal,Jason Weston,Xian Li	Large Language Models (LLMs) are frequently used for multi-faceted language generation and evaluation tasks that involve satisfying intricate user constraints or taking into account multiple aspects and criteria. However, their performance can fall short, due to the model's lack of coherence and inability to plan and decompose the problem. We propose Branch-Solve-Merge (BSM), a Large Language Model program (Schlag et al., 2023) for tackling such challenging natural language tasks. It consists of branch, solve, and merge modules that are parameterized with specific prompts to the base LLM. These three modules plan a decomposition of the task into multiple parallel sub-tasks, independently solve them, and fuse the solutions to the sub-tasks. We apply our method to the tasks of LLM response evaluation and constrained text generation and evaluate its effectiveness with multiple LLMs, including Vicuna, LLaMA-2-chat, and GPT-4. BSM improves the evaluation correctness and consistency for each LLM by enhancing human-LLM agreement by up to 26%, reducing length and pairwise position biases by up to 50%, and allowing LLaMA-2-chat to match or outperform GPT-4 on most domains. On the constraint story generation task, BSM improves the coherence of the stories while also improving constraint satisfaction by 12%.	cs.CL	22 pages, 7 figures, 10 tables
0	A Reactive Molecular Dynamics Model for Uranium-Hydrogen Containing Systems	A. Soshnikov,R. K. Lindsey,A. Kulkarni,N. Goldman	Uranium-based materials are valuable assets in the energy, medical, and military industries. However, understanding their sensitivity to hydrogen embrittlement is particularly challenging due to the toxicity of uranium and computationally expensive nature of the quantum-based methods generally required to study such processes. In this regard, we have developed a Chebyshev Interaction Model for Efficient Simulation (ChIMES) model that can be employed to compute energies and forces of U and UH3 bulk structures with vacancies and hydrogen interstitials with similar accuracy to Density Functional Theory (DFT) while yielding linear scaling and orders of magnitude improvement in computational efficiency. We show that that the bulk structural parameters, uranium and hydrogen vacancy formation energies, and diffusion barriers predicted by the ChIMES potential are in strong agreement with the reference DFT data. We then use ChIMES to conduct molecular dynamics simulations of the temperature-dependent diffusion of a hydrogen interstitial and determine the corresponding diffusion activation energy. Our model has particular significance in studies of actinides and other high-Z materials, where there is a strong need for computationally efficient methods to bridge length and time scales between experiments and quantum theory.	cond-mat.mtrl-sci	Reactive molecular dynamics model for U/H systems based on the ChIMES   reactive force field
1	Crystal Facet Effect in Plasmonic Catalysis	Yicui Kang,Sim√£o M. Jo√£o,Rui Lin,Li Zhu,Junwei Fu,Weng-Chon,Cheong,Seunghoon Lee,Kilian Frank,Bert Nickel,Min Liu,Johannes Lischner,Emiliano Cort√©s	In the realm of plasmonic catalytic systems, much attention has been devoted to the plasmon-derived mechanisms, yet the influence of nanoparticles' crystal facets in this type of processes has been sparsely investigated. In this work, we study the plasmon-assisted electrocatalytic CO2 reduction reaction using three different shapes of plasmonic Au nanoparticles - nanocube (NC), rhombic dodecahedron (RD) and octahedron (OC) - with three different exposed facets: {100}, {110} and {111}, respectively. These particles were synthesized with similar sizes and LSPR wavelengths to reveal the role of the facet more than other contributions to the plasmon-assisted reaction. Upon plasmon excitation, Au OCs exhibited nearly a doubling in the Faradaic efficiency of CO (FE(CO)) and a remarkable threefold enhancement in the partial current density of CO (j(CO)) compared to the non-illuminated response, NCs also demonstrated an improved performance under illumination. In contrast, Au RDs showed nearly the same performance in dark or light conditions. Temperature-dependent experiments ruled out heat as the main factor in the enhanced response of Au OCs and NCs. Large-scale atomistic simulations of the nanoparticles' electronic structure and electromagnetic modeling revealed higher hot carrier abundance and electric field enhancement on Au OCs and NCs compared to RDs. Abundant hot carriers on edges facilitate molecular activation, leading to enhanced selectivity and activity. Thus, OCs with the highest edge/facet ratio exhibited the strongest enhancement in FE(CO) and j(CO) upon illumination. This observation is further supported by plasmon-assisted H2 evolution reaction experiments. Our findings highlight the dominance of low coordinated sites over facets in plasmonic catalytic processes, providing valuable insights for designing more efficient catalysts for solar fuels production.	physics.optics	None
2	Modeling Path Importance for Effective Alzheimer's Disease Drug Repurposing	Shunian Xiang,Patrick J. Lawrence,Bo Peng,ChienWei Chiang PhD,Dokyoon Kim PhD,Li Shen PhD,Xia Ning	Recently, drug repurposing has emerged as an effective and resource-efficient paradigm for AD drug discovery. Among various methods for drug repurposing, network-based methods have shown promising results as they are capable of leveraging complex networks that integrate multiple interaction types, such as protein-protein interactions, to more effectively identify candidate drugs. However, existing approaches typically assume paths of the same length in the network have equal importance in identifying the therapeutic effect of drugs. Other domains have found that same length paths do not necessarily have the same importance. Thus, relying on this assumption may be deleterious to drug repurposing attempts. In this work, we propose MPI (Modeling Path Importance), a novel network-based method for AD drug repurposing. MPI is unique in that it prioritizes important paths via learned node embeddings, which can effectively capture a network's rich structural information. Thus, leveraging learned embeddings allows MPI to effectively differentiate the importance among paths. We evaluate MPI against a commonly used baseline method that identifies anti-AD drug candidates primarily based on the shortest paths between drugs and AD in the network. We observe that among the top-50 ranked drugs, MPI prioritizes 20.0% more drugs with anti-AD evidence compared to the baseline. Finally, Cox proportional-hazard models produced from insurance claims data aid us in identifying the use of etodolac, nicotine, and BBB-crossing ACE-INHs as having a reduced risk of AD, suggesting such drugs may be viable candidates for repurposing and should be explored further in future studies.	q-bio.QM	16 pages, 3 figures, 2 tables, 1 supplementary figure, 5   supplementary tables, Preprint of an article accepted for publication in   Pacific Symposium on Biocomputing \c{opyright} 2023 World Scientific   Publishing Co., Singapore, http://psb.stanford.edu/
3	Causal Inference Using LLM-Guided Discovery	Aniket Vashishtha,Abbavaram Gowtham Reddy,Abhinav Kumar,Saketh Bachu,Vineeth N Balasubramanian,Amit Sharma	At the core of causal inference lies the challenge of determining reliable causal graphs solely based on observational data. Since the well-known backdoor criterion depends on the graph, any errors in the graph can propagate downstream to effect inference. In this work, we initially show that complete graph information is not necessary for causal effect inference; the topological order over graph variables (causal order) alone suffices. Further, given a node pair, causal order is easier to elicit from domain experts compared to graph edges since determining the existence of an edge can depend extensively on other variables. Interestingly, we find that the same principle holds for Large Language Models (LLMs) such as GPT-3.5-turbo and GPT-4, motivating an automated method to obtain causal order (and hence causal effect) with LLMs acting as virtual domain experts. To this end, we employ different prompting strategies and contextual cues to propose a robust technique of obtaining causal order from LLMs. Acknowledging LLMs' limitations, we also study possible techniques to integrate LLMs with established causal discovery algorithms, including constraint-based and score-based methods, to enhance their performance. Extensive experiments demonstrate that our approach significantly improves causal ordering accuracy as compared to discovery algorithms, highlighting the potential of LLMs to enhance causal inference across diverse fields.	cs.AI	None
4	Hermite-Pad√© approximation, multiple orthogonal polynomials, and multidimensional Toda equations	Adam Doliwa	We review recent results on the connection between Hermite-Pad\'e approximation problem, multiple orthogonal polynomials, and multidimensional Toda equations in continuous and discrete time. In order to motivate interest in the subject we first present a pedagogical introduction to the classical, by now, relation between the Pad\'e approximation problem, orthogonal polynomials, and the Toda lattice equations. We describe also briefly generalization of the connection to the interpolation problems and to the non-commutative algebra level.	nlin.SI	22 pages, XL Workshop on Geometric Methods in Physics,   Bia{\l}owie\.za 2023
5	How To Build Competitive Multi-gender Speech Translation Models For Controlling Speaker Gender Translation	Marco Gaido,Dennis Fucci,Matteo Negri,Luisa Bentivogli	"When translating from notional gender languages (e.g., English) into grammatical gender languages (e.g., Italian), the generated translation requires explicit gender assignments for various words, including those referring to the speaker. When the source sentence does not convey the speaker's gender, speech translation (ST) models either rely on the possibly-misleading vocal traits of the speaker or default to the masculine gender, the most frequent in existing training corpora. To avoid such biased and not inclusive behaviors, the gender assignment of speaker-related expressions should be guided by externally-provided metadata about the speaker's gender. While previous work has shown that the most effective solution is represented by separate, dedicated gender-specific models, the goal of this paper is to achieve the same results by integrating the speaker's gender metadata into a single ""multi-gender"" neural ST model, easier to maintain. Our experiments demonstrate that a single multi-gender model outperforms gender-specialized ones when trained from scratch (with gender accuracy gains up to 12.9 for feminine forms), while fine-tuning from existing ST models does not lead to competitive results."	cs.CL	To appear in CLiC-it 2023
